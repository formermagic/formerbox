 """ API ▁ for ▁ converting ▁ notebooks ▁ between ▁ versions. """  <newline>  # ▁ Copyright ▁ (c) ▁ IPython ▁ Development ▁ Team. <encdom>  # ▁ Distributed ▁ under ▁ the ▁ terms ▁ of ▁ the ▁ Modified ▁ BSD ▁ License. <encdom> from . import versions <newline> from . reader import get_version <newline> def convert ( nb , to_version ) : <newline> <indent>  """ Convert ▁ a ▁ notebook ▁ node ▁ object ▁ to ▁ a ▁ specific ▁ version. ▁ Assumes ▁ that <strnewline> ▁ all ▁ the ▁ versions ▁ starting ▁ from ▁ 1 ▁ to ▁ the ▁ latest ▁ major ▁ X ▁ are ▁ implemented. <strnewline> ▁ In ▁ other ▁ words, ▁ there ▁ should ▁ never ▁ be ▁ a ▁ case ▁ where ▁ v1 ▁ v2 ▁ v3 ▁ v5 ▁ exist ▁ without <strnewline> ▁ a ▁ v4. ▁ Also ▁ assumes ▁ that ▁ all ▁ conversions ▁ can ▁ be ▁ made ▁ in ▁ one ▁ step ▁ increments <strnewline> ▁ between ▁ major ▁ versions ▁ and ▁ ignores ▁ minor ▁ revisions. <strnewline> <strnewline> ▁ Parameters <strnewline> ▁ ----- <strnewline> ▁ nb ▁ : ▁ NotebookNode <strnewline> ▁ to_version ▁ : ▁ int <strnewline> ▁ Major ▁ revision ▁ to ▁ convert ▁ the ▁ notebook ▁ to. ▁ Can ▁ either ▁ be ▁ an ▁ upgrade ▁ or <strnewline> ▁ a ▁ downgrade. <strnewline> ▁ """  <newline>  # ▁ Get ▁ input ▁ notebook ▁ version. <encdom> ( version , version_minor ) = get_version ( nb ) <newline>  # ▁ Check ▁ if ▁ destination ▁ is ▁ target ▁ version, ▁ if ▁ so ▁ return ▁ contents <encdom> if version == to_version : <newline> <indent> return nb <newline>  # ▁ If ▁ the ▁ version ▁ exist, ▁ try ▁ to ▁ convert ▁ to ▁ it ▁ one ▁ step ▁ at ▁ a ▁ time. <encdom> <dedent> elif to_version in versions : <newline>  # ▁ Get ▁ the ▁ the ▁ version ▁ that ▁ this ▁ recursion ▁ will ▁ convert ▁ to ▁ as ▁ a ▁ step ▁ <encdom>  # ▁ closer ▁ to ▁ the ▁ final ▁ revision. ▁ Make ▁ sure ▁ the ▁ newer ▁ of ▁ the ▁ conversion <encdom>  # ▁ functions ▁ is ▁ used ▁ to ▁ perform ▁ the ▁ conversion. <encdom> <indent> if to_version > version : <newline> <indent> step_version = version + 1 <newline> convert_function = versions [ step_version ] . upgrade <newline> <dedent> else : <newline> <indent> step_version = version - 1 <newline> convert_function = versions [ version ] . downgrade <newline>  # ▁ Convert ▁ and ▁ make ▁ sure ▁ version ▁ changed ▁ during ▁ conversion. <encdom> <dedent> converted = convert_function ( nb ) <newline> if converted . get ( 'nbformat' , 1 ) == version : <newline> <indent> raise ValueError ( "Failed ▁ to ▁ convert ▁ notebook ▁ from ▁ v%d ▁ to ▁ v%d." % ( version , step_version ) ) <newline>  # ▁ Recursively ▁ convert ▁ until ▁ target ▁ version ▁ is ▁ reached. <encdom> <dedent> return convert ( converted , to_version ) <newline> <dedent> else : <newline> <indent> raise ValueError ( "Cannot ▁ convert ▁ notebook ▁ to ▁ v%d ▁ because ▁ that ▁ " "version ▁ doesn't ▁ exist" % ( to_version ) ) <newline> <dedent> <dedent>
 # ▁ Copyright ▁ (C) ▁ 2003-2007, ▁ 2009, ▁ 2010 ▁ Nominum, ▁ Inc. <encdom>  # ▁ Permission ▁ to ▁ use, ▁ copy, ▁ modify, ▁ and ▁ distribute ▁ this ▁ software ▁ and ▁ its <encdom>  # ▁ documentation ▁ for ▁ any ▁ purpose ▁ with ▁ or ▁ without ▁ fee ▁ is ▁ hereby ▁ granted, <encdom>  # ▁ provided ▁ that ▁ the ▁ above ▁ copyright ▁ notice ▁ and ▁ this ▁ permission ▁ notice <encdom>  # ▁ appear ▁ in ▁ all ▁ copies. <encdom>  # ▁ THE ▁ SOFTWARE ▁ IS ▁ PROVIDED ▁"AS ▁ IS" ▁ AND ▁ NOMINUM ▁ DISCLAIMS ▁ ALL ▁ WARRANTIES <encdom>  # ▁ WITH ▁ REGARD ▁ TO ▁ THIS ▁ SOFTWARE ▁ INCLUDING ▁ ALL ▁ IMPLIED ▁ WARRANTIES ▁ OF <encdom>  # ▁ MERCHANTABILITY ▁ AND ▁ FITNESS. ▁ IN ▁ NO ▁ EVENT ▁ SHALL ▁ NOMINUM ▁ BE ▁ LIABLE ▁ FOR <encdom>  # ▁ ANY ▁ SPECIAL, ▁ DIRECT, ▁ INDIRECT, ▁ OR ▁ CONSEQUENTIAL ▁ DAMAGES ▁ OR ▁ ANY ▁ DAMAGES <encdom>  # ▁ WHATSOEVER ▁ RESULTING ▁ FROM ▁ LOSS ▁ OF ▁ USE, ▁ DATA ▁ OR ▁ PROFITS, ▁ WHETHER ▁ IN ▁ AN <encdom>  # ▁ ACTION ▁ OF ▁ CONTRACT, ▁ NEGLIGENCE ▁ OR ▁ OTHER ▁ TORTIOUS ▁ ACTION, ▁ ARISING ▁ OUT <encdom>  # ▁ OF ▁ OR ▁ IN ▁ CONNECTION ▁ WITH ▁ THE ▁ USE ▁ OR ▁ PERFORMANCE ▁ OF ▁ THIS ▁ SOFTWARE. <encdom> import struct <newline> import dns . exception <newline> import dns . rdata <newline> import dns . name <newline> class PX ( dns . rdata . Rdata ) : <newline> <indent>  """ PX ▁ record. <strnewline> <strnewline> ▁ @ivar ▁ preference: ▁ the ▁ preference ▁ value <strnewline> ▁ @type ▁ preference: ▁ int <strnewline> ▁ @ivar ▁ map822: ▁ the ▁ map822 ▁ name <strnewline> ▁ @type ▁ map822: ▁ dns.name.Name ▁ object <strnewline> ▁ @ivar ▁ mapx400: ▁ the ▁ mapx400 ▁ name <strnewline> ▁ @type ▁ mapx400: ▁ dns.name.Name ▁ object <strnewline> ▁ @see: ▁ RFC ▁ 2163 """  <newline> __slots__ = [ 'preference' , 'map822' , 'mapx400' ] <newline> def __init__ ( self , rdclass , rdtype , preference , map822 , mapx400 ) : <newline> <indent> super ( PX , self ) . __init__ ( rdclass , rdtype ) <newline> self . preference = preference <newline> self . map822 = map822 <newline> self . mapx400 = mapx400 <newline> <dedent> def to_text ( self , origin = None , relativize = True , ** kw ) : <newline> <indent> map822 = self . map822 . choose_relativity ( origin , relativize ) <newline> mapx400 = self . mapx400 . choose_relativity ( origin , relativize ) <newline> return '%d ▁ %s ▁ %s' % ( self . preference , map822 , mapx400 ) <newline> <dedent> def from_text ( cls , rdclass , rdtype , tok , origin = None , relativize = True ) : <newline> <indent> preference = tok . get_uint16 ( ) <newline> map822 = tok . get_name ( ) <newline> map822 = map822 . choose_relativity ( origin , relativize ) <newline> mapx400 = tok . get_name ( None ) <newline> mapx400 = mapx400 . choose_relativity ( origin , relativize ) <newline> tok . get_eol ( ) <newline> return cls ( rdclass , rdtype , preference , map822 , mapx400 ) <newline> <dedent> from_text = classmethod ( from_text ) <newline> def to_wire ( self , file , compress = None , origin = None ) : <newline> <indent> pref = struct . pack ( "!H" , self . preference ) <newline> file . write ( pref ) <newline> self . map822 . to_wire ( file , None , origin ) <newline> self . mapx400 . to_wire ( file , None , origin ) <newline> <dedent> def from_wire ( cls , rdclass , rdtype , wire , current , rdlen , origin = None ) : <newline> <indent> ( preference , ) = struct . unpack ( '!H' , wire [ current : current + 2 ] ) <newline> current += 2 <newline> rdlen -= 2 <newline> ( map822 , cused ) = dns . name . from_wire ( wire [ : current + rdlen ] , current ) <newline> if cused > rdlen : <newline> <indent> raise dns . exception . FormError <newline> <dedent> current += cused <newline> rdlen -= cused <newline> if not origin is None : <newline> <indent> map822 = map822 . relativize ( origin ) <newline> <dedent> ( mapx400 , cused ) = dns . name . from_wire ( wire [ : current + rdlen ] , current ) <newline> if cused != rdlen : <newline> <indent> raise dns . exception . FormError <newline> <dedent> if not origin is None : <newline> <indent> mapx400 = mapx400 . relativize ( origin ) <newline> <dedent> return cls ( rdclass , rdtype , preference , map822 , mapx400 ) <newline> <dedent> from_wire = classmethod ( from_wire ) <newline> def choose_relativity ( self , origin = None , relativize = True ) : <newline> <indent> self . map822 = self . map822 . choose_relativity ( origin , relativize ) <newline> self . mapx400 = self . mapx400 . choose_relativity ( origin , relativize ) <newline> <dedent> def _cmp ( self , other ) : <newline> <indent> sp = struct . pack ( "!H" , self . preference ) <newline> op = struct . pack ( "!H" , other . preference ) <newline> v = cmp ( sp , op ) <newline> if v == 0 : <newline> <indent> v = cmp ( self . map822 , other . map822 ) <newline> if v == 0 : <newline> <indent> v = cmp ( self . mapx400 , other . mapx400 ) <newline> <dedent> <dedent> return v <newline> <dedent> <dedent>
 # ▁ -*- ▁ coding: ▁ utf-8 ▁ -*- <encdom>  """ <strnewline> Tests ▁ for ▁ authentication ▁ widget <strnewline> <strnewline> From ▁ build ▁ dir, ▁ run ▁ from ▁ test ▁ directory: <strnewline> LC_ALL=en_US.UTF-8 ▁ ctest ▁ -R ▁ PyQgsAuthSettingsWidget ▁ -V <strnewline> <strnewline> .. ▁ note:: ▁ This ▁ program ▁ is ▁ free ▁ software; ▁ you ▁ can ▁ redistribute ▁ it ▁ and/or ▁ modify <strnewline> it ▁ under ▁ the ▁ terms ▁ of ▁ the ▁ GNU ▁ General ▁ Public ▁ License ▁ as ▁ published ▁ by <strnewline> the ▁ Free ▁ Software ▁ Foundation; ▁ either ▁ version ▁ 2 ▁ of ▁ the ▁ License, ▁ or <strnewline> (at ▁ your ▁ option) ▁ any ▁ later ▁ version. <strnewline> """  <newline> import os <newline> import re <newline> import string <newline> import sys <newline> from shutil import rmtree <newline> import tempfile <newline> import random <newline> from qgis . core import QgsAuthMethodConfig , QgsNetworkAccessManager , QgsSettings , QgsApplication <newline> from qgis . gui import QgsAuthSettingsWidget <newline> from qgis . testing import start_app , unittest <newline> from utilities import unitTestDataPath <newline> __author__ = 'Alessandro ▁ Pasotti' <newline> __date__ = '27/09/2017' <newline> __copyright__ = 'Copyright ▁ 2017, ▁ The ▁ QGIS ▁ Project' <newline> QGIS_AUTH_DB_DIR_PATH = tempfile . mkdtemp ( ) <newline> os . environ [ 'QGIS_AUTH_DB_DIR_PATH' ] = QGIS_AUTH_DB_DIR_PATH <newline> qgis_app = start_app ( ) <newline> class TestAuthenticationWidget ( unittest . TestCase ) : <newline> <indent> @ classmethod <newline> def setUpClass ( cls ) : <newline> <indent>  """ Run ▁ before ▁ all ▁ tests: <strnewline> ▁ Creates ▁ an ▁ auth ▁ configuration """  <newline>  # ▁ Enable ▁ auth <encdom>  # ▁ os.environ['QGIS_AUTH_PASSWORD_FILE'] ▁ = ▁ QGIS_AUTH_PASSWORD_FILE <encdom> authm = QgsApplication . authManager ( ) <newline> assert ( authm . setMasterPassword ( 'masterpassword' , True ) ) <newline> cls . auth_config = QgsAuthMethodConfig ( 'Basic' ) <newline> cls . auth_config . setName ( 'test_auth_config' ) <newline> cls . username = '' . join ( random . choice ( string . ascii_uppercase + string . digits ) for _ in range ( 6 ) ) <newline> cls . password = cls . username [ : : - 1 ]  # ▁ reversed <encdom> <newline> cls . auth_config . setConfig ( 'username' , cls . username ) <newline> cls . auth_config . setConfig ( 'password' , cls . password ) <newline> assert ( authm . storeAuthenticationConfig ( cls . auth_config ) [ 0 ] ) <newline> <dedent> @ classmethod <newline> def tearDownClass ( cls ) : <newline> <indent>  """ Run ▁ after ▁ all ▁ tests """  <newline> rmtree ( QGIS_AUTH_DB_DIR_PATH ) <newline> <dedent> def setUp ( self ) : <newline> <indent>  """ Run ▁ before ▁ each ▁ test. """  <newline> pass <newline> <dedent> def tearDown ( self ) : <newline> <indent>  """ Run ▁ after ▁ each ▁ test. """  <newline> pass <newline> <dedent> def testWidgetNoArgs ( self ) : <newline> <indent>  """ <strnewline> ▁ Test ▁ the ▁ widget ▁ with ▁ no ▁ args <strnewline> ▁ """  <newline> w = QgsAuthSettingsWidget ( ) <newline> self . assertEqual ( w . username ( ) , '' ) <newline> self . assertEqual ( w . password ( ) , '' ) <newline> self . assertEqual ( w . configId ( ) , '' ) <newline> self . assertTrue ( w . configurationTabIsSelected ( ) ) <newline> self . assertFalse ( w . btnConvertToEncryptedIsEnabled ( ) ) <newline> <dedent> def testWidgetConfigId ( self ) : <newline> <indent>  """ <strnewline> ▁ Test ▁ the ▁ widget ▁ with ▁ configId <strnewline> ▁ """  <newline> w = QgsAuthSettingsWidget ( None , self . auth_config . id ( ) ) <newline> self . assertEqual ( w . username ( ) , '' ) <newline> self . assertEqual ( w . password ( ) , '' ) <newline> self . assertEqual ( w . configId ( ) , self . auth_config . id ( ) ) <newline> self . assertTrue ( w . configurationTabIsSelected ( ) ) <newline> self . assertFalse ( w . btnConvertToEncryptedIsEnabled ( ) ) <newline> <dedent> def testWidgetUsername ( self ) : <newline> <indent>  """ <strnewline> ▁ Test ▁ the ▁ widget ▁ with ▁ username ▁ only <strnewline> ▁ """  <newline> w = QgsAuthSettingsWidget ( None , None , 'username' ) <newline> self . assertEqual ( w . username ( ) , 'username' ) <newline> self . assertEqual ( w . password ( ) , '' ) <newline> self . assertEqual ( w . configId ( ) , '' ) <newline> self . assertFalse ( w . configurationTabIsSelected ( ) ) <newline> <dedent> def testWidgetPassword ( self ) : <newline> <indent>  """ <strnewline> ▁ Test ▁ the ▁ widget ▁ with ▁ password ▁ only <strnewline> ▁ """  <newline> w = QgsAuthSettingsWidget ( None , None , None , 'password' ) <newline> self . assertEqual ( w . username ( ) , '' ) <newline> self . assertEqual ( w . password ( ) , 'password' ) <newline> self . assertEqual ( w . configId ( ) , '' ) <newline> self . assertFalse ( w . configurationTabIsSelected ( ) ) <newline> <dedent> def testWidgetUsernameAndPassword ( self ) : <newline> <indent>  """ <strnewline> ▁ Test ▁ the ▁ widget ▁ with ▁ username ▁ and ▁ password <strnewline> ▁ """  <newline> w = QgsAuthSettingsWidget ( None , None , 'username' , 'password' ) <newline> self . assertEqual ( w . username ( ) , 'username' ) <newline> self . assertEqual ( w . password ( ) , 'password' ) <newline> self . assertEqual ( w . configId ( ) , '' ) <newline> self . assertFalse ( w . configurationTabIsSelected ( ) ) <newline> self . assertTrue ( w . btnConvertToEncryptedIsEnabled ( ) ) <newline> <dedent> def testConvertToEncrypted ( self ) : <newline> <indent>  """ <strnewline> ▁ Test ▁ the ▁ widget ▁ to ▁ encrypted ▁ conversion <strnewline> ▁ """  <newline> w = QgsAuthSettingsWidget ( None , None , 'username' , 'password' ) <newline> self . assertEqual ( w . username ( ) , 'username' ) <newline> self . assertEqual ( w . password ( ) , 'password' ) <newline> self . assertEqual ( w . configId ( ) , '' ) <newline> self . assertFalse ( w . configurationTabIsSelected ( ) ) <newline> self . assertTrue ( w . btnConvertToEncryptedIsEnabled ( ) ) <newline> self . assertTrue ( w . convertToEncrypted ( ) ) <newline> self . assertNotEqual ( w . configId ( ) , '' ) <newline> self . assertEqual ( w . username ( ) , '' ) <newline> self . assertEqual ( w . password ( ) , '' ) <newline> self . assertTrue ( w . configurationTabIsSelected ( ) ) <newline> self . assertFalse ( w . btnConvertToEncryptedIsEnabled ( ) ) <newline> <dedent> def test_setters ( self ) : <newline> <indent>  """ <strnewline> ▁ Test ▁ setters <strnewline> ▁ """  <newline> w = QgsAuthSettingsWidget ( ) <newline> w . setUsername ( 'username' ) <newline> self . assertFalse ( w . configurationTabIsSelected ( ) ) <newline> self . assertEqual ( w . username ( ) , 'username' ) <newline> w = QgsAuthSettingsWidget ( ) <newline> w . setPassword ( 'password' ) <newline> self . assertEqual ( w . password ( ) , 'password' ) <newline> self . assertFalse ( w . configurationTabIsSelected ( ) ) <newline> w = QgsAuthSettingsWidget ( ) <newline> w . setConfigId ( self . auth_config . id ( ) ) <newline> self . assertEqual ( w . configId ( ) , self . auth_config . id ( ) ) <newline> self . assertTrue ( w . configurationTabIsSelected ( ) ) <newline> w = QgsAuthSettingsWidget ( ) <newline> w . setUsername ( 'username' ) <newline> w . setPassword ( 'password' ) <newline> w . setConfigId ( self . auth_config . id ( ) ) <newline> self . assertEqual ( w . configId ( ) , self . auth_config . id ( ) ) <newline> self . assertTrue ( w . configurationTabIsSelected ( ) ) <newline> w = QgsAuthSettingsWidget ( ) <newline> w . setDataprovider ( 'db2' ) <newline> self . assertEqual ( w . dataprovider ( ) , 'db2' ) <newline> <dedent> def test_storeCheckBoxes ( self ) : <newline> <indent>  """ <strnewline> ▁ Test ▁ store ▁ cb ▁ setters ▁ and ▁ getters <strnewline> ▁ """  <newline> w = QgsAuthSettingsWidget ( ) <newline> self . assertFalse ( w . storePasswordIsChecked ( ) ) <newline> self . assertFalse ( w . storeUsernameIsChecked ( ) ) <newline> w = QgsAuthSettingsWidget ( ) <newline> w . setStorePasswordChecked ( True ) <newline> self . assertTrue ( w . storePasswordIsChecked ( ) ) <newline> self . assertFalse ( w . storeUsernameIsChecked ( ) ) <newline> w = QgsAuthSettingsWidget ( ) <newline> w . setStoreUsernameChecked ( True ) <newline> self . assertFalse ( w . storePasswordIsChecked ( ) ) <newline> self . assertTrue ( w . storeUsernameIsChecked ( ) ) <newline> w = QgsAuthSettingsWidget ( ) <newline> w . setStoreUsernameChecked ( True ) <newline> w . setStorePasswordChecked ( True ) <newline> self . assertTrue ( w . storePasswordIsChecked ( ) ) <newline> self . assertTrue ( w . storeUsernameIsChecked ( ) ) <newline> <dedent> <dedent> if __name__ == '__main__' : <newline> <indent> unittest . main ( ) <newline> <dedent>
 # !/usr/bin/env ▁ python <encdom>  # ▁ -*- ▁ coding: ▁ utf-8 ▁ -*- ▁ # <encdom> from __future__ import unicode_literals <newline> AUTHOR = 'KMOL' <newline> SITENAME = '2016Fall ▁ 課程網誌 ▁ (虎尾科大MDE)' <newline>  # ▁ 不要用文章所在目錄作為類別 <encdom> USE_FOLDER_AS_CATEGORY = False <newline>  # PATH ▁ = ▁'content' <encdom>  # OUTPUT_PATH ▁ = ▁'output' <encdom> TIMEZONE = 'Asia/Taipei' <newline> DEFAULT_LANG = 'en' <newline>  # ▁ Feed ▁ generation ▁ is ▁ usually ▁ not ▁ desired ▁ when ▁ developing <encdom> FEED_ALL_ATOM = None <newline> CATEGORY_FEED_ATOM = None <newline> TRANSLATION_FEED_ATOM = None <newline> AUTHOR_FEED_ATOM = None <newline> AUTHOR_FEED_RSS = None <newline>  # ▁ Blogroll <encdom> LINKS = ( ( 'Pelican' , 'http://getpelican.com/' ) , ( 'pelican-bootstrap3' , 'https://github.com/DandyDev/pelican-bootstrap3/' ) , ( 'pelican-plugins' , 'https://github.com/getpelican/pelican-plugins' ) , ( 'Tipue ▁ search' , 'https://github.com/Tipue/Tipue-Search' ) , ) <newline>  # ▁ Social ▁ widget <encdom>  # SOCIAL ▁ = ▁ (('You ▁ can ▁ add ▁ links ▁ in ▁ your ▁ config ▁ file', ▁' # '),('Another ▁ social ▁ link', ▁' # '),) <encdom> DEFAULT_PAGINATION = 10 <newline>  # ▁ Uncomment ▁ following ▁ line ▁ if ▁ you ▁ want ▁ document-relative ▁ URLs ▁ when ▁ developing <encdom>  # RELATIVE_URLS ▁ = ▁ True <encdom>  # ▁ 必須絕對目錄或相對於設定檔案所在目錄 <encdom> PLUGIN_PATHS = [ 'plugin' ] <newline> PLUGINS = [ 'liquid_tags.notebook' , 'summary' , 'tipue_search' , 'sitemap' ] <newline>  # ▁ for ▁ sitemap ▁ plugin <encdom> SITEMAP = { 'format' : 'xml' , 'priorities' : { 'articles' : 0.5 , 'indexes' : 0.5 , 'pages' : 0.5 } , 'changefreqs' : { 'articles' : 'monthly' , 'indexes' : 'daily' , 'pages' : 'monthly' } } <newline>  # ▁ search ▁ is ▁ for ▁ Tipue ▁ search <encdom> DIRECT_TEMPLATES = ( ( 'index' , 'tags' , 'categories' , 'authors' , 'archives' , 'search' ) ) <newline>  # ▁ for ▁ pelican-bootstrap3 ▁ theme ▁ settings <encdom>  # TAG_CLOUD_MAX_ITEMS ▁ = ▁ 50 <encdom> DISPLAY_CATEGORIES_ON_SIDEBAR = True <newline> DISPLAY_RECENT_POSTS_ON_SIDEBAR = True <newline> DISPLAY_TAGS_ON_SIDEBAR = True <newline> DISPLAY_TAGS_INLINE = True <newline> TAGS_URL = "tags.html" <newline> CATEGORIES_URL = "categories.html" <newline>  # SHOW_ARTICLE_AUTHOR ▁ = ▁ True <encdom>  # MENUITEMS ▁ = ▁ [('Home', ▁'/'), ▁ ('Archives', ▁'/archives.html'), ▁ ('Search', ▁'/search.html')] <encdom>
 """ engine.SCons.Platform.hpux <strnewline> <strnewline> Platform-specific ▁ initialization ▁ for ▁ HP-UX ▁ systems. <strnewline> <strnewline> There ▁ normally ▁ shouldn't ▁ be ▁ any ▁ need ▁ to ▁ import ▁ this ▁ module ▁ directly. ▁ It <strnewline> will ▁ usually ▁ be ▁ imported ▁ through ▁ the ▁ generic ▁ SCons.Platform.Platform() <strnewline> selection ▁ method. <strnewline> """  <newline>  # ▁ Copyright ▁ (c) ▁ 2001, ▁ 2002, ▁ 2003, ▁ 2004, ▁ 2005, ▁ 2006, ▁ 2007, ▁ 2008, ▁ 2009, ▁ 2010, ▁ 2011, ▁ 2012 ▁ The ▁ SCons ▁ Foundation <encdom>  # ▁ Permission ▁ is ▁ hereby ▁ granted, ▁ free ▁ of ▁ charge, ▁ to ▁ any ▁ person ▁ obtaining <encdom>  # ▁ a ▁ copy ▁ of ▁ this ▁ software ▁ and ▁ associated ▁ documentation ▁ files ▁ (the <encdom>  # ▁"Software"), ▁ to ▁ deal ▁ in ▁ the ▁ Software ▁ without ▁ restriction, ▁ including <encdom>  # ▁ without ▁ limitation ▁ the ▁ rights ▁ to ▁ use, ▁ copy, ▁ modify, ▁ merge, ▁ publish, <encdom>  # ▁ distribute, ▁ sublicense, ▁ and/or ▁ sell ▁ copies ▁ of ▁ the ▁ Software, ▁ and ▁ to <encdom>  # ▁ permit ▁ persons ▁ to ▁ whom ▁ the ▁ Software ▁ is ▁ furnished ▁ to ▁ do ▁ so, ▁ subject ▁ to <encdom>  # ▁ the ▁ following ▁ conditions: <encdom>  # ▁ The ▁ above ▁ copyright ▁ notice ▁ and ▁ this ▁ permission ▁ notice ▁ shall ▁ be ▁ included <encdom>  # ▁ in ▁ all ▁ copies ▁ or ▁ substantial ▁ portions ▁ of ▁ the ▁ Software. <encdom>  # ▁ THE ▁ SOFTWARE ▁ IS ▁ PROVIDED ▁"AS ▁ IS", ▁ WITHOUT ▁ WARRANTY ▁ OF ▁ ANY <encdom>  # ▁ KIND, ▁ EXPRESS ▁ OR ▁ IMPLIED, ▁ INCLUDING ▁ BUT ▁ NOT ▁ LIMITED ▁ TO ▁ THE <encdom>  # ▁ WARRANTIES ▁ OF ▁ MERCHANTABILITY, ▁ FITNESS ▁ FOR ▁ A ▁ PARTICULAR ▁ PURPOSE ▁ AND <encdom>  # ▁ NONINFRINGEMENT. ▁ IN ▁ NO ▁ EVENT ▁ SHALL ▁ THE ▁ AUTHORS ▁ OR ▁ COPYRIGHT ▁ HOLDERS ▁ BE <encdom>  # ▁ LIABLE ▁ FOR ▁ ANY ▁ CLAIM, ▁ DAMAGES ▁ OR ▁ OTHER ▁ LIABILITY, ▁ WHETHER ▁ IN ▁ AN ▁ ACTION <encdom>  # ▁ OF ▁ CONTRACT, ▁ TORT ▁ OR ▁ OTHERWISE, ▁ ARISING ▁ FROM, ▁ OUT ▁ OF ▁ OR ▁ IN ▁ CONNECTION <encdom>  # ▁ WITH ▁ THE ▁ SOFTWARE ▁ OR ▁ THE ▁ USE ▁ OR ▁ OTHER ▁ DEALINGS ▁ IN ▁ THE ▁ SOFTWARE. <encdom> __revision__ = "src/engine/SCons/Platform/hpux.py ▁ issue-2856:2676:d23b7a2f45e8 ▁ 2012/08/05 ▁ 15:38:28 ▁ garyo" <newline> import posix <newline> def generate ( env ) : <newline> <indent> posix . generate ( env ) <newline>  # Based ▁ on ▁ HP-UX11i: ▁ ARG_MAX=2048000 ▁ - ▁ 3000 ▁ for ▁ environment ▁ expansion <encdom> env [ 'MAXLINELENGTH' ] = 2045000 <newline>  # ▁ Local ▁ Variables: <encdom>  # ▁ tab-width:4 <encdom>  # ▁ indent-tabs-mode:nil <encdom>  # ▁ End: <encdom>  # ▁ vim: ▁ set ▁ expandtab ▁ tabstop=4 ▁ shiftwidth=4: <encdom> <dedent>
 # ▁ Copyright ▁ IBM ▁ Corp. ▁ 2016 ▁ All ▁ Rights ▁ Reserved. <encdom>  # ▁ Licensed ▁ under ▁ the ▁ Apache ▁ License, ▁ Version ▁ 2.0 ▁ (the ▁"License"); <encdom>  # ▁ you ▁ may ▁ not ▁ use ▁ this ▁ file ▁ except ▁ in ▁ compliance ▁ with ▁ the ▁ License. <encdom>  # ▁ You ▁ may ▁ obtain ▁ a ▁ copy ▁ of ▁ the ▁ License ▁ at <encdom>  # ▁ http://www.apache.org/licenses/LICENSE-2.0 <encdom>  # ▁ Unless ▁ required ▁ by ▁ applicable ▁ law ▁ or ▁ agreed ▁ to ▁ in ▁ writing, ▁ software <encdom>  # ▁ distributed ▁ under ▁ the ▁ License ▁ is ▁ distributed ▁ on ▁ an ▁"AS ▁ IS" ▁ BASIS, <encdom>  # ▁ WITHOUT ▁ WARRANTIES ▁ OR ▁ CONDITIONS ▁ OF ▁ ANY ▁ KIND, ▁ either ▁ express ▁ or ▁ implied. <encdom>  # ▁ See ▁ the ▁ License ▁ for ▁ the ▁ specific ▁ language ▁ governing ▁ permissions ▁ and <encdom>  # ▁ limitations ▁ under ▁ the ▁ License. <encdom> from StringIO import StringIO <newline> from itertools import chain <newline> from google . protobuf . message import Message <newline> from b3j0f . aop import weave , unweave , is_intercepted , weave_on <newline> from jinja2 import Environment , PackageLoader , select_autoescape , FileSystemLoader , Template <newline> env = Environment ( loader = FileSystemLoader ( searchpath = "templates" ) , autoescape = select_autoescape ( [ 'html' , 'xml' ] ) , trim_blocks = True , lstrip_blocks = True ) <newline> from bootstrap_util import getDirectory <newline> class DocumentGenerator : <newline> <indent> def __init__ ( self , contextHelper , scenario ) : <newline> <indent> self . contextHelper = contextHelper <newline> self . directory = getDirectory ( contextHelper . context ) <newline> self . output = StringIO ( ) <newline> self . currentStep = 0 <newline> self . composition = None <newline>  # Weave ▁ advices ▁ into ▁ contextHelper <encdom> weave ( target = self . contextHelper . before_step , advices = self . beforeStepAdvice ) <newline> weave ( target = self . contextHelper . after_step , advices = self . afterStepAdvice ) <newline> weave ( target = self . contextHelper . after_scenario , advices = self . afterScenarioAdvice ) <newline> weave ( target = self . contextHelper . getBootrapHelper , advices = self . getBootstrapHelperAdvice ) <newline> weave ( target = self . contextHelper . registerComposition , advices = self . registerCompositionAdvice ) <newline>  # ▁ Weave ▁ advices ▁ into ▁ Directory <encdom> weave ( target = self . directory . _registerOrg , advices = self . registerOrgAdvice ) <newline> weave ( target = self . directory . _registerUser , advices = self . registerUserAdvice ) <newline> weave ( target = self . directory . registerOrdererAdminTuple , advices = self . registerNamedNodeAdminTupleAdvice ) <newline> <dedent> def beforeStepAdvice ( self , joinpoint ) : <newline> <indent> self . currentStep += 1 <newline> step = joinpoint . kwargs [ 'step' ] <newline>  # ▁ Now ▁ the ▁ jinja ▁ template <encdom> self . output . write ( env . get_template ( "html/step.html" ) . render ( step_id = "Step ▁ {0}" . format ( self . currentStep ) , step = step ) ) <newline> return joinpoint . proceed ( ) <newline> <dedent> def afterStepAdvice ( self , joinpoint ) : <newline> <indent> step = joinpoint . kwargs [ 'step' ] <newline>  # ▁ Now ▁ the ▁ jinja ▁ template <encdom> if step . status == "failed" : <newline> <indent> self . output . write ( env . get_template ( "html/error.html" ) . render ( err = step . error_message ) ) <newline> <dedent> return joinpoint . proceed ( ) <newline> <dedent> def compositionCallCLIAdvice ( self , joinpoint ) : <newline> <indent> 'This ▁ advice ▁ is ▁ called ▁ around ▁ the ▁ compositions ▁ usage ▁ of ▁ the ▁ cli' <newline> result = joinpoint . proceed ( ) <newline>  # ▁ Create ▁ table ▁ for ▁ environment <encdom> composition = joinpoint . kwargs [ 'self' ] <newline> envAdditions = composition . getEnvAdditions ( ) <newline> keys = envAdditions . keys ( ) <newline> keys . sort ( ) <newline> envPreamble = " ▁ " . join ( [ "{0}={1}" . format ( key , envAdditions [ key ] ) for key in keys ] ) <newline> args = " ▁ " . join ( joinpoint . kwargs [ 'argList' ] ) <newline> self . output . write ( env . get_template ( "html/cli.html" ) . render ( command = "{0} ▁ {1}" . format ( envPreamble , args ) ) ) <newline> return result <newline> <dedent> def _getNetworkGroup ( self , serviceName ) : <newline> <indent> groups = { "peer" : 1 , "orderer" : 2 , "kafka" : 7 , "zookeeper" : 8 , "couchdb" : 9 } <newline> groupId = 0 <newline> for group , id in groups . iteritems ( ) : <newline> <indent> if serviceName . lower ( ) . startswith ( group ) : <newline> <indent> groupId = id <newline> <dedent> <dedent> return groupId <newline> <dedent> def _getNetworkForConfig ( self , configAsYaml ) : <newline> <indent> import yaml <newline> config = yaml . load ( configAsYaml ) <newline> assert "services" in config , "Expected ▁ config ▁ from ▁ docker-compose ▁ config ▁ to ▁ have ▁ services ▁ key ▁ at ▁ top ▁ level: ▁ ▁ \n {0}" . format ( config ) <newline> network = { "nodes" : [ ] , "links" : [ ] } <newline> for serviceName in config [ 'services' ] . keys ( ) : <newline> <indent> network [ 'nodes' ] . append ( { "id" : serviceName , "group" : self . _getNetworkGroup ( serviceName ) , "type" : "node" } ) <newline>  # ▁ Now ▁ get ▁ links <encdom> if "depends_on" in config [ 'services' ] [ serviceName ] : <newline> <indent> for dependedOnServiceName in config [ 'services' ] [ serviceName ] [ 'depends_on' ] : <newline> <indent> network [ 'links' ] . append ( { "source" : serviceName , "target" : dependedOnServiceName , "value" : 1 } ) <newline> <dedent> <dedent> <dedent> return network <newline> <dedent> def _getNetworkForDirectory ( self ) : <newline> <indent> network = { "nodes" : [ ] , "links" : [ ] } <newline> for orgName , org in self . directory . getOrganizations ( ) . iteritems ( ) : <newline> <indent> network [ 'nodes' ] . append ( { "id" : orgName , "group" : 3 , "type" : "org" } ) <newline> <dedent> for userName , user in self . directory . getUsers ( ) . iteritems ( ) : <newline> <indent> network [ 'nodes' ] . append ( { "id" : userName , "group" : 4 , "type" : "user" } ) <newline>  # ▁ Now ▁ get ▁ links <encdom> <dedent> for nct , cert in self . directory . getNamedCtxTuples ( ) . iteritems ( ) : <newline> <indent> nctId = "{0}-{1}-{2}" . format ( nct . user , nct . nodeName , nct . organization ) <newline> network [ 'nodes' ] . append ( { "id" : nctId , "group" : 5 , "type" : "cert" } ) <newline> network [ 'links' ] . append ( { "source" : nctId , "target" : nct . organization , "value" : 1 } ) <newline> network [ 'links' ] . append ( { "source" : nctId , "target" : nct . user , "value" : 1 } ) <newline>  # ▁ Only ▁ add ▁ the ▁ context ▁ link ▁ if ▁ it ▁ is ▁ a ▁ compose ▁ service, ▁ else ▁ the ▁ target ▁ may ▁ not ▁ exist. <encdom> if nct . nodeName in self . composition . getServiceNames ( ) : <newline> <indent> network [ 'links' ] . append ( { "source" : nctId , "target" : nct . nodeName , "value" : 1 } ) <newline> <dedent> <dedent> return network <newline> <dedent> def _writeNetworkJson ( self ) : <newline> <indent> if self . composition : <newline> <indent> import json <newline> configNetwork = self . _getNetworkForConfig ( configAsYaml = self . composition . getConfig ( ) ) <newline> directoryNetwork = self . _getNetworkForDirectory ( ) <newline>  # ▁ Join ▁ the ▁ network ▁ info ▁ together <encdom> fullNetwork = dict ( chain ( [ ( key , configNetwork [ key ] + directoryNetwork [ key ] ) for key in configNetwork . keys ( ) ] ) ) <newline> ( fileName , fileExists ) = self . contextHelper . getTmpPathForName ( "network" , extension = "json" ) <newline> with open ( fileName , "w" ) as f : <newline> <indent> f . write ( json . dumps ( fullNetwork ) ) <newline> <dedent> <dedent> <dedent> def registerCompositionAdvice ( self , joinpoint ) : <newline> <indent> composition = joinpoint . kwargs [ 'composition' ] <newline> weave ( target = composition . _callCLI , advices = self . compositionCallCLIAdvice ) <newline> result = joinpoint . proceed ( ) <newline> if composition : <newline>  # Now ▁ get ▁ the ▁ config ▁ for ▁ the ▁ composition ▁ and ▁ dump ▁ out. <encdom> <indent> self . composition = composition <newline> configAsYaml = composition . getConfig ( ) <newline> ( dokerComposeYmlFileName , fileExists ) = self . contextHelper . getTmpPathForName ( name = "docker-compose" , extension = "yml" ) <newline> with open ( dokerComposeYmlFileName , 'w' ) as f : <newline> <indent> f . write ( configAsYaml ) <newline> <dedent> self . output . write ( env . get_template ( "html/composition-py.html" ) . render ( compose_project_name = self . composition . projectName , docker_compose_yml_file = dokerComposeYmlFileName ) ) <newline> self . output . write ( env . get_template ( "html/header.html" ) . render ( text = "Configuration" , level = 4 ) ) <newline> self . output . write ( env . get_template ( "html/cli.html" ) . render ( command = configAsYaml ) ) <newline>  # Inject ▁ the ▁ graph <encdom> self . output . write ( env . get_template ( "html/header.html" ) . render ( text = "Network ▁ Graph" , level = 4 ) ) <newline> self . output . write ( env . get_template ( "html/graph.html" ) . render ( ) ) <newline> <dedent> return result <newline> <dedent> def _addLinkToFile ( self , fileName , linkText ) : <newline> <indent> import ntpath <newline> baseName = ntpath . basename ( fileName ) <newline>  # ▁ self.markdownWriter.addLink(linkUrl="./{0}".format(baseName), ▁ linkText=linkText, ▁ linkTitle=baseName) <encdom> <dedent> def _getLinkInfoForFile ( self , fileName ) : <newline> <indent> import ntpath <newline> return "./{0}" . format ( ntpath . basename ( fileName ) ) <newline> <dedent> def registerOrgAdvice ( self , joinpoint ) : <newline> <indent> orgName = joinpoint . kwargs [ 'orgName' ] <newline> newlyRegisteredOrg = joinpoint . proceed ( ) <newline> orgCert = newlyRegisteredOrg . getCertAsPEM ( ) <newline>  # Write ▁ out ▁ key ▁ material <encdom> ( fileName , fileExists ) = self . contextHelper . getTmpPathForName ( name = "dir-org-{0}-cert" . format ( orgName ) , extension = "pem" ) <newline> with open ( fileName , 'w' ) as f : <newline> <indent> f . write ( orgCert ) <newline> <dedent> self . _addLinkToFile ( fileName = fileName , linkText = "Public ▁ cert ▁ for ▁ Organization" ) <newline>  # Now ▁ the ▁ jinja ▁ output <encdom> self . output . write ( env . get_template ( "html/org.html" ) . render ( org = newlyRegisteredOrg , cert_href = self . _getLinkInfoForFile ( fileName ) , path_to_cert = fileName ) ) <newline> return newlyRegisteredOrg <newline> <dedent> def registerUserAdvice ( self , joinpoint ) : <newline> <indent> userName = joinpoint . kwargs [ 'userName' ] <newline> newlyRegisteredUser = joinpoint . proceed ( ) <newline>  # Write ▁ out ▁ key ▁ material <encdom> privateKeyAsPem = newlyRegisteredUser . getPrivateKeyAsPEM ( ) <newline> ( fileName , fileExists ) = self . contextHelper . getTmpPathForName ( name = "dir-user-{0}-privatekey" . format ( userName ) , extension = "pem" ) <newline> with open ( fileName , 'w' ) as f : <newline> <indent> f . write ( privateKeyAsPem ) <newline>  # Weave ▁ into ▁ user ▁ tags ▁ setting <encdom> <dedent> weave ( target = newlyRegisteredUser . setTagValue , advices = self . userSetTagValueAdvice ) <newline>  # Now ▁ the ▁ jinja ▁ output <encdom> self . output . write ( env . get_template ( "html/user.html" ) . render ( user = newlyRegisteredUser , private_key_href = self . _getLinkInfoForFile ( fileName ) ) ) <newline> return newlyRegisteredUser <newline> <dedent> def _dump_context ( self ) : <newline> <indent> ( dirPickleFileName , fileExists ) = self . contextHelper . getTmpPathForName ( "dir" , extension = "pickle" ) <newline> with open ( dirPickleFileName , 'w' ) as f : <newline> <indent> self . directory . dump ( f ) <newline>  # Now ▁ the ▁ jinja ▁ output <encdom> <dedent> self . output . write ( env . get_template ( "html/directory.html" ) . render ( directory = self . directory , path_to_pickle = dirPickleFileName ) ) <newline> if self . composition : <newline> <indent> ( dokerComposeYmlFileName , fileExists ) = self . contextHelper . getTmpPathForName ( name = "docker-compose" , extension = "yml" ) <newline> self . output . write ( env . get_template ( "html/appendix-py.html" ) . render ( directory = self . directory , path_to_pickle = dirPickleFileName , compose_project_name = self . composition . projectName , docker_compose_yml_file = dokerComposeYmlFileName ) ) <newline> <dedent> <dedent> def afterScenarioAdvice ( self , joinpoint ) : <newline> <indent> scenario = joinpoint . kwargs [ 'scenario' ] <newline> self . _dump_context ( ) <newline>  # Render ▁ with ▁ jinja <encdom> header = env . get_template ( "html/scenario.html" ) . render ( scenario = scenario , steps = scenario . steps ) <newline> main = env . get_template ( "html/main.html" ) . render ( header = header , body = self . output . getvalue ( ) ) <newline> ( fileName , fileExists ) = self . contextHelper . getTmpPathForName ( "scenario" , extension = "html" ) <newline> with open ( fileName , 'w' ) as f : <newline> <indent> f . write ( main . encode ( "utf-8" ) ) <newline> <dedent> self . _writeNetworkJson ( ) <newline> return joinpoint . proceed ( ) <newline> <dedent> def registerNamedNodeAdminTupleAdvice ( self , joinpoint ) : <newline> <indent> namedNodeAdminTuple = joinpoint . proceed ( ) <newline> directory = joinpoint . kwargs [ 'self' ] <newline>  # jinja <encdom> newCertAsPEM = directory . getCertAsPEM ( namedNodeAdminTuple ) <newline> self . output . write ( env . get_template ( "html/header.html" ) . render ( text = "Created ▁ new ▁ named ▁ node ▁ admin ▁ tuple: ▁ {0}" . format ( namedNodeAdminTuple ) , level = 4 ) ) <newline> self . output . write ( env . get_template ( "html/cli.html" ) . render ( command = newCertAsPEM ) ) <newline>  # Write ▁ cert ▁ out <encdom> fileNameTocheck = "dir-user-{0}-cert-{1}-{2}" . format ( namedNodeAdminTuple . user , namedNodeAdminTuple . nodeName , namedNodeAdminTuple . organization ) <newline> ( fileName , fileExists ) = self . contextHelper . getTmpPathForName ( fileNameTocheck , extension = "pem" ) <newline> with open ( fileName , 'w' ) as f : <newline> <indent> f . write ( newCertAsPEM ) <newline> <dedent> return namedNodeAdminTuple <newline> <dedent> def bootstrapHelperSignConfigItemAdvice ( self , joinpoint ) : <newline> <indent> configItem = joinpoint . kwargs [ 'configItem' ] <newline>  # jinja <encdom> self . output . write ( env . get_template ( "html/header.html" ) . render ( text = "Dumping ▁ signed ▁ config ▁ item..." , level = 4 ) ) <newline> self . output . write ( env . get_template ( "html/protobuf.html" ) . render ( msg = configItem , msgLength = len ( str ( configItem ) ) ) ) <newline> signedConfigItem = joinpoint . proceed ( ) <newline> return signedConfigItem <newline> <dedent> def getBootstrapHelperAdvice ( self , joinpoint ) : <newline> <indent> bootstrapHelper = joinpoint . proceed ( ) <newline> weave ( target = bootstrapHelper . signConfigItem , advices = self . bootstrapHelperSignConfigItemAdvice ) <newline> return bootstrapHelper <newline> <dedent> def _isProtobufMessage ( self , target ) : <newline> <indent> return isinstance ( target , Message ) <newline> <dedent> def _isListOfProtobufMessages ( self , target ) : <newline> <indent> result = False <newline> if isinstance ( target , list ) : <newline> <indent> messageList = [ item for item in target if self . _isProtobufMessage ( item ) ] <newline> result = len ( messageList ) == len ( target ) <newline> <dedent> return result <newline> <dedent> def _isDictOfProtobufMessages ( self , target ) : <newline> <indent> result = False <newline> if isinstance ( target , dict ) : <newline> <indent> messageList = [ item for item in target . values ( ) if self . _isProtobufMessage ( item ) ] <newline> result = len ( messageList ) == len ( target ) <newline> <dedent> return result <newline> <dedent> def _writeProtobuf ( self , fileName , msg ) : <newline> <indent> import ntpath <newline> baseName = ntpath . basename ( fileName ) <newline> dataToWrite = msg . SerializeToString ( ) <newline> with open ( "{0}" . format ( fileName ) , 'wb' ) as f : <newline> <indent> f . write ( dataToWrite ) <newline> <dedent> self . output . write ( env . get_template ( "html/protobuf.html" ) . render ( id = baseName , msg = msg , path_to_protobuf = fileName , msgLength = len ( dataToWrite ) , linkUrl = "./{0}" . format ( baseName ) , linkText = "Protobuf ▁ message ▁ in ▁ binary ▁ form" , linkTitle = baseName ) ) <newline> <dedent> def userSetTagValueAdvice ( self , joinpoint ) : <newline> <indent> result = joinpoint . proceed ( ) <newline> user = joinpoint . kwargs [ 'self' ] <newline> tagKey = joinpoint . kwargs [ 'tagKey' ] <newline> tagValue = joinpoint . kwargs [ 'tagValue' ] <newline>  # jinja ▁ invoke <encdom> self . output . write ( env . get_template ( "html/tag.html" ) . render ( user = user , tag_key = tagKey ) ) <newline>  # ▁ If ▁ protobuf ▁ message, ▁ write ▁ out ▁ in ▁ binary ▁ form <encdom> if self . _isProtobufMessage ( tagValue ) : <newline> <indent> import ntpath <newline> ( fileName , fileExists ) = self . contextHelper . getTmpPathForName ( "{0}-{1}" . format ( user . getUserName ( ) , tagKey ) , extension = "protobuf" ) <newline> self . _writeProtobuf ( fileName = fileName , msg = tagValue ) <newline>  # ▁ If ▁ protobuf ▁ message, ▁ write ▁ out ▁ in ▁ binary ▁ form <encdom> <dedent> elif self . _isListOfProtobufMessages ( tagValue ) : <newline> <indent> index = 0 <newline> for msg in tagValue : <newline> <indent> ( fileName , fileExists ) = self . contextHelper . getTmpPathForName ( "{0}-{1}-{2:0>4}" . format ( user . getUserName ( ) , tagKey , index ) , extension = "protobuf" ) <newline> self . _writeProtobuf ( fileName = fileName , msg = msg ) <newline> index += 1 <newline> <dedent> <dedent> elif self . _isDictOfProtobufMessages ( tagValue ) : <newline> <indent> for key , msg in tagValue . iteritems ( ) : <newline> <indent> ( fileName , fileExists ) = self . contextHelper . getTmpPathForName ( "{0}-{1}-{2}" . format ( user . getUserName ( ) , tagKey , key ) , extension = "protobuf" ) <newline> self . _writeProtobuf ( fileName = fileName , msg = msg ) <newline> <dedent> <dedent> else : <newline> <indent> self . output . write ( env . get_template ( "html/cli.html" ) . render ( command = str ( tagValue ) ) ) <newline> <dedent> return result <newline> <dedent> <dedent>
 # ▁ Copyright ▁ (C) ▁ 2009 ▁ Google ▁ Inc. ▁ All ▁ rights ▁ reserved. <encdom>  # ▁ Redistribution ▁ and ▁ use ▁ in ▁ source ▁ and ▁ binary ▁ forms, ▁ with ▁ or ▁ without <encdom>  # ▁ modification, ▁ are ▁ permitted ▁ provided ▁ that ▁ the ▁ following ▁ conditions ▁ are <encdom>  # ▁ met: <encdom>  # ▁ * ▁ Redistributions ▁ of ▁ source ▁ code ▁ must ▁ retain ▁ the ▁ above ▁ copyright <encdom>  # ▁ notice, ▁ this ▁ list ▁ of ▁ conditions ▁ and ▁ the ▁ following ▁ disclaimer. <encdom>  # ▁ * ▁ Redistributions ▁ in ▁ binary ▁ form ▁ must ▁ reproduce ▁ the ▁ above <encdom>  # ▁ copyright ▁ notice, ▁ this ▁ list ▁ of ▁ conditions ▁ and ▁ the ▁ following ▁ disclaimer <encdom>  # ▁ in ▁ the ▁ documentation ▁ and/or ▁ other ▁ materials ▁ provided ▁ with ▁ the <encdom>  # ▁ distribution. <encdom>  # ▁ * ▁ Neither ▁ the ▁ name ▁ of ▁ Google ▁ Inc. ▁ nor ▁ the ▁ names ▁ of ▁ its <encdom>  # ▁ contributors ▁ may ▁ be ▁ used ▁ to ▁ endorse ▁ or ▁ promote ▁ products ▁ derived ▁ from <encdom>  # ▁ this ▁ software ▁ without ▁ specific ▁ prior ▁ written ▁ permission. <encdom>  # ▁ THIS ▁ SOFTWARE ▁ IS ▁ PROVIDED ▁ BY ▁ THE ▁ COPYRIGHT ▁ HOLDERS ▁ AND ▁ CONTRIBUTORS <encdom>  # ▁"AS ▁ IS" ▁ AND ▁ ANY ▁ EXPRESS ▁ OR ▁ IMPLIED ▁ WARRANTIES, ▁ INCLUDING, ▁ BUT ▁ NOT <encdom>  # ▁ LIMITED ▁ TO, ▁ THE ▁ IMPLIED ▁ WARRANTIES ▁ OF ▁ MERCHANTABILITY ▁ AND ▁ FITNESS ▁ FOR <encdom>  # ▁ A ▁ PARTICULAR ▁ PURPOSE ▁ ARE ▁ DISCLAIMED. ▁ IN ▁ NO ▁ EVENT ▁ SHALL ▁ THE ▁ COPYRIGHT <encdom>  # ▁ OWNER ▁ OR ▁ CONTRIBUTORS ▁ BE ▁ LIABLE ▁ FOR ▁ ANY ▁ DIRECT, ▁ INDIRECT, ▁ INCIDENTAL, <encdom>  # ▁ SPECIAL, ▁ EXEMPLARY, ▁ OR ▁ CONSEQUENTIAL ▁ DAMAGES ▁ (INCLUDING, ▁ BUT ▁ NOT <encdom>  # ▁ LIMITED ▁ TO, ▁ PROCUREMENT ▁ OF ▁ SUBSTITUTE ▁ GOODS ▁ OR ▁ SERVICES; ▁ LOSS ▁ OF ▁ USE, <encdom>  # ▁ DATA, ▁ OR ▁ PROFITS; ▁ OR ▁ BUSINESS ▁ INTERRUPTION) ▁ HOWEVER ▁ CAUSED ▁ AND ▁ ON ▁ ANY <encdom>  # ▁ THEORY ▁ OF ▁ LIABILITY, ▁ WHETHER ▁ IN ▁ CONTRACT, ▁ STRICT ▁ LIABILITY, ▁ OR ▁ TORT <encdom>  # ▁ (INCLUDING ▁ NEGLIGENCE ▁ OR ▁ OTHERWISE) ▁ ARISING ▁ IN ▁ ANY ▁ WAY ▁ OUT ▁ OF ▁ THE ▁ USE <encdom>  # ▁ OF ▁ THIS ▁ SOFTWARE, ▁ EVEN ▁ IF ▁ ADVISED ▁ OF ▁ THE ▁ POSSIBILITY ▁ OF ▁ SUCH ▁ DAMAGE. <encdom> from google . appengine . ext import webapp <newline> import model <newline> class SVNRevision ( webapp . RequestHandler ) : <newline> <indent> def get ( self , svn_revision_number ) : <newline> <indent> svn_revisions = model . SVNRevision . all ( ) . filter ( 'number ▁ =' , int ( svn_revision_number ) ) . order ( '-date' ) . fetch ( 1 ) <newline> if not svn_revisions : <newline> <indent> self . error ( 404 ) <newline> return <newline> <dedent> self . response . out . write ( svn_revisions [ 0 ] . to_xml ( ) ) <newline> <dedent> <dedent>
from django . template . defaultfilters import wordcount <newline> from django . test import SimpleTestCase <newline> from django . utils . safestring import mark_safe <newline> from . . utils import setup <newline> class WordcountTests ( SimpleTestCase ) : <newline> <indent> @ setup ( { 'wordcount01' : '{% ▁ autoescape ▁ off ▁ %}{{ ▁ a|wordcount ▁ }} ▁ {{ ▁ b|wordcount ▁ }}{% ▁ endautoescape ▁ %}' } ) <newline> def test_wordcount01 ( self ) : <newline> <indent> output = self . engine . render_to_string ( 'wordcount01' , { 'a' : 'a ▁ & ▁ b' , 'b' : mark_safe ( 'a ▁ &amp; ▁ b' ) } ) <newline> self . assertEqual ( output , '3 ▁ 3' ) <newline> <dedent> @ setup ( { 'wordcount02' : '{{ ▁ a|wordcount ▁ }} ▁ {{ ▁ b|wordcount ▁ }}' } ) <newline> def test_wordcount02 ( self ) : <newline> <indent> output = self . engine . render_to_string ( 'wordcount02' , { 'a' : 'a ▁ & ▁ b' , 'b' : mark_safe ( 'a ▁ &amp; ▁ b' ) } ) <newline> self . assertEqual ( output , '3 ▁ 3' ) <newline> <dedent> <dedent> class FunctionTests ( SimpleTestCase ) : <newline> <indent> def test_empty_string ( self ) : <newline> <indent> self . assertEqual ( wordcount ( '' ) , 0 ) <newline> <dedent> def test_count_one ( self ) : <newline> <indent> self . assertEqual ( wordcount ( 'oneword' ) , 1 ) <newline> <dedent> def test_count_multiple ( self ) : <newline> <indent> self . assertEqual ( wordcount ( 'lots ▁ of ▁ words' ) , 3 ) <newline> <dedent> def test_non_string_input ( self ) : <newline> <indent> self . assertEqual ( wordcount ( 123 ) , 1 ) <newline> <dedent> <dedent>
 # ▁ The ▁ MIT ▁ License ▁ (MIT) <encdom>  # ▁ Copyright ▁ (c) ▁ Tavendo ▁ GmbH <encdom>  # ▁ Permission ▁ is ▁ hereby ▁ granted, ▁ free ▁ of ▁ charge, ▁ to ▁ any ▁ person ▁ obtaining ▁ a ▁ copy <encdom>  # ▁ of ▁ this ▁ software ▁ and ▁ associated ▁ documentation ▁ files ▁ (the ▁"Software"), ▁ to ▁ deal <encdom>  # ▁ in ▁ the ▁ Software ▁ without ▁ restriction, ▁ including ▁ without ▁ limitation ▁ the ▁ rights <encdom>  # ▁ to ▁ use, ▁ copy, ▁ modify, ▁ merge, ▁ publish, ▁ distribute, ▁ sublicense, ▁ and/or ▁ sell <encdom>  # ▁ copies ▁ of ▁ the ▁ Software, ▁ and ▁ to ▁ permit ▁ persons ▁ to ▁ whom ▁ the ▁ Software ▁ is <encdom>  # ▁ furnished ▁ to ▁ do ▁ so, ▁ subject ▁ to ▁ the ▁ following ▁ conditions: <encdom>  # ▁ The ▁ above ▁ copyright ▁ notice ▁ and ▁ this ▁ permission ▁ notice ▁ shall ▁ be ▁ included ▁ in <encdom>  # ▁ all ▁ copies ▁ or ▁ substantial ▁ portions ▁ of ▁ the ▁ Software. <encdom>  # ▁ THE ▁ SOFTWARE ▁ IS ▁ PROVIDED ▁"AS ▁ IS", ▁ WITHOUT ▁ WARRANTY ▁ OF ▁ ANY ▁ KIND, ▁ EXPRESS ▁ OR <encdom>  # ▁ IMPLIED, ▁ INCLUDING ▁ BUT ▁ NOT ▁ LIMITED ▁ TO ▁ THE ▁ WARRANTIES ▁ OF ▁ MERCHANTABILITY, <encdom>  # ▁ FITNESS ▁ FOR ▁ A ▁ PARTICULAR ▁ PURPOSE ▁ AND ▁ NONINFRINGEMENT. ▁ IN ▁ NO ▁ EVENT ▁ SHALL ▁ THE <encdom>  # ▁ AUTHORS ▁ OR ▁ COPYRIGHT ▁ HOLDERS ▁ BE ▁ LIABLE ▁ FOR ▁ ANY ▁ CLAIM, ▁ DAMAGES ▁ OR ▁ OTHER <encdom>  # ▁ LIABILITY, ▁ WHETHER ▁ IN ▁ AN ▁ ACTION ▁ OF ▁ CONTRACT, ▁ TORT ▁ OR ▁ OTHERWISE, ▁ ARISING ▁ FROM, <encdom>  # ▁ OUT ▁ OF ▁ OR ▁ IN ▁ CONNECTION ▁ WITH ▁ THE ▁ SOFTWARE ▁ OR ▁ THE ▁ USE ▁ OR ▁ OTHER ▁ DEALINGS ▁ IN <encdom>  # ▁ THE ▁ SOFTWARE. <encdom> try : <newline> <indent> import asyncio <newline> <dedent> except ImportError : <newline>  # ▁ Trollius ▁ >= ▁ 0.3 ▁ was ▁ renamed <encdom> <indent> import trollius as asyncio <newline> <dedent> from os import environ <newline> from autobahn . asyncio . wamp import ApplicationSession , ApplicationRunner <newline> class Component ( ApplicationSession ) : <newline> <indent>  """ <strnewline> ▁ An ▁ application ▁ component ▁ providing ▁ procedures ▁ with ▁ different ▁ kinds <strnewline> ▁ of ▁ arguments. <strnewline> ▁ """  <newline> @ asyncio . coroutine <newline> def onJoin ( self , details ) : <newline> <indent> def ping ( ) : <newline> <indent> return <newline> <dedent> def add2 ( a , b ) : <newline> <indent> return a + b <newline> <dedent> def stars ( nick = "somebody" , stars = 0 ) : <newline> <indent> return u"{} ▁ starred ▁ {}x" . format ( nick , stars ) <newline>  # ▁ noinspection ▁ PyUnusedLocal <encdom> <dedent> def orders ( product , limit = 5 ) : <newline> <indent> return [ u"Product ▁ {}" . format ( i ) for i in range ( 50 ) ] [ : limit ] <newline> <dedent> def arglen ( * args , ** kwargs ) : <newline> <indent> return [ len ( args ) , len ( kwargs ) ] <newline> <dedent> yield from self . register ( ping , u'com.arguments.ping' ) <newline> yield from self . register ( add2 , u'com.arguments.add2' ) <newline> yield from self . register ( stars , u'com.arguments.stars' ) <newline> yield from self . register ( orders , u'com.arguments.orders' ) <newline> yield from self . register ( arglen , u'com.arguments.arglen' ) <newline> print ( "Registered ▁ methods; ▁ ready ▁ for ▁ frontend." ) <newline> <dedent> <dedent> if __name__ == '__main__' : <newline> <indent> runner = ApplicationRunner ( environ . get ( "AUTOBAHN_DEMO_ROUTER" , u"ws://127.0.0.1:8080/ws" ) , u"crossbardemo" , debug = False ,  # ▁ optional; ▁ log ▁ even ▁ more ▁ details <encdom> ) <newline> runner . run ( Component ) <newline> <dedent>
 ''' <strnewline> Created ▁ on ▁ Jun ▁ 14, ▁ 2011 <strnewline> <strnewline> @author: ▁ lebleu1 <strnewline> '''  <newline> import unittest <newline> from network . ipAddress import IpAddress <newline> class Test ( unittest . TestCase ) : <newline> <indent> def testPack ( self ) : <newline> <indent> address = IpAddress ( "192.168.1.12" ) <newline> self . assertEquals ( "\xC0\xA8\x01\x0C" , address . pack ( ) ) <newline> <dedent> <dedent>
 # ▁ Copyright ▁ (C) ▁ 2012 ▁ Massimo ▁ Santini ▁ <massimo.santini@unimi.it> <encdom>  # ▁ This ▁ file ▁ is ▁ part ▁ of ▁ Learning-Week-2012-Software. <encdom>  # ▁ Learning-Week-2012-Software ▁ is ▁ free ▁ software: ▁ you ▁ can ▁ redistribute ▁ it ▁ and/or <encdom>  # ▁ modify ▁ it ▁ under ▁ the ▁ terms ▁ of ▁ the ▁ GNU ▁ General ▁ Public ▁ License ▁ as ▁ published ▁ by <encdom>  # ▁ the ▁ Free ▁ Software ▁ Foundation, ▁ either ▁ version ▁ 3 ▁ of ▁ the ▁ License, ▁ or ▁ (at ▁ your <encdom>  # ▁ option) ▁ any ▁ later ▁ version. <encdom>  # ▁ Learning-Week-2012-Software ▁ is ▁ distributed ▁ in ▁ the ▁ hope ▁ that ▁ it ▁ will ▁ be <encdom>  # ▁ useful, ▁ but ▁ WITHOUT ▁ ANY ▁ WARRANTY; ▁ without ▁ even ▁ the ▁ implied ▁ warranty ▁ of <encdom>  # ▁ MERCHANTABILITY ▁ or ▁ FITNESS ▁ FOR ▁ A ▁ PARTICULAR ▁ PURPOSE. <tabsymbol> See ▁ the ▁ GNU ▁ General <encdom>  # ▁ Public ▁ License ▁ for ▁ more ▁ details. <encdom>  # ▁ You ▁ should ▁ have ▁ received ▁ a ▁ copy ▁ of ▁ the ▁ GNU ▁ General ▁ Public ▁ License ▁ along ▁ with <encdom>  # ▁ Learning-Week-2012-Software ▁ If ▁ not, ▁ see ▁ <http://www.gnu.org/licenses/>. <encdom> from . usr import usr <newline> from . img import img <newline> from . gby import gby <newline> from . xml import xml <newline> APPLICATIONS = { 'usr' : usr , 'img' : img , 'gby' : gby , 'xml' : xml , } <newline>
from django . contrib . gis . gdal . base import GDALBase <newline> from django . contrib . gis . gdal . error import GDALException , OGRIndexError <newline> from django . contrib . gis . gdal . field import Field <newline> from django . contrib . gis . gdal . geometries import OGRGeometry , OGRGeomType <newline> from django . contrib . gis . gdal . prototypes import ds as capi , geom as geom_api <newline> from django . utils import six <newline> from django . utils . encoding import force_bytes , force_text <newline> from django . utils . six . moves import range <newline>  # ▁ For ▁ more ▁ information, ▁ see ▁ the ▁ OGR ▁ C ▁ API ▁ source ▁ code: <encdom>  # ▁ http://www.gdal.org/ogr/ogr__api_8h.html <encdom>  # ▁ The ▁ OGR_F_* ▁ routines ▁ are ▁ relevant ▁ here. <encdom> class Feature ( GDALBase ) : <newline> <indent>  """ <strnewline> ▁ This ▁ class ▁ that ▁ wraps ▁ an ▁ OGR ▁ Feature, ▁ needs ▁ to ▁ be ▁ instantiated <strnewline> ▁ from ▁ a ▁ Layer ▁ object. <strnewline> ▁ """  <newline> def __init__ ( self , feat , layer ) : <newline> <indent>  """ <strnewline> ▁ Initializes ▁ Feature ▁ from ▁ a ▁ pointer ▁ and ▁ its ▁ Layer ▁ object. <strnewline> ▁ """  <newline> if not feat : <newline> <indent> raise GDALException ( 'Cannot ▁ create ▁ OGR ▁ Feature, ▁ invalid ▁ pointer ▁ given.' ) <newline> <dedent> self . ptr = feat <newline> self . _layer = layer <newline> <dedent> def __del__ ( self ) : <newline> <indent> "Releases ▁ a ▁ reference ▁ to ▁ this ▁ object." <newline> if self . _ptr and capi : <newline> <indent> capi . destroy_feature ( self . _ptr ) <newline> <dedent> <dedent> def __getitem__ ( self , index ) : <newline> <indent>  """ <strnewline> ▁ Gets ▁ the ▁ Field ▁ object ▁ at ▁ the ▁ specified ▁ index, ▁ which ▁ may ▁ be ▁ either <strnewline> ▁ an ▁ integer ▁ or ▁ the ▁ Field's ▁ string ▁ label. ▁ Note ▁ that ▁ the ▁ Field ▁ object <strnewline> ▁ is ▁ not ▁ the ▁ field's ▁ _value_ ▁ -- ▁ use ▁ the ▁ `get` ▁ method ▁ instead ▁ to <strnewline> ▁ retrieve ▁ the ▁ value ▁ (e.g. ▁ an ▁ integer) ▁ instead ▁ of ▁ a ▁ Field ▁ instance. <strnewline> ▁ """  <newline> if isinstance ( index , six . string_types ) : <newline> <indent> i = self . index ( index ) <newline> <dedent> else : <newline> <indent> if index < 0 or index > self . num_fields : <newline> <indent> raise OGRIndexError ( 'index ▁ out ▁ of ▁ range' ) <newline> <dedent> i = index <newline> <dedent> return Field ( self , i ) <newline> <dedent> def __iter__ ( self ) : <newline> <indent> "Iterates ▁ over ▁ each ▁ field ▁ in ▁ the ▁ Feature." <newline> for i in range ( self . num_fields ) : <newline> <indent> yield self [ i ] <newline> <dedent> <dedent> def __len__ ( self ) : <newline> <indent> "Returns ▁ the ▁ count ▁ of ▁ fields ▁ in ▁ this ▁ feature." <newline> return self . num_fields <newline> <dedent> def __str__ ( self ) : <newline> <indent> "The ▁ string ▁ name ▁ of ▁ the ▁ feature." <newline> return 'Feature ▁ FID ▁ %d ▁ in ▁ Layer<%s>' % ( self . fid , self . layer_name ) <newline> <dedent> def __eq__ ( self , other ) : <newline> <indent> "Does ▁ equivalence ▁ testing ▁ on ▁ the ▁ features." <newline> return bool ( capi . feature_equal ( self . ptr , other . _ptr ) ) <newline>  # ▁ # # # # ▁ Feature ▁ Properties ▁ # # # # <encdom> <dedent> @ property <newline> def encoding ( self ) : <newline> <indent> return self . _layer . _ds . encoding <newline> <dedent> @ property <newline> def fid ( self ) : <newline> <indent> "Returns ▁ the ▁ feature ▁ identifier." <newline> return capi . get_fid ( self . ptr ) <newline> <dedent> @ property <newline> def layer_name ( self ) : <newline> <indent> "Returns ▁ the ▁ name ▁ of ▁ the ▁ layer ▁ for ▁ the ▁ feature." <newline> name = capi . get_feat_name ( self . _layer . _ldefn ) <newline> return force_text ( name , self . encoding , strings_only = True ) <newline> <dedent> @ property <newline> def num_fields ( self ) : <newline> <indent> "Returns ▁ the ▁ number ▁ of ▁ fields ▁ in ▁ the ▁ Feature." <newline> return capi . get_feat_field_count ( self . ptr ) <newline> <dedent> @ property <newline> def fields ( self ) : <newline> <indent> "Returns ▁ a ▁ list ▁ of ▁ fields ▁ in ▁ the ▁ Feature." <newline> return [ capi . get_field_name ( capi . get_field_defn ( self . _layer . _ldefn , i ) ) for i in range ( self . num_fields ) ] <newline> <dedent> @ property <newline> def geom ( self ) : <newline> <indent> "Returns ▁ the ▁ OGR ▁ Geometry ▁ for ▁ this ▁ Feature." <newline>  # ▁ Retrieving ▁ the ▁ geometry ▁ pointer ▁ for ▁ the ▁ feature. <encdom> geom_ptr = capi . get_feat_geom_ref ( self . ptr ) <newline> return OGRGeometry ( geom_api . clone_geom ( geom_ptr ) ) <newline> <dedent> @ property <newline> def geom_type ( self ) : <newline> <indent> "Returns ▁ the ▁ OGR ▁ Geometry ▁ Type ▁ for ▁ this ▁ Feture." <newline> return OGRGeomType ( capi . get_fd_geom_type ( self . _layer . _ldefn ) ) <newline>  # ▁ # # # # ▁ Feature ▁ Methods ▁ # # # # <encdom> <dedent> def get ( self , field ) : <newline> <indent>  """ <strnewline> ▁ Returns ▁ the ▁ value ▁ of ▁ the ▁ field, ▁ instead ▁ of ▁ an ▁ instance ▁ of ▁ the ▁ Field <strnewline> ▁ object. ▁ May ▁ take ▁ a ▁ string ▁ of ▁ the ▁ field ▁ name ▁ or ▁ a ▁ Field ▁ object ▁ as <strnewline> ▁ parameters. <strnewline> ▁ """  <newline> field_name = getattr ( field , 'name' , field ) <newline> return self [ field_name ] . value <newline> <dedent> def index ( self , field_name ) : <newline> <indent> "Returns ▁ the ▁ index ▁ of ▁ the ▁ given ▁ field ▁ name." <newline> i = capi . get_field_index ( self . ptr , force_bytes ( field_name ) ) <newline> if i < 0 : <newline> <indent> raise OGRIndexError ( 'invalid ▁ OFT ▁ field ▁ name ▁ given: ▁"%s"' % field_name ) <newline> <dedent> return i <newline> <dedent> <dedent>
 # ▁ Gramps ▁ - ▁ a ▁ GTK+/GNOME ▁ based ▁ genealogy ▁ program <encdom>  # ▁ Copyright ▁ (C) ▁ 2001 ▁ David ▁ R. ▁ Hampton <encdom>  # ▁ Copyright ▁ (C) ▁ 2001-2006 ▁ Donald ▁ N. ▁ Allingham <encdom>  # ▁ Copyright ▁ (C) ▁ 2007 ▁ Brian ▁ G. ▁ Matherly <encdom>  # ▁ Copyright ▁ (C) ▁ 2010 ▁ Jakim ▁ Friant <encdom>  # ▁ This ▁ program ▁ is ▁ free ▁ software; ▁ you ▁ can ▁ redistribute ▁ it ▁ and/or ▁ modify <encdom>  # ▁ it ▁ under ▁ the ▁ terms ▁ of ▁ the ▁ GNU ▁ General ▁ Public ▁ License ▁ as ▁ published ▁ by <encdom>  # ▁ the ▁ Free ▁ Software ▁ Foundation; ▁ either ▁ version ▁ 2 ▁ of ▁ the ▁ License, ▁ or <encdom>  # ▁ (at ▁ your ▁ option) ▁ any ▁ later ▁ version. <encdom>  # ▁ This ▁ program ▁ is ▁ distributed ▁ in ▁ the ▁ hope ▁ that ▁ it ▁ will ▁ be ▁ useful, <encdom>  # ▁ but ▁ WITHOUT ▁ ANY ▁ WARRANTY; ▁ without ▁ even ▁ the ▁ implied ▁ warranty ▁ of <encdom>  # ▁ MERCHANTABILITY ▁ or ▁ FITNESS ▁ FOR ▁ A ▁ PARTICULAR ▁ PURPOSE. ▁ See ▁ the <encdom>  # ▁ GNU ▁ General ▁ Public ▁ License ▁ for ▁ more ▁ details. <encdom>  # ▁ You ▁ should ▁ have ▁ received ▁ a ▁ copy ▁ of ▁ the ▁ GNU ▁ General ▁ Public ▁ License <encdom>  # ▁ along ▁ with ▁ this ▁ program; ▁ if ▁ not, ▁ write ▁ to ▁ the ▁ Free ▁ Software <encdom>  # ▁ Foundation, ▁ Inc., ▁ 51 ▁ Franklin ▁ Street, ▁ Fifth ▁ Floor, ▁ Boston, ▁ MA ▁ 02110-1301 ▁ USA. <encdom>  # ▁ gen.plug.report.__init__ <encdom> "Report ▁ Generation ▁ Framework" <newline> from . _constants import * <newline> from . _reportbase import Report <newline> from . _bibliography import Bibliography , Citation <newline> from . _options import MenuReportOptions , ReportOptions , DocOptions <newline> from . _book import BookList , Book , BookItem , append_styles <newline>
 """ <strnewline> [2017-08-03] ▁ Challenge ▁ # 325 ▁ [Intermediate] ▁ Arrow ▁ maze <strnewline> <strnewline> https://www.reddit.com/r/dailyprogrammer/comments/6rb98p/20170803_challenge_325_intermediate_arrow_maze/ <strnewline> <strnewline> # Description <strnewline> We ▁ want ▁ to ▁ return ▁ home, ▁ but ▁ we ▁ have ▁ to ▁ go ▁ trough ▁ an ▁ [arrow ▁ maze](http://imgur.com/TjYhSB4). <strnewline> We ▁ start ▁ at ▁ [a ▁ certain ▁ point](http://imgur.com/QTxERGr) ▁ an ▁ in ▁ a ▁ arrow ▁ maze ▁ you ▁ can ▁ only ▁ follow ▁ [the ▁ direction ▁ of ▁ the <strnewline> arrow](http://imgur.com/a097dDJ). <strnewline> At ▁ each ▁ node ▁ in ▁ the ▁ maze ▁ we ▁ can ▁ decide ▁ to ▁ change ▁ direction ▁ (depending ▁ on ▁ the ▁ new ▁ node) ▁ or ▁ follow ▁ the ▁ direction ▁ we ▁ where <strnewline> going. <strnewline> When ▁ done ▁ right, ▁ we ▁ should ▁ have ▁ a ▁ path ▁ to ▁ [home](http://imgur.com/UqD5Brf) ▁ <strnewline> # Formal ▁ Inputs ▁ & ▁ Outputs <strnewline> # # Input ▁ description <strnewline> You ▁ recieve ▁ on ▁ the ▁ first ▁ line ▁ the ▁ coordinates ▁ of ▁ the ▁ node ▁ where ▁ you ▁ will ▁ start ▁ and ▁ after ▁ that ▁ the ▁ maze. <strnewline> `n ▁ ne ▁ e ▁ se ▁ s ▁ sw ▁ w ▁ nw` ▁ are ▁ the ▁ direction ▁ you ▁ can ▁ travel ▁ to ▁ and ▁ `h` ▁ is ▁ your ▁ target ▁ in ▁ the ▁ maze. <strnewline> ▁ (2,0) <strnewline> ▁ e ▁ se ▁ se ▁ sw ▁ s <strnewline> ▁ s ▁ nw ▁ nw ▁ n ▁ w <strnewline> ▁ ne ▁ s ▁ h ▁ e ▁ sw <strnewline> ▁ se ▁ n ▁ w ▁ ne ▁ sw <strnewline> ▁ ne ▁ nw ▁ nw ▁ n ▁ n <strnewline> I ▁ have ▁ added ▁ extra ▁ whitespace ▁ for ▁ formatting ▁ reasons <strnewline> # # Output ▁ description <strnewline> You ▁ need ▁ to ▁ output ▁ the ▁ path ▁ to ▁ the ▁ center. <strnewline> ▁ (2,0) <strnewline> ▁ (3,1) <strnewline> ▁ (3,0) <strnewline> ▁ (1,2) <strnewline> ▁ (1,3) <strnewline> ▁ (1,1) <strnewline> ▁ (0,0) <strnewline> ▁ (4,0) <strnewline> ▁ (4,1) <strnewline> ▁ (0,1) <strnewline> ▁ (0,4) <strnewline> ▁ (2,2) <strnewline> you ▁ can ▁ get ▁ creative ▁ and ▁ use ▁ acii ▁ art ▁ or ▁ even ▁ better <strnewline> # Notes/Hints <strnewline> If ▁ you ▁ have ▁ a ▁ hard ▁ time ▁ starting ▁ from ▁ the ▁ beginning, ▁ then ▁ backtracking ▁ might ▁ be ▁ a ▁ good ▁ option. <strnewline> # Finally <strnewline> Have ▁ a ▁ good ▁ challenge ▁ idea? <strnewline> Consider ▁ submitting ▁ it ▁ to ▁ /r/dailyprogrammer_ideas <strnewline> """  <newline> def main ( ) : <newline> <indent> pass <newline> <dedent> if __name__ == "__main__" : <newline> <indent> main ( ) <newline> <dedent>
 # ▁ Copyright ▁ (c) ▁ 2016 ▁ Mirantis, ▁ Inc. <encdom>  # ▁ All ▁ Rights ▁ Reserved. <encdom>  # ▁ Licensed ▁ under ▁ the ▁ Apache ▁ License, ▁ Version ▁ 2.0 ▁ (the ▁"License"); ▁ you ▁ may <encdom>  # ▁ not ▁ use ▁ this ▁ file ▁ except ▁ in ▁ compliance ▁ with ▁ the ▁ License. ▁ You ▁ may ▁ obtain <encdom>  # ▁ a ▁ copy ▁ of ▁ the ▁ License ▁ at <encdom>  # ▁ http://www.apache.org/licenses/LICENSE-2.0 <encdom>  # ▁ Unless ▁ required ▁ by ▁ applicable ▁ law ▁ or ▁ agreed ▁ to ▁ in ▁ writing, ▁ software <encdom>  # ▁ distributed ▁ under ▁ the ▁ License ▁ is ▁ distributed ▁ on ▁ an ▁"AS ▁ IS" ▁ BASIS, ▁ WITHOUT <encdom>  # ▁ WARRANTIES ▁ OR ▁ CONDITIONS ▁ OF ▁ ANY ▁ KIND, ▁ either ▁ express ▁ or ▁ implied. ▁ See ▁ the <encdom>  # ▁ License ▁ for ▁ the ▁ specific ▁ language ▁ governing ▁ permissions ▁ and ▁ limitations <encdom>  # ▁ under ▁ the ▁ License. <encdom> from tempest . common import credentials_factory as common_creds <newline> from tempest . common import dynamic_creds <newline> from tempest import config <newline> from tempest . lib import base <newline> from murano_tempest_tests import clients <newline> from murano_tempest_tests import utils <newline> CONF = config . CONF <newline> class BaseArtifactsTest ( base . BaseTestCase ) : <newline> <indent>  """ Base ▁ test ▁ class ▁ for ▁ Murano ▁ Glare ▁ tests. """  <newline> @ classmethod <newline> def setUpClass ( cls ) : <newline> <indent> super ( BaseArtifactsTest , cls ) . setUpClass ( ) <newline> cls . resource_setup ( ) <newline> <dedent> @ classmethod <newline> def tearDownClass ( cls ) : <newline> <indent> cls . resource_cleanup ( ) <newline> super ( BaseArtifactsTest , cls ) . tearDownClass ( ) <newline> <dedent> @ classmethod <newline> def get_client_with_isolated_creds ( cls , type_of_creds = "admin" ) : <newline> <indent> creds = cls . get_configured_isolated_creds ( type_of_creds = type_of_creds ) <newline> os = clients . Manager ( credentials = creds ) <newline> client = os . artifacts_client <newline> return client <newline> <dedent> @ classmethod <newline> def get_configured_isolated_creds ( cls , type_of_creds = 'admin' ) : <newline> <indent> identity_version = CONF . identity . auth_version <newline> if identity_version == 'v3' : <newline> <indent> cls . admin_role = CONF . identity . admin_role <newline> <dedent> else : <newline> <indent> cls . admin_role = 'admin' <newline> <dedent> cls . dynamic_cred = dynamic_creds . DynamicCredentialProvider ( identity_version = CONF . identity . auth_version , name = cls . __name__ , admin_role = cls . admin_role , admin_creds = common_creds . get_configured_admin_credentials ( 'identity_admin' ) ) <newline> if type_of_creds == 'primary' : <newline> <indent> creds = cls . dynamic_cred . get_primary_creds ( ) <newline> <dedent> elif type_of_creds == 'admin' : <newline> <indent> creds = cls . dynamic_cred . get_admin_creds ( ) <newline> <dedent> elif type_of_creds == 'alt' : <newline> <indent> creds = cls . dynamic_cred . get_alt_creds ( ) <newline> <dedent> else : <newline> <indent> creds = cls . dynamic_cred . get_credentials ( type_of_creds ) <newline> <dedent> cls . dynamic_cred . type_of_creds = type_of_creds <newline> return creds . credentials <newline> <dedent> @ classmethod <newline> def verify_nonempty ( cls , * args ) : <newline> <indent> if not all ( args ) : <newline> <indent> msg = "Missing ▁ API ▁ credentials ▁ in ▁ configuration." <newline> raise cls . skipException ( msg ) <newline> <dedent> <dedent> @ classmethod <newline> def resource_setup ( cls ) : <newline> <indent> if not CONF . service_available . murano : <newline> <indent> skip_msg = "Murano ▁ is ▁ disabled" <newline> raise cls . skipException ( skip_msg ) <newline> <dedent> if not hasattr ( cls , "os" ) : <newline> <indent> creds = cls . get_configured_isolated_creds ( type_of_creds = 'primary' ) <newline> cls . os = clients . Manager ( credentials = creds ) <newline> <dedent> cls . artifacts_client = cls . os . artifacts_client <newline> cls . application_catalog_client = cls . os . application_catalog_client <newline> <dedent> @ classmethod <newline> def resource_cleanup ( cls ) : <newline> <indent> cls . clear_isolated_creds ( ) <newline> <dedent> @ classmethod <newline> def clear_isolated_creds ( cls ) : <newline> <indent> if hasattr ( cls , "dynamic_cred" ) : <newline> <indent> cls . dynamic_cred . clear_creds ( ) <newline> <dedent> <dedent> @ classmethod <newline> def upload_package ( cls , application_name , version = None , require = None ) : <newline> <indent> abs_archive_path , dir_with_archive , archive_name = utils . prepare_package ( application_name , version = version , add_class_name = True , require = require ) <newline> package = cls . artifacts_client . upload_package ( application_name , archive_name , dir_with_archive , { "categories" : [ ] , "tags" : [ ] , 'is_public' : False } ) <newline> return package , abs_archive_path <newline> <dedent> @ staticmethod <newline> def create_obj_model ( package ) : <newline> <indent> return { "name" : package [ 'display_name' ] , "?" : { "type" : package [ 'name' ] , "id" : utils . generate_uuid ( ) , "classVersion" : package [ 'version' ] } } <newline> <dedent> <dedent>
 # !/usr/bin/env ▁ python <encdom>  # ▁ Copyright ▁ (c) ▁ 2012 ▁ Google ▁ Inc. ▁ All ▁ rights ▁ reserved. <encdom>  # ▁ Use ▁ of ▁ this ▁ source ▁ code ▁ is ▁ governed ▁ by ▁ a ▁ BSD-style ▁ license ▁ that ▁ can ▁ be <encdom>  # ▁ found ▁ in ▁ the ▁ LICENSE ▁ file. <encdom>  """ <strnewline> Verifies ▁ that ▁ a ▁ dependency ▁ on ▁ two ▁ gyp ▁ files ▁ with ▁ the ▁ same ▁ name ▁ do ▁ not ▁ create ▁ a <strnewline> uid ▁ collision ▁ in ▁ the ▁ resulting ▁ generated ▁ xcode ▁ file. <strnewline> """  <newline> import TestGyp <newline> import sys <newline> test = TestGyp . TestGyp ( ) <newline> test . run_gyp ( 'test.gyp' , chdir = 'library' ) <newline> test . pass_test ( ) <newline>
 # ▁ Copyright ▁ (c) ▁ Twisted ▁ Matrix ▁ Laboratories. <encdom>  # ▁ See ▁ LICENSE ▁ for ▁ details. <encdom>  """ <strnewline> Service ▁ architecture ▁ for ▁ Twisted. <strnewline> <strnewline> Services ▁ are ▁ arranged ▁ in ▁ a ▁ hierarchy. ▁ At ▁ the ▁ leafs ▁ of ▁ the ▁ hierarchy, <strnewline> the ▁ services ▁ which ▁ actually ▁ interact ▁ with ▁ the ▁ outside ▁ world ▁ are ▁ started. <strnewline> Services ▁ can ▁ be ▁ named ▁ or ▁ anonymous ▁ -- ▁ usually, ▁ they ▁ will ▁ be ▁ named ▁ if <strnewline> there ▁ is ▁ need ▁ to ▁ access ▁ them ▁ through ▁ the ▁ hierarchy ▁ (from ▁ a ▁ parent ▁ or <strnewline> a ▁ sibling). <strnewline> <strnewline> Maintainer: ▁ Moshe ▁ Zadka <strnewline> """  <newline> from zope . interface import implements , Interface , Attribute <newline> from twisted . python . reflect import namedAny <newline> from twisted . python import components <newline> from twisted . internet import defer <newline> from twisted . persisted import sob <newline> from twisted . plugin import IPlugin <newline> class IServiceMaker ( Interface ) : <newline> <indent>  """ <strnewline> ▁ An ▁ object ▁ which ▁ can ▁ be ▁ used ▁ to ▁ construct ▁ services ▁ in ▁ a ▁ flexible <strnewline> ▁ way. <strnewline> <strnewline> ▁ This ▁ interface ▁ should ▁ most ▁ often ▁ be ▁ implemented ▁ along ▁ with <strnewline> ▁ L{twisted.plugin.IPlugin}, ▁ and ▁ will ▁ most ▁ often ▁ be ▁ used ▁ by ▁ the <strnewline> ▁'twistd' ▁ command. <strnewline> ▁ """  <newline> tapname = Attribute ( "A ▁ short ▁ string ▁ naming ▁ this ▁ Twisted ▁ plugin, ▁ for ▁ example ▁'web' ▁ or ▁ " "'pencil'. ▁ This ▁ name ▁ will ▁ be ▁ used ▁ as ▁ the ▁ subcommand ▁ of ▁'twistd'." ) <newline> description = Attribute ( "A ▁ brief ▁ summary ▁ of ▁ the ▁ features ▁ provided ▁ by ▁ this ▁ " "Twisted ▁ application ▁ plugin." ) <newline> options = Attribute ( "A ▁ C{twisted.python.usage.Options} ▁ subclass ▁ defining ▁ the ▁ " "configuration ▁ options ▁ for ▁ this ▁ application." ) <newline> def makeService ( options ) : <newline> <indent>  """ <strnewline> ▁ Create ▁ and ▁ return ▁ an ▁ object ▁ providing <strnewline> ▁ L{twisted.application.service.IService}. <strnewline> <strnewline> ▁ @param ▁ options: ▁ A ▁ mapping ▁ (typically ▁ a ▁ C{dict} ▁ or <strnewline> ▁ L{twisted.python.usage.Options} ▁ instance) ▁ of ▁ configuration <strnewline> ▁ options ▁ to ▁ desired ▁ configuration ▁ values. <strnewline> ▁ """  <newline> <dedent> <dedent> class ServiceMaker ( object ) : <newline> <indent>  """ <strnewline> ▁ Utility ▁ class ▁ to ▁ simplify ▁ the ▁ definition ▁ of ▁ L{IServiceMaker} ▁ plugins. <strnewline> ▁ """  <newline> implements ( IPlugin , IServiceMaker ) <newline> def __init__ ( self , name , module , description , tapname ) : <newline> <indent> self . name = name <newline> self . module = module <newline> self . description = description <newline> self . tapname = tapname <newline> <dedent> def options ( ) : <newline> <indent> def get ( self ) : <newline> <indent> return namedAny ( self . module ) . Options <newline> <dedent> return get , <newline> <dedent> options = property ( * options ( ) ) <newline> def makeService ( ) : <newline> <indent> def get ( self ) : <newline> <indent> return namedAny ( self . module ) . makeService <newline> <dedent> return get , <newline> <dedent> makeService = property ( * makeService ( ) ) <newline> <dedent> class IService ( Interface ) : <newline> <indent>  """ <strnewline> ▁ A ▁ service. <strnewline> <strnewline> ▁ Run ▁ start-up ▁ and ▁ shut-down ▁ code ▁ at ▁ the ▁ appropriate ▁ times. <strnewline> <strnewline> ▁ @type ▁ name: ▁ C{string} <strnewline> ▁ @ivar ▁ name: ▁ The ▁ name ▁ of ▁ the ▁ service ▁ (or ▁ None) <strnewline> ▁ @type ▁ running: ▁ C{boolean} <strnewline> ▁ @ivar ▁ running: ▁ Whether ▁ the ▁ service ▁ is ▁ running. <strnewline> ▁ """  <newline> def setName ( name ) : <newline> <indent>  """ <strnewline> ▁ Set ▁ the ▁ name ▁ of ▁ the ▁ service. <strnewline> <strnewline> ▁ @type ▁ name: ▁ C{str} <strnewline> ▁ @raise ▁ RuntimeError: ▁ Raised ▁ if ▁ the ▁ service ▁ already ▁ has ▁ a ▁ parent. <strnewline> ▁ """  <newline> <dedent> def setServiceParent ( parent ) : <newline> <indent>  """ <strnewline> ▁ Set ▁ the ▁ parent ▁ of ▁ the ▁ service. ▁ This ▁ method ▁ is ▁ responsible ▁ for ▁ setting <strnewline> ▁ the ▁ C{parent} ▁ attribute ▁ on ▁ this ▁ service ▁ (the ▁ child ▁ service). <strnewline> <strnewline> ▁ @type ▁ parent: ▁ L{IServiceCollection} <strnewline> ▁ @raise ▁ RuntimeError: ▁ Raised ▁ if ▁ the ▁ service ▁ already ▁ has ▁ a ▁ parent <strnewline> ▁ or ▁ if ▁ the ▁ service ▁ has ▁ a ▁ name ▁ and ▁ the ▁ parent ▁ already ▁ has ▁ a ▁ child <strnewline> ▁ by ▁ that ▁ name. <strnewline> ▁ """  <newline> <dedent> def disownServiceParent ( ) : <newline> <indent>  """ <strnewline> ▁ Use ▁ this ▁ API ▁ to ▁ remove ▁ an ▁ L{IService} ▁ from ▁ an ▁ L{IServiceCollection}. <strnewline> <strnewline> ▁ This ▁ method ▁ is ▁ used ▁ symmetrically ▁ with ▁ L{setServiceParent} ▁ in ▁ that ▁ it <strnewline> ▁ sets ▁ the ▁ C{parent} ▁ attribute ▁ on ▁ the ▁ child. <strnewline> <strnewline> ▁ @rtype: ▁ L{Deferred<defer.Deferred>} <strnewline> ▁ @return: ▁ a ▁ L{Deferred<defer.Deferred>} ▁ which ▁ is ▁ triggered ▁ when ▁ the <strnewline> ▁ service ▁ has ▁ finished ▁ shutting ▁ down. ▁ If ▁ shutting ▁ down ▁ is ▁ immediate, <strnewline> ▁ a ▁ value ▁ can ▁ be ▁ returned ▁ (usually, ▁ C{None}). <strnewline> ▁ """  <newline> <dedent> def startService ( ) : <newline> <indent>  """ <strnewline> ▁ Start ▁ the ▁ service. <strnewline> ▁ """  <newline> <dedent> def stopService ( ) : <newline> <indent>  """ <strnewline> ▁ Stop ▁ the ▁ service. <strnewline> <strnewline> ▁ @rtype: ▁ L{Deferred<defer.Deferred>} <strnewline> ▁ @return: ▁ a ▁ L{Deferred<defer.Deferred>} ▁ which ▁ is ▁ triggered ▁ when ▁ the <strnewline> ▁ service ▁ has ▁ finished ▁ shutting ▁ down. ▁ If ▁ shutting ▁ down ▁ is ▁ immediate, <strnewline> ▁ a ▁ value ▁ can ▁ be ▁ returned ▁ (usually, ▁ C{None}). <strnewline> ▁ """  <newline> <dedent> def privilegedStartService ( ) : <newline> <indent>  """ <strnewline> ▁ Do ▁ preparation ▁ work ▁ for ▁ starting ▁ the ▁ service. <strnewline> <strnewline> ▁ Here ▁ things ▁ which ▁ should ▁ be ▁ done ▁ before ▁ changing ▁ directory, <strnewline> ▁ root ▁ or ▁ shedding ▁ privileges ▁ are ▁ done. <strnewline> ▁ """  <newline> <dedent> <dedent> class Service : <newline> <indent>  """ <strnewline> ▁ Base ▁ class ▁ for ▁ services. <strnewline> <strnewline> ▁ Most ▁ services ▁ should ▁ inherit ▁ from ▁ this ▁ class. ▁ It ▁ handles ▁ the <strnewline> ▁ book-keeping ▁ reponsibilities ▁ of ▁ starting ▁ and ▁ stopping, ▁ as ▁ well <strnewline> ▁ as ▁ not ▁ serializing ▁ this ▁ book-keeping ▁ information. <strnewline> ▁ """  <newline> implements ( IService ) <newline> running = 0 <newline> name = None <newline> parent = None <newline> def __getstate__ ( self ) : <newline> <indent> dict = self . __dict__ . copy ( ) <newline> if "running" in dict : <newline> <indent> del dict [ 'running' ] <newline> <dedent> return dict <newline> <dedent> def setName ( self , name ) : <newline> <indent> if self . parent is not None : <newline> <indent> raise RuntimeError ( "cannot ▁ change ▁ name ▁ when ▁ parent ▁ exists" ) <newline> <dedent> self . name = name <newline> <dedent> def setServiceParent ( self , parent ) : <newline> <indent> if self . parent is not None : <newline> <indent> self . disownServiceParent ( ) <newline> <dedent> parent = IServiceCollection ( parent , parent ) <newline> self . parent = parent <newline> self . parent . addService ( self ) <newline> <dedent> def disownServiceParent ( self ) : <newline> <indent> d = self . parent . removeService ( self ) <newline> self . parent = None <newline> return d <newline> <dedent> def privilegedStartService ( self ) : <newline> <indent> pass <newline> <dedent> def startService ( self ) : <newline> <indent> self . running = 1 <newline> <dedent> def stopService ( self ) : <newline> <indent> self . running = 0 <newline> <dedent> <dedent> class IServiceCollection ( Interface ) : <newline> <indent>  """ <strnewline> ▁ Collection ▁ of ▁ services. <strnewline> <strnewline> ▁ Contain ▁ several ▁ services, ▁ and ▁ manage ▁ their ▁ start-up/shut-down. <strnewline> ▁ Services ▁ can ▁ be ▁ accessed ▁ by ▁ name ▁ if ▁ they ▁ have ▁ a ▁ name, ▁ and ▁ it <strnewline> ▁ is ▁ always ▁ possible ▁ to ▁ iterate ▁ over ▁ them. <strnewline> ▁ """  <newline> def getServiceNamed ( name ) : <newline> <indent>  """ <strnewline> ▁ Get ▁ the ▁ child ▁ service ▁ with ▁ a ▁ given ▁ name. <strnewline> <strnewline> ▁ @type ▁ name: ▁ C{str} <strnewline> ▁ @rtype: ▁ L{IService} <strnewline> ▁ @raise ▁ KeyError: ▁ Raised ▁ if ▁ the ▁ service ▁ has ▁ no ▁ child ▁ with ▁ the <strnewline> ▁ given ▁ name. <strnewline> ▁ """  <newline> <dedent> def __iter__ ( ) : <newline> <indent>  """ <strnewline> ▁ Get ▁ an ▁ iterator ▁ over ▁ all ▁ child ▁ services. <strnewline> ▁ """  <newline> <dedent> def addService ( service ) : <newline> <indent>  """ <strnewline> ▁ Add ▁ a ▁ child ▁ service. <strnewline> <strnewline> ▁ Only ▁ implementations ▁ of ▁ L{IService.setServiceParent} ▁ should ▁ use ▁ this <strnewline> ▁ method. <strnewline> <strnewline> ▁ @type ▁ service: ▁ L{IService} <strnewline> ▁ @raise ▁ RuntimeError: ▁ Raised ▁ if ▁ the ▁ service ▁ has ▁ a ▁ child ▁ with <strnewline> ▁ the ▁ given ▁ name. <strnewline> ▁ """  <newline> <dedent> def removeService ( service ) : <newline> <indent>  """ <strnewline> ▁ Remove ▁ a ▁ child ▁ service. <strnewline> <strnewline> ▁ Only ▁ implementations ▁ of ▁ L{IService.disownServiceParent} ▁ should <strnewline> ▁ use ▁ this ▁ method. <strnewline> <strnewline> ▁ @type ▁ service: ▁ L{IService} <strnewline> ▁ @raise ▁ ValueError: ▁ Raised ▁ if ▁ the ▁ given ▁ service ▁ is ▁ not ▁ a ▁ child. <strnewline> ▁ @rtype: ▁ L{Deferred<defer.Deferred>} <strnewline> ▁ @return: ▁ a ▁ L{Deferred<defer.Deferred>} ▁ which ▁ is ▁ triggered ▁ when ▁ the <strnewline> ▁ service ▁ has ▁ finished ▁ shutting ▁ down. ▁ If ▁ shutting ▁ down ▁ is ▁ immediate, <strnewline> ▁ a ▁ value ▁ can ▁ be ▁ returned ▁ (usually, ▁ C{None}). <strnewline> ▁ """  <newline> <dedent> <dedent> class MultiService ( Service ) : <newline> <indent>  """ <strnewline> ▁ Straightforward ▁ Service ▁ Container. <strnewline> <strnewline> ▁ Hold ▁ a ▁ collection ▁ of ▁ services, ▁ and ▁ manage ▁ them ▁ in ▁ a ▁ simplistic <strnewline> ▁ way. ▁ No ▁ service ▁ will ▁ wait ▁ for ▁ another, ▁ but ▁ this ▁ object ▁ itself <strnewline> ▁ will ▁ not ▁ finish ▁ shutting ▁ down ▁ until ▁ all ▁ of ▁ its ▁ child ▁ services <strnewline> ▁ will ▁ finish. <strnewline> ▁ """  <newline> implements ( IServiceCollection ) <newline> def __init__ ( self ) : <newline> <indent> self . services = [ ] <newline> self . namedServices = { } <newline> self . parent = None <newline> <dedent> def privilegedStartService ( self ) : <newline> <indent> Service . privilegedStartService ( self ) <newline> for service in self : <newline> <indent> service . privilegedStartService ( ) <newline> <dedent> <dedent> def startService ( self ) : <newline> <indent> Service . startService ( self ) <newline> for service in self : <newline> <indent> service . startService ( ) <newline> <dedent> <dedent> def stopService ( self ) : <newline> <indent> Service . stopService ( self ) <newline> l = [ ] <newline> services = list ( self ) <newline> services . reverse ( ) <newline> for service in services : <newline> <indent> l . append ( defer . maybeDeferred ( service . stopService ) ) <newline> <dedent> return defer . DeferredList ( l ) <newline> <dedent> def getServiceNamed ( self , name ) : <newline> <indent> return self . namedServices [ name ] <newline> <dedent> def __iter__ ( self ) : <newline> <indent> return iter ( self . services ) <newline> <dedent> def addService ( self , service ) : <newline> <indent> if service . name is not None : <newline> <indent> if service . name in self . namedServices : <newline> <indent> raise RuntimeError ( "cannot ▁ have ▁ two ▁ services ▁ with ▁ same ▁ name" " ▁'%s'" % service . name ) <newline> <dedent> self . namedServices [ service . name ] = service <newline> <dedent> self . services . append ( service ) <newline> if self . running : <newline>  # ▁ It ▁ may ▁ be ▁ too ▁ late ▁ for ▁ that, ▁ but ▁ we ▁ will ▁ do ▁ our ▁ best <encdom> <indent> service . privilegedStartService ( ) <newline> service . startService ( ) <newline> <dedent> <dedent> def removeService ( self , service ) : <newline> <indent> if service . name : <newline> <indent> del self . namedServices [ service . name ] <newline> <dedent> self . services . remove ( service ) <newline> if self . running : <newline>  # ▁ Returning ▁ this ▁ so ▁ as ▁ not ▁ to ▁ lose ▁ information ▁ from ▁ the <encdom>  # ▁ MultiService.stopService ▁ deferred. <encdom> <indent> return service . stopService ( ) <newline> <dedent> else : <newline> <indent> return None <newline> <dedent> <dedent> <dedent> class IProcess ( Interface ) : <newline> <indent>  """ <strnewline> ▁ Process ▁ running ▁ parameters. <strnewline> <strnewline> ▁ Represents ▁ parameters ▁ for ▁ how ▁ processes ▁ should ▁ be ▁ run. <strnewline> ▁ """  <newline> processName = Attribute (  """ <strnewline> ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ A ▁ C{str} ▁ giving ▁ the ▁ name ▁ the ▁ process ▁ should ▁ have ▁ in ▁ ps ▁ (or ▁ C{None} <strnewline> ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ to ▁ leave ▁ the ▁ name ▁ alone). <strnewline> ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ """  ) <newline> uid = Attribute (  """ <strnewline> ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ An ▁ C{int} ▁ giving ▁ the ▁ user ▁ id ▁ as ▁ which ▁ the ▁ process ▁ should ▁ run ▁ (or <strnewline> ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ C{None} ▁ to ▁ leave ▁ the ▁ UID ▁ alone). <strnewline> ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ """  ) <newline> gid = Attribute (  """ <strnewline> ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ An ▁ C{int} ▁ giving ▁ the ▁ group ▁ id ▁ as ▁ which ▁ the ▁ process ▁ should ▁ run ▁ (or <strnewline> ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ C{None} ▁ to ▁ leave ▁ the ▁ GID ▁ alone). <strnewline> ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ """  ) <newline> <dedent> class Process : <newline> <indent>  """ <strnewline> ▁ Process ▁ running ▁ parameters. <strnewline> <strnewline> ▁ Sets ▁ up ▁ uid/gid ▁ in ▁ the ▁ constructor, ▁ and ▁ has ▁ a ▁ default <strnewline> ▁ of ▁ C{None} ▁ as ▁ C{processName}. <strnewline> ▁ """  <newline> implements ( IProcess ) <newline> processName = None <newline> def __init__ ( self , uid = None , gid = None ) : <newline> <indent>  """ <strnewline> ▁ Set ▁ uid ▁ and ▁ gid. <strnewline> <strnewline> ▁ @param ▁ uid: ▁ The ▁ user ▁ ID ▁ as ▁ whom ▁ to ▁ execute ▁ the ▁ process. ▁ If <strnewline> ▁ this ▁ is ▁ C{None}, ▁ no ▁ attempt ▁ will ▁ be ▁ made ▁ to ▁ change ▁ the ▁ UID. <strnewline> <strnewline> ▁ @param ▁ gid: ▁ The ▁ group ▁ ID ▁ as ▁ whom ▁ to ▁ execute ▁ the ▁ process. ▁ If <strnewline> ▁ this ▁ is ▁ C{None}, ▁ no ▁ attempt ▁ will ▁ be ▁ made ▁ to ▁ change ▁ the ▁ GID. <strnewline> ▁ """  <newline> self . uid = uid <newline> self . gid = gid <newline> <dedent> <dedent> def Application ( name , uid = None , gid = None ) : <newline> <indent>  """ <strnewline> ▁ Return ▁ a ▁ compound ▁ class. <strnewline> <strnewline> ▁ Return ▁ an ▁ object ▁ supporting ▁ the ▁ L{IService}, ▁ L{IServiceCollection}, <strnewline> ▁ L{IProcess} ▁ and ▁ L{sob.IPersistable} ▁ interfaces, ▁ with ▁ the ▁ given <strnewline> ▁ parameters. ▁ Always ▁ access ▁ the ▁ return ▁ value ▁ by ▁ explicit ▁ casting ▁ to <strnewline> ▁ one ▁ of ▁ the ▁ interfaces. <strnewline> ▁ """  <newline> ret = components . Componentized ( ) <newline> for comp in ( MultiService ( ) , sob . Persistent ( ret , name ) , Process ( uid , gid ) ) : <newline> <indent> ret . addComponent ( comp , ignoreClass = 1 ) <newline> <dedent> IService ( ret ) . setName ( name ) <newline> return ret <newline> <dedent> def loadApplication ( filename , kind , passphrase = None ) : <newline> <indent>  """ <strnewline> ▁ Load ▁ Application ▁ from ▁ a ▁ given ▁ file. <strnewline> <strnewline> ▁ The ▁ serialization ▁ format ▁ it ▁ was ▁ saved ▁ in ▁ should ▁ be ▁ given ▁ as <strnewline> ▁ C{kind}, ▁ and ▁ is ▁ one ▁ of ▁ C{pickle}, ▁ C{source}, ▁ C{xml} ▁ or ▁ C{python}. ▁ If <strnewline> ▁ C{passphrase} ▁ is ▁ given, ▁ the ▁ application ▁ was ▁ encrypted ▁ with ▁ the <strnewline> ▁ given ▁ passphrase. <strnewline> <strnewline> ▁ @type ▁ filename: ▁ C{str} <strnewline> ▁ @type ▁ kind: ▁ C{str} <strnewline> ▁ @type ▁ passphrase: ▁ C{str} <strnewline> ▁ """  <newline> if kind == 'python' : <newline> <indent> application = sob . loadValueFromFile ( filename , 'application' , passphrase ) <newline> <dedent> else : <newline> <indent> application = sob . load ( filename , kind , passphrase ) <newline> <dedent> return application <newline> <dedent> __all__ = [ 'IServiceMaker' , 'IService' , 'Service' , 'IServiceCollection' , 'MultiService' , 'IProcess' , 'Process' , 'Application' , 'loadApplication' ] <newline>
from paste . errordocument import forward <newline> from paste . fixture import * <newline> from paste . recursive import RecursiveMiddleware <newline> def simple_app ( environ , start_response ) : <newline> <indent> start_response ( "200 ▁ OK" , [ ( 'Content-type' , 'text/plain' ) ] ) <newline> return [ b'requested ▁ page ▁ returned' ] <newline> <dedent> def not_found_app ( environ , start_response ) : <newline> <indent> start_response ( "404 ▁ Not ▁ found" , [ ( 'Content-type' , 'text/plain' ) ] ) <newline> return [ b'requested ▁ page ▁ returned' ] <newline> <dedent> def test_ok ( ) : <newline> <indent> app = TestApp ( simple_app ) <newline> res = app . get ( '' ) <newline> assert res . header ( 'content-type' ) == 'text/plain' <newline> assert res . full_status == '200 ▁ OK' <newline> assert 'requested ▁ page ▁ returned' in res <newline> <dedent> def error_docs_app ( environ , start_response ) : <newline> <indent> if environ [ 'PATH_INFO' ] == '/not_found' : <newline> <indent> start_response ( "404 ▁ Not ▁ found" , [ ( 'Content-type' , 'text/plain' ) ] ) <newline> return [ b'Not ▁ found' ] <newline> <dedent> elif environ [ 'PATH_INFO' ] == '/error' : <newline> <indent> start_response ( "200 ▁ OK" , [ ( 'Content-type' , 'text/plain' ) ] ) <newline> return [ b'Page ▁ not ▁ found' ] <newline> <dedent> else : <newline> <indent> return simple_app ( environ , start_response ) <newline> <dedent> <dedent> def test_error_docs_app ( ) : <newline> <indent> app = TestApp ( error_docs_app ) <newline> res = app . get ( '' ) <newline> assert res . header ( 'content-type' ) == 'text/plain' <newline> assert res . full_status == '200 ▁ OK' <newline> assert 'requested ▁ page ▁ returned' in res <newline> res = app . get ( '/error' ) <newline> assert res . header ( 'content-type' ) == 'text/plain' <newline> assert res . full_status == '200 ▁ OK' <newline> assert 'Page ▁ not ▁ found' in res <newline> res = app . get ( '/not_found' , status = 404 ) <newline> assert res . header ( 'content-type' ) == 'text/plain' <newline> assert res . full_status == '404 ▁ Not ▁ found' <newline> assert 'Not ▁ found' in res <newline> <dedent> def test_forward ( ) : <newline> <indent> app = forward ( error_docs_app , codes = { 404 : '/error' } ) <newline> app = TestApp ( RecursiveMiddleware ( app ) ) <newline> res = app . get ( '' ) <newline> assert res . header ( 'content-type' ) == 'text/plain' <newline> assert res . full_status == '200 ▁ OK' <newline> assert 'requested ▁ page ▁ returned' in res <newline> res = app . get ( '/error' ) <newline> assert res . header ( 'content-type' ) == 'text/plain' <newline> assert res . full_status == '200 ▁ OK' <newline> assert 'Page ▁ not ▁ found' in res <newline> res = app . get ( '/not_found' , status = 404 ) <newline> assert res . header ( 'content-type' ) == 'text/plain' <newline> assert res . full_status == '404 ▁ Not ▁ found' <newline>  # ▁ Note ▁ changed ▁ response <encdom> assert 'Page ▁ not ▁ found' in res <newline> <dedent> def auth_required_app ( environ , start_response ) : <newline> <indent> start_response ( '401 ▁ Unauthorized' , [ ( 'content-type' , 'text/plain' ) , ( 'www-authenticate' , 'Basic ▁ realm="Foo"' ) ] ) <newline> return [ 'Sign ▁ in!' ] <newline> <dedent> def auth_docs_app ( environ , start_response ) : <newline> <indent> if environ [ 'PATH_INFO' ] == '/auth' : <newline> <indent> return auth_required_app ( environ , start_response ) <newline> <dedent> elif environ [ 'PATH_INFO' ] == '/auth_doc' : <newline> <indent> start_response ( "200 ▁ OK" , [ ( 'Content-type' , 'text/html' ) ] ) <newline> return [ b'<html>Login!</html>' ] <newline> <dedent> else : <newline> <indent> return simple_app ( environ , start_response ) <newline> <dedent> <dedent> def test_auth_docs_app ( ) : <newline> <indent> wsgi_app = forward ( auth_docs_app , codes = { 401 : '/auth_doc' } ) <newline> app = TestApp ( wsgi_app ) <newline> res = app . get ( '/auth_doc' ) <newline> assert res . header ( 'content-type' ) == 'text/html' <newline> res = app . get ( '/auth' , status = 401 ) <newline> assert res . header ( 'content-type' ) == 'text/html' <newline> assert res . header ( 'www-authenticate' ) == 'Basic ▁ realm="Foo"' <newline> assert res . body == b'<html>Login!</html>' <newline> <dedent> def test_bad_error ( ) : <newline> <indent> def app ( environ , start_response ) : <newline> <indent> start_response ( '404 ▁ Not ▁ Found' , [ ( 'content-type' , 'text/plain' ) ] ) <newline> return [ 'not ▁ found' ] <newline> <dedent> app = forward ( app , { 404 : '/404.html' } ) <newline> app = TestApp ( app ) <newline> resp = app . get ( '/test' , expect_errors = True ) <newline> print ( resp ) <newline> <dedent>
 # # ▁ @file <encdom>  # ▁ This ▁ file ▁ is ▁ used ▁ to ▁ parse ▁ a ▁ xml ▁ file ▁ of ▁ .PKG ▁ file <encdom>  # ▁ Copyright ▁ (c) ▁ 2011, ▁ Intel ▁ Corporation. ▁ All ▁ rights ▁ reserved.<BR> <encdom>  # ▁ This ▁ program ▁ and ▁ the ▁ accompanying ▁ materials ▁ are ▁ licensed ▁ and ▁ made ▁ available ▁ <encdom>  # ▁ under ▁ the ▁ terms ▁ and ▁ conditions ▁ of ▁ the ▁ BSD ▁ License ▁ which ▁ accompanies ▁ this ▁ <encdom>  # ▁ distribution. ▁ The ▁ full ▁ text ▁ of ▁ the ▁ license ▁ may ▁ be ▁ found ▁ at ▁ <encdom>  # ▁ http://opensource.org/licenses/bsd-license.php <encdom>  # ▁ THE ▁ PROGRAM ▁ IS ▁ DISTRIBUTED ▁ UNDER ▁ THE ▁ BSD ▁ LICENSE ▁ ON ▁ AN ▁"AS ▁ IS" ▁ BASIS, <encdom>  # ▁ WITHOUT ▁ WARRANTIES ▁ OR ▁ REPRESENTATIONS ▁ OF ▁ ANY ▁ KIND, ▁ EITHER ▁ EXPRESS ▁ OR ▁ IMPLIED. <encdom>  ''' <strnewline> GuidProtocolPpiXml <strnewline> '''  <newline> from Library . String import ConvertNEToNOTEQ <newline> from Library . String import ConvertNOTEQToNE <newline> from Library . String import GetStringOfList <newline> from Library . Xml . XmlRoutines import XmlElement <newline> from Library . Xml . XmlRoutines import XmlAttribute <newline> from Library . Xml . XmlRoutines import XmlNode <newline> from Library . Xml . XmlRoutines import XmlList <newline> from Library . Xml . XmlRoutines import CreateXmlElement <newline> from Object . POM . CommonObject import GuidObject <newline> from Object . POM . CommonObject import ProtocolObject <newline> from Object . POM . CommonObject import PpiObject <newline> from Xml . CommonXml import CommonDefinesXml <newline> from Xml . CommonXml import HelpTextXml <newline> from Xml . XmlParserMisc import GetHelpTextList <newline>  # GUID/Protocol/Ppi ▁ Common <encdom> class GuidProtocolPpiXml ( object ) : <newline> <indent> def __init__ ( self , Mode ) : <newline> <indent> self . UiName = '' <newline> self . GuidTypes = '' <newline> self . Notify = '' <newline> self . CName = '' <newline> self . GuidValue = '' <newline> self . CommonDefines = CommonDefinesXml ( ) <newline> self . HelpText = [ ] <newline>  # ▁ Guid/Ppi/Library, ▁ internal ▁ used ▁ for ▁ indicate ▁ return ▁ object ▁ for ▁ <encdom>  # ▁ FromXml <encdom> self . Type = '' <newline>  # ▁ there ▁ are ▁ slightly ▁ different ▁ field ▁ between ▁ package ▁ and ▁ module <encdom> self . Mode = Mode <newline> self . GuidType = '' <newline> self . VariableName = '' <newline> <dedent> def FromXml ( self , Item , Key ) : <newline> <indent> self . UiName = XmlAttribute ( XmlNode ( Item , '%s' % Key ) , 'UiName' ) <newline> self . GuidType = XmlAttribute ( XmlNode ( Item , '%s' % Key ) , 'GuidType' ) <newline> self . Notify = XmlAttribute ( XmlNode ( Item , '%s' % Key ) , 'Notify' ) <newline> self . CName = XmlElement ( Item , '%s/CName' % Key ) <newline> self . GuidValue = XmlElement ( Item , '%s/GuidValue' % Key ) <newline> self . VariableName = XmlElement ( Item , '%s/VariableName' % Key ) <newline> self . CommonDefines . FromXml ( XmlNode ( Item , '%s' % Key ) , Key ) <newline> for HelpTextItem in XmlList ( Item , '%s/HelpText' % Key ) : <newline> <indent> HelpTextObj = HelpTextXml ( ) <newline> HelpTextObj . FromXml ( HelpTextItem , '%s/HelpText' % Key ) <newline> self . HelpText . append ( HelpTextObj ) <newline> <dedent> if self . Type == 'Guid' : <newline> <indent> GuidProtocolPpi = GuidObject ( ) <newline> <dedent> elif self . Type == 'Protocol' : <newline> <indent> GuidProtocolPpi = ProtocolObject ( ) <newline> <dedent> else : <newline> <indent> GuidProtocolPpi = PpiObject ( ) <newline> <dedent> GuidProtocolPpi . SetHelpTextList ( GetHelpTextList ( self . HelpText ) ) <newline> return GuidProtocolPpi <newline> <dedent> def ToXml ( self , GuidProtocolPpi , Key ) : <newline> <indent> if self . GuidValue : <newline> <indent> pass <newline> <dedent> AttributeList = [ [ 'Usage' , GetStringOfList ( GuidProtocolPpi . GetUsage ( ) ) ] , [ 'UiName' , GuidProtocolPpi . GetName ( ) ] , [ 'GuidType' , GetStringOfList ( GuidProtocolPpi . GetGuidTypeList ( ) ) ] , [ 'Notify' , str ( GuidProtocolPpi . GetNotify ( ) ) . lower ( ) ] , [ 'SupArchList' , GetStringOfList ( GuidProtocolPpi . GetSupArchList ( ) ) ] , [ 'SupModList' , GetStringOfList ( GuidProtocolPpi . GetSupModuleList ( ) ) ] , [ 'FeatureFlag' , ConvertNEToNOTEQ ( GuidProtocolPpi . GetFeatureFlag ( ) ) ] ] <newline> NodeList = [ [ 'CName' , GuidProtocolPpi . GetCName ( ) ] , [ 'GuidValue' , GuidProtocolPpi . GetGuid ( ) ] , [ 'VariableName' , GuidProtocolPpi . VariableName ] ] <newline> for Item in GuidProtocolPpi . GetHelpTextList ( ) : <newline> <indent> Tmp = HelpTextXml ( ) <newline> NodeList . append ( Tmp . ToXml ( Item ) ) <newline> <dedent> Root = CreateXmlElement ( '%s' % Key , '' , NodeList , AttributeList ) <newline> return Root <newline> <dedent> def __str__ ( self ) : <newline> <indent> Str = "UiName ▁ = ▁ %s ▁ Notify ▁ = ▁ %s ▁ GuidTypes ▁ = ▁ %s ▁ CName ▁ = ▁ %s ▁ GuidValue ▁ = ▁ %s ▁ %s" % ( self . UiName , self . Notify , self . GuidTypes , self . CName , self . GuidValue , self . CommonDefines ) <newline> for Item in self . HelpText : <newline> <indent> Str = Str + " \n \t" + str ( Item ) <newline> <dedent> return Str <newline>  # GUID ▁ Xml <encdom> <dedent> <dedent> class GuidXml ( GuidProtocolPpiXml ) : <newline> <indent> def __init__ ( self , Mode ) : <newline> <indent> GuidProtocolPpiXml . __init__ ( self , Mode ) <newline> self . Type = 'Guid' <newline> <dedent> def FromXml ( self , Item , Key ) : <newline> <indent> GuidProtocolPpi = GuidProtocolPpiXml . FromXml ( self , Item , Key ) <newline> if self . Mode == 'Package' : <newline> <indent> GuidProtocolPpi . SetSupArchList ( self . CommonDefines . SupArchList ) <newline> GuidProtocolPpi . SetSupModuleList ( self . CommonDefines . SupModList ) <newline> GuidProtocolPpi . SetCName ( self . CName ) <newline> GuidProtocolPpi . SetGuid ( self . GuidValue ) <newline> <dedent> else : <newline> <indent> GuidProtocolPpi . SetUsage ( self . CommonDefines . Usage ) <newline> if self . GuidType : <newline> <indent> GuidProtocolPpi . SetGuidTypeList ( [ self . GuidType ] ) <newline> <dedent> GuidProtocolPpi . SetSupArchList ( self . CommonDefines . SupArchList ) <newline> GuidProtocolPpi . SetFeatureFlag ( ConvertNOTEQToNE ( self . CommonDefines . FeatureFlag ) ) <newline> GuidProtocolPpi . SetCName ( self . CName ) <newline> GuidProtocolPpi . SetVariableName ( self . VariableName ) <newline> <dedent> return GuidProtocolPpi <newline> <dedent> def ToXml ( self , GuidProtocolPpi , Key ) : <newline> <indent> if self . Mode == 'Package' : <newline> <indent> AttributeList = [ [ 'GuidType' , GetStringOfList ( GuidProtocolPpi . GetGuidTypeList ( ) ) ] , [ 'SupArchList' , GetStringOfList ( GuidProtocolPpi . GetSupArchList ( ) ) ] , [ 'SupModList' , GetStringOfList ( GuidProtocolPpi . GetSupModuleList ( ) ) ] , ] <newline> NodeList = [ [ 'CName' , GuidProtocolPpi . GetCName ( ) ] , [ 'GuidValue' , GuidProtocolPpi . GetGuid ( ) ] , ] <newline> <dedent> else : <newline> <indent> AttributeList = [ [ 'Usage' , GetStringOfList ( GuidProtocolPpi . GetUsage ( ) ) ] , [ 'GuidType' , GetStringOfList ( GuidProtocolPpi . GetGuidTypeList ( ) ) ] , [ 'SupArchList' , GetStringOfList ( GuidProtocolPpi . GetSupArchList ( ) ) ] , [ 'FeatureFlag' , ConvertNEToNOTEQ ( GuidProtocolPpi . GetFeatureFlag ( ) ) ] ] <newline> NodeList = [ [ 'CName' , GuidProtocolPpi . GetCName ( ) ] , [ 'VariableName' , GuidProtocolPpi . GetVariableName ( ) ] ] <newline> <dedent> for Item in GuidProtocolPpi . GetHelpTextList ( ) : <newline> <indent> Tmp = HelpTextXml ( ) <newline> NodeList . append ( Tmp . ToXml ( Item ) ) <newline> <dedent> Root = CreateXmlElement ( '%s' % Key , '' , NodeList , AttributeList ) <newline> return Root <newline>  # Protocol ▁ Xml <encdom> <dedent> <dedent> class ProtocolXml ( GuidProtocolPpiXml ) : <newline> <indent> def __init__ ( self , Mode ) : <newline> <indent> GuidProtocolPpiXml . __init__ ( self , Mode ) <newline> self . Type = 'Protocol' <newline> <dedent> def FromXml ( self , Item , Key ) : <newline> <indent> GuidProtocolPpi = GuidProtocolPpiXml . FromXml ( self , Item , Key ) <newline> if self . Mode == 'Package' : <newline> <indent> GuidProtocolPpi . SetFeatureFlag ( self . CommonDefines . FeatureFlag ) <newline> GuidProtocolPpi . SetSupArchList ( self . CommonDefines . SupArchList ) <newline> GuidProtocolPpi . SetSupModuleList ( self . CommonDefines . SupModList ) <newline> GuidProtocolPpi . SetCName ( self . CName ) <newline> GuidProtocolPpi . SetGuid ( self . GuidValue ) <newline> <dedent> else : <newline> <indent> GuidProtocolPpi . SetUsage ( self . CommonDefines . Usage ) <newline> if self . Notify . upper ( ) == "TRUE" : <newline> <indent> GuidProtocolPpi . SetNotify ( True ) <newline> <dedent> elif self . Notify . upper ( ) == "FALSE" : <newline> <indent> GuidProtocolPpi . SetNotify ( False ) <newline> <dedent> else : <newline> <indent> GuidProtocolPpi . SetNotify ( '' ) <newline> <dedent> GuidProtocolPpi . SetSupArchList ( self . CommonDefines . SupArchList ) <newline> GuidProtocolPpi . SetFeatureFlag ( ConvertNOTEQToNE ( self . CommonDefines . FeatureFlag ) ) <newline> GuidProtocolPpi . SetCName ( self . CName ) <newline> <dedent> return GuidProtocolPpi <newline> <dedent> def ToXml ( self , GuidProtocolPpi , Key ) : <newline> <indent> if self . Mode == 'Package' : <newline> <indent> AttributeList = [ [ 'SupArchList' , GetStringOfList ( GuidProtocolPpi . GetSupArchList ( ) ) ] , [ 'SupModList' , GetStringOfList ( GuidProtocolPpi . GetSupModuleList ( ) ) ] , [ 'FeatureFlag' , GuidProtocolPpi . GetFeatureFlag ( ) ] ] <newline> NodeList = [ [ 'CName' , GuidProtocolPpi . GetCName ( ) ] , [ 'GuidValue' , GuidProtocolPpi . GetGuid ( ) ] , ] <newline> <dedent> else : <newline> <indent> AttributeList = [ [ 'Usage' , GetStringOfList ( GuidProtocolPpi . GetUsage ( ) ) ] , [ 'Notify' , str ( GuidProtocolPpi . GetNotify ( ) ) . lower ( ) ] , [ 'SupArchList' , GetStringOfList ( GuidProtocolPpi . GetSupArchList ( ) ) ] , [ 'FeatureFlag' , ConvertNEToNOTEQ ( GuidProtocolPpi . GetFeatureFlag ( ) ) ] ] <newline> NodeList = [ [ 'CName' , GuidProtocolPpi . GetCName ( ) ] , ] <newline> <dedent> for Item in GuidProtocolPpi . GetHelpTextList ( ) : <newline> <indent> Tmp = HelpTextXml ( ) <newline> NodeList . append ( Tmp . ToXml ( Item ) ) <newline> <dedent> Root = CreateXmlElement ( '%s' % Key , '' , NodeList , AttributeList ) <newline> return Root <newline>  # Ppi ▁ Xml <encdom> <dedent> <dedent> class PpiXml ( GuidProtocolPpiXml ) : <newline> <indent> def __init__ ( self , Mode ) : <newline> <indent> GuidProtocolPpiXml . __init__ ( self , Mode ) <newline> self . Type = 'Ppi' <newline> <dedent> def FromXml ( self , Item , Key ) : <newline> <indent> GuidProtocolPpi = GuidProtocolPpiXml . FromXml ( self , Item , Key ) <newline> if self . Mode == 'Package' : <newline> <indent> GuidProtocolPpi . SetSupArchList ( self . CommonDefines . SupArchList ) <newline> GuidProtocolPpi . SetSupModuleList ( self . CommonDefines . SupModList ) <newline> GuidProtocolPpi . SetCName ( self . CName ) <newline> GuidProtocolPpi . SetGuid ( self . GuidValue ) <newline> <dedent> else : <newline> <indent> GuidProtocolPpi . SetUsage ( self . CommonDefines . Usage ) <newline> if self . Notify . upper ( ) == "TRUE" : <newline> <indent> GuidProtocolPpi . SetNotify ( True ) <newline> <dedent> elif self . Notify . upper ( ) == "FALSE" : <newline> <indent> GuidProtocolPpi . SetNotify ( False ) <newline> <dedent> else : <newline> <indent> GuidProtocolPpi . SetNotify ( '' ) <newline> <dedent> GuidProtocolPpi . SetSupArchList ( self . CommonDefines . SupArchList ) <newline> GuidProtocolPpi . SetFeatureFlag ( ConvertNOTEQToNE ( self . CommonDefines . FeatureFlag ) ) <newline> GuidProtocolPpi . SetCName ( self . CName ) <newline> <dedent> return GuidProtocolPpi <newline> <dedent> def ToXml ( self , GuidProtocolPpi , Key ) : <newline> <indent> if self . Mode == 'Package' : <newline> <indent> AttributeList = [ [ 'SupArchList' , GetStringOfList ( GuidProtocolPpi . GetSupArchList ( ) ) ] , ] <newline> NodeList = [ [ 'CName' , GuidProtocolPpi . GetCName ( ) ] , [ 'GuidValue' , GuidProtocolPpi . GetGuid ( ) ] , ] <newline> <dedent> else : <newline> <indent> AttributeList = [ [ 'Usage' , GetStringOfList ( GuidProtocolPpi . GetUsage ( ) ) ] , [ 'Notify' , str ( GuidProtocolPpi . GetNotify ( ) ) . lower ( ) ] , [ 'SupArchList' , GetStringOfList ( GuidProtocolPpi . GetSupArchList ( ) ) ] , [ 'FeatureFlag' , ConvertNEToNOTEQ ( GuidProtocolPpi . GetFeatureFlag ( ) ) ] ] <newline> NodeList = [ [ 'CName' , GuidProtocolPpi . GetCName ( ) ] , ] <newline> <dedent> for Item in GuidProtocolPpi . GetHelpTextList ( ) : <newline> <indent> Tmp = HelpTextXml ( ) <newline> NodeList . append ( Tmp . ToXml ( Item ) ) <newline> <dedent> Root = CreateXmlElement ( '%s' % Key , '' , NodeList , AttributeList ) <newline> return Root <newline> <dedent> <dedent>
 # !/usr/bin/env ▁ python <encdom> import unittest <newline> from pyutil import mathutil <newline> from pyutil . assertutil import _assert <newline> class MathUtilTestCase ( unittest . TestCase ) : <newline> <indent> def _help_test_is_power_of_k ( self , k ) : <newline> <indent> for i in range ( 2 , 40 ) : <newline> <indent> _assert ( mathutil . is_power_of_k ( k ** i , k ) , k , i ) <newline> <dedent> <dedent> def test_is_power_of_k ( self ) : <newline> <indent> for i in range ( 2 , 5 ) : <newline> <indent> self . _help_test_is_power_of_k ( i ) <newline> <dedent> <dedent> def test_log_ceil ( self ) : <newline> <indent> f = mathutil . log_ceil <newline> self . failUnlessEqual ( f ( 1 , 2 ) , 0 ) <newline> self . failUnlessEqual ( f ( 1 , 3 ) , 0 ) <newline> self . failUnlessEqual ( f ( 2 , 2 ) , 1 ) <newline> self . failUnlessEqual ( f ( 2 , 3 ) , 1 ) <newline> self . failUnlessEqual ( f ( 3 , 2 ) , 2 ) <newline> <dedent> def test_log_floor ( self ) : <newline> <indent> f = mathutil . log_floor <newline> self . failUnlessEqual ( f ( 1 , 2 ) , 0 ) <newline> self . failUnlessEqual ( f ( 1 , 3 ) , 0 ) <newline> self . failUnlessEqual ( f ( 2 , 2 ) , 1 ) <newline> self . failUnlessEqual ( f ( 2 , 3 ) , 0 ) <newline> self . failUnlessEqual ( f ( 3 , 2 ) , 1 ) <newline> <dedent> def test_div_ceil ( self ) : <newline> <indent> f = mathutil . div_ceil <newline> self . failUnlessEqual ( f ( 0 , 1 ) , 0 ) <newline> self . failUnlessEqual ( f ( 0 , 2 ) , 0 ) <newline> self . failUnlessEqual ( f ( 0 , 3 ) , 0 ) <newline> self . failUnlessEqual ( f ( 1 , 3 ) , 1 ) <newline> self . failUnlessEqual ( f ( 2 , 3 ) , 1 ) <newline> self . failUnlessEqual ( f ( 3 , 3 ) , 1 ) <newline> self . failUnlessEqual ( f ( 4 , 3 ) , 2 ) <newline> self . failUnlessEqual ( f ( 5 , 3 ) , 2 ) <newline> self . failUnlessEqual ( f ( 6 , 3 ) , 2 ) <newline> self . failUnlessEqual ( f ( 7 , 3 ) , 3 ) <newline> self . failUnless ( isinstance ( f ( 0.0 , 1 ) , int ) ) <newline> self . failUnlessEqual ( f ( 7.0 , 3.0 ) , 3 ) <newline> self . failUnlessEqual ( f ( 7 , 3.0 ) , 3 ) <newline> self . failUnlessEqual ( f ( 7.0 , 3 ) , 3 ) <newline> self . failUnlessEqual ( f ( 6.0 , 3.0 ) , 2 ) <newline> self . failUnlessEqual ( f ( 6.0 , 3 ) , 2 ) <newline> self . failUnlessEqual ( f ( 6 , 3.0 ) , 2 ) <newline> <dedent> def test_next_multiple ( self ) : <newline> <indent> f = mathutil . next_multiple <newline> self . failUnlessEqual ( f ( 5 , 1 ) , 5 ) <newline> self . failUnlessEqual ( f ( 5 , 2 ) , 6 ) <newline> self . failUnlessEqual ( f ( 5 , 3 ) , 6 ) <newline> self . failUnlessEqual ( f ( 5 , 4 ) , 8 ) <newline> self . failUnlessEqual ( f ( 5 , 5 ) , 5 ) <newline> self . failUnlessEqual ( f ( 5 , 6 ) , 6 ) <newline> self . failUnlessEqual ( f ( 32 , 1 ) , 32 ) <newline> self . failUnlessEqual ( f ( 32 , 2 ) , 32 ) <newline> self . failUnlessEqual ( f ( 32 , 3 ) , 33 ) <newline> self . failUnlessEqual ( f ( 32 , 4 ) , 32 ) <newline> self . failUnlessEqual ( f ( 32 , 5 ) , 35 ) <newline> self . failUnlessEqual ( f ( 32 , 6 ) , 36 ) <newline> self . failUnlessEqual ( f ( 32 , 7 ) , 35 ) <newline> self . failUnlessEqual ( f ( 32 , 8 ) , 32 ) <newline> self . failUnlessEqual ( f ( 32 , 9 ) , 36 ) <newline> self . failUnlessEqual ( f ( 32 , 10 ) , 40 ) <newline> self . failUnlessEqual ( f ( 32 , 11 ) , 33 ) <newline> self . failUnlessEqual ( f ( 32 , 12 ) , 36 ) <newline> self . failUnlessEqual ( f ( 32 , 13 ) , 39 ) <newline> self . failUnlessEqual ( f ( 32 , 14 ) , 42 ) <newline> self . failUnlessEqual ( f ( 32 , 15 ) , 45 ) <newline> self . failUnlessEqual ( f ( 32 , 16 ) , 32 ) <newline> self . failUnlessEqual ( f ( 32 , 17 ) , 34 ) <newline> self . failUnlessEqual ( f ( 32 , 18 ) , 36 ) <newline> self . failUnlessEqual ( f ( 32 , 589 ) , 589 ) <newline> <dedent> def test_pad_size ( self ) : <newline> <indent> f = mathutil . pad_size <newline> self . failUnlessEqual ( f ( 0 , 4 ) , 0 ) <newline> self . failUnlessEqual ( f ( 1 , 4 ) , 3 ) <newline> self . failUnlessEqual ( f ( 2 , 4 ) , 2 ) <newline> self . failUnlessEqual ( f ( 3 , 4 ) , 1 ) <newline> self . failUnlessEqual ( f ( 4 , 4 ) , 0 ) <newline> self . failUnlessEqual ( f ( 5 , 4 ) , 3 ) <newline> <dedent> def test_is_power_of_k_part_2 ( self ) : <newline> <indent> f = mathutil . is_power_of_k <newline> for i in range ( 1 , 100 ) : <newline> <indent> if i in ( 1 , 2 , 4 , 8 , 16 , 32 , 64 ) : <newline> <indent> self . failUnless ( f ( i , 2 ) , "but ▁ %d ▁ *is* ▁ a ▁ power ▁ of ▁ 2" % i ) <newline> <dedent> else : <newline> <indent> self . failIf ( f ( i , 2 ) , "but ▁ %d ▁ is ▁ *not* ▁ a ▁ power ▁ of ▁ 2" % i ) <newline> <dedent> <dedent> for i in range ( 1 , 100 ) : <newline> <indent> if i in ( 1 , 3 , 9 , 27 , 81 ) : <newline> <indent> self . failUnless ( f ( i , 3 ) , "but ▁ %d ▁ *is* ▁ a ▁ power ▁ of ▁ 3" % i ) <newline> <dedent> else : <newline> <indent> self . failIf ( f ( i , 3 ) , "but ▁ %d ▁ is ▁ *not* ▁ a ▁ power ▁ of ▁ 3" % i ) <newline> <dedent> <dedent> <dedent> def test_next_power_of_k ( self ) : <newline> <indent> f = mathutil . next_power_of_k <newline> self . failUnlessEqual ( f ( 0 , 2 ) , 1 ) <newline> self . failUnlessEqual ( f ( 1 , 2 ) , 1 ) <newline> self . failUnlessEqual ( f ( 2 , 2 ) , 2 ) <newline> self . failUnlessEqual ( f ( 3 , 2 ) , 4 ) <newline> self . failUnlessEqual ( f ( 4 , 2 ) , 4 ) <newline> for i in range ( 5 , 8 ) : self . failUnlessEqual ( f ( i , 2 ) , 8 , "%d" % i ) <newline> for i in range ( 9 , 16 ) : self . failUnlessEqual ( f ( i , 2 ) , 16 , "%d" % i ) <newline> for i in range ( 17 , 32 ) : self . failUnlessEqual ( f ( i , 2 ) , 32 , "%d" % i ) <newline> for i in range ( 33 , 64 ) : self . failUnlessEqual ( f ( i , 2 ) , 64 , "%d" % i ) <newline> for i in range ( 65 , 100 ) : self . failUnlessEqual ( f ( i , 2 ) , 128 , "%d" % i ) <newline> self . failUnlessEqual ( f ( 0 , 3 ) , 1 ) <newline> self . failUnlessEqual ( f ( 1 , 3 ) , 1 ) <newline> self . failUnlessEqual ( f ( 2 , 3 ) , 3 ) <newline> self . failUnlessEqual ( f ( 3 , 3 ) , 3 ) <newline> for i in range ( 4 , 9 ) : self . failUnlessEqual ( f ( i , 3 ) , 9 , "%d" % i ) <newline> for i in range ( 10 , 27 ) : self . failUnlessEqual ( f ( i , 3 ) , 27 , "%d" % i ) <newline> for i in range ( 28 , 81 ) : self . failUnlessEqual ( f ( i , 3 ) , 81 , "%d" % i ) <newline> for i in range ( 82 , 200 ) : self . failUnlessEqual ( f ( i , 3 ) , 243 , "%d" % i ) <newline> <dedent> def test_ave ( self ) : <newline> <indent> f = mathutil . ave <newline> self . failUnlessEqual ( f ( [ 1 , 2 , 3 ] ) , 2 ) <newline> self . failUnlessEqual ( f ( [ 0 , 0 , 0 , 4 ] ) , 1 ) <newline> self . failUnlessAlmostEqual ( f ( [ 0.0 , 1.0 , 1.0 ] ) , .666666666666 ) <newline> <dedent> def failUnlessEqualContents ( self , a , b ) : <newline> <indent> self . failUnlessEqual ( sorted ( a ) , sorted ( b ) ) <newline> <dedent> def test_permute ( self ) : <newline> <indent> f = mathutil . permute <newline> self . failUnlessEqualContents ( f ( [ ] ) , [ ] ) <newline> self . failUnlessEqualContents ( f ( [ 1 ] ) , [ [ 1 ] ] ) <newline> self . failUnlessEqualContents ( f ( [ 1 , 2 ] ) , [ [ 1 , 2 ] , [ 2 , 1 ] ] ) <newline> self . failUnlessEqualContents ( f ( [ 1 , 2 , 3 ] ) , [ [ 1 , 2 , 3 ] , [ 1 , 3 , 2 ] , [ 2 , 1 , 3 ] , [ 2 , 3 , 1 ] , [ 3 , 1 , 2 ] , [ 3 , 2 , 1 ] ] ) <newline> <dedent> <dedent>
 # ▁ -*- ▁ coding: ▁ utf-8 ▁ -*- <encdom> from __future__ import unicode_literals <newline> from . resort import Resort <newline> from django . db import models <newline> from django . contrib . postgres . fields import ArrayField <newline> from dynamic_scraper . models import Scraper , SchedulerRuntime <newline> from scrapy_djangoitem import DjangoItem <newline> import datetime <newline>  # ▁ Past ▁ and ▁ forecasted ▁ conditions ▁ for ▁ a ▁ resort <encdom> class Conditions ( models . Model ) : <newline>  # ▁ Hard-coded ▁ attributes ▁ needed ▁ for ▁ scraping <encdom> <indent> resort = models . ForeignKey ( Resort , null = True , default = 6 ) <newline> conditions_page_url = models . URLField ( blank = True ) <newline> checker_runtime = models . ForeignKey ( SchedulerRuntime , blank = True , null = True , on_delete = models . SET_NULL ) <newline>  # ▁ Attributes ▁ collected ▁ during ▁ scraping <encdom> date = models . DateField ( default = datetime . date . today ) <newline> base_temp = models . DecimalField ( max_digits = 6 , decimal_places = 2 , default = 0 ) <newline> summit_temp = models . DecimalField ( max_digits = 6 , decimal_places = 2 , default = 0 ) <newline> wind_speed = models . DecimalField ( max_digits = 6 , decimal_places = 2 , default = 0 ) <newline> base_depth = models . DecimalField ( max_digits = 6 , decimal_places = 2 , default = 0 ) <newline> num_trails_open = models . IntegerField ( default = 0 ) <newline> new_snow_24_hr = models . IntegerField ( default = 0 ) <newline>  # past_n_day_snowfall ▁ = ▁ ArrayField(models.DecimalField(max_digits ▁ = ▁ 6, ▁ decimal_places ▁ = ▁ 2, ▁ default ▁ = ▁ 0), ▁ size ▁ = ▁ 15) <encdom>  # past_n_day_wind_speed ▁ = ▁ ArrayField(models.DecimalField(max_digits ▁ = ▁ 6, ▁ decimal_places ▁ = ▁ 2, ▁ default ▁ = ▁ 0), ▁ size ▁ = ▁ 15) <encdom>  # future_n_day_snowfall ▁ = ▁ ArrayField(models.DecimalField(max_digits ▁ = ▁ 6, ▁ decimal_places ▁ = ▁ 2, ▁ default ▁ = ▁ 0), ▁ size ▁ = ▁ 15) <encdom>  # future_n_day_wind_speed ▁ = ▁ ArrayField(models.DecimalField(max_digits ▁ = ▁ 6, ▁ decimal_places ▁ = ▁ 2, ▁ default ▁ = ▁ 0), ▁ size ▁ = ▁ 15) <encdom>  # ▁ For ▁ database ▁ querying <encdom> unique_id = models . CharField ( default = '' , max_length = 200 ) <newline> def __init__ ( self , * args , ** kwargs ) : <newline> <indent> super ( Conditions , self ) . __init__ ( * args , ** kwargs ) <newline> if not self . id : <newline> <indent> day = datetime . date . today <newline> self . conditions_page_url = self . resort . conditions_page_url <newline> self . unique_id = self . resort . name + str ( datetime . date . today ( ) ) <newline> <dedent> <dedent> def __unicode__ ( self ) : <newline> <indent> return self . resort . name + ": ▁ " + str ( self . date ) <newline> <dedent> def __str__ ( self ) : <newline> <indent> return self . resort . name + ": ▁ " + str ( self . date ) <newline> <dedent> class Meta : <newline> <indent> verbose_name_plural = "Conditions" <newline> <dedent> <dedent> class ConditionsItem ( DjangoItem ) : <newline> <indent> django_model = Conditions <newline> <dedent>
 # ▁ Copyright ▁ 2010 ▁ United ▁ States ▁ Government ▁ as ▁ represented ▁ by ▁ the <encdom>  # ▁ Administrator ▁ of ▁ the ▁ National ▁ Aeronautics ▁ and ▁ Space ▁ Administration. <encdom>  # ▁ All ▁ Rights ▁ Reserved. <encdom>  # ▁ Copyright ▁ (c) ▁ 2010 ▁ Citrix ▁ Systems, ▁ Inc. <encdom>  # ▁ Copyright ▁ 2011 ▁ Ken ▁ Pepple <encdom>  # ▁ Licensed ▁ under ▁ the ▁ Apache ▁ License, ▁ Version ▁ 2.0 ▁ (the ▁"License"); ▁ you ▁ may <encdom>  # ▁ not ▁ use ▁ this ▁ file ▁ except ▁ in ▁ compliance ▁ with ▁ the ▁ License. ▁ You ▁ may ▁ obtain <encdom>  # ▁ a ▁ copy ▁ of ▁ the ▁ License ▁ at <encdom>  # ▁ http://www.apache.org/licenses/LICENSE-2.0 <encdom>  # ▁ Unless ▁ required ▁ by ▁ applicable ▁ law ▁ or ▁ agreed ▁ to ▁ in ▁ writing, ▁ software <encdom>  # ▁ distributed ▁ under ▁ the ▁ License ▁ is ▁ distributed ▁ on ▁ an ▁"AS ▁ IS" ▁ BASIS, ▁ WITHOUT <encdom>  # ▁ WARRANTIES ▁ OR ▁ CONDITIONS ▁ OF ▁ ANY ▁ KIND, ▁ either ▁ express ▁ or ▁ implied. ▁ See ▁ the <encdom>  # ▁ License ▁ for ▁ the ▁ specific ▁ language ▁ governing ▁ permissions ▁ and ▁ limitations <encdom>  # ▁ under ▁ the ▁ License. <encdom>  """ Built-in ▁ instance ▁ properties. """  <newline> import re <newline> import uuid <newline> from oslo_config import cfg <newline> from oslo_log import log as logging <newline> from oslo_utils import strutils <newline> import six <newline> from nova . api . validation import parameter_types <newline> from nova import context <newline> from nova import db <newline> from nova import exception <newline> from nova . i18n import _ <newline> from nova . i18n import _LE <newline> from nova import objects <newline> from nova import utils <newline> flavor_opts = [ cfg . StrOpt ( 'default_flavor' , default = 'm1.small' , help = 'Default ▁ flavor ▁ to ▁ use ▁ for ▁ the ▁ EC2 ▁ API ▁ only. ▁ The ▁ Nova ▁ API ▁ ' 'does ▁ not ▁ support ▁ a ▁ default ▁ flavor.' ) , ] <newline> CONF = cfg . CONF <newline> CONF . register_opts ( flavor_opts ) <newline> LOG = logging . getLogger ( __name__ ) <newline>  # ▁ NOTE(luisg): ▁ Flavor ▁ names ▁ can ▁ include ▁ non-ascii ▁ characters ▁ so ▁ that ▁ users ▁ can <encdom>  # ▁ create ▁ flavor ▁ names ▁ in ▁ locales ▁ that ▁ use ▁ them, ▁ however ▁ flavor ▁ IDs ▁ are ▁ limited <encdom>  # ▁ to ▁ ascii ▁ characters. <encdom> VALID_ID_REGEX = re . compile ( "^[\w\.\- ▁ ]*$" ) <newline> VALID_NAME_REGEX = re . compile ( parameter_types . valid_name_regex , re . UNICODE ) <newline>  # ▁ NOTE(dosaboy): ▁ This ▁ is ▁ supposed ▁ to ▁ represent ▁ the ▁ maximum ▁ value ▁ that ▁ we ▁ can <encdom>  # ▁ place ▁ into ▁ a ▁ SQL ▁ single ▁ precision ▁ float ▁ so ▁ that ▁ we ▁ can ▁ check ▁ whether ▁ values <encdom>  # ▁ are ▁ oversize. ▁ Postgres ▁ and ▁ MySQL ▁ both ▁ define ▁ this ▁ as ▁ their ▁ max ▁ whereas ▁ Sqlite <encdom>  # ▁ uses ▁ dynamic ▁ typing ▁ so ▁ this ▁ would ▁ not ▁ apply. ▁ Different ▁ dbs ▁ react ▁ in ▁ different <encdom>  # ▁ ways ▁ to ▁ oversize ▁ values ▁ e.g. ▁ postgres ▁ will ▁ raise ▁ an ▁ exception ▁ while ▁ mysql <encdom>  # ▁ will ▁ round ▁ off ▁ the ▁ value. ▁ Nevertheless ▁ we ▁ may ▁ still ▁ want ▁ to ▁ know ▁ prior ▁ to <encdom>  # ▁ insert ▁ whether ▁ the ▁ value ▁ is ▁ oversize. <encdom> SQL_SP_FLOAT_MAX = 3.40282e+38 <newline>  # ▁ Validate ▁ extra ▁ specs ▁ key ▁ names. <encdom> VALID_EXTRASPEC_NAME_REGEX = re . compile ( r"[\w\.\- ▁ :]+$" , re . UNICODE ) <newline> def _int_or_none ( val ) : <newline> <indent> if val is not None : <newline> <indent> return int ( val ) <newline> <dedent> <dedent> system_metadata_flavor_props = { 'id' : int , 'name' : str , 'memory_mb' : int , 'vcpus' : int , 'root_gb' : int , 'ephemeral_gb' : int , 'flavorid' : str , 'swap' : int , 'rxtx_factor' : float , 'vcpu_weight' : _int_or_none , } <newline> system_metadata_flavor_extra_props = [ 'hw:numa_cpus.' , 'hw:numa_mem.' , ] <newline> def create ( name , memory , vcpus , root_gb , ephemeral_gb = 0 , flavorid = None , swap = 0 , rxtx_factor = 1.0 , is_public = True ) : <newline> <indent>  """ Creates ▁ flavors. """  <newline> if not flavorid : <newline> <indent> flavorid = uuid . uuid4 ( ) <newline> <dedent> kwargs = { 'memory_mb' : memory , 'vcpus' : vcpus , 'root_gb' : root_gb , 'ephemeral_gb' : ephemeral_gb , 'swap' : swap , 'rxtx_factor' : rxtx_factor , } <newline> if isinstance ( name , six . string_types ) : <newline> <indent> name = name . strip ( ) <newline>  # ▁ ensure ▁ name ▁ do ▁ not ▁ exceed ▁ 255 ▁ characters <encdom> <dedent> utils . check_string_length ( name , 'name' , min_length = 1 , max_length = 255 ) <newline>  # ▁ ensure ▁ name ▁ does ▁ not ▁ contain ▁ any ▁ special ▁ characters <encdom> valid_name = VALID_NAME_REGEX . search ( name ) <newline> if not valid_name : <newline> <indent> msg = _ ( "Flavor ▁ names ▁ can ▁ only ▁ contain ▁ printable ▁ characters ▁ " "and ▁ horizontal ▁ spaces." ) <newline> raise exception . InvalidInput ( reason = msg ) <newline>  # ▁ NOTE(vish): ▁ Internally, ▁ flavorid ▁ is ▁ stored ▁ as ▁ a ▁ string ▁ but ▁ it ▁ comes <encdom>  # ▁ in ▁ through ▁ json ▁ as ▁ an ▁ integer, ▁ so ▁ we ▁ convert ▁ it ▁ here. <encdom> <dedent> flavorid = unicode ( flavorid ) <newline>  # ▁ ensure ▁ leading/trailing ▁ whitespaces ▁ not ▁ present. <encdom> if flavorid . strip ( ) != flavorid : <newline> <indent> msg = _ ( "id ▁ cannot ▁ contain ▁ leading ▁ and/or ▁ trailing ▁ whitespace(s)" ) <newline> raise exception . InvalidInput ( reason = msg ) <newline>  # ▁ ensure ▁ flavor ▁ id ▁ does ▁ not ▁ exceed ▁ 255 ▁ characters <encdom> <dedent> utils . check_string_length ( flavorid , 'id' , min_length = 1 , max_length = 255 ) <newline>  # ▁ ensure ▁ flavor ▁ id ▁ does ▁ not ▁ contain ▁ any ▁ special ▁ characters <encdom> valid_flavor_id = VALID_ID_REGEX . search ( flavorid ) <newline> if not valid_flavor_id : <newline> <indent> msg = _ ( "Flavor ▁ id ▁ can ▁ only ▁ contain ▁ letters ▁ from ▁ A-Z ▁ (both ▁ cases), ▁ " "periods, ▁ dashes, ▁ underscores ▁ and ▁ spaces." ) <newline> raise exception . InvalidInput ( reason = msg ) <newline>  # ▁ NOTE(wangbo): ▁ validate ▁ attributes ▁ of ▁ the ▁ creating ▁ flavor. <encdom>  # ▁ ram ▁ and ▁ vcpus ▁ should ▁ be ▁ positive ▁ ( ▁ > ▁ 0) ▁ integers. <encdom>  # ▁ disk, ▁ ephemeral ▁ and ▁ swap ▁ should ▁ be ▁ non-negative ▁ ( ▁ >= ▁ 0) ▁ integers. <encdom> <dedent> flavor_attributes = { 'memory_mb' : ( 'ram' , 1 ) , 'vcpus' : ( 'vcpus' , 1 ) , 'root_gb' : ( 'disk' , 0 ) , 'ephemeral_gb' : ( 'ephemeral' , 0 ) , 'swap' : ( 'swap' , 0 ) } <newline> for key , value in flavor_attributes . items ( ) : <newline> <indent> kwargs [ key ] = utils . validate_integer ( kwargs [ key ] , value [ 0 ] , value [ 1 ] , db . MAX_INT ) <newline>  # ▁ rxtx_factor ▁ should ▁ be ▁ a ▁ positive ▁ float <encdom> <dedent> try : <newline> <indent> kwargs [ 'rxtx_factor' ] = float ( kwargs [ 'rxtx_factor' ] ) <newline> if ( kwargs [ 'rxtx_factor' ] <= 0 or kwargs [ 'rxtx_factor' ] > SQL_SP_FLOAT_MAX ) : <newline> <indent> raise ValueError ( ) <newline> <dedent> <dedent> except ValueError : <newline> <indent> msg = ( _ ( "'rxtx_factor' ▁ argument ▁ must ▁ be ▁ a ▁ float ▁ between ▁ 0 ▁ and ▁ %g" ) % SQL_SP_FLOAT_MAX ) <newline> raise exception . InvalidInput ( reason = msg ) <newline> <dedent> kwargs [ 'name' ] = name <newline> kwargs [ 'flavorid' ] = flavorid <newline>  # ▁ ensure ▁ is_public ▁ attribute ▁ is ▁ boolean <encdom> try : <newline> <indent> kwargs [ 'is_public' ] = strutils . bool_from_string ( is_public , strict = True ) <newline> <dedent> except ValueError : <newline> <indent> raise exception . InvalidInput ( reason = _ ( "is_public ▁ must ▁ be ▁ a ▁ boolean" ) ) <newline> <dedent> flavor = objects . Flavor ( context = context . get_admin_context ( ) , ** kwargs ) <newline> flavor . create ( ) <newline> return flavor <newline> <dedent> def destroy ( name ) : <newline> <indent>  """ Marks ▁ flavor ▁ as ▁ deleted. """  <newline> try : <newline> <indent> if not name : <newline> <indent> raise ValueError ( ) <newline> <dedent> flavor = objects . Flavor ( context = context . get_admin_context ( ) , name = name ) <newline> flavor . destroy ( ) <newline> <dedent> except ( ValueError , exception . NotFound ) : <newline> <indent> LOG . exception ( _LE ( 'Instance ▁ type ▁ %s ▁ not ▁ found ▁ for ▁ deletion' ) , name ) <newline> raise exception . FlavorNotFoundByName ( flavor_name = name ) <newline> <dedent> <dedent> def get_all_flavors ( ctxt = None , inactive = False , filters = None ) : <newline> <indent>  """ Get ▁ all ▁ non-deleted ▁ flavors ▁ as ▁ a ▁ dict. <strnewline> <strnewline> ▁ Pass ▁ inactive=True ▁ if ▁ you ▁ want ▁ deleted ▁ flavors ▁ returned ▁ also. <strnewline> ▁ """  <newline> if ctxt is None : <newline> <indent> ctxt = context . get_admin_context ( ) <newline> <dedent> inst_types = objects . FlavorList . get_all ( ctxt , inactive = inactive , filters = filters ) <newline> inst_type_dict = { } <newline> for inst_type in inst_types : <newline> <indent> inst_type_dict [ inst_type . id ] = inst_type <newline> <dedent> return inst_type_dict <newline> <dedent> def get_all_flavors_sorted_list ( ctxt = None , filters = None , sort_key = 'flavorid' , sort_dir = 'asc' , limit = None , marker = None ) : <newline> <indent>  """ Get ▁ all ▁ non-deleted ▁ flavors ▁ as ▁ a ▁ sorted ▁ list. <strnewline> ▁ """  <newline> if ctxt is None : <newline> <indent> ctxt = context . get_admin_context ( ) <newline> <dedent> return objects . FlavorList . get_all ( ctxt , filters = filters , sort_key = sort_key , sort_dir = sort_dir , limit = limit , marker = marker ) <newline> <dedent> def get_default_flavor ( ) : <newline> <indent>  """ Get ▁ the ▁ default ▁ flavor. """  <newline> name = CONF . default_flavor <newline> return get_flavor_by_name ( name ) <newline> <dedent> def get_flavor ( instance_type_id , ctxt = None , inactive = False ) : <newline> <indent>  """ Retrieves ▁ single ▁ flavor ▁ by ▁ id. """  <newline> if instance_type_id is None : <newline> <indent> return get_default_flavor ( ) <newline> <dedent> if ctxt is None : <newline> <indent> ctxt = context . get_admin_context ( ) <newline> <dedent> if inactive : <newline> <indent> ctxt = ctxt . elevated ( read_deleted = "yes" ) <newline> <dedent> return objects . Flavor . get_by_id ( ctxt , instance_type_id ) <newline> <dedent> def get_flavor_by_name ( name , ctxt = None ) : <newline> <indent>  """ Retrieves ▁ single ▁ flavor ▁ by ▁ name. """  <newline> if name is None : <newline> <indent> return get_default_flavor ( ) <newline> <dedent> if ctxt is None : <newline> <indent> ctxt = context . get_admin_context ( ) <newline> <dedent> return objects . Flavor . get_by_name ( ctxt , name ) <newline>  # ▁ TODO(termie): ▁ flavor-specific ▁ code ▁ should ▁ probably ▁ be ▁ in ▁ the ▁ API ▁ that ▁ uses <encdom>  # ▁ flavors. <encdom> <dedent> def get_flavor_by_flavor_id ( flavorid , ctxt = None , read_deleted = "yes" ) : <newline> <indent>  """ Retrieve ▁ flavor ▁ by ▁ flavorid. <strnewline> <strnewline> ▁ :raises: ▁ FlavorNotFound <strnewline> ▁ """  <newline> if ctxt is None : <newline> <indent> ctxt = context . get_admin_context ( read_deleted = read_deleted ) <newline> <dedent> return objects . Flavor . get_by_flavor_id ( ctxt , flavorid , read_deleted ) <newline> <dedent> def get_flavor_access_by_flavor_id ( flavorid , ctxt = None ) : <newline> <indent>  """ Retrieve ▁ flavor ▁ access ▁ list ▁ by ▁ flavor ▁ id. """  <newline> if ctxt is None : <newline> <indent> ctxt = context . get_admin_context ( ) <newline> <dedent> flavor = objects . Flavor . get_by_flavor_id ( ctxt , flavorid ) <newline> return flavor . projects <newline>  # ▁ NOTE(danms): ▁ This ▁ method ▁ is ▁ deprecated, ▁ do ▁ not ▁ use ▁ it! <encdom>  # ▁ Use ▁ instance.{old_,new_,}flavor ▁ instead, ▁ as ▁ instances ▁ no ▁ longer <encdom>  # ▁ have ▁ flavor ▁ information ▁ in ▁ system_metadata. <encdom> <dedent> def extract_flavor ( instance , prefix = '' ) : <newline> <indent>  """ Create ▁ a ▁ Flavor ▁ object ▁ from ▁ instance's ▁ system_metadata <strnewline> ▁ information. <strnewline> ▁ """  <newline> flavor = objects . Flavor ( ) <newline> sys_meta = utils . instance_sys_meta ( instance ) <newline> if not sys_meta : <newline> <indent> return None <newline> <dedent> for key in system_metadata_flavor_props . keys ( ) : <newline> <indent> type_key = '%sinstance_type_%s' % ( prefix , key ) <newline> setattr ( flavor , key , sys_meta [ type_key ] ) <newline>  # ▁ NOTE(danms): ▁ We ▁ do ▁ NOT ▁ save ▁ all ▁ of ▁ extra_specs, ▁ but ▁ only ▁ the <encdom>  # ▁ NUMA-related ▁ ones ▁ that ▁ we ▁ need ▁ to ▁ avoid ▁ an ▁ uglier ▁ alternative. ▁ This <encdom>  # ▁ should ▁ be ▁ replaced ▁ by ▁ a ▁ general ▁ split-out ▁ of ▁ flavor ▁ information ▁ from <encdom>  # ▁ system_metadata ▁ very ▁ soon. <encdom> <dedent> extra_specs = [ ( k , v ) for k , v in sys_meta . items ( ) if k . startswith ( '%sinstance_type_extra_' % prefix ) ] <newline> if extra_specs : <newline> <indent> flavor . extra_specs = { } <newline> for key , value in extra_specs : <newline> <indent> extra_key = key [ len ( '%sinstance_type_extra_' % prefix ) : ] <newline> flavor . extra_specs [ extra_key ] = value <newline> <dedent> <dedent> return flavor <newline>  # ▁ NOTE(danms): ▁ This ▁ method ▁ is ▁ deprecated, ▁ do ▁ not ▁ use ▁ it! <encdom>  # ▁ Use ▁ instance.{old_,new_,}flavor ▁ instead, ▁ as ▁ instances ▁ no ▁ longer <encdom>  # ▁ have ▁ flavor ▁ information ▁ in ▁ system_metadata. <encdom> <dedent> def save_flavor_info ( metadata , instance_type , prefix = '' ) : <newline> <indent>  """ Save ▁ properties ▁ from ▁ instance_type ▁ into ▁ instance's ▁ system_metadata, <strnewline> ▁ in ▁ the ▁ format ▁ of: <strnewline> <strnewline> ▁ [prefix]instance_type_[key] <strnewline> <strnewline> ▁ This ▁ can ▁ be ▁ used ▁ to ▁ update ▁ system_metadata ▁ in ▁ place ▁ from ▁ a ▁ type, ▁ as ▁ well <strnewline> ▁ as ▁ stash ▁ information ▁ about ▁ another ▁ instance_type ▁ for ▁ later ▁ use ▁ (such ▁ as <strnewline> ▁ during ▁ resize). <strnewline> ▁ """  <newline> for key in system_metadata_flavor_props . keys ( ) : <newline> <indent> to_key = '%sinstance_type_%s' % ( prefix , key ) <newline> metadata [ to_key ] = instance_type [ key ] <newline>  # ▁ NOTE(danms): ▁ We ▁ do ▁ NOT ▁ save ▁ all ▁ of ▁ extra_specs ▁ here, ▁ but ▁ only ▁ the <encdom>  # ▁ NUMA-related ▁ ones ▁ that ▁ we ▁ need ▁ to ▁ avoid ▁ an ▁ uglier ▁ alternative. ▁ This <encdom>  # ▁ should ▁ be ▁ replaced ▁ by ▁ a ▁ general ▁ split-out ▁ of ▁ flavor ▁ information ▁ from <encdom>  # ▁ system_metadata ▁ very ▁ soon. <encdom> <dedent> extra_specs = instance_type . get ( 'extra_specs' , { } ) <newline> for extra_prefix in system_metadata_flavor_extra_props : <newline> <indent> for key in extra_specs : <newline> <indent> if key . startswith ( extra_prefix ) : <newline> <indent> to_key = '%sinstance_type_extra_%s' % ( prefix , key ) <newline> metadata [ to_key ] = extra_specs [ key ] <newline> <dedent> <dedent> <dedent> return metadata <newline>  # ▁ NOTE(danms): ▁ This ▁ method ▁ is ▁ deprecated, ▁ do ▁ not ▁ use ▁ it! <encdom>  # ▁ Instances ▁ no ▁ longer ▁ store ▁ flavor ▁ information ▁ in ▁ system_metadata <encdom> <dedent> def delete_flavor_info ( metadata , * prefixes ) : <newline> <indent>  """ Delete ▁ flavor ▁ instance_type ▁ information ▁ from ▁ instance's ▁ system_metadata <strnewline> ▁ by ▁ prefix. <strnewline> ▁ """  <newline> for key in system_metadata_flavor_props . keys ( ) : <newline> <indent> for prefix in prefixes : <newline> <indent> to_key = '%sinstance_type_%s' % ( prefix , key ) <newline> del metadata [ to_key ] <newline>  # ▁ NOTE(danms): ▁ We ▁ do ▁ NOT ▁ save ▁ all ▁ of ▁ extra_specs, ▁ but ▁ only ▁ the <encdom>  # ▁ NUMA-related ▁ ones ▁ that ▁ we ▁ need ▁ to ▁ avoid ▁ an ▁ uglier ▁ alternative. ▁ This <encdom>  # ▁ should ▁ be ▁ replaced ▁ by ▁ a ▁ general ▁ split-out ▁ of ▁ flavor ▁ information ▁ from <encdom>  # ▁ system_metadata ▁ very ▁ soon. <encdom> <dedent> <dedent> for key in metadata . keys ( ) : <newline> <indent> for prefix in prefixes : <newline> <indent> if key . startswith ( '%sinstance_type_extra_' % prefix ) : <newline> <indent> del metadata [ key ] <newline> <dedent> <dedent> <dedent> return metadata <newline> <dedent> def validate_extra_spec_keys ( key_names_list ) : <newline> <indent> for key_name in key_names_list : <newline> <indent> if not VALID_EXTRASPEC_NAME_REGEX . match ( key_name ) : <newline> <indent> expl = _ ( 'Key ▁ Names ▁ can ▁ only ▁ contain ▁ alphanumeric ▁ characters, ▁ ' 'periods, ▁ dashes, ▁ underscores, ▁ colons ▁ and ▁ spaces.' ) <newline> raise exception . InvalidInput ( message = expl ) <newline> <dedent> <dedent> <dedent>
 # ▁ This ▁ file ▁ is ▁ part ▁ of ▁ the ▁ MapProxy ▁ project. <encdom>  # ▁ Copyright ▁ (C) ▁ 2012 ▁ Omniscale ▁ <http://omniscale.de> <encdom>  # ▁ Licensed ▁ under ▁ the ▁ Apache ▁ License, ▁ Version ▁ 2.0 ▁ (the ▁"License"); <encdom>  # ▁ you ▁ may ▁ not ▁ use ▁ this ▁ file ▁ except ▁ in ▁ compliance ▁ with ▁ the ▁ License. <encdom>  # ▁ You ▁ may ▁ obtain ▁ a ▁ copy ▁ of ▁ the ▁ License ▁ at <encdom>  # ▁ http://www.apache.org/licenses/LICENSE-2.0 <encdom>  # ▁ Unless ▁ required ▁ by ▁ applicable ▁ law ▁ or ▁ agreed ▁ to ▁ in ▁ writing, ▁ software <encdom>  # ▁ distributed ▁ under ▁ the ▁ License ▁ is ▁ distributed ▁ on ▁ an ▁"AS ▁ IS" ▁ BASIS, <encdom>  # ▁ WITHOUT ▁ WARRANTIES ▁ OR ▁ CONDITIONS ▁ OF ▁ ANY ▁ KIND, ▁ either ▁ express ▁ or ▁ implied. <encdom>  # ▁ See ▁ the ▁ License ▁ for ▁ the ▁ specific ▁ language ▁ governing ▁ permissions ▁ and <encdom>  # ▁ limitations ▁ under ▁ the ▁ License. <encdom> from __future__ import with_statement <newline> import multiprocessing <newline> import os <newline> import shutil <newline> import tempfile <newline> import time <newline> from mapproxy . seed . cachelock import CacheLocker , CacheLockedError <newline> class TestCacheLock ( object ) : <newline> <indent> def setup ( self ) : <newline> <indent> self . tmp_dir = tempfile . mkdtemp ( ) <newline> self . lock_file = os . path . join ( self . tmp_dir , 'lock' ) <newline> <dedent> def teardown ( self ) : <newline> <indent> shutil . rmtree ( self . tmp_dir ) <newline> <dedent> def test_free_lock ( self ) : <newline> <indent> locker = CacheLocker ( self . lock_file ) <newline> with locker . lock ( 'foo' ) : <newline> <indent> assert True <newline> <dedent> <dedent> def test_locked_by_process_no_block ( self ) : <newline> <indent> proc_is_locked = multiprocessing . Event ( ) <newline> def lock ( ) : <newline> <indent> locker = CacheLocker ( self . lock_file ) <newline> with locker . lock ( 'foo' ) : <newline> <indent> proc_is_locked . set ( ) <newline> time . sleep ( 10 ) <newline> <dedent> <dedent> p = multiprocessing . Process ( target = lock ) <newline> p . start ( ) <newline>  # ▁ wait ▁ for ▁ process ▁ to ▁ start <encdom> proc_is_locked . wait ( ) <newline> locker = CacheLocker ( self . lock_file ) <newline>  # ▁ test ▁ unlocked ▁ bar <encdom> with locker . lock ( 'bar' , no_block = True ) : <newline> <indent> assert True <newline>  # ▁ test ▁ locked ▁ foo <encdom> <dedent> try : <newline> <indent> with locker . lock ( 'foo' , no_block = True ) : <newline> <indent> assert False <newline> <dedent> <dedent> except CacheLockedError : <newline> <indent> pass <newline> <dedent> finally : <newline> <indent> p . terminate ( ) <newline> p . join ( ) <newline> <dedent> <dedent> def test_locked_by_process_waiting ( self ) : <newline> <indent> proc_is_locked = multiprocessing . Event ( ) <newline> def lock ( ) : <newline> <indent> locker = CacheLocker ( self . lock_file ) <newline> with locker . lock ( 'foo' ) : <newline> <indent> proc_is_locked . set ( ) <newline> time . sleep ( .1 ) <newline> <dedent> <dedent> p = multiprocessing . Process ( target = lock ) <newline> start_time = time . time ( ) <newline> p . start ( ) <newline>  # ▁ wait ▁ for ▁ process ▁ to ▁ start <encdom> proc_is_locked . wait ( ) <newline> locker = CacheLocker ( self . lock_file , polltime = 0.02 ) <newline> try : <newline> <indent> with locker . lock ( 'foo' , no_block = False ) : <newline> <indent> diff = time . time ( ) - start_time <newline> assert diff > 0.1 <newline> <dedent> <dedent> finally : <newline> <indent> p . terminate ( ) <newline> p . join ( ) <newline> <dedent> <dedent> <dedent>
 # ▁ Copyright ▁ 2008 ▁ Armin ▁ Ronacher. <encdom>  # ▁ Licensed ▁ to ▁ PSF ▁ under ▁ a ▁ Contributor ▁ Agreement. <encdom>  """ Fixer ▁ that ▁ cleans ▁ up ▁ a ▁ tuple ▁ argument ▁ to ▁ isinstance ▁ after ▁ the ▁ tokens <strnewline> in ▁ it ▁ were ▁ fixed. ▁ This ▁ is ▁ mainly ▁ used ▁ to ▁ remove ▁ double ▁ occurrences ▁ of <strnewline> tokens ▁ as ▁ a ▁ leftover ▁ of ▁ the ▁ long ▁ -> ▁ int ▁ / ▁ unicode ▁ -> ▁ str ▁ conversion. <strnewline> <strnewline> eg. ▁ isinstance(x, ▁ (int, ▁ long)) ▁ -> ▁ isinstance(x, ▁ (int, ▁ int)) <strnewline> ▁ -> ▁ isinstance(x, ▁ int) <strnewline> """  <newline> from . . import fixer_base <newline> from . . fixer_util import token <newline> class FixIsinstance ( fixer_base . BaseFix ) : <newline> <indent> BM_compatible = True <newline> PATTERN =  """ <strnewline> ▁ ▁ ▁ ▁ power< <strnewline> ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁'isinstance' <strnewline> ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ trailer< ▁'(' ▁ arglist< ▁ any ▁',' ▁ atom< ▁'(' <strnewline> ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ args=testlist_gexp< ▁ any+ ▁ > <strnewline> ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁')' ▁ > ▁ > ▁')' ▁ > <strnewline> ▁ ▁ ▁ ▁ > <strnewline> ▁ ▁ ▁ ▁ """  <newline> run_order = 6 <newline> def transform ( self , node , results ) : <newline> <indent> names_inserted = set ( ) <newline> testlist = results [ "args" ] <newline> args = testlist . children <newline> new_args = [ ] <newline> iterator = enumerate ( args ) <newline> for idx , arg in iterator : <newline> <indent> if arg . type == token . NAME and arg . value in names_inserted : <newline> <indent> if idx < len ( args ) - 1 and args [ idx + 1 ] . type == token . COMMA : <newline> <indent> iterator . next ( ) <newline> continue <newline> <dedent> <dedent> else : <newline> <indent> new_args . append ( arg ) <newline> if arg . type == token . NAME : <newline> <indent> names_inserted . add ( arg . value ) <newline> <dedent> <dedent> <dedent> if new_args and new_args [ - 1 ] . type == token . COMMA : <newline> <indent> del new_args [ - 1 ] <newline> <dedent> if len ( new_args ) == 1 : <newline> <indent> atom = testlist . parent <newline> new_args [ 0 ] . prefix = atom . prefix <newline> atom . replace ( new_args [ 0 ] ) <newline> <dedent> else : <newline> <indent> args [ : ] = new_args <newline> node . changed ( ) <newline> <dedent> <dedent> <dedent>
 # ▁ Copyright ▁ 2013 ▁ OpenStack ▁ Foundation <encdom>  # ▁ Licensed ▁ under ▁ the ▁ Apache ▁ License, ▁ Version ▁ 2.0 ▁ (the ▁"License"); ▁ you ▁ may <encdom>  # ▁ not ▁ use ▁ this ▁ file ▁ except ▁ in ▁ compliance ▁ with ▁ the ▁ License. ▁ You ▁ may ▁ obtain <encdom>  # ▁ a ▁ copy ▁ of ▁ the ▁ License ▁ at <encdom>  # ▁ http://www.apache.org/licenses/LICENSE-2.0 <encdom>  # ▁ Unless ▁ required ▁ by ▁ applicable ▁ law ▁ or ▁ agreed ▁ to ▁ in ▁ writing, ▁ software <encdom>  # ▁ distributed ▁ under ▁ the ▁ License ▁ is ▁ distributed ▁ on ▁ an ▁"AS ▁ IS" ▁ BASIS, ▁ WITHOUT <encdom>  # ▁ WARRANTIES ▁ OR ▁ CONDITIONS ▁ OF ▁ ANY ▁ KIND, ▁ either ▁ express ▁ or ▁ implied. ▁ See ▁ the <encdom>  # ▁ License ▁ for ▁ the ▁ specific ▁ language ▁ governing ▁ permissions ▁ and ▁ limitations <encdom>  # ▁ under ▁ the ▁ License. <encdom> import ast <newline> import contextlib <newline> try : <newline> <indent> import cPickle as pickle <newline> <dedent> except ImportError : <newline> <indent> import pickle <newline> <dedent> import errno <newline> import socket <newline> import time <newline> from eventlet import queue <newline> from eventlet import timeout <newline> from oslo_log import log as logging <newline> from oslo_utils import versionutils <newline> from six . moves import http_client <newline> from six . moves import range <newline> from six . moves import urllib <newline> try : <newline> <indent> import xmlrpclib <newline> <dedent> except ImportError : <newline> <indent> import six . moves . xmlrpc_client as xmlrpclib <newline> <dedent> import nova . conf <newline> from nova import context <newline> from nova import exception <newline> from nova . i18n import _ , _LE , _LW <newline> from nova import objects <newline> from nova import version <newline> from nova . virt . xenapi . client import objects as cli_objects <newline> from nova . virt . xenapi import pool <newline> from nova . virt . xenapi import pool_states <newline> LOG = logging . getLogger ( __name__ ) <newline> CONF = nova . conf . CONF <newline> def apply_session_helpers ( session ) : <newline> <indent> session . VM = cli_objects . VM ( session ) <newline> session . SR = cli_objects . SR ( session ) <newline> session . VDI = cli_objects . VDI ( session ) <newline> session . VIF = cli_objects . VIF ( session ) <newline> session . VBD = cli_objects . VBD ( session ) <newline> session . PBD = cli_objects . PBD ( session ) <newline> session . PIF = cli_objects . PIF ( session ) <newline> session . VLAN = cli_objects . VLAN ( session ) <newline> session . host = cli_objects . Host ( session ) <newline> session . network = cli_objects . Network ( session ) <newline> session . pool = cli_objects . Pool ( session ) <newline> <dedent> class XenAPISession ( object ) : <newline> <indent>  """ The ▁ session ▁ to ▁ invoke ▁ XenAPI ▁ SDK ▁ calls. """  <newline>  # ▁ This ▁ is ▁ not ▁ a ▁ config ▁ option ▁ as ▁ it ▁ should ▁ only ▁ ever ▁ be <encdom>  # ▁ changed ▁ in ▁ development ▁ environments. <encdom>  # ▁ MAJOR ▁ VERSION: ▁ Incompatible ▁ changes ▁ with ▁ the ▁ plugins <encdom>  # ▁ MINOR ▁ VERSION: ▁ Compatible ▁ changes, ▁ new ▁ plguins, ▁ etc <encdom> PLUGIN_REQUIRED_VERSION = '1.7' <newline> def __init__ ( self , url , user , pw ) : <newline> <indent> version_string = version . version_string_with_package ( ) <newline> self . nova_version = ( '%(vendor)s ▁ %(product)s ▁ %(version)s' % { 'vendor' : version . vendor_string ( ) , 'product' : version . product_string ( ) , 'version' : version_string } ) <newline> import XenAPI <newline> self . XenAPI = XenAPI <newline> self . _sessions = queue . Queue ( ) <newline> self . is_slave = False <newline> self . host_checked = False <newline> exception = self . XenAPI . Failure ( _ ( "Unable ▁ to ▁ log ▁ in ▁ to ▁ XenAPI ▁ " "(is ▁ the ▁ Dom0 ▁ disk ▁ full?)" ) ) <newline> self . url = self . _create_first_session ( url , user , pw , exception ) <newline> self . _populate_session_pool ( url , user , pw , exception ) <newline> self . host_uuid = self . _get_host_uuid ( ) <newline> self . host_ref = self . _get_host_ref ( ) <newline> self . product_version , self . product_brand = self . _get_product_version_and_brand ( ) <newline> self . _verify_plugin_version ( ) <newline> apply_session_helpers ( self ) <newline> <dedent> def _login_with_password ( self , user , pw , session , exception ) : <newline> <indent> with timeout . Timeout ( CONF . xenserver . login_timeout , exception ) : <newline> <indent> session . login_with_password ( user , pw , self . nova_version , 'OpenStack' ) <newline> <dedent> <dedent> def _verify_plugin_version ( self ) : <newline> <indent> requested_version = self . PLUGIN_REQUIRED_VERSION <newline> current_version = self . call_plugin_serialized ( 'nova_plugin_version' , 'get_version' ) <newline> if not versionutils . is_compatible ( requested_version , current_version ) : <newline> <indent> raise self . XenAPI . Failure ( _ ( "Plugin ▁ version ▁ mismatch ▁ (Expected ▁ %(exp)s, ▁ got ▁ %(got)s)" ) % { 'exp' : requested_version , 'got' : current_version } ) <newline> <dedent> <dedent> def _create_first_session ( self , url , user , pw , exception ) : <newline> <indent> try : <newline> <indent> session = self . _create_session_and_login ( url , user , pw , exception ) <newline> <dedent> except self . XenAPI . Failure as e : <newline>  # ▁ if ▁ user ▁ and ▁ pw ▁ of ▁ the ▁ master ▁ are ▁ different, ▁ we're ▁ doomed! <encdom> <indent> if e . details [ 0 ] == 'HOST_IS_SLAVE' : <newline> <indent> master = e . details [ 1 ] <newline> url = pool . swap_xapi_host ( url , master ) <newline> session = self . _create_session_and_login ( url , user , pw , exception ) <newline> self . is_slave = True <newline> <dedent> else : <newline> <indent> raise <newline> <dedent> <dedent> self . _sessions . put ( session ) <newline> return url <newline> <dedent> def _populate_session_pool ( self , url , user , pw , exception ) : <newline> <indent> for i in range ( CONF . xenserver . connection_concurrent - 1 ) : <newline> <indent> session = self . _create_session_and_login ( url , user , pw , exception ) <newline> self . _sessions . put ( session ) <newline> <dedent> <dedent> def _get_host_uuid ( self ) : <newline> <indent> if self . is_slave : <newline> <indent> aggr = objects . AggregateList . get_by_host ( context . get_admin_context ( ) , CONF . host , key = pool_states . POOL_FLAG ) [ 0 ] <newline> if not aggr : <newline> <indent> LOG . error ( _LE ( 'Host ▁ is ▁ member ▁ of ▁ a ▁ pool, ▁ but ▁ DB ▁ ' 'says ▁ otherwise' ) ) <newline> raise exception . AggregateHostNotFound ( ) <newline> <dedent> return aggr . metadata [ CONF . host ] <newline> <dedent> else : <newline> <indent> with self . _get_session ( ) as session : <newline> <indent> host_ref = session . xenapi . session . get_this_host ( session . handle ) <newline> return session . xenapi . host . get_uuid ( host_ref ) <newline> <dedent> <dedent> <dedent> def _get_product_version_and_brand ( self ) : <newline> <indent>  """ Return ▁ a ▁ tuple ▁ of ▁ (major, ▁ minor, ▁ rev) ▁ for ▁ the ▁ host ▁ version ▁ and <strnewline> ▁ a ▁ string ▁ of ▁ the ▁ product ▁ brand. <strnewline> ▁ """  <newline> software_version = self . _get_software_version ( ) <newline> product_version_str = software_version . get ( 'product_version' ) <newline>  # ▁ Product ▁ version ▁ is ▁ only ▁ set ▁ in ▁ some ▁ cases ▁ (e.g. ▁ XCP, ▁ XenServer) ▁ and <encdom>  # ▁ not ▁ in ▁ others ▁ (e.g. ▁ xenserver-core, ▁ XAPI-XCP). <encdom>  # ▁ In ▁ these ▁ cases, ▁ the ▁ platform ▁ version ▁ is ▁ the ▁ best ▁ number ▁ to ▁ use. <encdom> if product_version_str is None : <newline> <indent> product_version_str = software_version . get ( 'platform_version' , '0.0.0' ) <newline> <dedent> product_brand = software_version . get ( 'product_brand' ) <newline> product_version = versionutils . convert_version_to_tuple ( product_version_str ) <newline> return product_version , product_brand <newline> <dedent> def _get_software_version ( self ) : <newline> <indent> return self . call_xenapi ( 'host.get_software_version' , self . host_ref ) <newline> <dedent> def get_session_id ( self ) : <newline> <indent>  """ Return ▁ a ▁ string ▁ session_id. ▁ Used ▁ for ▁ vnc ▁ consoles. """  <newline> with self . _get_session ( ) as session : <newline> <indent> return str ( session . _session ) <newline> <dedent> <dedent> @ contextlib . contextmanager <newline> def _get_session ( self ) : <newline> <indent>  """ Return ▁ exclusive ▁ session ▁ for ▁ scope ▁ of ▁ with ▁ statement. """  <newline> session = self . _sessions . get ( ) <newline> try : <newline> <indent> yield session <newline> <dedent> finally : <newline> <indent> self . _sessions . put ( session ) <newline> <dedent> <dedent> def _get_host_ref ( self ) : <newline> <indent>  """ Return ▁ the ▁ xenapi ▁ host ▁ on ▁ which ▁ nova-compute ▁ runs ▁ on. """  <newline> with self . _get_session ( ) as session : <newline> <indent> return session . xenapi . host . get_by_uuid ( self . host_uuid ) <newline> <dedent> <dedent> def call_xenapi ( self , method , * args ) : <newline> <indent>  """ Call ▁ the ▁ specified ▁ XenAPI ▁ method ▁ on ▁ a ▁ background ▁ thread. """  <newline> with self . _get_session ( ) as session : <newline> <indent> return session . xenapi_request ( method , args ) <newline> <dedent> <dedent> def call_plugin ( self , plugin , fn , args ) : <newline> <indent>  """ Call ▁ host.call_plugin ▁ on ▁ a ▁ background ▁ thread. """  <newline>  # ▁ NOTE(armando): ▁ pass ▁ the ▁ host ▁ uuid ▁ along ▁ with ▁ the ▁ args ▁ so ▁ that <encdom>  # ▁ the ▁ plugin ▁ gets ▁ executed ▁ on ▁ the ▁ right ▁ host ▁ when ▁ using ▁ XS ▁ pools <encdom> args [ 'host_uuid' ] = self . host_uuid <newline> with self . _get_session ( ) as session : <newline> <indent> return self . _unwrap_plugin_exceptions ( session . xenapi . host . call_plugin , self . host_ref , plugin , fn , args ) <newline> <dedent> <dedent> def call_plugin_serialized ( self , plugin , fn , * args , ** kwargs ) : <newline> <indent> params = { 'params' : pickle . dumps ( dict ( args = args , kwargs = kwargs ) ) } <newline> rv = self . call_plugin ( plugin , fn , params ) <newline> return pickle . loads ( rv ) <newline> <dedent> def call_plugin_serialized_with_retry ( self , plugin , fn , num_retries , callback , retry_cb = None , * args , ** kwargs ) : <newline> <indent>  """ Allows ▁ a ▁ plugin ▁ to ▁ raise ▁ RetryableError ▁ so ▁ we ▁ can ▁ try ▁ again. """  <newline> attempts = num_retries + 1 <newline> sleep_time = 0.5 <newline> for attempt in range ( 1 , attempts + 1 ) : <newline> <indent> try : <newline> <indent> if attempt > 1 : <newline> <indent> time . sleep ( sleep_time ) <newline> sleep_time = min ( 2 * sleep_time , 15 ) <newline> <dedent> callback_result = None <newline> if callback : <newline> <indent> callback_result = callback ( kwargs ) <newline> <dedent> msg = ( '%(plugin)s.%(fn)s ▁ attempt ▁ %(attempt)d/%(attempts)d, ▁ ' 'callback_result: ▁ %(callback_result)s' ) <newline> LOG . debug ( msg , { 'plugin' : plugin , 'fn' : fn , 'attempt' : attempt , 'attempts' : attempts , 'callback_result' : callback_result } ) <newline> return self . call_plugin_serialized ( plugin , fn , * args , ** kwargs ) <newline> <dedent> except self . XenAPI . Failure as exc : <newline> <indent> if self . _is_retryable_exception ( exc , fn ) : <newline> <indent> LOG . warning ( _LW ( '%(plugin)s.%(fn)s ▁ failed. ▁ ' 'Retrying ▁ call.' ) , { 'plugin' : plugin , 'fn' : fn } ) <newline> if retry_cb : <newline> <indent> retry_cb ( exc = exc ) <newline> <dedent> <dedent> else : <newline> <indent> raise <newline> <dedent> <dedent> except socket . error as exc : <newline> <indent> if exc . errno == errno . ECONNRESET : <newline> <indent> LOG . warning ( _LW ( 'Lost ▁ connection ▁ to ▁ XenAPI ▁ during ▁ call ▁ to ▁ ' '%(plugin)s.%(fn)s. ▁ ▁ Retrying ▁ call.' ) , { 'plugin' : plugin , 'fn' : fn } ) <newline> if retry_cb : <newline> <indent> retry_cb ( exc = exc ) <newline> <dedent> <dedent> else : <newline> <indent> raise <newline> <dedent> <dedent> <dedent> raise exception . PluginRetriesExceeded ( num_retries = num_retries ) <newline> <dedent> def _is_retryable_exception ( self , exc , fn ) : <newline> <indent> _type , method , error = exc . details [ : 3 ] <newline> if error == 'RetryableError' : <newline> <indent> LOG . debug ( "RetryableError, ▁ so ▁ retrying ▁ %(fn)s" , { 'fn' : fn } , exc_info = True ) <newline> return True <newline> <dedent> elif "signal" in method : <newline> <indent> LOG . debug ( "Error ▁ due ▁ to ▁ a ▁ signal, ▁ retrying ▁ %(fn)s" , { 'fn' : fn } , exc_info = True ) <newline> return True <newline> <dedent> else : <newline> <indent> return False <newline> <dedent> <dedent> def _create_session ( self , url ) : <newline> <indent>  """ Stubout ▁ point. ▁ This ▁ can ▁ be ▁ replaced ▁ with ▁ a ▁ mock ▁ session. """  <newline> self . is_local_connection = url == "unix://local" <newline> if self . is_local_connection : <newline> <indent> return self . XenAPI . xapi_local ( ) <newline> <dedent> return self . XenAPI . Session ( url ) <newline> <dedent> def _create_session_and_login ( self , url , user , pw , exception ) : <newline> <indent> session = self . _create_session ( url ) <newline> self . _login_with_password ( user , pw , session , exception ) <newline> return session <newline> <dedent> def _unwrap_plugin_exceptions ( self , func , * args , ** kwargs ) : <newline> <indent>  """ Parse ▁ exception ▁ details. """  <newline> try : <newline> <indent> return func ( * args , ** kwargs ) <newline> <dedent> except self . XenAPI . Failure as exc : <newline> <indent> LOG . debug ( "Got ▁ exception: ▁ %s" , exc ) <newline> if ( len ( exc . details ) == 4 and exc . details [ 0 ] == 'XENAPI_PLUGIN_EXCEPTION' and exc . details [ 2 ] == 'Failure' ) : <newline> <indent> params = None <newline> try : <newline> <indent> params = ast . literal_eval ( exc . details [ 3 ] ) <newline> <dedent> except Exception : <newline> <indent> raise exc <newline> <dedent> raise self . XenAPI . Failure ( params ) <newline> <dedent> else : <newline> <indent> raise <newline> <dedent> <dedent> except xmlrpclib . ProtocolError as exc : <newline> <indent> LOG . debug ( "Got ▁ exception: ▁ %s" , exc ) <newline> raise <newline> <dedent> <dedent> def get_rec ( self , record_type , ref ) : <newline> <indent> try : <newline> <indent> return self . call_xenapi ( '%s.get_record' % record_type , ref ) <newline> <dedent> except self . XenAPI . Failure as e : <newline> <indent> if e . details [ 0 ] != 'HANDLE_INVALID' : <newline> <indent> raise <newline> <dedent> <dedent> return None <newline> <dedent> def get_all_refs_and_recs ( self , record_type ) : <newline> <indent>  """ Retrieve ▁ all ▁ refs ▁ and ▁ recs ▁ for ▁ a ▁ Xen ▁ record ▁ type. <strnewline> <strnewline> ▁ Handles ▁ race-conditions ▁ where ▁ the ▁ record ▁ may ▁ be ▁ deleted ▁ between <strnewline> ▁ the ▁ `get_all` ▁ call ▁ and ▁ the ▁ `get_record` ▁ call. <strnewline> ▁ """  <newline> return self . call_xenapi ( '%s.get_all_records' % record_type ) . items ( ) <newline> <dedent> @ contextlib . contextmanager <newline> def custom_task ( self , label , desc = '' ) : <newline> <indent>  """ Return ▁ exclusive ▁ session ▁ for ▁ scope ▁ of ▁ with ▁ statement. """  <newline> name = 'nova-%s' % ( label ) <newline> task_ref = self . call_xenapi ( "task.create" , name , desc ) <newline> try : <newline> <indent> LOG . debug ( 'Created ▁ task ▁ %s ▁ with ▁ ref ▁ %s' % ( name , task_ref ) ) <newline> yield task_ref <newline> <dedent> finally : <newline> <indent> self . call_xenapi ( "task.destroy" , task_ref ) <newline> LOG . debug ( 'Destroyed ▁ task ▁ ref ▁ %s' % ( task_ref ) ) <newline> <dedent> <dedent> @ contextlib . contextmanager <newline> def http_connection ( session ) : <newline> <indent> conn = None <newline> xs_url = urllib . parse . urlparse ( session . url ) <newline> LOG . debug ( "Creating ▁ http(s) ▁ connection ▁ to ▁ %s" % session . url ) <newline> if xs_url . scheme == 'http' : <newline> <indent> conn = http_client . HTTPConnection ( xs_url . netloc ) <newline> <dedent> elif xs_url . scheme == 'https' : <newline> <indent> conn = http_client . HTTPSConnection ( xs_url . netloc ) <newline> <dedent> conn . connect ( ) <newline> try : <newline> <indent> yield conn <newline> <dedent> finally : <newline> <indent> conn . close ( ) <newline> <dedent> <dedent> <dedent>
import time <newline> import datetime <newline> from django import forms <newline> from django . forms . util import ErrorDict <newline> from django . conf import settings <newline> from django . contrib . contenttypes . models import ContentType <newline> from models import Comment <newline> from django . utils . crypto import salted_hmac , constant_time_compare <newline> from django . utils . encoding import force_unicode <newline> from django . utils . hashcompat import sha_constructor <newline> from django . utils . text import get_text_list <newline> from django . utils . translation import ungettext , ugettext_lazy as _ <newline> COMMENT_MAX_LENGTH = getattr ( settings , 'COMMENT_MAX_LENGTH' , 3000 ) <newline> class CommentSecurityForm ( forms . Form ) : <newline> <indent>  """ <strnewline> ▁ Handles ▁ the ▁ security ▁ aspects ▁ (anti-spoofing) ▁ for ▁ comment ▁ forms. <strnewline> ▁ """  <newline> content_type = forms . CharField ( widget = forms . HiddenInput ) <newline> object_pk = forms . CharField ( widget = forms . HiddenInput ) <newline> timestamp = forms . IntegerField ( widget = forms . HiddenInput ) <newline> security_hash = forms . CharField ( min_length = 40 , max_length = 40 , widget = forms . HiddenInput ) <newline> def __init__ ( self , target_object , data = None , initial = None ) : <newline> <indent> self . target_object = target_object <newline> if initial is None : <newline> <indent> initial = { } <newline> <dedent> initial . update ( self . generate_security_data ( ) ) <newline> super ( CommentSecurityForm , self ) . __init__ ( data = data , initial = initial ) <newline> <dedent> def security_errors ( self ) : <newline> <indent>  """ Return ▁ just ▁ those ▁ errors ▁ associated ▁ with ▁ security """  <newline> errors = ErrorDict ( ) <newline> for f in [ "honeypot" , "timestamp" , "security_hash" ] : <newline> <indent> if f in self . errors : <newline> <indent> errors [ f ] = self . errors [ f ] <newline> <dedent> <dedent> return errors <newline> <dedent> def clean_security_hash ( self ) : <newline> <indent>  """ Check ▁ the ▁ security ▁ hash. """  <newline> security_hash_dict = { 'content_type' : self . data . get ( "content_type" , "" ) , 'object_pk' : self . data . get ( "object_pk" , "" ) , 'timestamp' : self . data . get ( "timestamp" , "" ) , } <newline> expected_hash = self . generate_security_hash ( ** security_hash_dict ) <newline> actual_hash = self . cleaned_data [ "security_hash" ] <newline> if not constant_time_compare ( expected_hash , actual_hash ) : <newline>  # ▁ Fallback ▁ to ▁ Django ▁ 1.2 ▁ method ▁ for ▁ compatibility <encdom>  # ▁ PendingDeprecationWarning ▁ <- ▁ here ▁ to ▁ remind ▁ us ▁ to ▁ remove ▁ this <encdom>  # ▁ fallback ▁ in ▁ Django ▁ 1.5 <encdom> <indent> expected_hash_old = self . _generate_security_hash_old ( ** security_hash_dict ) <newline> if not constant_time_compare ( expected_hash_old , actual_hash ) : <newline> <indent> raise forms . ValidationError ( "Security ▁ hash ▁ check ▁ failed." ) <newline> <dedent> <dedent> return actual_hash <newline> <dedent> def clean_timestamp ( self ) : <newline> <indent>  """ Make ▁ sure ▁ the ▁ timestamp ▁ isn't ▁ too ▁ far ▁ (> ▁ 2 ▁ hours) ▁ in ▁ the ▁ past. """  <newline> ts = self . cleaned_data [ "timestamp" ] <newline> if time . time ( ) - ts > ( 2 * 60 * 60 ) : <newline> <indent> raise forms . ValidationError ( "Timestamp ▁ check ▁ failed" ) <newline> <dedent> return ts <newline> <dedent> def generate_security_data ( self ) : <newline> <indent>  """ Generate ▁ a ▁ dict ▁ of ▁ security ▁ data ▁ for ▁"initial" ▁ data. """  <newline> timestamp = int ( time . time ( ) ) <newline> security_dict = { 'content_type' : str ( self . target_object . _meta ) , 'object_pk' : str ( self . target_object . _get_pk_val ( ) ) , 'timestamp' : str ( timestamp ) , 'security_hash' : self . initial_security_hash ( timestamp ) , } <newline> return security_dict <newline> <dedent> def initial_security_hash ( self , timestamp ) : <newline> <indent>  """ <strnewline> ▁ Generate ▁ the ▁ initial ▁ security ▁ hash ▁ from ▁ self.content_object <strnewline> ▁ and ▁ a ▁ (unix) ▁ timestamp. <strnewline> ▁ """  <newline> initial_security_dict = { 'content_type' : str ( self . target_object . _meta ) , 'object_pk' : str ( self . target_object . _get_pk_val ( ) ) , 'timestamp' : str ( timestamp ) , } <newline> return self . generate_security_hash ( ** initial_security_dict ) <newline> <dedent> def generate_security_hash ( self , content_type , object_pk , timestamp ) : <newline> <indent>  """ <strnewline> ▁ Generate ▁ a ▁ HMAC ▁ security ▁ hash ▁ from ▁ the ▁ provided ▁ info. <strnewline> ▁ """  <newline> info = ( content_type , object_pk , timestamp ) <newline> key_salt = "django.contrib.forms.CommentSecurityForm" <newline> value = "-" . join ( info ) <newline> return salted_hmac ( key_salt , value ) . hexdigest ( ) <newline> <dedent> def _generate_security_hash_old ( self , content_type , object_pk , timestamp ) : <newline> <indent>  """ Generate ▁ a ▁ (SHA1) ▁ security ▁ hash ▁ from ▁ the ▁ provided ▁ info. """  <newline>  # ▁ Django ▁ 1.2 ▁ compatibility <encdom> info = ( content_type , object_pk , timestamp , settings . SECRET_KEY ) <newline> return sha_constructor ( "" . join ( info ) ) . hexdigest ( ) <newline> <dedent> <dedent> class CommentDetailsForm ( CommentSecurityForm ) : <newline> <indent>  """ <strnewline> ▁ Handles ▁ the ▁ specific ▁ details ▁ of ▁ the ▁ comment ▁ (name, ▁ comment, ▁ etc.). <strnewline> ▁ """  <newline> name = forms . CharField ( label = _ ( "Name" ) , max_length = 50 ) <newline> email = forms . EmailField ( label = _ ( "Email ▁ address" ) ) <newline> url = forms . URLField ( label = _ ( "URL" ) , required = False ) <newline> comment = forms . CharField ( label = _ ( 'Comment' ) , widget = forms . Textarea , max_length = COMMENT_MAX_LENGTH ) <newline> def get_comment_object ( self ) : <newline> <indent>  """ <strnewline> ▁ Return ▁ a ▁ new ▁ (unsaved) ▁ comment ▁ object ▁ based ▁ on ▁ the ▁ information ▁ in ▁ this <strnewline> ▁ form. ▁ Assumes ▁ that ▁ the ▁ form ▁ is ▁ already ▁ validated ▁ and ▁ will ▁ throw ▁ a <strnewline> ▁ ValueError ▁ if ▁ not. <strnewline> <strnewline> ▁ Does ▁ not ▁ set ▁ any ▁ of ▁ the ▁ fields ▁ that ▁ would ▁ come ▁ from ▁ a ▁ Request ▁ object <strnewline> ▁ (i.e. ▁ ``user`` ▁ or ▁ ``ip_address``). <strnewline> ▁ """  <newline> if not self . is_valid ( ) : <newline> <indent> raise ValueError ( "get_comment_object ▁ may ▁ only ▁ be ▁ called ▁ on ▁ valid ▁ forms" ) <newline> <dedent> CommentModel = self . get_comment_model ( ) <newline> new = CommentModel ( ** self . get_comment_create_data ( ) ) <newline> new = self . check_for_duplicate_comment ( new ) <newline> return new <newline> <dedent> def get_comment_model ( self ) : <newline> <indent>  """ <strnewline> ▁ Get ▁ the ▁ comment ▁ model ▁ to ▁ create ▁ with ▁ this ▁ form. ▁ Subclasses ▁ in ▁ custom <strnewline> ▁ comment ▁ apps ▁ should ▁ override ▁ this, ▁ get_comment_create_data, ▁ and ▁ perhaps <strnewline> ▁ check_for_duplicate_comment ▁ to ▁ provide ▁ custom ▁ comment ▁ models. <strnewline> ▁ """  <newline> return Comment <newline> <dedent> def get_comment_create_data ( self ) : <newline> <indent>  """ <strnewline> ▁ Returns ▁ the ▁ dict ▁ of ▁ data ▁ to ▁ be ▁ used ▁ to ▁ create ▁ a ▁ comment. ▁ Subclasses ▁ in <strnewline> ▁ custom ▁ comment ▁ apps ▁ that ▁ override ▁ get_comment_model ▁ can ▁ override ▁ this <strnewline> ▁ method ▁ to ▁ add ▁ extra ▁ fields ▁ onto ▁ a ▁ custom ▁ comment ▁ model. <strnewline> ▁ """  <newline> return dict ( content_type = ContentType . objects . get_for_model ( self . target_object ) , object_pk = force_unicode ( self . target_object . _get_pk_val ( ) ) , user_name = self . cleaned_data [ "name" ] , user_email = self . cleaned_data [ "email" ] , user_url = self . cleaned_data [ "url" ] , comment = self . cleaned_data [ "comment" ] , submit_date = datetime . datetime . now ( ) , site_id = settings . SITE_ID , is_public = True , is_removed = False , ) <newline> <dedent> def check_for_duplicate_comment ( self , new ) : <newline> <indent>  """ <strnewline> ▁ Check ▁ that ▁ a ▁ submitted ▁ comment ▁ isn't ▁ a ▁ duplicate. ▁ This ▁ might ▁ be ▁ caused <strnewline> ▁ by ▁ someone ▁ posting ▁ a ▁ comment ▁ twice. ▁ If ▁ it ▁ is ▁ a ▁ dup, ▁ silently ▁ return ▁ the ▁ *previous* ▁ comment. <strnewline> ▁ """  <newline> possible_duplicates = self . get_comment_model ( ) . _default_manager . using ( self . target_object . _state . db ) . filter ( content_type = new . content_type , object_pk = new . object_pk , user_name = new . user_name , user_email = new . user_email , user_url = new . user_url , ) <newline> for old in possible_duplicates : <newline> <indent> if old . submit_date . date ( ) == new . submit_date . date ( ) and old . comment == new . comment : <newline> <indent> return old <newline> <dedent> <dedent> return new <newline> <dedent> def clean_comment ( self ) : <newline> <indent>  """ <strnewline> ▁ If ▁ COMMENTS_ALLOW_PROFANITIES ▁ is ▁ False, ▁ check ▁ that ▁ the ▁ comment ▁ doesn't <strnewline> ▁ contain ▁ anything ▁ in ▁ PROFANITIES_LIST. <strnewline> ▁ """  <newline> comment = self . cleaned_data [ "comment" ] <newline> if settings . COMMENTS_ALLOW_PROFANITIES == False : <newline> <indent> bad_words = [ w for w in settings . PROFANITIES_LIST if w in comment . lower ( ) ] <newline> if bad_words : <newline> <indent> plural = len ( bad_words ) > 1 <newline> raise forms . ValidationError ( ungettext ( "Watch ▁ your ▁ mouth! ▁ The ▁ word ▁ %s ▁ is ▁ not ▁ allowed ▁ here." , "Watch ▁ your ▁ mouth! ▁ The ▁ words ▁ %s ▁ are ▁ not ▁ allowed ▁ here." , plural ) % get_text_list ( [ '"%s%s%s"' % ( i [ 0 ] , '-' * ( len ( i ) - 2 ) , i [ - 1 ] ) for i in bad_words ] , 'and' ) ) <newline> <dedent> <dedent> return comment <newline> <dedent> <dedent> class CommentForm ( CommentDetailsForm ) : <newline> <indent> honeypot = forms . CharField ( required = False , label = _ ( 'If ▁ you ▁ enter ▁ anything ▁ in ▁ this ▁ field ▁ ' 'your ▁ comment ▁ will ▁ be ▁ treated ▁ as ▁ spam' ) ) <newline> def clean_honeypot ( self ) : <newline> <indent>  """ Check ▁ that ▁ nothing's ▁ been ▁ entered ▁ into ▁ the ▁ honeypot. """  <newline> value = self . cleaned_data [ "honeypot" ] <newline> if value : <newline> <indent> raise forms . ValidationError ( self . fields [ "honeypot" ] . label ) <newline> <dedent> return value <newline> <dedent> <dedent>
 # !/usr/bin/env ▁ python <encdom>  """ <strnewline> obelisk-cardiograph <strnewline> Script ▁ to ▁ monitor ▁ obelisk ▁ servers' ▁ heartbeat. <strnewline> Author: ▁ Noel ▁ Maersk ▁ <veox ▁ ta ▁ wemakethings ▁ tod ▁ net> <strnewline> License: ▁ Affero ▁ GNU ▁ GPLv3 ▁ (see ▁ LICENSE). <strnewline> <strnewline> A ▁ few ▁ examples ▁ from ▁ `zguide` ▁ were ▁ used, ▁ see: <strnewline> https://github.com/imatix/zguide <strnewline> <strnewline> """  <newline> import zmq <newline>  # ▁ This ▁ list ▁ is ▁ necessarily ▁ over ▁ 72 ▁ characters ▁ wide. <encdom> serverlist = [ { 'address' : 'tcp://obelisk.coinkite.com:9092' , 'network' : 'bitcoin' } , { 'address' : 'tcp://preacher.veox.pw:9092' , 'network' : 'bitcoin-testnet' } ] <newline> class Server ( object ) : <newline> <indent> def __init__ ( self , zmqcontext , properties ) : <newline> <indent>  # ▁ Consider ▁ using ▁ an ▁ initialiser ▁ wrapper ▁ as ▁ in <encdom>  # ▁ https://stackoverflow.com/questions/1389180 <encdom>  # ▁ if ▁ the ▁ property ▁ list ▁ gets ▁ too ▁ long. <encdom>  # ▁ Alternatively, ▁ find ▁ if ▁ there's ▁ a ▁ lib ▁ way ▁ to ▁ do ▁ it. <encdom> self . _address = properties [ 'address' ] <newline> self . _network = properties [ 'network' ] <newline> self . socket = zmqcontext . socket ( zmq . SUB ) <newline> <dedent> @ property <newline> def address ( self ) : <newline> <indent>  """ tcp://<server-address>:<port> """  <newline> return self . _address <newline> <dedent> @ address . setter <newline> def address ( self , value ) : <newline> <indent> self . _address = value <newline> <dedent> @ property <newline> def network ( self ) : <newline> <indent>  """ Human-readable ▁ string ▁ description ▁ of ▁ the ▁ P2P ▁ network. """  <newline> return self . _network <newline> <dedent> @ network . setter <newline> def network ( self , value ) : <newline> <indent> self . _network = value <newline> <dedent> def receive_heartbeat ( self ) : <newline> <indent> rawreply = self . socket . recv ( ) <newline> reply = rawreply [ : : - 1 ]  # ▁ obelisk ▁ sends ▁ little-endian <encdom> <newline> return ':' . join ( hex ( x ) [ 2 : ] for x in reply ) <newline> <dedent> def connect ( self , address = None ) : <newline> <indent> if address == None : <newline> <indent> address = self . _address <newline> <dedent> self . socket . connect ( address ) <newline> self . socket . setsockopt ( zmq . SUBSCRIBE , b'' ) <newline> <dedent> def disconnect ( self ) : <newline> <indent> self . socket . close ( ) <newline> <dedent> <dedent> def main ( ) : <newline> <indent>  """ ▁ main ▁ method ▁ """  <newline> context = zmq . Context ( ) <newline> servers = [ ] <newline> for i in serverlist : <newline> <indent> server = Server ( context , i ) <newline> server . connect ( ) <newline> servers . append ( server ) <newline> <dedent> print ( "Entering ▁ main ▁ loop." ) <newline> while True : <newline> <indent> for server in servers : <newline> <indent> print ( server . network , server . address , server . receive_heartbeat ( ) ) <newline>  # ▁ We ▁ never ▁ get ▁ here ▁ but ▁ clean ▁ up ▁ anyhow <encdom> <dedent> <dedent> for server in servers : <newline> <indent> server . disconnect ( ) <newline> <dedent> context . term ( ) <newline> <dedent> if __name__ == "__main__" : <newline> <indent> main ( ) <newline> <dedent>
 # ▁ coding=utf-8 <encdom>  """ <strnewline> The ▁ JCollectdCollector ▁ is ▁ capable ▁ of ▁ receiving ▁ Collectd ▁ network ▁ traffic <strnewline> as ▁ sent ▁ by ▁ the ▁ JCollectd ▁ jvm ▁ agent ▁ (and ▁ child ▁ Collectd ▁ processes). <strnewline> <strnewline> Reason ▁ for ▁ developing ▁ this ▁ collector ▁ is ▁ allowing ▁ to ▁ use ▁ JCollectd, ▁ without <strnewline> the ▁ need ▁ for ▁ Collectd. <strnewline> <strnewline> A ▁ few ▁ notes: <strnewline> <strnewline> This ▁ collector ▁ starts ▁ a ▁ UDP ▁ server ▁ to ▁ receive ▁ data. ▁ This ▁ server ▁ runs ▁ in <strnewline> a ▁ separate ▁ thread ▁ and ▁ puts ▁ it ▁ on ▁ a ▁ queue, ▁ waiting ▁ for ▁ the ▁ collect() ▁ method <strnewline> to ▁ pull. ▁ Because ▁ of ▁ this ▁ setup, ▁ the ▁ collector ▁ interval ▁ parameter ▁ is ▁ of <strnewline> less ▁ importance. ▁ What ▁ matters ▁ is ▁ the ▁'sendinterval' ▁ JCollectd ▁ parameter. <strnewline> <strnewline> See ▁ https://github.com/emicklei/jcollectd ▁ for ▁ an ▁ up-to-date ▁ jcollect ▁ fork. <strnewline> <strnewline> # # # # ▁ Dependencies <strnewline> <strnewline> ▁ * ▁ jcollectd ▁ sending ▁ metrics <strnewline> <strnewline> """  <newline> import threading <newline> import re <newline> import Queue <newline> import diamond . collector <newline> import diamond . metric <newline> import collectd_network <newline> ALIVE = True <newline> class JCollectdCollector ( diamond . collector . Collector ) : <newline> <indent> def __init__ ( self , * args , ** kwargs ) : <newline> <indent> super ( JCollectdCollector , self ) . __init__ ( * args , ** kwargs ) <newline> self . listener_thread = None <newline> <dedent> def get_default_config ( self ) : <newline> <indent>  """ <strnewline> ▁ Returns ▁ the ▁ default ▁ collector ▁ settings <strnewline> ▁ """  <newline> config = super ( JCollectdCollector , self ) . get_default_config ( ) <newline> config . update ( { 'path' : 'jvm' , 'listener_host' : '127.0.0.1' , 'listener_port' : 25826 , } ) <newline> return config <newline> <dedent> def collect ( self ) : <newline> <indent> if not self . listener_thread : <newline> <indent> self . start_listener ( ) <newline> <dedent> q = self . listener_thread . queue <newline> while True : <newline> <indent> try : <newline> <indent> dp = q . get ( False ) <newline> metric = self . make_metric ( dp ) <newline> <dedent> except Queue . Empty : <newline> <indent> break <newline> <dedent> self . publish_metric ( metric ) <newline> <dedent> <dedent> def start_listener ( self ) : <newline> <indent> self . listener_thread = ListenerThread ( self . config [ 'listener_host' ] , self . config [ 'listener_port' ] , self . log ) <newline> self . listener_thread . start ( ) <newline> <dedent> def stop_listener ( self ) : <newline> <indent> global ALIVE <newline> ALIVE = False <newline> self . listener_thread . join ( ) <newline> self . log . error ( 'Listener ▁ thread ▁ is ▁ shut ▁ down.' ) <newline> <dedent> def make_metric ( self , dp ) : <newline> <indent> path = "." . join ( ( dp . host , self . config [ 'path' ] , dp . name ) ) <newline> if 'path_prefix' in self . config : <newline> <indent> prefix = self . config [ 'path_prefix' ] <newline> if prefix : <newline> <indent> path = "." . join ( ( prefix , path ) ) <newline> <dedent> <dedent> if 'path_suffix' in self . config : <newline> <indent> suffix = self . config [ 'path_suffix' ] <newline> if suffix : <newline> <indent> path = "." . join ( ( path , suffix ) ) <newline> <dedent> <dedent> if dp . is_counter : <newline> <indent> metric_type = "COUNTER" <newline> <dedent> else : <newline> <indent> metric_type = "GAUGE" <newline> <dedent> metric = diamond . metric . Metric ( path , dp . value , dp . time , metric_type = metric_type ) <newline> return metric <newline> <dedent> def __del__ ( self ) : <newline> <indent> if self . listener_thread : <newline> <indent> self . stop_listener ( ) <newline> <dedent> <dedent> <dedent> class ListenerThread ( threading . Thread ) : <newline> <indent> def __init__ ( self , host , port , log , poll_interval = 0.4 ) : <newline> <indent> super ( ListenerThread , self ) . __init__ ( ) <newline> self . name = 'JCollectdListener'  # ▁ thread ▁ name <encdom> <newline> self . host = host <newline> self . port = port <newline> self . log = log <newline> self . poll_interval = poll_interval <newline> self . queue = Queue . Queue ( ) <newline> <dedent> def run ( self ) : <newline> <indent> self . log . info ( 'ListenerThread ▁ started ▁ on ▁ {0}:{1}(udp)' . format ( self . host , self . port ) ) <newline> rdr = collectd_network . Reader ( self . host , self . port ) <newline> try : <newline> <indent> while ALIVE : <newline> <indent> try : <newline> <indent> items = rdr . interpret ( poll_interval = self . poll_interval ) <newline> self . send_to_collector ( items ) <newline> <dedent> except ValueError , e : <newline> <indent> self . log . warn ( 'Dropping ▁ bad ▁ packet: ▁ {0}' . format ( e ) ) <newline> <dedent> <dedent> <dedent> except Exception , e : <newline> <indent> self . log . error ( 'caught ▁ exception: ▁ type={0}, ▁ exc={1}' . format ( type ( e ) , e ) ) <newline> <dedent> self . log . info ( 'ListenerThread ▁ - ▁ stop' ) <newline> <dedent> def send_to_collector ( self , items ) : <newline> <indent> if items is None : <newline> <indent> return <newline> <dedent> for item in items : <newline> <indent> try : <newline> <indent> metric = self . transform ( item ) <newline> self . queue . put ( metric ) <newline> <dedent> except Queue . Full : <newline> <indent> self . log . error ( 'Queue ▁ to ▁ collector ▁ is ▁ FULL' ) <newline> <dedent> except Exception , e : <newline> <indent> self . log . error ( 'B00M! ▁ type={0}, ▁ exception={1}' . format ( type ( e ) , e ) ) <newline> <dedent> <dedent> <dedent> def transform ( self , item ) : <newline> <indent> parts = [ ] <newline> path = item . plugininstance <newline>  # ▁ extract ▁ jvm ▁ name ▁ from ▁'logstash-MemoryPool ▁ Eden ▁ Space' <encdom> if '-' in path : <newline> <indent> ( jvm , tail ) = path . split ( '-' , 1 ) <newline> path = tail <newline> <dedent> else : <newline> <indent> jvm = 'unnamed' <newline>  # ▁ add ▁ JVM ▁ name <encdom> <dedent> parts . append ( jvm ) <newline>  # ▁ add ▁ mbean ▁ name ▁ (e.g. ▁'java_lang') <encdom> parts . append ( item . plugin ) <newline>  # ▁ get ▁ typed ▁ mbean: ▁'MemoryPool ▁ Eden ▁ Space' <encdom> if ' ▁ ' in path : <newline> <indent> ( mb_type , mb_name ) = path . split ( ' ▁ ' , 1 ) <newline> parts . append ( mb_type ) <newline> parts . append ( mb_name ) <newline> <dedent> else : <newline> <indent> parts . append ( path ) <newline>  # ▁ add ▁ property ▁ name <encdom> <dedent> parts . append ( item . typeinstance ) <newline>  # ▁ construct ▁ full ▁ path, ▁ from ▁ safe ▁ parts <encdom> name = '.' . join ( [ sanitize_word ( part ) for part in parts ] ) <newline> if item [ 0 ] [ 0 ] == 0 : <newline> <indent> is_counter = True <newline> <dedent> else : <newline> <indent> is_counter = False <newline> <dedent> dp = Datapoint ( item . host , item . time , name , item [ 0 ] [ 1 ] , is_counter ) <newline> return dp <newline> <dedent> <dedent> def sanitize_word ( s ) : <newline> <indent>  """ Remove ▁ non-alphanumerical ▁ characters ▁ from ▁ metric ▁ word. <strnewline> ▁ And ▁ trim ▁ excessive ▁ underscores. <strnewline> ▁ """  <newline> s = re . sub ( '[^\w-]+' , '_' , s ) <newline> s = re . sub ( '__+' , '_' , s ) <newline> return s . strip ( '_' ) <newline> <dedent> class Datapoint ( object ) : <newline> <indent> def __init__ ( self , host , time , name , value , is_counter ) : <newline> <indent> self . host = host <newline> self . time = time <newline> self . name = name <newline> self . value = value <newline> self . is_counter = is_counter <newline> <dedent> <dedent>
 # !/usr/bin/env ▁ python <encdom>  """ \ <strnewline> Sanitize ▁ a ▁ bitbake ▁ file ▁ following ▁ the ▁ OpenEmbedded ▁ style ▁ guidelines, <strnewline> see ▁ http://openembedded.org/wiki/StyleGuide ▁ <strnewline> <strnewline> (C) ▁ 2006 ▁ Cyril ▁ Romain ▁ <cyril.romain@gmail.com> <strnewline> MIT ▁ license <strnewline> <strnewline> TODO: ▁ <strnewline> ▁ - ▁ add ▁ the ▁ others ▁ OpenEmbedded ▁ variables ▁ commonly ▁ used: <strnewline> ▁ - ▁ parse ▁ command ▁ arguments ▁ and ▁ print ▁ usage ▁ on ▁ misuse <strnewline> ▁ . ▁ prevent ▁ giving ▁ more ▁ than ▁ one ▁ .bb ▁ file ▁ in ▁ arguments <strnewline> ▁ - ▁ write ▁ result ▁ to ▁ a ▁ file <strnewline> ▁ - ▁ backup ▁ the ▁ original ▁ .bb ▁ file <strnewline> ▁ - ▁ make ▁ a ▁ diff ▁ and ▁ ask ▁ confirmation ▁ for ▁ patching ▁ ? <strnewline> ▁ - ▁ do ▁ not ▁ use ▁ startswith ▁ only: <strnewline> ▁ /!\ ▁ startswith('SOMETHING') ▁ is ▁ not ▁ taken ▁ into ▁ account ▁ due ▁ to ▁ the ▁ previous ▁ startswith('S'). <strnewline> ▁ - ▁ count ▁ rule ▁ breaks ▁ and ▁ displays ▁ them ▁ in ▁ the ▁ order ▁ frequence <strnewline> """  <newline> import fileinput <newline> import string <newline> import re <newline> __author__ = "Cyril ▁ Romain ▁ <cyril.romain@gmail.com>" <newline> __version__ = "$Revision: ▁ 0.5 ▁ $" <newline>  # ▁ The ▁ standard ▁ set ▁ of ▁ variables ▁ often ▁ found ▁ in ▁ .bb ▁ files ▁ in ▁ the ▁ preferred ▁ order <encdom> OE_vars = [ 'DESCRIPTION' , 'AUTHOR' , 'HOMEPAGE' , 'SECTION' , 'PRIORITY' , 'LICENSE' , 'DEPENDS' , 'RDEPENDS' , 'RRECOMMENDS' , 'RSUGGESTS' , 'PROVIDES' , 'RPROVIDES' , 'RCONFLICTS' , 'SRCDATE' , 'PE' , 'PV' , 'PR' , 'SRC_URI' , 'S' , 'GPE_TARBALL_SUFFIX' , 'inherit' , 'EXTRA_' , 'do_fetch' , 'do_unpack' , 'do_patch' , 'do_configure' , 'do_compile' , 'do_install' , 'do_package' , 'do_stage' , 'PACKAGE_ARCH' , 'PACKAGES' , 'FILES' , 'WORKDIR' , 'acpaths' , 'addhandler' , 'addtask' , 'bindir' , 'export' , 'headers' , 'include' , 'includedir' , 'python' , 'qtopiadir' , 'pkg_preins' , 'pkg_prerm' , 'pkg_postins' , 'pkg_postrm' , 'require' , 'sbindir' , 'basesysconfdir' , 'sysconfdir' , 'ALLOW_EMPTY' , 'ALTERNATIVE_NAME' , 'ALTERNATIVE_PATH' , 'ALTERNATIVE_LINK' , 'ALTERNATIVE_PRIORITY' , 'ALTNAME' , 'AMD_DRIVER_LABEL' , 'AMD_DRIVER_VERSION' , 'ANGSTROM_EXTRA_INSTALL' , 'APPDESKTOP' , 'APPIMAGE' , 'APPNAME' , 'APPTYPE' , 'APPWEB_BUILD' , 'APPWEB_HOST' , 'AR' , 'ARCH' , 'ARM_INSTRUCTION_SET' , 'ARM_MUTEX' , 'ART_CONFIG' , 'B' , 'BJAM_OPTS' , 'BJAM_TOOLS' , 'BONOBO_HEADERS' , 'BOOTSCRIPTS' , 'BROKEN' , 'BUILD_CPPFLAGS' , 'CFLAGS' , 'CCFLAGS' , 'CMDLINE' , 'COLLIE_MEMORY_SIZE' , 'COMPATIBLE_HOST' , 'COMPATIBLE_MACHINE' , 'COMPILE_HERMES' , 'CONFFILES' , 'CONFLICTS' , 'CORE_EXTRA_D' , 'CORE_PACKAGES_D' , 'CORE_PACKAGES_RD' , 'CPPFLAGS' , 'CVSDATE' , 'CXXFLAGS' , 'DEBIAN_NOAUTONAME' , 'DEBUG_APPS' , 'DEFAULT_PREFERENCE' , 'DB4_CONFIG' , 'EXCLUDE_FROM_SHLIBS' , 'EXCLUDE_FROM_WORLD' , 'FIXEDSRCDATE' , 'GLIBC_ADDONS' , 'GLIBC_EXTRA_OECONF' , 'GNOME_VFS_HEADERS' , 'HEADERS' , 'INHIBIT_DEFAULT_DEPS' , 'INITSCRIPT_PACKAGES' , 'INITSCRIPT_NAME' , 'INITSCRIPT_PARAMS' , 'PACKAGE_INSTALL' , 'KERNEL_IMAGETYPE' , 'KERNEL_IMAGEDEST' , 'KERNEL_OUTPUT' , 'KERNEL_RELEASE' , 'KERNEL_PRIORITY' , 'KERNEL_SOURCE' , 'KERNEL_SUFFIX' , 'KERNEL_VERSION' , 'K_MAJOR' , 'K_MICRO' , 'K_MINOR' , 'HHV' , 'KV' , 'LDFLAGS' , 'LD' , 'LD_SO' , 'LDLIBS' , 'LEAD_SONAME' , 'LIBTOOL' , 'LIBBDB_EXTRA' , 'LIBV' , 'MACHINE_ESSENTIAL_EXTRA_RDEPENDS' , 'MACHINE_ESSENTIAL_EXTRA_RRECOMMENDS' , 'MACHINE_EXTRA_RDEPENDS' , 'MACHINE_EXTRA_RRECOMMENDS' , 'MACHINE_FEATURES' , 'MACHINE_TASKS' , 'MACHINE' , 'MACHTYPE' , 'MAKE_TARGETS' , 'MESSAGEUSER' , 'MESSAGEHOME' , 'MIRRORS' , 'MUTEX' , 'OE_QMAKE_INCDIR_QT' , 'OE_QMAKE_CXXFLAGS' , 'ORBIT_IDL_SRC' , 'PARALLEL_MAKE' , 'PAKCAGE_ARCH' , 'PCMCIA_MANAGER' , 'PKG_BASENAME' , 'PKG' , 'QEMU' , 'QMAKE_PROFILES' , 'QPEDIR' , 'QPF_DESCRIPTION' , 'QPF_PKGPATTERN' , 'QT_CONFIG_FLAGS' , 'QT_LIBRARY' , 'ROOTFS_POSTPROCESS_COMMAND' , 'RREPLACES' , 'TARGET_CFLAGS' , 'TARGET_CPPFLAGS' , 'TARGET_LDFLAGS' , 'UBOOT_MACHINE' , 'UCLIBC_BASE' , 'UCLIBC_PATCHES' , 'VIRTUAL_NAME' , 'XORG_PN' , 'XSERVER' , 'others' ] <newline> varRegexp = r'^([a-zA-Z_0-9${}-]*)([ ▁ \t]*)([+.:]?=[+.]?)([ ▁ \t]*)([^\t]+)' <newline> routineRegexp = r'^([a-zA-Z0-9_ ▁ ${}-]+?)\(' <newline>  # ▁ Variables ▁ seen ▁ in ▁ the ▁ processed ▁ .bb <encdom> seen_vars = { } <newline> for v in OE_vars : <newline> <indent> seen_vars [ v ] = [ ] <newline>  # ▁ _Format ▁ guideline ▁ # 0_: ▁ <encdom>  # ▁ No ▁ spaces ▁ are ▁ allowed ▁ at ▁ the ▁ beginning ▁ of ▁ lines ▁ that ▁ define ▁ a ▁ variable ▁ or ▁ <encdom>  # ▁ a ▁ do_ ▁ routine <encdom> <dedent> def respect_rule0 ( line ) : <newline> <indent> return line . lstrip ( ) == line <newline> <dedent> def conformTo_rule0 ( line ) : <newline> <indent> return line . lstrip ( ) <newline>  # ▁ _Format ▁ guideline ▁ # 1_: ▁ <encdom>  # ▁ No ▁ spaces ▁ are ▁ allowed ▁ behind ▁ the ▁ line ▁ continuation ▁ symbol ▁ '\' <encdom> <dedent> def respect_rule1 ( line ) : <newline> <indent> if line . rstrip ( ) . endswith ( '\\' ) : <newline> <indent> return line . endswith ( '\\' ) <newline> <dedent> else : <newline> <indent> return True <newline> <dedent> <dedent> def conformTo_rule1 ( line ) : <newline> <indent> return line . rstrip ( ) <newline>  # ▁ _Format ▁ guideline ▁ # 2_: ▁ <encdom>  # ▁ Tabs ▁ should ▁ not ▁ be ▁ used ▁ (use ▁ spaces ▁ instead). <encdom> <dedent> def respect_rule2 ( line ) : <newline> <indent> return line . count ( '\t' ) == 0 <newline> <dedent> def conformTo_rule2 ( line ) : <newline> <indent> return line . expandtabs ( ) <newline>  # ▁ _Format ▁ guideline ▁ # 3_: <encdom>  # ▁ Comments ▁ inside ▁ bb ▁ files ▁ are ▁ allowed ▁ using ▁ the ▁' # ' ▁ character ▁ at ▁ the ▁ <encdom>  # ▁ beginning ▁ of ▁ a ▁ line. <encdom> <dedent> def respect_rule3 ( line ) : <newline> <indent> if line . lstrip ( ) . startswith ( ' # ' ) : <newline> <indent> return line . startswith ( ' # ' ) <newline> <dedent> else : <newline> <indent> return True <newline> <dedent> <dedent> def conformTo_rule3 ( line ) : <newline> <indent> return line . lstrip ( ) <newline>  # ▁ _Format ▁ guideline ▁ # 4_: <encdom>  # ▁ Use ▁ quotes ▁ on ▁ the ▁ right ▁ hand ▁ side ▁ of ▁ assignments ▁ FOO ▁ = ▁"BAR" <encdom> <dedent> def respect_rule4 ( line ) : <newline> <indent> r = re . search ( varRegexp , line ) <newline> if r is not None : <newline> <indent> r2 = re . search ( r'("?)([^"\\]*)(["\\]?)' , r . group ( 5 ) ) <newline>  # ▁ do ▁ not ▁ test ▁ for ▁ None ▁ it ▁ because ▁ always ▁ match <encdom> return r2 . group ( 1 ) == '"' and r2 . group ( 3 ) != '' <newline> <dedent> return False <newline> <dedent> def conformTo_rule4 ( line ) : <newline> <indent> r = re . search ( varRegexp , line ) <newline> return '' . join ( [ r . group ( 1 ) , ' ▁ ' , r . group ( 3 ) , ' ▁ "' , r . group ( 5 ) , r . group ( 5 ) . endswith ( '"' ) and '' or '"' ] ) <newline>  # ▁ _Format ▁ guideline ▁ # 5_: <encdom>  # ▁ The ▁ correct ▁ spacing ▁ for ▁ a ▁ variable ▁ is ▁ FOO ▁ = ▁"BAR". <encdom> <dedent> def respect_rule5 ( line ) : <newline> <indent> r = re . search ( varRegexp , line ) <newline> return r is not None and r . group ( 2 ) == " ▁ " and r . group ( 4 ) == " ▁ " <newline> <dedent> def conformTo_rule5 ( line ) : <newline> <indent> r = re . search ( varRegexp , line ) <newline> return '' . join ( [ r . group ( 1 ) , ' ▁ ' , r . group ( 3 ) , ' ▁ ' , r . group ( 5 ) ] ) <newline>  # ▁ _Format ▁ guideline ▁ # 6_: <encdom>  # ▁ Don't ▁ use ▁ spaces ▁ or ▁ tabs ▁ on ▁ empty ▁ lines <encdom> <dedent> def respect_rule6 ( line ) : <newline> <indent> return not line . isspace ( ) or line == " \n " <newline> <dedent> def conformTo_rule6 ( line ) : <newline> <indent> return "" <newline>  # ▁ _Format ▁ guideline ▁ # 7_: <encdom>  # ▁ Indentation ▁ of ▁ multiline ▁ variables ▁ such ▁ as ▁ SRC_URI ▁ is ▁ desireable. <encdom> <dedent> def respect_rule7 ( line ) : <newline> <indent> return True <newline> <dedent> def conformTo_rule7 ( line ) : <newline> <indent> return line <newline> <dedent> rules = ( ( respect_rule0 , conformTo_rule0 , "No ▁ spaces ▁ are ▁ allowed ▁ at ▁ the ▁ beginning ▁ of ▁ lines ▁ that ▁ define ▁ a ▁ variable ▁ or ▁ a ▁ do_ ▁ routine" ) , ( respect_rule1 , conformTo_rule1 , "No ▁ spaces ▁ are ▁ allowed ▁ behind ▁ the ▁ line ▁ continuation ▁ symbol ▁'\\'" ) , ( respect_rule2 , conformTo_rule2 , "Tabs ▁ should ▁ not ▁ be ▁ used ▁ (use ▁ spaces ▁ instead)" ) , ( respect_rule3 , conformTo_rule3 , "Comments ▁ inside ▁ bb ▁ files ▁ are ▁ allowed ▁ using ▁ the ▁' # ' ▁ character ▁ at ▁ the ▁ beginning ▁ of ▁ a ▁ line" ) , ( respect_rule4 , conformTo_rule4 , "Use ▁ quotes ▁ on ▁ the ▁ right ▁ hand ▁ side ▁ of ▁ assignments ▁ FOO ▁ = ▁ \"BAR\"" ) , ( respect_rule5 , conformTo_rule5 , "The ▁ correct ▁ spacing ▁ for ▁ a ▁ variable ▁ is ▁ FOO ▁ = ▁ \"BAR\"" ) , ( respect_rule6 , conformTo_rule6 , "Don't ▁ use ▁ spaces ▁ or ▁ tabs ▁ on ▁ empty ▁ lines" ) , ( respect_rule7 , conformTo_rule7 , "Indentation ▁ of ▁ multiline ▁ variables ▁ such ▁ as ▁ SRC_URI ▁ is ▁ desireable" ) , ) <newline>  # ▁ Function ▁ to ▁ check ▁ that ▁ a ▁ line ▁ respects ▁ a ▁ rule. ▁ If ▁ not, ▁ it ▁ tries ▁ to ▁ conform <encdom>  # ▁ the ▁ line ▁ to ▁ the ▁ rule. ▁ Reminder ▁ or ▁ Disgression ▁ message ▁ are ▁ dump ▁ accordingly. <encdom> def follow_rule ( i , line ) : <newline> <indent> oldline = line <newline>  # ▁ if ▁ the ▁ line ▁ does ▁ not ▁ respect ▁ the ▁ rule <encdom> if not rules [ i ] [ 0 ] ( line ) : <newline>  # ▁ try ▁ to ▁ conform ▁ it ▁ to ▁ the ▁ rule <encdom> <indent> line = rules [ i ] [ 1 ] ( line ) <newline>  # ▁ if ▁ the ▁ line ▁ still ▁ does ▁ not ▁ respect ▁ the ▁ rule <encdom> if not rules [ i ] [ 0 ] ( line ) : <newline>  # ▁ this ▁ is ▁ a ▁ rule ▁ disgression <encdom> <indent> print " # # ▁ Disgression: ▁ " , rules [ i ] [ 2 ] , " ▁ in:" , oldline <newline> <dedent> else : <newline>  # ▁ just ▁ remind ▁ user ▁ about ▁ his/her ▁ errors <encdom> <indent> print " # # ▁ Reminder: ▁ " , rules [ i ] [ 2 ] , " ▁ in ▁ :" , oldline <newline> <dedent> <dedent> return line <newline> <dedent> if __name__ == "__main__" : <newline>  # ▁ -- ▁ retrieves ▁ the ▁ lines ▁ of ▁ the ▁ .bb ▁ file ▁ -- <encdom> <indent> lines = [ ] <newline> for line in fileinput . input ( ) : <newline>  # ▁ use ▁'if ▁ True' ▁ to ▁ warn ▁ user ▁ about ▁ all ▁ the ▁ rule ▁ he/she ▁ breaks <encdom>  # ▁ use ▁'if ▁ False' ▁ to ▁ conform ▁ to ▁ rules{2,1,6} ▁ without ▁ warnings <encdom> <indent> if True : <newline> <indent> lines . append ( line ) <newline> <dedent> else : <newline>  # ▁ expandtabs ▁ on ▁ each ▁ line ▁ so ▁ that ▁ rule2 ▁ is ▁ always ▁ respected ▁ <encdom>  # ▁ rstrip ▁ each ▁ line ▁ so ▁ that ▁ rule1 ▁ is ▁ always ▁ respected ▁ <encdom> <indent> line = line . expandtabs ( ) . rstrip ( ) <newline>  # ▁ ignore ▁ empty ▁ lines ▁ (or ▁ line ▁ filled ▁ with ▁ spaces ▁ or ▁ tabs ▁ only) <encdom>  # ▁ so ▁ that ▁ rule6 ▁ is ▁ always ▁ respected <encdom> if line is not '' : <newline> <indent> lines . append ( line ) <newline>  # ▁ -- ▁ parse ▁ the ▁ file ▁ -- <encdom> <dedent> <dedent> <dedent> var = "" <newline> in_routine = False <newline> commentBloc = [ ] <newline> olines = [ ] <newline> for line in lines : <newline> <indent> originalLine = line <newline>  # ▁ rstrip ▁ line ▁ to ▁ remove ▁ line ▁ breaks ▁ characters <encdom> line = line . rstrip ( ) <newline> line = follow_rule ( 2 , line ) <newline> line = follow_rule ( 1 , line ) <newline> line = follow_rule ( 6 , line ) <newline>  # ▁ ignore ▁ empty ▁ lines <encdom> if line . isspace ( ) or line is '' : <newline>  # ▁ flush ▁ comments ▁ into ▁ the ▁ olines <encdom> <indent> for c in commentBloc : olines . append ( c ) <newline> commentBloc = [ ] <newline> continue <newline> <dedent> if line . startswith ( '}' ) : <newline> <indent> in_routine = False <newline> <dedent> keep = line . endswith ( '\\' ) or in_routine <newline>  # ▁ handles ▁ commented ▁ lines <encdom> if line . lstrip ( ) . startswith ( ' # ' ) : <newline>  # ▁ check ▁ and ▁ follow ▁ rule3 ▁ if ▁ not ▁ in ▁ a ▁ variables ▁ or ▁ routines <encdom> <indent> if not in_routine : <newline> <indent> line = follow_rule ( 3 , line ) <newline> <dedent> commentBloc . append ( line ) <newline> continue <newline> <dedent> if seen_vars . has_key ( var ) : <newline> <indent> for c in commentBloc : seen_vars [ var ] . append ( c ) <newline> commentBloc = [ ] <newline> seen_vars [ var ] . append ( line ) <newline> <dedent> else : <newline> <indent> for k in OE_vars : <newline> <indent> if line . startswith ( k ) : <newline> <indent> var = k <newline> break <newline> <dedent> <dedent> if re . match ( routineRegexp , line ) is not None : <newline> <indent> in_routine = True <newline> line = follow_rule ( 0 , line ) <newline> <dedent> elif re . match ( varRegexp , line ) is not None : <newline> <indent> line = follow_rule ( 0 , line ) <newline> line = follow_rule ( 4 , line ) <newline> line = follow_rule ( 5 , line ) <newline> <dedent> if var == "" : <newline> <indent> if not in_routine : <newline> <indent> print " # # ▁ Warning: ▁ unknown ▁ variable/routine ▁ \"%s\"" % originalLine <newline> <dedent> var = 'others' <newline> <dedent> for c in commentBloc : seen_vars [ var ] . append ( c ) <newline> commentBloc = [ ] <newline> seen_vars [ var ] . append ( line ) <newline> <dedent> if not keep and not in_routine : var = "" <newline>  # ▁ -- ▁ dump ▁ the ▁ sanitized ▁ .bb ▁ file ▁ -- <encdom> <dedent> addEmptyLine = False <newline>  # ▁ write ▁ comments ▁ that ▁ are ▁ not ▁ related ▁ to ▁ variables ▁ nor ▁ routines <encdom> for l in commentBloc : olines . append ( l ) <newline>  # ▁ write ▁ variables ▁ and ▁ routines <encdom> previourVarPrefix = "unknown" <newline> for k in OE_vars : <newline> <indent> if k == 'SRC_URI' : addEmptyLine = True <newline> if seen_vars [ k ] != [ ] : <newline> <indent> if addEmptyLine and not k . startswith ( previourVarPrefix ) : <newline> <indent> olines . append ( "" ) <newline> <dedent> for l in seen_vars [ k ] : <newline> <indent> olines . append ( l ) <newline> <dedent> previourVarPrefix = k . split ( '_' ) [ 0 ] == '' and "unknown" or k . split ( '_' ) [ 0 ] <newline> <dedent> <dedent> for line in olines : print line <newline> <dedent>
 # ▁ coding=UTF-8 <encdom>  # ▁ Author: ▁ Dennis ▁ Lutter ▁ <lad1337@gmail.com> <encdom>  # ▁ URL: ▁ https://sickrage.github.io <encdom>  # ▁ This ▁ file ▁ is ▁ part ▁ of ▁ SickRage. <encdom>  # ▁ SickRage ▁ is ▁ free ▁ software: ▁ you ▁ can ▁ redistribute ▁ it ▁ and/or ▁ modify <encdom>  # ▁ it ▁ under ▁ the ▁ terms ▁ of ▁ the ▁ GNU ▁ General ▁ Public ▁ License ▁ as ▁ published ▁ by <encdom>  # ▁ the ▁ Free ▁ Software ▁ Foundation, ▁ either ▁ version ▁ 3 ▁ of ▁ the ▁ License, ▁ or <encdom>  # ▁ (at ▁ your ▁ option) ▁ any ▁ later ▁ version. <encdom>  # ▁ SickRage ▁ is ▁ distributed ▁ in ▁ the ▁ hope ▁ that ▁ it ▁ will ▁ be ▁ useful, <encdom>  # ▁ but ▁ WITHOUT ▁ ANY ▁ WARRANTY; ▁ without ▁ even ▁ the ▁ implied ▁ warranty ▁ of <encdom>  # ▁ MERCHANTABILITY ▁ or ▁ FITNESS ▁ FOR ▁ A ▁ PARTICULAR ▁ PURPOSE. ▁ See ▁ the <encdom>  # ▁ GNU ▁ General ▁ Public ▁ License ▁ for ▁ more ▁ details. <encdom>  # ▁ You ▁ should ▁ have ▁ received ▁ a ▁ copy ▁ of ▁ the ▁ GNU ▁ General ▁ Public ▁ License <encdom>  # ▁ along ▁ with ▁ SickRage. ▁ If ▁ not, ▁ see ▁ <http://www.gnu.org/licenses/>. <encdom>  """ <strnewline> Test ▁ exception ▁ logging <strnewline> """  <newline> from __future__ import print_function , unicode_literals <newline> import os . path <newline> import sys <newline> import unittest <newline> sys . path . insert ( 1 , os . path . abspath ( os . path . join ( os . path . dirname ( __file__ ) , '../lib' ) ) ) <newline> sys . path . insert ( 1 , os . path . abspath ( os . path . join ( os . path . dirname ( __file__ ) , '..' ) ) ) <newline> from sickbeard import logger , ex <newline> def exception_generator ( ) : <newline> <indent>  """ <strnewline> ▁ Dummy ▁ function ▁ to ▁ raise ▁ a ▁ fake ▁ exception ▁ and ▁ log ▁ it <strnewline> ▁ """  <newline> try : <newline> <indent> raise Exception ( 'FAKE ▁ EXCEPTION' ) <newline> <dedent> except Exception as error : <newline> <indent> logger . log ( "FAKE ▁ ERROR: ▁ " + ex ( error ) , logger . ERROR )  # ▁ pylint: ▁ disable=no-member <encdom> <newline> logger . submit_errors ( )  # ▁ pylint: ▁ disable=no-member <encdom> <newline> raise <newline> <dedent> <dedent> class IssueSubmitterBasicTests ( unittest . TestCase ) : <newline> <indent>  """ <strnewline> ▁ Tests ▁ logging ▁ of ▁ exceptions <strnewline> ▁ """  <newline> def test_submitter ( self ) : <newline> <indent>  """ <strnewline> ▁ Test ▁ that ▁ an ▁ exception ▁ is ▁ raised <strnewline> ▁ """  <newline> self . assertRaises ( Exception , exception_generator ) <newline> <dedent> <dedent> if __name__ == "__main__" : <newline> <indent> print ( "==================" ) <newline> print ( "STARTING ▁ - ▁ ISSUE ▁ SUBMITTER ▁ TESTS" ) <newline> print ( "==================" ) <newline> print ( " # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # " ) <newline> SUITE = unittest . TestLoader ( ) . loadTestsFromTestCase ( IssueSubmitterBasicTests ) <newline> unittest . TextTestRunner ( verbosity = 2 ) . run ( SUITE ) <newline> <dedent>
 # !/usr/bin/env ▁ python <encdom>  """ Start ▁ a ▁ webserver ▁ which ▁ can ▁ record ▁ the ▁ data ▁ and ▁ work ▁ as ▁ a ▁ classifier. """  <newline>  # ▁ Core ▁ Library ▁ modules <encdom> import json <newline> import logging <newline> import os <newline> import uuid <newline> from typing import Any , Dict , List , Optional <newline>  # ▁ Third ▁ party ▁ modules <encdom> import pkg_resources <newline> import requests <newline> from flask import Flask , render_template , request <newline> from flask_bootstrap import Bootstrap <newline> from six . moves . urllib . request import urlopen <newline>  # ▁ First ▁ party ▁ modules <encdom> import hwrt <newline>  # ▁ Local ▁ modules <encdom> from . import classify <newline> from . import segmentation as se <newline> from . import utils <newline> logger = logging . getLogger ( __name__ ) <newline> logging . getLogger ( "requests" ) . setLevel ( logging . WARNING ) <newline>  # ▁ Global ▁ variables <encdom> n = 10 <newline> use_segmenter_flag = False <newline> def submit_recording ( raw_data_json ) : <newline> <indent>  """ Submit ▁ a ▁ recording ▁ to ▁ the ▁ database ▁ on ▁ write-math.com. <strnewline> <strnewline> ▁ Parameters <strnewline> ▁ ----- <strnewline> ▁ raw_data_json ▁ : ▁ str <strnewline> ▁ Raw ▁ data ▁ in ▁ JSON ▁ format <strnewline> <strnewline> ▁ Raises <strnewline> ▁ ----- <strnewline> ▁ requests.exceptions.ConnectionError <strnewline> ▁ If ▁ the ▁ internet ▁ connection ▁ is ▁ lost. <strnewline> ▁ """  <newline> url = "http://www.martin-thoma.de/write-math/classify/index.php" <newline> headers = { "User-Agent" : "Mozilla/5.0" , "Content-Type" : "application/x-www-form-urlencoded" , } <newline> payload = { "drawnJSON" : raw_data_json } <newline> s = requests . Session ( ) <newline> req = requests . Request ( "POST" , url , headers = headers , data = payload ) <newline> prepared = req . prepare ( ) <newline> s . send ( prepared ) <newline> <dedent> def show_results ( results : List [ Dict [ str , float ] ] , n : int = 10 ) -> str : <newline> <indent> r """ Show ▁ the ▁ TOP ▁ n ▁ results ▁ of ▁ a ▁ classification. <strnewline> ▁ >>> ▁ results ▁ = ▁ [{'\\alpha': ▁ 0.67, ▁'semantics': ▁'\\alpha', ▁'probability': ▁ 0.67}, <strnewline> ▁ ... ▁ {'\\propto': ▁ 0.25, ▁'semantics': ▁'\\propto', ▁'probability': ▁ 0.33}] <strnewline> ▁ >>> ▁ result_str ▁ = ▁ show_results(results) <strnewline> ▁ Class ▁ Prob <strnewline> ▁ # # # # # <strnewline> ▁ \alpha ▁ 67.0000% <strnewline> ▁ \propto ▁ 33.0000% <strnewline> ▁ # # # # # <strnewline> <strnewline> ▁ """  <newline> import nntoolkit . evaluate <newline> classification = nntoolkit . evaluate . show_results ( results , n ) <newline> return "<pre>" + classification . replace ( " \n " , "<br/>" ) + "</pre>" <newline>  # ▁ configuration <encdom> <dedent> DEBUG = True <newline> template_path = utils . get_template_folder ( ) <newline> app = Flask ( __name__ , template_folder = template_path ) <newline> Bootstrap ( app ) <newline> app . config . from_object ( __name__ ) <newline> @ app . route ( "/" , methods = [ "GET" ] ) <newline> def interactive ( ) : <newline> <indent>  """ Interactive ▁ classifier. """  <newline> if request . method == "GET" and request . args . get ( "heartbeat" , "" ) != "" : <newline> <indent> return request . args . get ( "heartbeat" , "" ) <newline> <dedent> return render_template ( "canvas.html" ) <newline> <dedent> def get_json_result ( results : List [ Dict [ str , Any ] ] , n : int = 10 ) -> str : <newline> <indent>  """ Return ▁ the ▁ top ▁ `n` ▁ results ▁ as ▁ a ▁ JSON ▁ list. <strnewline> <strnewline> ▁ Examples <strnewline> ▁ ----- <strnewline> ▁ >>> ▁ results ▁ = ▁ [{'probability': ▁ 0.65, <strnewline> ▁ ... ▁'whatever': ▁'bar'}, <strnewline> ▁ ... ▁ {'probability': ▁ 0.21, <strnewline> ▁ ... ▁'whatever': ▁'bar'}, <strnewline> ▁ ... ▁ {'probability': ▁ 0.05, <strnewline> ▁ ... ▁'whatever': ▁'bar'},] <strnewline> ▁ >>> ▁ get_json_result(results, ▁ n=2) <strnewline> ▁'[{"probability": ▁ 0.65, ▁ "whatever": ▁ "bar"}, ▁ {"probability": ▁ 0.21, ▁ "whatever": ▁ "bar"}]' <strnewline> ▁ """  <newline> s = [ ] <newline> last = - 1 <newline> for res in results [ : min ( len ( results ) , n ) ] : <newline> <indent> if res [ "probability" ] < last * 0.5 and res [ "probability" ] < 0.05 : <newline> <indent> break <newline> <dedent> if res [ "probability" ] < 0.01 : <newline> <indent> break <newline> <dedent> s . append ( res ) <newline> last = res [ "probability" ] <newline> <dedent> return json . dumps ( s ) <newline> <dedent> @ app . route ( "/worker" , methods = [ "POST" , "GET" ] ) <newline> def worker ( ) : <newline> <indent>  """ Implement ▁ a ▁ worker ▁ for ▁ write-math.com. """  <newline> global n <newline> global use_segmenter_flag <newline> if request . method == "POST" : <newline> <indent> raw_data_json = request . form [ "classify" ] <newline> secret_uuid = request . form . get ( "secret" , None ) <newline> if secret_uuid is None : <newline> <indent> logger . info ( "No ▁ secret ▁ uuid ▁ given. ▁ Create ▁ one." ) <newline> secret_uuid = str ( uuid . uuid4 ( ) ) <newline>  # ▁ Check ▁ recording <encdom> <dedent> try : <newline> <indent> json . loads ( raw_data_json ) <newline> <dedent> except ValueError : <newline> <indent> return "Invalid ▁ JSON ▁ string: ▁ %s" % raw_data_json <newline>  # ▁ Classify <encdom> <dedent> if use_segmenter_flag : <newline> <indent> strokelist = json . loads ( raw_data_json ) <newline> beam = utils . get_beam ( secret_uuid ) <newline> if beam is None : <newline> <indent> beam = se . Beam ( ) <newline> for stroke in strokelist : <newline> <indent> beam . add_stroke ( stroke ) <newline> <dedent> results = beam . get_results ( ) <newline> utils . store_beam ( beam , secret_uuid ) <newline> <dedent> else : <newline> <indent> stroke = strokelist [ - 1 ] <newline> beam . add_stroke ( stroke ) <newline> results = beam . get_results ( ) <newline> utils . store_beam ( beam , secret_uuid ) <newline> <dedent> <dedent> else : <newline> <indent> results = classify . classify_segmented_recording ( raw_data_json ) <newline> <dedent> return get_json_result ( results , n = n ) <newline> <dedent> else : <newline>  # ▁ Page ▁ where ▁ the ▁ user ▁ can ▁ enter ▁ a ▁ recording <encdom> <indent> return "Classification ▁ Worker ▁ (Version ▁ %s)" % hwrt . __version__ <newline> <dedent> <dedent> def _get_part ( pointlist , strokes ) : <newline> <indent>  """ Get ▁ some ▁ strokes ▁ of ▁ pointlist <strnewline> <strnewline> ▁ Parameters <strnewline> ▁ ----- <strnewline> ▁ pointlist ▁ : ▁ list ▁ of ▁ lists ▁ of ▁ dicts <strnewline> ▁ strokes ▁ : ▁ list ▁ of ▁ integers <strnewline> <strnewline> ▁ Returns <strnewline> ▁ ----- <strnewline> ▁ list ▁ of ▁ lists ▁ of ▁ dicts <strnewline> ▁ """  <newline> result = [ ] <newline> strokes = sorted ( strokes ) <newline> for stroke_index in strokes : <newline> <indent> result . append ( pointlist [ stroke_index ] ) <newline> <dedent> return result <newline> <dedent> def _get_translate ( ) -> Dict [ str , str ] : <newline> <indent>  """ <strnewline> ▁ Get ▁ a ▁ dictionary ▁ which ▁ translates ▁ from ▁ a ▁ neural ▁ network ▁ output ▁ to <strnewline> ▁ semantics. <strnewline> ▁ """  <newline> translate = { } <newline> model_path = pkg_resources . resource_filename ( "hwrt" , "misc/" ) <newline> translation_csv = os . path . join ( model_path , "latex2writemathindex.csv" ) <newline> with open ( translation_csv , newline = "" , encoding = "utf8" ) as csvfile : <newline> <indent> contents = csvfile . read ( ) <newline> <dedent> lines = contents . split ( " \n " ) <newline> for csvrow_str in lines : <newline> <indent> csvrow = csvrow_str . split ( "," ) <newline> if len ( csvrow ) == 1 : <newline> <indent> writemathid = csvrow [ 0 ] <newline> latex = "" <newline> <dedent> else : <newline> <indent> writemathid , latex_list = csvrow [ 0 ] , csvrow [ 1 : ] <newline> latex = "," . join ( latex_list ) <newline> <dedent> translate [ latex ] = writemathid <newline> <dedent> return translate <newline> <dedent> def get_writemath_id ( el : Dict [ Any , Any ] , translate ) -> Optional [ int ] : <newline> <indent>  """ <strnewline> ▁ Parameters <strnewline> ▁ ----- <strnewline> ▁ el ▁ : ▁ Dict <strnewline> ▁ with ▁ key ▁'semantics' <strnewline> ▁ results ▁ element <strnewline> <strnewline> ▁ Returns <strnewline> ▁ ----- <strnewline> ▁ writemathid: ▁ Optional[int] <strnewline> ▁ ID ▁ of ▁ the ▁ symbol ▁ on ▁ write-math.com <strnewline> ▁ """  <newline> semantics = el [ "semantics" ] . split ( ";" ) [ 1 ] <newline> if semantics not in translate : <newline> <indent> logger . debug ( f"Could ▁ not ▁ find ▁'{semantics}' ▁ in ▁ translate. ▁ el={el}" ) <newline> return None <newline> <dedent> else : <newline> <indent> writemathid = translate [ semantics ] <newline> <dedent> return writemathid <newline> <dedent> def fix_writemath_answer ( results : List [ Dict [ str , Any ] ] ) : <newline> <indent>  """ <strnewline> ▁ Bring ▁ ``results`` ▁ into ▁ a ▁ format ▁ that ▁ is ▁ accepted ▁ by ▁ write-math.com. ▁ This <strnewline> ▁ means ▁ using ▁ the ▁ ID ▁ for ▁ the ▁ formula ▁ that ▁ is ▁ used ▁ by ▁ the ▁ write-math ▁ server. <strnewline> <strnewline> ▁ Examples <strnewline> ▁ ----- <strnewline> ▁ >>> ▁ results ▁ = ▁ [{'symbolnr': ▁ 214, <strnewline> ▁ ... ▁'semantics': ▁'foobar;A', <strnewline> ▁ ... ▁'probability': ▁ 0.03}] <strnewline> ▁ >>> ▁ fix_writemath_answer(results) <strnewline> ▁ [{'symbolnr': ▁ 214, ▁'semantics': ▁'31', ▁'probability': ▁ 0.03}] <strnewline> ▁ """  <newline> new_results = [ ] <newline>  # ▁ Read ▁ csv <encdom> translate = _get_translate ( ) <newline> for i , el in enumerate ( results ) : <newline> <indent> writemathid = get_writemath_id ( el , translate ) <newline> if writemathid is None : <newline> <indent> continue <newline> <dedent> new_results . append ( { "symbolnr" : el [ "symbolnr" ] , "semantics" : writemathid , "probability" : el [ "probability" ] , } ) <newline> if i >= 10 or ( i > 0 and el [ "probability" ] < 0.20 ) : <newline> <indent> break <newline> <dedent> <dedent> return new_results <newline> <dedent> @ app . route ( "/work" , methods = [ "POST" , "GET" ] ) <newline> def work ( ) : <newline> <indent>  """ Implement ▁ a ▁ worker ▁ for ▁ write-math.com. """  <newline> global n <newline> cmd = utils . get_project_configuration ( ) <newline> if "worker_api_key" not in cmd : <newline> <indent> return "You ▁ need ▁ to ▁ define ▁ a ▁'worker_api_key' ▁ in ▁ your ▁ ~/" <newline> <dedent> chunk_size = 1000 <newline> logger . info ( "Start ▁ working ▁ with ▁ n=%i" , n ) <newline> for _ in range ( chunk_size ) : <newline>  # ▁ contact ▁ the ▁ write-math ▁ server ▁ and ▁ get ▁ something ▁ to ▁ classify <encdom> <indent> url = "http://www.martin-thoma.de/write-math/api/get_unclassified.php" <newline> response = urlopen ( url ) <newline> page_source = response . read ( ) <newline> parsed_json = json . loads ( page_source ) <newline> if parsed_json is False : <newline> <indent> return "Nothing ▁ left ▁ to ▁ classify" <newline> <dedent> raw_data_json = parsed_json [ "recording" ] <newline>  # ▁ Classify <encdom>  # ▁ Check ▁ recording <encdom> try : <newline> <indent> json . loads ( raw_data_json ) <newline> <dedent> except ValueError : <newline> <indent> return "Raw ▁ Data ▁ ID ▁ {}; ▁ Invalid ▁ JSON ▁ string: ▁ {}" . format ( parsed_json [ "id" ] , raw_data_json , ) <newline>  # ▁ Classify <encdom> <dedent> if use_segmenter_flag : <newline> <indent> strokelist = json . loads ( raw_data_json ) <newline> beam = se . Beam ( ) <newline> for stroke in strokelist : <newline> <indent> beam . add_stroke ( stroke ) <newline> <dedent> results = beam . get_writemath_results ( ) <newline> <dedent> else : <newline> <indent> results_sym = classify . classify_segmented_recording ( raw_data_json ) <newline> results = [ ] <newline> strokelist = json . loads ( raw_data_json ) <newline> segmentation = [ list ( range ( len ( strokelist ) ) ) ] <newline> translate = _get_translate ( ) <newline> for symbol in results_sym : <newline> <indent> s = { "id" : get_writemath_id ( symbol , translate ) , "probability" : symbol [ "probability" ] , } <newline> results . append ( { "probability" : symbol [ "probability" ] , "segmentation" : segmentation , "symbols" : [ s ] , } ) <newline> <dedent> <dedent> print ( "\thttp://write-math.com/view/?raw_data_id=%s" % str ( parsed_json [ "id" ] ) ) <newline>  # ▁ Submit ▁ classification ▁ to ▁ write-math.com ▁ server <encdom> results_json = get_json_result ( results , n = n ) <newline> headers = { "User-Agent" : "Mozilla/5.0" , "Content-Type" : "application/x-www-form-urlencoded" , } <newline> payload = { "recording_id" : parsed_json [ "id" ] , "results" : results_json , "api_key" : cmd [ "worker_api_key" ] , } <newline> s = requests . Session ( ) <newline> req = requests . Request ( "POST" , url , headers = headers , data = payload ) <newline> prepared = req . prepare ( ) <newline> response = s . send ( prepared ) <newline> try : <newline> <indent> response = json . loads ( response . text ) <newline> <dedent> except ValueError : <newline> <indent> return "Invalid ▁ JSON ▁ response: ▁ %s" % response . text <newline> <dedent> if "error" in response : <newline> <indent> logger . info ( response ) <newline> return str ( response ) <newline> <dedent> <dedent> return "Done ▁ - ▁ Classified ▁ %i ▁ recordings" % chunk_size <newline> <dedent> def main ( port = 8000 , n_output = 10 , use_segmenter = False ) : <newline> <indent>  """ Main ▁ function ▁ starting ▁ the ▁ webserver. """  <newline> global n <newline> global use_segmenter_flag <newline> n = n_output <newline> use_segmenter_flag = use_segmenter <newline> logger . info ( "Start ▁ webserver..." ) <newline> app . run ( port = port ) <newline> <dedent>
 # !/usr/bin/env ▁ python3 <encdom>  # -*- ▁ encoding:utf-8 ▁ -*- <encdom>  # ▁ silva2011.py ▁ - ▁ Syllable ▁ separation ▁ using ▁ the ▁ algorithm ▁ described ▁ in ▁ Silva <encdom>  # ▁ [2011]. <encdom>  # ▁ Copyright ▁ (C) ▁ 2014 ▁ Alessandro ▁ Bokan <encdom>  # ▁ This ▁ program ▁ is ▁ free ▁ software: ▁ you ▁ can ▁ redistribute ▁ it ▁ and/or ▁ modify ▁ it <encdom>  # ▁ under ▁ the ▁ terms ▁ of ▁ the ▁ GNU ▁ General ▁ Public ▁ License ▁ as ▁ published ▁ by ▁ the ▁ Free <encdom>  # ▁ Software ▁ Foundation, ▁ either ▁ version ▁ 3 ▁ of ▁ the ▁ License, ▁ or ▁ (at ▁ your ▁ option) <encdom>  # ▁ any ▁ later ▁ version. <encdom>  # ▁ This ▁ program ▁ is ▁ distributed ▁ in ▁ the ▁ hope ▁ that ▁ it ▁ will ▁ be ▁ useful, ▁ but ▁ WITHOUT <encdom>  # ▁ ANY ▁ WARRANTY; ▁ without ▁ even ▁ the ▁ implied ▁ warranty ▁ of ▁ MERCHANTABILITY ▁ or <encdom>  # ▁ FITNESS ▁ FOR ▁ A ▁ PARTICULAR ▁ PURPOSE. ▁ See ▁ the ▁ GNU ▁ General ▁ Public ▁ License ▁ for <encdom>  # ▁ more ▁ details. <encdom>  # ▁ You ▁ should ▁ have ▁ received ▁ a ▁ copy ▁ of ▁ the ▁ GNU ▁ General ▁ Public ▁ License ▁ along ▁ with <encdom>  # ▁ this ▁ program. ▁ If ▁ not, ▁ see ▁ <http://www.gnu.org/licenses/>. <encdom>  # ▁ Authors: ▁ Alessandro ▁ Bokan ▁ <alessandro.bokan@gmail.com> <encdom>  # ▁ Andre ▁ Cunha ▁ <andre.lv.cunha@gmail.com> ▁ (minor ▁ modifications) <encdom> from . cases import case1 , case2 , case3 , case4 , case5 , case6 , case7 , case8 <newline> from . tonic import tonic_vowel <newline> from . api import SyllableSeparator <newline> import re <newline> from sys import argv <newline>  # ▁ Vowels <encdom> V = [ 'a' , 'e' , 'o' , 'á' , 'é' , 'í' , 'ó' , 'ú' , 'ã' , 'õ' , 'â' , 'ê' , 'ô' , 'à' , 'ü' ] <newline>  # ▁ Semivowels <encdom> G = [ 'i' , 'u' ] <newline>  # ▁ Stop ▁ consonants <encdom> COc = [ 'ca' , 'co' , 'cu' , 'que' , 'qui' , 'ga' , 'go' , 'gu' , 'gue' , 'gui' ] <newline> CO = [ 'p' , 't' , 'b' , 'd' , 'c' , 'g' , 'q' ] + COc <newline>  # ▁ Fricative ▁ consonants <encdom> CFc = [ 'ce' , 'ci' , 'ss' , 'ch' , 'ge' , 'gi' ] <newline> CF = [ 'f' , 'v' , 's' , 'ç' , 'z' , 'j' , 'x' ] + CFc <newline>  # ▁ Liquid ▁ consonants <encdom> CL = [ 'l' , 'r' , 'rr' ] <newline>  # ▁ Nasal ▁ consonants <encdom> CN = [ 'm' , 'n' ] <newline>  # ▁ Consonants <encdom> C = [ 'lh' , 'nh' ] + CO + CF + CL + CN <newline> class Silva2011SyllableSeparator ( SyllableSeparator ) : <newline> <indent>  """ This ▁ class ▁ implements ▁ the ▁ syllabic ▁ separation ▁ algorithm ▁ presented ▁ in <strnewline> ▁ the ▁ fourth ▁ chapther ▁ of ▁ the ▁ PhD ▁ thesis: <strnewline> <strnewline> ▁ Silva, ▁ D.C. ▁ (2011) ▁ Algoritmos ▁ de ▁ Processamento ▁ da ▁ Linguagem ▁ e ▁ Síntese <strnewline> ▁ de ▁ Voz ▁ com ▁ Emoções ▁ Aplicados ▁ a ▁ um ▁ Conversor ▁ Text-Fala ▁ Baseado <strnewline> ▁ em ▁ HMM. ▁ PhD ▁ dissertation, ▁ COPPE, ▁ UFRJ. <strnewline> ▁ """  <newline> def separate ( self , w ) : <newline> <indent>  """ Separate ▁ the ▁ syllables ▁ of ▁ a ▁ word. <strnewline> <strnewline> ▁ Required ▁ arguments: <strnewline> ▁ w ▁ -- ▁ the ▁ word ▁ that ▁ will ▁ be ▁ separated ▁ in ▁ syllables <strnewline> <strnewline> ▁ Returns: <strnewline> ▁ A ▁ list ▁ of ▁ strings, ▁ containing ▁ each ▁ syllable ▁ of ▁ the ▁ word. <strnewline> ▁ """  <newline> vowels = 'a|e|o|i|u|á|é|í|ó|ú|ã|õ|â|ê|ô|à|ü' <newline> p = [ match . start ( ) for match in re . finditer ( vowels , w , re . UNICODE ) ] <newline> p0 = 0  # ▁ syllable ▁ start ▁ position <encdom> <newline> pVt = tonic_vowel ( w )  # ▁ tonic ▁ vowel ▁ position <encdom> <newline> k = 0 <newline> c = 0  # ▁ Count ▁ hyfens <encdom> <newline>  # ▁ Just ▁ to ▁ pass ▁ the ▁ Biderman ▁ test. <encdom> if len ( w ) == 1 : <newline> <indent> return [ w ] <newline> <dedent> while p0 <= ( len ( w ) - 1 ) : <newline>  # ▁ Rule ▁ 1: <encdom> <indent> if p [ k ] + 1 < len ( w ) and w [ p0 ] in V and not w [ p [ k ] ] in [ 'ã' , 'õ' ] and w [ p [ k ] + 1 ] in V and not w [ p [ k ] + 1 ] in G : <newline>  # ▁ print ▁"RULE ▁ 1" <encdom> <indent> if p [ k ] + 3 < len ( w ) and w [ p [ k ] + 2 ] == 's' and p [ k ] + 3 == len ( w ) : <newline>  # ▁ print ▁"RULE ▁ 1.1" <encdom> <indent> return w <newline> <dedent> else : <newline>  # ▁ print ▁"RULE ▁ 1.2" <encdom> <indent> w , p0 , k , c , p , pVt = case1 ( w , p , p0 , pVt , k , c ) <newline>  # ▁ Rule ▁ 2: <encdom> <dedent> <dedent> elif p [ k ] + 3 < len ( w ) and w [ p0 ] in V and w [ p [ k ] + 1 ] in C and w [ p [ k ] + 2 ] in C and w [ p [ k ] + 3 ] in CO : <newline>  # ▁ print ▁"RULE ▁ 2" <encdom> <indent> w , p0 , k , c , p , pVt = case5 ( w , p , p0 , pVt , k , c ) <newline>  # ▁ Rule ▁ 3: <encdom> <dedent> elif p [ k ] + 2 < len ( w ) and w [ p0 ] in V and w [ p [ k ] + 1 ] in G + CN + [ 's' , 'r' , 'l' , 'x' ] and w [ p [ k ] + 2 ] in C : <newline>  # ▁ TODO ▁ Problema ▁"arr". <encdom>  # ▁ Exemplo: ▁ arrendar ▁ -> ▁ a-rre-dar ▁ (N) ▁ | ▁ ar-ren-dar ▁ (Y) <encdom>  # ▁ print ▁"RULE ▁ 3" <encdom> <indent> if w [ p [ k ] + 1 ] == 'i' and w [ p [ k ] + 2 ] in CN :  # ▁ NOVA ▁ REGRA, ▁ p.ex: ▁"ainda" <encdom> <newline>  # ▁ print ▁"RULE ▁ 3.0" <encdom> <indent> w , p0 , k , c , p , pVt = case1 ( w , p , p0 , pVt , k , c ) <newline> <dedent> elif not w [ p [ k ] + 2 ] in [ 's' , 'h' ] and w [ p [ k ] + 1 ] != w [ p [ k ] + 2 ] : <newline>  # ▁ print ▁"RULE ▁ 3.1" <encdom> <indent> w , p0 , k , c , p , pVt = case2 ( w , p , p0 , pVt , k , c ) <newline> <dedent> elif p [ k ] + 3 < len ( w ) and w [ p [ k ] + 1 ] in CN and w [ p [ k ] + 2 ] == 's' and not w [ p [ k ] + 3 ] in V : <newline>  # ▁ print ▁"RULE ▁ 3.2" <encdom> <indent> w , p0 , k , c , p , pVt = case7 ( w , p , p0 , pVt , k , c ) <newline> <dedent> elif w [ p [ k ] + 1 ] == w [ p [ k ] + 2 ] or w [ p [ k ] + 2 ] == 'h' : <newline>  # ▁ print ▁"RULE ▁ 3.3" <encdom> <indent> w , p0 , k , c , p , pVt = case1 ( w , p , p0 , pVt , k , c ) <newline> <dedent> elif p [ k ] + 3 < len ( w ) and w [ p [ k ] + 2 ] == 's' and ( ( w [ p [ k ] + 3 ] in C and w [ p [ k ] + 3 ] != 's' ) or not w [ p [ k ] + 3 ] in C + V ) : <newline>  # ▁ print ▁"RULE ▁ 3.4" <encdom> <indent> w , p0 , k , c , p , pVt = case7 ( w , p , p0 , pVt , k , c ) <newline> <dedent> else : <newline>  # ▁ print ▁"RULE ▁ 3.5" <encdom> <indent> w , p0 , k , c , p , pVt = case2 ( w , p , p0 , pVt , k , c ) <newline>  # ▁ Rule ▁ 4: <encdom> <dedent> <dedent> elif p [ k ] + 3 < len ( w ) and w [ p0 ] in V and w [ p [ k ] + 1 ] in CO + CF + [ 'g' , 'p' ] and w [ p [ k ] + 2 ] in CO + CF + CN + [ 'ç' ] and w [ p [ k ] + 3 ] in V + G : <newline>  # ▁ print ▁"RULE ▁ 4" <encdom>  # ▁ TODO ▁ adicionando ▁ um ▁ G ▁ ao ▁ w[p[k] ▁ + ▁ 3], ▁ p.ex: ▁ ab-di-car <encdom> <indent> if w [ p [ k ] + 1 ] == w [ p [ k ] + 2 ] : <newline> <indent> w , p0 , k , c , p , pVt = case1 ( w , p , p0 , pVt , k , c ) <newline> <dedent> else : <newline> <indent> w , p0 , k , c , p , pVt = case2 ( w , p , p0 , pVt , k , c ) <newline>  # ▁ Rule ▁ 5: <encdom> <dedent> <dedent> elif p [ k ] + 2 < len ( w ) and w [ p0 ] in V and w [ p [ k ] + 1 ] in C and w [ p [ k ] + 2 ] in V + G + CL + [ 'h' ] : <newline>  # ▁ print ▁"RULE ▁ 5" <encdom> <indent> w , p0 , k , c , p , pVt = case1 ( w , p , p0 , pVt , k , c ) <newline>  # ▁ Rule ▁ 6: <encdom> <dedent> elif p [ k ] + 3 < len ( w ) and w [ p0 ] in V and w [ p [ k ] + 1 ] in G and w [ p [ k ] + 2 ] == 's' and w [ p [ k ] + 3 ] in CO : <newline>  # ▁ TODO ▁ Regra ▁ 6 ▁ esta ▁ dentro ▁ da ▁ regra ▁ 3 <encdom>  # ▁ print ▁"RULE ▁ 6" <encdom> <indent> w , p0 , k , c , p , pVt = case5 ( w , p , p0 , pVt , k , c ) <newline>  # ▁ Rule ▁ 7: <encdom> <dedent> elif p [ k ] + 2 < len ( w ) and not w [ p0 ] in V and w [ p [ k ] - 1 ] in C + [ 'u' , 'ü' , 'q' ] and w [ p [ k ] + 1 ] in C and w [ p [ k ] + 2 ] in V : <newline>  # ▁ print ▁"RULE ▁ 7" <encdom> <indent> w , p0 , k , c , p , pVt = case3 ( w , p , p0 , pVt , k , c ) <newline>  # ▁ Rule ▁ 8: <encdom> <dedent> elif p [ k ] + 3 < len ( w ) and not w [ p0 ] in V and w [ p [ k ] - 1 ] in C and w [ p [ k ] + 1 ] in G and w [ p [ k ] + 2 ] == 'r' and w [ p [ k ] + 3 ] in C : <newline>  # ▁ print ▁"RULE ▁ 8" <encdom>  # ▁ if ▁ p[k] ▁ == ▁ pVt: <encdom>  # ▁ w, ▁ p0, ▁ k, ▁ c, ▁ p, ▁ pVt ▁ = ▁ case4(w, ▁ p, ▁ p0, ▁ pVt, ▁ k, ▁ c) <encdom>  # ▁ else: <encdom> <indent> w , p0 , k , c , p , pVt = case3 ( w , p , p0 , pVt , k , c ) <newline>  # ▁ Rule ▁ 9: <encdom> <dedent> elif p [ k ] + 3 < len ( w ) and not w [ p0 ] in V and w [ p [ k ] - 1 ] in C and w [ p [ k ] + 1 ] in G + CN and w [ p [ k ] + 2 ] == 's' and w [ p [ k ] + 3 ] in CO : <newline>  # ▁ print ▁"RULE ▁ 9" <encdom> <indent> w , p0 , k , c , p , pVt = case7 ( w , p , p0 , pVt , k , c ) <newline>  # ▁ Rule ▁ 10: <encdom> <dedent> elif p [ k ] + 3 < len ( w ) and not w [ p0 ] in V and w [ p [ k ] - 1 ] in C + G and w [ p [ k ] + 1 ] in [ 'i' , 'u' , 'e' , 'o' ] and p [ k ] + 1 != pVt and w [ p [ k ] ] != w [ p [ k ] + 1 ] and w [ p [ k ] + 2 ] in C and w [ p [ k ] + 3 ] in C + V and w [ p [ k ] + 2 ] != 's' : <newline>  # ▁ print ▁"RULE ▁ 10" <encdom>  # ▁ a-juizado <encdom> <indent> if p [ k ] == pVt and w [ p [ k ] + 2 ] != 'n' and not w [ p [ k ] + 3 ] in C : <newline>  # ▁ print ▁"RULE ▁ 10.1" <encdom> <indent> w , p0 , k , c , p , pVt = case4 ( w , p , p0 , pVt , k , c ) <newline> <dedent> elif not w [ p [ k ] - 1 ] in [ 'q' , 'g' ] and w [ p [ k ] ] == 'u' and w [ p [ k ] + 1 ] == 'i' and w [ p [ k ] + 2 ] != 'n' : <newline> <indent> w , p0 , k , c , p , pVt = case1 ( w , p , p0 , pVt , k , c ) <newline> <dedent> elif p [ k ] != pVt and w [ p [ k ] + 1 ] == 'i' and w [ p [ k ] + 2 ] != 'n' : <newline>  # ▁ print ▁"RULE ▁ 10.2" <encdom> <indent> w , p0 , k , c , p , pVt = case2 ( w , p , p0 , pVt , k , c ) <newline> <dedent> elif ( w [ p [ k ] + 1 ] != 'i' and w [ p [ k ] + 2 ] in CN + [ 'r' ] and not w [ p [ k ] + 3 ] in [ 'h' , w [ pVt ] ] ) or ( w [ p [ k ] ] in [ 'a' , 'e' , 'o' ] and w [ p [ k ] + 1 ] in [ 'a' , 'e' , 'o' ] and w [ p [ k ] + 2 ] in CN and not w [ p [ k ] + 3 ] in [ 'h' , 's' ] and w [ p [ k ] + 4 ] in V + C ) : <newline>  # ▁ print ▁"RULE ▁ 10.3" <encdom> <indent> if w [ p [ k ] - 1 : p [ k ] + 1 ] == "gu" and w [ p [ k ] + 1 ] in V and w [ p [ k ] + 2 ] in CN : <newline> <indent> w , p0 , k , c , p , pVt = case5 ( w , p , p0 , pVt , k , c ) <newline> <dedent> elif w [ p [ k ] - 1 : p [ k ] + 1 ] == "gu" and w [ p [ k ] + 1 ] in V and w [ p [ k ] + 2 ] in CL : <newline> <indent> w , p0 , k , c , p , pVt = case2 ( w , p , p0 , pVt , k , c ) <newline> <dedent> else : <newline> <indent> w , p0 , k , c , p , pVt = case1 ( w , p , p0 , pVt , k , c ) <newline> <dedent> <dedent> elif w [ p [ k ] ] in G and w [ p [ k ] + 1 ] in [ 'a' , 'e' , 'o' ] and w [ p [ k ] + 2 ] in CN : <newline>  # ▁ print ▁"RULE ▁ 10.4" <encdom> <indent> w , p0 , k , c , p , pVt = case1 ( w , p , p0 , pVt , k , c ) <newline> <dedent> else : <newline>  # ▁ print ▁"RULE ▁ 10.5" <encdom> <indent> w , p0 , k , c , p , pVt = case4 ( w , p , p0 , pVt , k , c ) <newline>  # ▁ Rule ▁ 11: <encdom> <dedent> <dedent> elif p [ k ] + 2 < len ( w ) and not w [ p0 ] in V and w [ p [ k ] - 1 ] in C and w [ p [ k ] + 1 ] in G and w [ p [ k ] + 2 ] in V : <newline>  # ▁ print ▁"RULE ▁ 11" <encdom> <indent> w , p0 , k , c , p , pVt = case4 ( w , p , p0 , pVt , k , c ) <newline>  # ▁ Rule ▁ 12: <encdom> <dedent> elif p [ k ] + 3 < len ( w ) and not w [ p0 ] in V and w [ p [ k ] - 1 ] in C and w [ p [ k ] ] in G and w [ p [ k ] + 1 ] in V + [ 'i' ] and w [ p [ k ] ] != w [ p [ k ] + 1 ] and w [ p [ k ] + 2 ] in C and w [ p [ k ] + 3 ] in V : <newline>  # ▁ TODO ▁ Agregue ▁ un ▁"i" ▁ as ▁ vogais <encdom>  # ▁ porque ▁ sino ▁ no ▁ entra ▁ ao ▁ exemplo. <encdom>  # ▁ print ▁"RULE ▁ 12" <encdom> <indent> if w [ p [ k ] - 1 ] in [ 'q' , 'g' ] and ( ( w [ p [ k ] + 2 ] == 'ç' and w [ p [ k ] + 3 ] in [ 'ã' , 'õ' ] ) or ( w [ p [ k ] - 1 ] == 'q' and w [ p [ k ] + 1 ] in V ) ) : <newline>  # ▁ print ▁"RULE ▁ 12.1" <encdom> <indent> w , p0 , k , c , p , pVt = case2 ( w , p , p0 , pVt , k , c ) <newline> <dedent> elif p [ k ] + 1 == pVt or w [ p [ k ] - 1 ] == 'r' and p [ k ] + 3 == pVt : <newline>  # ▁ print ▁"RULE ▁ 12.2" <encdom> <indent> w , p0 , k , c , p , pVt = case1 ( w , p , p0 , pVt , k , c ) <newline> <dedent> else : <newline>  # ▁ print ▁"RULE ▁ 12.3" <encdom> <indent> w , p0 , k , c , p , pVt = case8 ( w , p , p0 , pVt , k , c ) <newline>  # ▁ Rule ▁ 13: <encdom> <dedent> <dedent> elif p [ k ] + 3 < len ( w ) and not w [ p0 ] in V and ( w [ p [ k ] - 1 ] in C or ( w [ p [ k ] - 1 : p [ k ] + 1 ] in [ 'qu' , 'qü' , 'gu' , 'gü' ] ) ) and w [ p [ k ] + 1 ] in V + CL + CN + [ 'c' , 'x' ] and w [ p [ k ] + 2 ] in [ 'h' , 'l' , 'r' ] and w [ p [ k ] + 3 ] in V + [ 'h' , 'l' , 'r' ] : <newline>  # ▁ TODO ▁ Arrumando ▁ regra ▁ para ▁"guerra" ▁ -> ▁ gue-rra <encdom>  # ▁ print ▁"RULE ▁ 13" <encdom> <indent> if w [ p [ k ] + 1 ] == w [ p [ k ] + 2 ] or w [ p [ k ] + 1 ] in [ 'c' , 'l' ] or w [ p [ k ] + 1 : p [ k ] + 3 ] == 'nh' : <newline>  # ▁ print ▁"RULE ▁ 13.1" <encdom> <indent> w , p0 , k , c , p , pVt = case1 ( w , p , p0 , pVt , k , c ) <newline> <dedent> else : <newline>  # ▁ print ▁"RULE ▁ 13.2" <encdom> <indent> w , p0 , k , c , p , pVt = case4 ( w , p , p0 , pVt , k , c ) <newline>  # ▁ Rule ▁ 14: <encdom> <dedent> <dedent> elif p [ k ] + 2 < len ( w ) and not w [ p0 ] in V and w [ p [ k ] - 1 ] in C and w [ p [ k ] + 1 ] in CL + CN + [ 'i' ] and w [ p [ k ] + 2 ] == 's' : <newline>  # ▁ print ▁"RULE ▁ 14" <encdom> <indent> if p [ k ] + 3 == len ( w ) : <newline> <indent> p0 = case6 ( w , p0 ) <newline> <dedent> elif p [ k ] == pVt or ( p [ k ] + 3 < len ( w ) and w [ p [ k ] + 3 ] in V ) : <newline> <indent> w , p0 , k , c , p , pVt = case4 ( w , p , p0 , pVt , k , c ) <newline> <dedent> else : <newline> <indent> w , p0 , k , c , p , pVt = case5 ( w , p , p0 , pVt , k , c ) <newline>  # ▁ Rule ▁ 15: <encdom> <dedent> <dedent> elif p [ k ] + 2 < len ( w ) and not w [ p0 ] in V and w [ p [ k ] + 1 ] in V and w [ p [ k ] + 2 ] in V + G and not w [ p [ k ] - 1 : p [ k ] + 1 ] in [ 'qu' , 'gu' ] : <newline>  # ▁ print ▁"RULE ▁ 15", ▁ w[p0] <encdom> <indent> if p [ k ] + 3 < len ( w ) and p [ k ] == pVt and w [ p [ k ] + 1 ] in G and w [ p [ k ] + 3 ] in C : <newline>  # ▁ print ▁"RULE ▁ 15.1" <encdom> <indent> w , p0 , k , c , p , pVt = case2 ( w , p , p0 , pVt , k , c ) <newline> <dedent> else : <newline>  # ▁ print ▁"RULE ▁ 15.2" <encdom> <indent> w , p0 , k , c , p , pVt = case1 ( w , p , p0 , pVt , k , c ) <newline>  # ▁ Rule ▁ 16: <encdom> <dedent> <dedent> elif p [ k ] + 2 < len ( w ) and not w [ p0 ] in V and w [ p [ k ] ] != 'u' and w [ p [ k ] - 1 ] in C and w [ p [ k ] + 1 ] in V and w [ p [ k ] + 2 ] in CN : <newline>  # ▁ print ▁"RULE ▁ 16" <encdom> <indent> w , p0 , k , c , p , pVt = case3 ( w , p , p0 , pVt , k , c ) <newline>  # ▁ Rule ▁ 17: <encdom> <dedent> elif p [ k ] + 1 < len ( w ) and p [ k ] - 2 >= 0 and not w [ p0 ] in V and w [ p [ k ] ] == 'i' and ( w [ p [ k ] - 2 ] in [ 'á' , 'é' , 'í' , 'ó' , 'ú' ] or w [ p [ k ] - 3 ] in [ 'á' , 'é' , 'í' , 'ó' , 'ú' ] ) and w [ p [ k ] - 1 ] in C and w [ p [ k ] + 1 ] in [ 'a' , 'o' ] : <newline>  # ▁ TODO ▁ trocar ▁ caso ▁ 6 ▁ por ▁ caso ▁ 1. <encdom>  # ▁ carícia ▁ -> ▁ ca-rí-cia ▁ (N) ▁ | ▁ ca-rí-ci-a ▁ (Y) <encdom>  # ▁ print ▁"RULE ▁ 17" <encdom> <indent> w , p0 , k , c , p , pVt = case1 ( w , p , p0 , pVt , k , c ) <newline>  # ▁ Rule ▁ 18: <encdom> <dedent> elif p [ k ] + 1 < len ( w ) and not w [ p0 ] in V and w [ p [ k ] ] in [ 'ã' , 'õ' ] and w [ p [ k ] - 1 ] in C and w [ p [ k ] + 1 ] in [ 'e' , 'o' ] : <newline>  # ▁ print ▁"RULE ▁ 18" <encdom> <indent> p0 = case6 ( w , p0 ) <newline>  # ▁ ----- ▁ Change ▁ rule ▁ 19 ▁ by ▁ 20 ▁ ----- <encdom>  # ▁ Rule ▁ 20: <encdom> <dedent> elif p [ k ] + 3 < len ( w ) and not w [ p0 ] in V and w [ p [ k ] - 1 ] in C and w [ p [ k ] + 1 ] in V and w [ p [ k ] + 2 ] in CN and w [ p [ k ] + 3 ] in C : <newline>  # ▁ print ▁"RULE ▁ 20" <encdom> <indent> w , p0 , k , c , p , pVt = case7 ( w , p , p0 , pVt , k , c ) <newline>  # ▁ Rule ▁ 19: <encdom> <dedent> elif p [ k ] + 1 < len ( w ) and not w [ p0 ] in V and w [ p [ k ] - 1 ] in C and p [ k ] + 1 == pVt and not w [ p [ k ] + 1 ] in [ 'i' , 'u' ] and not w [ p [ k ] - 1 : p [ k ] + 1 ] in [ 'gu' , 'qu' ] : <newline>  # ▁ print ▁"RULE ▁ 19" <encdom> <indent> if p [ k ] + 3 == len ( w ) and w [ p [ k ] - 1 : p [ k ] + 1 ] in [ 'gu' , 'qu' ] and w [ p [ k ] + 1 ] in V and w [ p [ k ] + 2 ] in C : <newline>  # ▁ print ▁"RULE ▁ 19.1" <encdom> <indent> p0 = case6 ( w , p0 ) <newline> <dedent> elif p [ k ] + 2 < len ( w ) and w [ p [ k ] - 1 : p [ k ] + 1 ] in [ 'gu' , 'qu' ] and w [ p [ k ] + 1 ] in V and w [ p [ k ] + 2 ] in C + G : <newline>  # ▁ print ▁"RULE ▁ 19.2" <encdom> <indent> w , p0 , k , c , p , pVt = case5 ( w , p , p0 , pVt , k , c ) <newline> <dedent> else : <newline>  # ▁ print ▁"RULE ▁ 19.3" <encdom> <indent> w , p0 , k , c , p , pVt = case3 ( w , p , p0 , pVt , k , c ) <newline>  # ▁ Rule ▁ 21: <encdom> <dedent> <dedent> elif p [ k ] + 3 < len ( w ) and not w [ p0 ] in V and w [ p [ k ] + 1 ] in CO + [ 'f' , 'v' , 'g' ] and w [ p [ k ] + 2 ] in CL + CO and w [ p [ k ] + 3 ] in V + G : <newline>  # ▁ print ▁"RULE ▁ 21" <encdom> <indent> if w [ p [ k ] + 1 ] in [ 'f' , 'p' ] and w [ p [ k ] + 2 ] in [ 't' , 'ç' ] : <newline>  # ▁ print ▁"RULE ▁ 21.1" <encdom> <indent> w , p0 , k , c , p , pVt = case2 ( w , p , p0 , pVt , k , c ) <newline> <dedent> else : <newline>  # ▁ print ▁"RULE ▁ 21.2" <encdom> <indent> w , p0 , k , c , p , pVt = case1 ( w , p , p0 , pVt , k , c ) <newline>  # ▁ Rule ▁ 22: <encdom> <dedent> <dedent> elif p [ k ] + 1 < len ( w ) and p [ k ] - 2 >= 0 and not w [ p0 ] in V and ( w [ p [ k ] - 1 ] in C or w [ p [ k ] - 1 : p [ k ] + 1 ] in [ 'qu' , 'gu' ] ) and w [ p [ k ] + 1 ] in V and ( p [ k ] + 2 == len ( w ) or w [ p [ k ] + 2 ] in C ) : <newline>  # ▁ print ▁"RULE ▁ 22" <encdom> <indent> if ( w [ p [ k ] ] in [ 'i' , 'u' , 'í' , 'ú' , 'é' , 'ê' ] and p [ k ] == pVt and w [ p [ k ] + 1 ] != 'u' ) or ( p [ k ] + 3 < len ( w ) and not w [ p [ k ] ] in G and w [ p [ k ] + 2 ] == 's' and not w [ p [ k ] + 3 ] in C + V ) : <newline>  # ▁ print ▁"RULE ▁ 22.1" <encdom> <indent> w , p0 , k , c , p , pVt = case3 ( w , p , p0 , pVt , k , c ) <newline> <dedent> elif p [ k ] + 2 == len ( w ) and w [ p [ k ] ] == 'i' and p [ k ] == pVt and w [ p [ k ] + 1 ] == 'u' : <newline>  # ▁ print ▁"RULE ▁ 22.2" <encdom> <indent> w , p0 , k , c , p , pVt = case4 ( w , p , p0 , pVt , k , c ) <newline> <dedent> elif p [ k ] + 3 < len ( w ) and ( ( w [ p [ k ] ] in G and p [ k ] + 1 != pVt and not w [ p [ k ] + 2 ] in C + V ) or ( w [ p [ k ] + 2 ] == 's' and not w [ p [ k ] + 3 ] in C + V ) or ( p [ k ] != pVt and p [ k ] + 1 != pVt and w [ p [ k ] + 2 ] == 's' and p [ k ] + 3 == len ( w ) ) ) : <newline>  # ▁ print ▁"RULE ▁ 22.3" <encdom> <indent> p0 = case6 ( w , p0 ) <newline> <dedent> elif p [ k ] + 3 < len ( w ) and w [ p [ k ] - 1 : p [ k ] + 1 ] in [ 'qu' , 'gu' ] and w [ p [ k ] + 2 ] in C and w [ p [ k ] + 3 ] in V + G : <newline>  # ▁ print ▁"RULE ▁ 22.4" <encdom> <indent> w , p0 , k , c , p , pVt = case2 ( w , p , p0 , pVt , k , c ) <newline> <dedent> elif p [ k ] + 2 == len ( w ) and w [ p [ k ] - 1 : p [ k ] + 1 ] in [ 'qu' , 'gu' ] and w [ p [ k ] + 1 ] in V + G : <newline>  # ▁ print ▁"RULE ▁ 22.4.5" <encdom> <indent> p0 = case6 ( w , p0 ) <newline> <dedent> elif p [ k ] + 3 == len ( w ) and w [ p [ k ] + 1 ] in [ 'o' , 'u' ] and p [ k ] + 1 != pVt and w [ p [ k ] + 2 ] == 's' : <newline>  # ▁ print ▁"RULE ▁ 22.5" <encdom> <indent> w , p0 , k , c , p , pVt = case7 ( w , p , p0 , pVt , k , c ) <newline> <dedent> else : <newline>  # ▁ TODO ▁ Trocar ▁ case2 ▁ por ▁ case ▁ 1 <encdom>  # ▁ print ▁"RULE ▁ 22.6" <encdom> <indent> w , p0 , k , c , p , pVt = case1 ( w , p , p0 , pVt , k , c ) <newline>  # ▁ Rule ▁ 23: <encdom> <dedent> <dedent> elif p [ k ] + 2 < len ( w ) and not w [ p0 ] in V and ( w [ p [ k ] - 1 ] in C or w [ p [ k ] - 2 : p [ k ] - 1 ] == "qu" ) and w [ p [ k ] + 1 ] in C and w [ p [ k ] + 2 ] in C : <newline>  # ▁ print ▁"RULE ▁ 23" <encdom> <indent> if w [ p [ k ] + 1 ] == w [ p [ k ] + 2 ] : <newline>  # ▁ print ▁"RULE ▁ 23.1" <encdom> <indent> w , p0 , k , c , p , pVt = case1 ( w , p , p0 , pVt , k , c ) <newline> <dedent> elif w [ p [ k ] + 1 ] == 's' and w [ p [ k ] + 2 ] != 's' : <newline>  # ▁ print ▁"RULE ▁ 23.2" <encdom> <indent> w , p0 , k , c , p , pVt = case2 ( w , p , p0 , pVt , k , c ) <newline> <dedent> elif p [ k ] + 3 < len ( w ) and w [ p [ k ] + 2 ] == 's' and w [ p [ k ] + 3 ] in CO : <newline>  # ▁ print ▁"RULE ▁ 23.3" <encdom> <indent> w , p0 , k , c , p , pVt = case5 ( w , p , p0 , pVt , k , c ) <newline> <dedent> else :  # ▁ Adicionando ▁ ELSE <encdom> <newline>  # ▁ print ▁"RULE ▁ 23.4" <encdom> <indent> w , p0 , k , c , p , pVt = case2 ( w , p , p0 , pVt , k , c ) <newline>  # ▁ Rule ▁ 24: <encdom> <dedent> <dedent> elif p [ k ] + 2 < len ( w ) and not w [ p0 ] in V and w [ p [ k ] + 1 ] in C and w [ p [ k ] + 2 ] in G : <newline>  # ▁ Regra ▁ 24 ▁ igual ▁ a ▁ 23. ▁ Arrumar ▁ regra, ▁ p.ex: ▁ di-sen-"teria" <encdom>  # ▁ print ▁"RULE ▁ 24" <encdom> <indent> w , p0 , k , c , p , pVt = case1 ( w , p , p0 , pVt , k , c ) <newline>  # ▁ Rule ▁ 25: ▁ Already ▁ aplicated <encdom>  # ▁ Rule ▁ 26: <encdom> <dedent> elif p [ k ] + 2 < len ( w ) and not w [ p0 ] in V and ( w [ p [ k ] - 1 ] in C or ( w [ p [ k ] - 1 : p [ k ] + 1 ] in [ 'qu' , 'qü' , 'gu' , 'gü' ] ) ) and w [ p [ k ] + 1 ] in G and w [ p [ k ] + 2 ] in CN : <newline>  # ▁ Manual: ▁ a-mi-gui-nho ▁ | ▁ Automatic: ▁ a-mi-gu-i-nho <encdom>  # ▁ print ▁"RULE ▁ 26" <encdom> <indent> w , p0 , k , c , p , pVt = case4 ( w , p , p0 , pVt , k , c ) <newline>  # ▁ Rule ▁ 27: <encdom> <dedent> elif p [ k ] + 2 < len ( w ) and not w [ p0 ] in V and w [ p [ k ] - 1 ] in C and w [ p [ k ] - 2 ] in C and w [ p [ k ] + 1 ] in G and w [ p [ k ] + 2 ] in C : <newline>  # ▁ print ▁"RULE ▁ 27" <encdom> <indent> w , p0 , k , c , p , pVt = case1 ( w , p , p0 , pVt , k , c ) <newline>  # ▁ Rule ▁ 28 <encdom> <dedent> elif p [ k ] + 2 < len ( w ) and not w [ p0 ] in V and w [ p [ k ] - 1 : p [ k ] + 1 ] in [ 'qu' , 'qü' , 'gu' , 'gü' ] and w [ p [ k ] + 1 ] in V : <newline>  # ▁ print ▁"RULE ▁ 28" <encdom> <indent> if p [ k ] + 3 < len ( w ) and w [ p [ k ] + 2 ] in C and w [ p [ k ] + 3 ] in C : <newline>  # ▁ print ▁"RULE ▁ 28.1" <encdom> <indent> w , p0 , k , c , p , pVt = case5 ( w , p , p0 , pVt , k , c ) <newline> <dedent> elif p [ k ] + 3 < len ( w ) and w [ p [ k ] + 2 ] in C and w [ p [ k ] + 3 ] in V + G : <newline>  # ▁ print ▁"RULE ▁ 28.2" <encdom> <indent> w , p0 , k , c , p , pVt = case4 ( w , p , p0 , pVt , k , c ) <newline> <dedent> elif p [ k ] + 2 < len ( w ) and w [ p [ k ] + 2 ] in V : <newline>  # ▁ print ▁"RULE ▁ 28.3" <encdom> <indent> w , p0 , k , c , p , pVt = case4 ( w , p , p0 , pVt , k , c ) <newline> <dedent> elif p [ k ] + 2 < len ( w ) and w [ p [ k ] + 2 ] in G : <newline>  # ▁ print ▁"RULE ▁ 28.4" <encdom> <indent> w , p0 , k , c , p , pVt = case5 ( w , p , p0 , pVt , k , c ) <newline> <dedent> <dedent> p0 += 1 <newline> <dedent> return w . split ( '-' ) <newline> <dedent> def _test ( self ) : <newline> <indent> import codecs <newline> with codecs . open ( './test/biderman-UTF-8.txt' , encoding = 'utf-8' , mode = 'r' ) as content_file , codecs . open ( './test/biderman_output.txt' , encoding = 'utf-8' , mode = 'w' ) as output_file : <newline> <indent> content = content_file . read ( ) <newline> lines = content . split ( ' \n ' ) <newline> for line in lines : <newline> <indent> word = line . split ( ',' ) [ 0 ] <newline> print ( 'Testing ▁ word ▁ ' + word ) <newline> result = self . separate_syllables ( word ) <newline> output_file . write ( ' ▁ ' . join ( result ) + ' ▁ - ▁ ' + str ( len ( result ) ) + ' ▁ silabas \n ' ) <newline> <dedent> <dedent> <dedent> <dedent> if __name__ == '__main__' : <newline> <indent> separator = Silva2011SyllableSeparator ( ) <newline> if len ( argv ) == 1 : <newline> <indent> separator . _test ( ) <newline> <dedent> else : <newline> <indent> print ( separator . separate ( argv [ 1 ] ) ) <newline> <dedent> <dedent> syllable_separator = Silva2011SyllableSeparator ( ) <newline>
import unittest <newline> from datetime import ( date as original_date , datetime as original_datetime , time as original_time , ) <newline> from django . utils . datetime_safe import date , datetime , time <newline> class DatetimeTests ( unittest . TestCase ) : <newline> <indent> def setUp ( self ) : <newline> <indent> self . just_safe = ( 1900 , 1 , 1 ) <newline> self . just_unsafe = ( 1899 , 12 , 31 , 23 , 59 , 59 ) <newline> self . just_time = ( 11 , 30 , 59 ) <newline> self . really_old = ( 20 , 1 , 1 ) <newline> self . more_recent = ( 2006 , 1 , 1 ) <newline> <dedent> def test_compare_datetimes ( self ) : <newline> <indent> self . assertEqual ( original_datetime ( * self . more_recent ) , datetime ( * self . more_recent ) ) <newline> self . assertEqual ( original_datetime ( * self . really_old ) , datetime ( * self . really_old ) ) <newline> self . assertEqual ( original_date ( * self . more_recent ) , date ( * self . more_recent ) ) <newline> self . assertEqual ( original_date ( * self . really_old ) , date ( * self . really_old ) ) <newline> self . assertEqual ( original_date ( * self . just_safe ) . strftime ( '%Y-%m-%d' ) , date ( * self . just_safe ) . strftime ( '%Y-%m-%d' ) ) <newline> self . assertEqual ( original_datetime ( * self . just_safe ) . strftime ( '%Y-%m-%d' ) , datetime ( * self . just_safe ) . strftime ( '%Y-%m-%d' ) ) <newline> self . assertEqual ( original_time ( * self . just_time ) . strftime ( '%H:%M:%S' ) , time ( * self . just_time ) . strftime ( '%H:%M:%S' ) ) <newline> <dedent> def test_safe_strftime ( self ) : <newline> <indent> self . assertEqual ( date ( * self . just_unsafe [ : 3 ] ) . strftime ( '%Y-%m-%d ▁ (weekday ▁ %w)' ) , '1899-12-31 ▁ (weekday ▁ 0)' ) <newline> self . assertEqual ( date ( * self . just_safe ) . strftime ( '%Y-%m-%d ▁ (weekday ▁ %w)' ) , '1900-01-01 ▁ (weekday ▁ 1)' ) <newline> self . assertEqual ( datetime ( * self . just_unsafe ) . strftime ( '%Y-%m-%d ▁ %H:%M:%S ▁ (weekday ▁ %w)' ) , '1899-12-31 ▁ 23:59:59 ▁ (weekday ▁ 0)' ) <newline> self . assertEqual ( datetime ( * self . just_safe ) . strftime ( '%Y-%m-%d ▁ %H:%M:%S ▁ (weekday ▁ %w)' ) , '1900-01-01 ▁ 00:00:00 ▁ (weekday ▁ 1)' ) <newline> self . assertEqual ( time ( * self . just_time ) . strftime ( '%H:%M:%S ▁ AM' ) , '11:30:59 ▁ AM' ) <newline>  # ▁ %y ▁ will ▁ error ▁ before ▁ this ▁ date <encdom> self . assertEqual ( date ( * self . just_safe ) . strftime ( '%y' ) , '00' ) <newline> self . assertEqual ( datetime ( * self . just_safe ) . strftime ( '%y' ) , '00' ) <newline> self . assertEqual ( date ( 1850 , 8 , 2 ) . strftime ( "%Y/%m/%d ▁ was ▁ a ▁ %A" ) , '1850/08/02 ▁ was ▁ a ▁ Friday' ) <newline> <dedent> def test_zero_padding ( self ) : <newline> <indent>  """ <strnewline> ▁ Regression ▁ for ▁ # 12524 <strnewline> <strnewline> ▁ Check ▁ that ▁ pre-1000AD ▁ dates ▁ are ▁ padded ▁ with ▁ zeros ▁ if ▁ necessary <strnewline> ▁ """  <newline> self . assertEqual ( date ( 1 , 1 , 1 ) . strftime ( "%Y/%m/%d ▁ was ▁ a ▁ %A" ) , '0001/01/01 ▁ was ▁ a ▁ Monday' ) <newline> <dedent> <dedent>
from _ns3 import * <newline> import atexit <newline> atexit . register ( Simulator . Destroy ) <newline> del atexit <newline>
 # # ▁ Very, ▁ very ▁ experimental. ▁ Do ▁ NOT ▁ USE. <encdom> import curses <newline> from . import fmForm <newline> from . wgwidget import NotEnoughSpaceForWidget <newline> from . import wgNMenuDisplay <newline> class FormMultiPage ( fmForm . FormBaseNew ) : <newline> <indent> page_info_pre_pages_display = '[ ▁ ' <newline> page_info_post_pages_display = ' ▁ ]' <newline> page_info_pages_name = 'Page' <newline> page_info_out_of = 'of' <newline> def __init__ ( self , display_pages = True , pages_label_color = 'NORMAL' , * args , ** keywords ) : <newline> <indent> self . display_pages = display_pages <newline> self . pages_label_color = pages_label_color <newline> super ( FormMultiPage , self ) . __init__ ( * args , ** keywords ) <newline> self . switch_page ( 0 ) <newline> <dedent> def draw_form ( self , * args , ** keywords ) : <newline> <indent> super ( FormMultiPage , self ) . draw_form ( * args , ** keywords ) <newline> self . display_page_number ( ) <newline> <dedent> def _resize ( self , * args ) : <newline> <indent> if not self . ALLOW_RESIZE : <newline> <indent> return False <newline> <dedent> if hasattr ( self , 'parentApp' ) : <newline> <indent> self . parentApp . resize ( ) <newline> <dedent> self . _create_screen ( ) <newline> self . resize ( ) <newline> for page in self . _pages__ : <newline> <indent> for w in page : <newline> <indent> w . _resize ( ) <newline> <dedent> <dedent> self . DISPLAY ( ) <newline> <dedent> def display_page_number ( self ) : <newline> <indent> if not self . display_pages : <newline> <indent> return False <newline> <dedent> if len ( self . _pages__ ) > 1 : <newline> <indent> display_text = "%s%s ▁ %s ▁ %s ▁ %s%s" % ( self . page_info_pre_pages_display , self . page_info_pages_name , self . _active_page + 1 , self . page_info_out_of , len ( self . _pages__ ) , self . page_info_post_pages_display , ) <newline>  # ▁ for ▁ python2 <encdom> if isinstance ( display_text , bytes ) : <newline> <indent> display_text = display_text . decode ( 'utf-8' , 'replace' ) <newline> <dedent> maxy , maxx = self . curses_pad . getmaxyx ( ) <newline> if ( maxx - 5 ) <= len ( display_text ) : <newline>  # ▁ then ▁ give ▁ up. <encdom> <indent> return False <newline> <dedent> self . add_line ( maxy - 1 , maxx - len ( display_text ) - 2 , display_text , self . make_attributes_list ( display_text , curses . A_NORMAL | self . theme_manager . findPair ( self , self . pages_label_color ) ) , maxx - len ( display_text ) - 2 , ) <newline> <dedent> <dedent> def add_widget_intelligent ( self , * args , ** keywords ) : <newline> <indent> try : <newline> <indent> return self . add_widget ( * args , ** keywords ) <newline> <dedent> except NotEnoughSpaceForWidget : <newline> <indent> self . add_page ( ) <newline> return self . add_widget ( * args , ** keywords ) <newline> <dedent> <dedent> def _clear_all_widgets ( self , ) : <newline> <indent> super ( FormMultiPage , self ) . _clear_all_widgets ( ) <newline> self . _pages__ = [ [ ] , ] <newline> self . _active_page = 0 <newline> self . switch_page ( self . _active_page , display = False ) <newline> <dedent> def switch_page ( self , page , display = True ) : <newline> <indent> self . _widgets__ = self . _pages__ [ page ] <newline> self . _active_page = page <newline> self . editw = 0 <newline> if display : <newline> <indent> self . display ( clear = True ) <newline> <dedent> <dedent> def add_page ( self ) : <newline> <indent> self . _pages__ . append ( [ ] ) <newline> page_number = len ( self . _pages__ ) - 1 <newline> self . nextrely = self . DEFAULT_NEXTRELY <newline> self . nextrelx = self . DEFAULT_X_OFFSET <newline> self . switch_page ( page_number , display = False ) <newline> return page_number <newline> <dedent> def find_next_editable ( self , * args ) : <newline> <indent> if not self . editw == len ( self . _widgets__ ) : <newline> <indent> value_changed = False <newline> if not self . cycle_widgets : <newline> <indent> r = list ( range ( self . editw + 1 , len ( self . _widgets__ ) ) ) <newline> <dedent> else : <newline> <indent> r = list ( range ( self . editw + 1 , len ( self . _widgets__ ) ) ) + list ( range ( 0 , self . editw ) ) <newline> <dedent> for n in r : <newline> <indent> if self . _widgets__ [ n ] . editable and not self . _widgets__ [ n ] . hidden : <newline> <indent> self . editw = n <newline> value_changed = True <newline> break <newline> <dedent> <dedent> if not value_changed : <newline> <indent> if self . _active_page < len ( self . _pages__ ) - 1 : <newline> <indent> self . switch_page ( self . _active_page + 1 ) <newline> <dedent> <dedent> <dedent> self . display ( ) <newline> <dedent> def find_previous_editable ( self , * args ) : <newline> <indent> if self . editw == 0 : <newline> <indent> if self . _active_page > 0 : <newline> <indent> self . switch_page ( self . _active_page - 1 ) <newline> <dedent> <dedent> if not self . editw == 0 : <newline>  # ▁ remember ▁ that ▁ xrange ▁ does ▁ not ▁ return ▁ the ▁'last' ▁ value, <encdom>  # ▁ so ▁ go ▁ to ▁ -1, ▁ not ▁ 0! ▁ (fence ▁ post ▁ error ▁ in ▁ reverse) <encdom> <indent> for n in range ( self . editw - 1 , - 1 , - 1 ) : <newline> <indent> if self . _widgets__ [ n ] . editable and not self . _widgets__ [ n ] . hidden : <newline> <indent> self . editw = n <newline> break <newline> <dedent> <dedent> <dedent> <dedent> <dedent> class FormMultiPageAction ( FormMultiPage ) : <newline> <indent> CANCEL_BUTTON_BR_OFFSET = ( 2 , 12 ) <newline> OK_BUTTON_TEXT = "OK" <newline> CANCEL_BUTTON_TEXT = "Cancel" <newline> def on_ok ( self ) : <newline> <indent> pass <newline> <dedent> def on_cancel ( self ) : <newline> <indent> pass <newline> <dedent> def pre_edit_loop ( self ) : <newline> <indent> self . _page_for_buttons = len ( self . _pages__ ) - 1 <newline> self . switch_page ( self . _page_for_buttons ) <newline>  # ▁ Add ▁ ok ▁ and ▁ cancel ▁ buttons. ▁ Will ▁ remove ▁ later <encdom> tmp_rely , tmp_relx = self . nextrely , self . nextrelx <newline> c_button_text = self . CANCEL_BUTTON_TEXT <newline> cmy , cmx = self . curses_pad . getmaxyx ( ) <newline> cmy -= self . __class__ . CANCEL_BUTTON_BR_OFFSET [ 0 ] <newline> cmx -= len ( c_button_text ) + self . __class__ . CANCEL_BUTTON_BR_OFFSET [ 1 ] <newline> self . c_button = self . add_widget ( self . __class__ . OKBUTTON_TYPE , name = c_button_text , rely = cmy , relx = cmx , use_max_space = True ) <newline> self . _c_button_postion = len ( self . _widgets__ ) - 1 <newline> self . c_button . update ( ) <newline> my , mx = self . curses_pad . getmaxyx ( ) <newline> ok_button_text = self . OK_BUTTON_TEXT <newline> my -= self . __class__ . OK_BUTTON_BR_OFFSET [ 0 ] <newline> mx -= len ( ok_button_text ) + self . __class__ . OK_BUTTON_BR_OFFSET [ 1 ] <newline> self . ok_button = self . add_widget ( self . __class__ . OKBUTTON_TYPE , name = ok_button_text , rely = my , relx = mx , use_max_space = True ) <newline> self . _ok_button_postion = len ( self . _widgets__ ) - 1 <newline>  # ▁ End ▁ add ▁ buttons <encdom> self . nextrely , self . nextrelx = tmp_rely , tmp_relx <newline> self . switch_page ( 0 ) <newline> <dedent> def _during_edit_loop ( self ) : <newline> <indent> if self . ok_button . value or self . c_button . value : <newline> <indent> self . editing = False <newline> <dedent> if self . ok_button . value : <newline> <indent> self . ok_button . value = False <newline> self . edit_return_value = self . on_ok ( ) <newline> <dedent> elif self . c_button . value : <newline> <indent> self . c_button . value = False <newline> self . edit_return_value = self . on_cancel ( ) <newline> <dedent> <dedent> def resize ( self ) : <newline> <indent> super ( FormMultiPageAction , self ) . resize ( ) <newline> self . move_ok_button ( ) <newline> <dedent> def move_ok_button ( self ) : <newline> <indent> if hasattr ( self , 'ok_button' ) : <newline> <indent> my , mx = self . curses_pad . getmaxyx ( ) <newline> my -= self . __class__ . OK_BUTTON_BR_OFFSET [ 0 ] <newline> mx -= len ( self . __class__ . OK_BUTTON_TEXT ) + self . __class__ . OK_BUTTON_BR_OFFSET [ 1 ] <newline> self . ok_button . relx = mx <newline> self . ok_button . rely = my <newline> <dedent> if hasattr ( self , 'c_button' ) : <newline> <indent> c_button_text = self . CANCEL_BUTTON_TEXT <newline> cmy , cmx = self . curses_pad . getmaxyx ( ) <newline> cmy -= self . __class__ . CANCEL_BUTTON_BR_OFFSET [ 0 ] <newline> cmx -= len ( c_button_text ) + self . __class__ . CANCEL_BUTTON_BR_OFFSET [ 1 ] <newline> self . c_button . rely = cmy <newline> self . c_button . relx = cmx <newline> <dedent> <dedent> def post_edit_loop ( self ) : <newline> <indent> self . switch_page ( self . _page_for_buttons ) <newline> self . ok_button . destroy ( ) <newline> self . c_button . destroy ( ) <newline> del self . _widgets__ [ self . _ok_button_postion ] <newline> del self . ok_button <newline> del self . _widgets__ [ self . _c_button_postion ] <newline> del self . c_button <newline>  # self.nextrely, ▁ self.nextrelx ▁ = ▁ tmp_rely, ▁ tmp_relx <encdom> self . display ( ) <newline> self . editing = False <newline> return self . edit_return_value <newline> <dedent> <dedent> class FormMultiPageWithMenus ( fmForm . FormBaseNew ) : <newline> <indent> def __init__ ( self , * args , ** keywords ) : <newline> <indent> super ( FormMultiPageWithMenus , self ) . __init__ ( * args , ** keywords ) <newline> self . initialize_menus ( ) <newline> <dedent> <dedent> class FormMultiPageActionWithMenus ( FormMultiPageAction , wgNMenuDisplay . HasMenus ) : <newline> <indent> def __init__ ( self , * args , ** keywords ) : <newline> <indent> super ( FormMultiPageActionWithMenus , self ) . __init__ ( * args , ** keywords ) <newline> self . initialize_menus ( ) <newline> <dedent> <dedent>
import sys , socket , struct <newline> s = socket . socket ( ) <newline> s = socket . socket ( socket . AF_INET , socket . SOCK_DGRAM ) <newline> s . bind ( ( '192.168.0.123' , 5000 ) ) <newline> while True : <newline> <indent> data , addr = s . recvfrom ( 3 ) <newline> cmd = struct . unpack ( 'B' , data [ 0 ] ) [ 0 ] <newline> p1 = struct . unpack ( 'B' , data [ 1 ] ) [ 0 ] <newline> p2 = struct . unpack ( 'B' , data [ 2 ] ) [ 0 ] <newline> print ( addr , cmd , p1 , p2 ) <newline> <dedent> s . close ( ) <newline>
import json <newline> import os <newline> import os . path <newline> import re <newline> import sys <newline> from collections import defaultdict <newline> from distutils . command . build_scripts import build_scripts as BuildScripts <newline> from distutils . command . sdist import sdist as SDist <newline> try : <newline> <indent> from setuptools import setup , find_packages <newline> from setuptools . command . build_py import build_py as BuildPy <newline> from setuptools . command . install_lib import install_lib as InstallLib <newline> from setuptools . command . install_scripts import install_scripts as InstallScripts <newline> <dedent> except ImportError : <newline> <indent> print ( "Ansible ▁ now ▁ needs ▁ setuptools ▁ in ▁ order ▁ to ▁ build. ▁ Install ▁ it ▁ using" " ▁ your ▁ package ▁ manager ▁ (usually ▁ python-setuptools) ▁ or ▁ via ▁ pip ▁ (pip" " ▁ install ▁ setuptools)." ) <newline> sys . exit ( 1 ) <newline> <dedent> sys . path . insert ( 0 , os . path . abspath ( 'lib' ) ) <newline> from ansible . release import __version__ , __author__ <newline> SYMLINK_CACHE = 'SYMLINK_CACHE.json' <newline> def _find_symlinks ( topdir , extension = '' ) : <newline> <indent>  """ Find ▁ symlinks ▁ that ▁ should ▁ be ▁ maintained <strnewline> <strnewline> ▁ Maintained ▁ symlinks ▁ exist ▁ in ▁ the ▁ bin ▁ dir ▁ or ▁ are ▁ modules ▁ which ▁ have <strnewline> ▁ aliases. ▁ Our ▁ heuristic ▁ is ▁ that ▁ they ▁ are ▁ a ▁ link ▁ in ▁ a ▁ certain ▁ path ▁ which <strnewline> ▁ point ▁ to ▁ a ▁ file ▁ in ▁ the ▁ same ▁ directory. <strnewline> ▁ """  <newline> symlinks = defaultdict ( list ) <newline> for base_path , dirs , files in os . walk ( topdir ) : <newline> <indent> for filename in files : <newline> <indent> filepath = os . path . join ( base_path , filename ) <newline> if os . path . islink ( filepath ) and filename . endswith ( extension ) : <newline> <indent> target = os . readlink ( filepath ) <newline> if os . path . dirname ( target ) == '' : <newline> <indent> link = filepath [ len ( topdir ) : ] <newline> if link . startswith ( '/' ) : <newline> <indent> link = link [ 1 : ] <newline> <dedent> symlinks [ os . path . basename ( target ) ] . append ( link ) <newline> <dedent> <dedent> <dedent> <dedent> return symlinks <newline> <dedent> def _cache_symlinks ( symlink_data ) : <newline> <indent> with open ( SYMLINK_CACHE , 'w' ) as f : <newline> <indent> f . write ( json . dumps ( symlink_data ) ) <newline> <dedent> <dedent> def _maintain_symlinks ( symlink_type , base_path ) : <newline> <indent>  """ Switch ▁ a ▁ real ▁ file ▁ into ▁ a ▁ symlink """  <newline> try : <newline>  # ▁ Try ▁ the ▁ cache ▁ first ▁ because ▁ going ▁ from ▁ git ▁ checkout ▁ to ▁ sdist ▁ is ▁ the <encdom>  # ▁ only ▁ time ▁ we ▁ know ▁ that ▁ we're ▁ going ▁ to ▁ cache ▁ correctly <encdom> <indent> with open ( SYMLINK_CACHE , 'r' ) as f : <newline> <indent> symlink_data = json . loads ( f . read ( ) ) <newline> <dedent> <dedent> except ( IOError , OSError ) as e : <newline>  # ▁ IOError ▁ on ▁ py2, ▁ OSError ▁ on ▁ py3. ▁ Both ▁ have ▁ errno <encdom> <indent> if e . errno == 2 : <newline>  # ▁ SYMLINKS_CACHE ▁ doesn't ▁ exist. ▁ Fallback ▁ to ▁ trying ▁ to ▁ create ▁ the <encdom>  # ▁ cache ▁ now. ▁ Will ▁ work ▁ if ▁ we're ▁ running ▁ directly ▁ from ▁ a ▁ git <encdom>  # ▁ checkout ▁ or ▁ from ▁ an ▁ sdist ▁ created ▁ earlier. <encdom> <indent> symlink_data = { 'script' : _find_symlinks ( 'bin' ) , 'library' : _find_symlinks ( 'lib' , '.py' ) , } <newline>  # ▁ Sanity ▁ check ▁ that ▁ something ▁ we ▁ know ▁ should ▁ be ▁ a ▁ symlink ▁ was <encdom>  # ▁ found. ▁ We'll ▁ take ▁ that ▁ to ▁ mean ▁ that ▁ the ▁ current ▁ directory <encdom>  # ▁ structure ▁ properly ▁ reflects ▁ symlinks ▁ in ▁ the ▁ git ▁ repo <encdom> if 'ansible-playbook' in symlink_data [ 'script' ] [ 'ansible' ] : <newline> <indent> _cache_symlinks ( symlink_data ) <newline> <dedent> else : <newline> <indent> raise <newline> <dedent> <dedent> else : <newline> <indent> raise <newline> <dedent> <dedent> symlinks = symlink_data [ symlink_type ] <newline> for source in symlinks : <newline> <indent> for dest in symlinks [ source ] : <newline> <indent> dest_path = os . path . join ( base_path , dest ) <newline> if not os . path . islink ( dest_path ) : <newline> <indent> try : <newline> <indent> os . unlink ( dest_path ) <newline> <dedent> except OSError as e : <newline> <indent> if e . errno == 2 : <newline>  # ▁ File ▁ does ▁ not ▁ exist ▁ which ▁ is ▁ all ▁ we ▁ wanted <encdom> <indent> pass <newline> <dedent> <dedent> os . symlink ( source , dest_path ) <newline> <dedent> <dedent> <dedent> <dedent> class BuildPyCommand ( BuildPy ) : <newline> <indent> def run ( self ) : <newline> <indent> BuildPy . run ( self ) <newline> _maintain_symlinks ( 'library' , self . build_lib ) <newline> <dedent> <dedent> class BuildScriptsCommand ( BuildScripts ) : <newline> <indent> def run ( self ) : <newline> <indent> BuildScripts . run ( self ) <newline> _maintain_symlinks ( 'script' , self . build_dir ) <newline> <dedent> <dedent> class InstallLibCommand ( InstallLib ) : <newline> <indent> def run ( self ) : <newline> <indent> InstallLib . run ( self ) <newline> _maintain_symlinks ( 'library' , self . install_dir ) <newline> <dedent> <dedent> class InstallScriptsCommand ( InstallScripts ) : <newline> <indent> def run ( self ) : <newline> <indent> InstallScripts . run ( self ) <newline> _maintain_symlinks ( 'script' , self . install_dir ) <newline> <dedent> <dedent> class SDistCommand ( SDist ) : <newline> <indent> def run ( self ) : <newline>  # ▁ have ▁ to ▁ generate ▁ the ▁ cache ▁ of ▁ symlinks ▁ for ▁ release ▁ as ▁ sdist ▁ is ▁ the <encdom>  # ▁ only ▁ command ▁ that ▁ has ▁ access ▁ to ▁ symlinks ▁ from ▁ the ▁ git ▁ repo <encdom> <indent> symlinks = { 'script' : _find_symlinks ( 'bin' ) , 'library' : _find_symlinks ( 'lib' , '.py' ) , } <newline> _cache_symlinks ( symlinks ) <newline> SDist . run ( self ) <newline> <dedent> <dedent> with open ( 'requirements.txt' ) as requirements_file : <newline> <indent> install_requirements = requirements_file . read ( ) . splitlines ( ) <newline> if not install_requirements : <newline> <indent> print ( "Unable ▁ to ▁ read ▁ requirements ▁ from ▁ the ▁ requirements.txt ▁ file" "That ▁ indicates ▁ this ▁ copy ▁ of ▁ the ▁ source ▁ code ▁ is ▁ incomplete." ) <newline> sys . exit ( 2 ) <newline>  # ▁ pycrypto ▁ or ▁ cryptography. ▁ We ▁ choose ▁ a ▁ default ▁ but ▁ allow ▁ the ▁ user ▁ to <encdom>  # ▁ override ▁ it. ▁ This ▁ translates ▁ into ▁ pip ▁ install ▁ of ▁ the ▁ sdist ▁ deciding ▁ what <encdom>  # ▁ package ▁ to ▁ install ▁ and ▁ also ▁ the ▁ runtime ▁ dependencies ▁ that ▁ pkg_resources <encdom>  # ▁ knows ▁ about <encdom> <dedent> <dedent> crypto_backend = os . environ . get ( 'ANSIBLE_CRYPTO_BACKEND' , None ) <newline> if crypto_backend : <newline> <indent> if crypto_backend . strip ( ) == 'pycrypto' : <newline>  # ▁ Attempt ▁ to ▁ set ▁ version ▁ requirements <encdom> <indent> crypto_backend = 'pycrypto ▁ >= ▁ 2.6' <newline> <dedent> install_requirements = [ r for r in install_requirements if not ( r . lower ( ) . startswith ( 'pycrypto' ) or r . lower ( ) . startswith ( 'cryptography' ) ) ] <newline> install_requirements . append ( crypto_backend ) <newline>  # ▁ specify ▁ any ▁ extra ▁ requirements ▁ for ▁ installation <encdom> <dedent> extra_requirements = dict ( ) <newline> extra_requirements_dir = 'packaging/requirements' <newline> for extra_requirements_filename in os . listdir ( extra_requirements_dir ) : <newline> <indent> filename_match = re . search ( r'^requirements-(\w*).txt$' , extra_requirements_filename ) <newline> if filename_match : <newline> <indent> with open ( os . path . join ( extra_requirements_dir , extra_requirements_filename ) ) as extra_requirements_file : <newline> <indent> extra_requirements [ filename_match . group ( 1 ) ] = extra_requirements_file . read ( ) . splitlines ( ) <newline> <dedent> <dedent> <dedent> setup (  # ▁ Use ▁ the ▁ distutils ▁ SDist ▁ so ▁ that ▁ symlinks ▁ are ▁ not ▁ expanded <encdom>  # ▁ Use ▁ a ▁ custom ▁ Build ▁ for ▁ the ▁ same ▁ reason <encdom> cmdclass = { 'build_py' : BuildPyCommand , 'build_scripts' : BuildScriptsCommand , 'install_lib' : InstallLibCommand , 'install_scripts' : InstallScriptsCommand , 'sdist' : SDistCommand , } , name = 'ansible' , version = __version__ , description = 'Radically ▁ simple ▁ IT ▁ automation' , author = __author__ , author_email = 'info@ansible.com' , url = 'https://ansible.com/' , license = 'GPLv3+' ,  # ▁ Ansible ▁ will ▁ also ▁ make ▁ use ▁ of ▁ a ▁ system ▁ copy ▁ of ▁ python-six ▁ and <encdom>  # ▁ python-selectors2 ▁ if ▁ installed ▁ but ▁ use ▁ a ▁ Bundled ▁ copy ▁ if ▁ it's ▁ not. <encdom> install_requires = install_requirements , package_dir = { '' : 'lib' } , packages = find_packages ( 'lib' ) , package_data = { '' : [ 'module_utils/powershell/*.psm1' , 'module_utils/powershell/*/*.psm1' , 'modules/windows/*.ps1' , 'modules/windows/*/*.ps1' , 'galaxy/data/*/*.*' , 'galaxy/data/*/*/.*' , 'galaxy/data/*/*/*.*' , 'galaxy/data/*/tests/inventory' , 'config/base.yml' , ] , } , classifiers = [ 'Development ▁ Status ▁ :: ▁ 5 ▁ - ▁ Production/Stable' , 'Environment ▁ :: ▁ Console' , 'Intended ▁ Audience ▁ :: ▁ Developers' , 'Intended ▁ Audience ▁ :: ▁ Information ▁ Technology' , 'Intended ▁ Audience ▁ :: ▁ System ▁ Administrators' , 'License ▁ :: ▁ OSI ▁ Approved ▁ :: ▁ GNU ▁ General ▁ Public ▁ License ▁ v3 ▁ or ▁ later ▁ (GPLv3+)' , 'Natural ▁ Language ▁ :: ▁ English' , 'Operating ▁ System ▁ :: ▁ POSIX' , 'Programming ▁ Language ▁ :: ▁ Python ▁ :: ▁ 2.6' , 'Programming ▁ Language ▁ :: ▁ Python ▁ :: ▁ 2.7' , 'Topic ▁ :: ▁ System ▁ :: ▁ Installation/Setup' , 'Topic ▁ :: ▁ System ▁ :: ▁ Systems ▁ Administration' , 'Topic ▁ :: ▁ Utilities' , ] , scripts = [ 'bin/ansible' , 'bin/ansible-playbook' , 'bin/ansible-pull' , 'bin/ansible-doc' , 'bin/ansible-galaxy' , 'bin/ansible-console' , 'bin/ansible-connection' , 'bin/ansible-vault' , ] , data_files = [ ] , extras_require = extra_requirements ,  # ▁ Installing ▁ as ▁ zip ▁ files ▁ would ▁ break ▁ due ▁ to ▁ references ▁ to ▁ __file__ <encdom> zip_safe = False ) <newline>
 # ▁ acl.py ▁ - ▁ changeset ▁ access ▁ control ▁ for ▁ mercurial <encdom>  # ▁ Copyright ▁ 2006 ▁ Vadim ▁ Gelfer ▁ <vadim.gelfer@gmail.com> <encdom>  # ▁ This ▁ software ▁ may ▁ be ▁ used ▁ and ▁ distributed ▁ according ▁ to ▁ the ▁ terms ▁ of ▁ the <encdom>  # ▁ GNU ▁ General ▁ Public ▁ License ▁ version ▁ 2 ▁ or ▁ any ▁ later ▁ version. <encdom>  ''' hooks ▁ for ▁ controlling ▁ repository ▁ access <strnewline> <strnewline> This ▁ hook ▁ makes ▁ it ▁ possible ▁ to ▁ allow ▁ or ▁ deny ▁ write ▁ access ▁ to ▁ given <strnewline> branches ▁ and ▁ paths ▁ of ▁ a ▁ repository ▁ when ▁ receiving ▁ incoming ▁ changesets <strnewline> via ▁ pretxnchangegroup ▁ and ▁ pretxncommit. <strnewline> <strnewline> The ▁ authorization ▁ is ▁ matched ▁ based ▁ on ▁ the ▁ local ▁ user ▁ name ▁ on ▁ the <strnewline> system ▁ where ▁ the ▁ hook ▁ runs, ▁ and ▁ not ▁ the ▁ committer ▁ of ▁ the ▁ original <strnewline> changeset ▁ (since ▁ the ▁ latter ▁ is ▁ merely ▁ informative). <strnewline> <strnewline> The ▁ acl ▁ hook ▁ is ▁ best ▁ used ▁ along ▁ with ▁ a ▁ restricted ▁ shell ▁ like ▁ hgsh, <strnewline> preventing ▁ authenticating ▁ users ▁ from ▁ doing ▁ anything ▁ other ▁ than ▁ pushing <strnewline> or ▁ pulling. ▁ The ▁ hook ▁ is ▁ not ▁ safe ▁ to ▁ use ▁ if ▁ users ▁ have ▁ interactive <strnewline> shell ▁ access, ▁ as ▁ they ▁ can ▁ then ▁ disable ▁ the ▁ hook. ▁ Nor ▁ is ▁ it ▁ safe ▁ if <strnewline> remote ▁ users ▁ share ▁ an ▁ account, ▁ because ▁ then ▁ there ▁ is ▁ no ▁ way ▁ to <strnewline> distinguish ▁ them. <strnewline> <strnewline> The ▁ order ▁ in ▁ which ▁ access ▁ checks ▁ are ▁ performed ▁ is: <strnewline> <strnewline> 1) ▁ Deny ▁ list ▁ for ▁ branches ▁ (section ▁ ``acl.deny.branches``) <strnewline> 2) ▁ Allow ▁ list ▁ for ▁ branches ▁ (section ▁ ``acl.allow.branches``) <strnewline> 3) ▁ Deny ▁ list ▁ for ▁ paths ▁ (section ▁ ``acl.deny``) <strnewline> 4) ▁ Allow ▁ list ▁ for ▁ paths ▁ (section ▁ ``acl.allow``) <strnewline> <strnewline> The ▁ allow ▁ and ▁ deny ▁ sections ▁ take ▁ key-value ▁ pairs. <strnewline> <strnewline> Branch-based ▁ Access ▁ Control <strnewline> ----- <strnewline> <strnewline> Use ▁ the ▁ ``acl.deny.branches`` ▁ and ▁ ``acl.allow.branches`` ▁ sections ▁ to <strnewline> have ▁ branch-based ▁ access ▁ control. ▁ Keys ▁ in ▁ these ▁ sections ▁ can ▁ be <strnewline> either: <strnewline> <strnewline> - ▁ a ▁ branch ▁ name, ▁ or <strnewline> - ▁ an ▁ asterisk, ▁ to ▁ match ▁ any ▁ branch; <strnewline> <strnewline> The ▁ corresponding ▁ values ▁ can ▁ be ▁ either: <strnewline> <strnewline> - ▁ a ▁ comma-separated ▁ list ▁ containing ▁ users ▁ and ▁ groups, ▁ or <strnewline> - ▁ an ▁ asterisk, ▁ to ▁ match ▁ anyone; <strnewline> <strnewline> You ▁ can ▁ add ▁ the ▁"!" ▁ prefix ▁ to ▁ a ▁ user ▁ or ▁ group ▁ name ▁ to ▁ invert ▁ the ▁ sense <strnewline> of ▁ the ▁ match. <strnewline> <strnewline> Path-based ▁ Access ▁ Control <strnewline> ----- <strnewline> <strnewline> Use ▁ the ▁ ``acl.deny`` ▁ and ▁ ``acl.allow`` ▁ sections ▁ to ▁ have ▁ path-based <strnewline> access ▁ control. ▁ Keys ▁ in ▁ these ▁ sections ▁ accept ▁ a ▁ subtree ▁ pattern ▁ (with <strnewline> a ▁ glob ▁ syntax ▁ by ▁ default). ▁ The ▁ corresponding ▁ values ▁ follow ▁ the ▁ same <strnewline> syntax ▁ as ▁ the ▁ other ▁ sections ▁ above. <strnewline> <strnewline> Groups <strnewline> ----- <strnewline> <strnewline> Group ▁ names ▁ must ▁ be ▁ prefixed ▁ with ▁ an ▁ ``@`` ▁ symbol. ▁ Specifying ▁ a ▁ group <strnewline> name ▁ has ▁ the ▁ same ▁ effect ▁ as ▁ specifying ▁ all ▁ the ▁ users ▁ in ▁ that ▁ group. <strnewline> <strnewline> You ▁ can ▁ define ▁ group ▁ members ▁ in ▁ the ▁ ``acl.groups`` ▁ section. <strnewline> If ▁ a ▁ group ▁ name ▁ is ▁ not ▁ defined ▁ there, ▁ and ▁ Mercurial ▁ is ▁ running ▁ under <strnewline> a ▁ Unix-like ▁ system, ▁ the ▁ list ▁ of ▁ users ▁ will ▁ be ▁ taken ▁ from ▁ the ▁ OS. <strnewline> Otherwise, ▁ an ▁ exception ▁ will ▁ be ▁ raised. <strnewline> <strnewline> Example ▁ Configuration <strnewline> ----- <strnewline> <strnewline> :: <strnewline> <strnewline> ▁ [hooks] <strnewline> <strnewline> ▁ # ▁ Use ▁ this ▁ if ▁ you ▁ want ▁ to ▁ check ▁ access ▁ restrictions ▁ at ▁ commit ▁ time <strnewline> ▁ pretxncommit.acl ▁ = ▁ python:hgext.acl.hook <strnewline> <strnewline> ▁ # ▁ Use ▁ this ▁ if ▁ you ▁ want ▁ to ▁ check ▁ access ▁ restrictions ▁ for ▁ pull, ▁ push, <strnewline> ▁ # ▁ bundle ▁ and ▁ serve. <strnewline> ▁ pretxnchangegroup.acl ▁ = ▁ python:hgext.acl.hook <strnewline> <strnewline> ▁ [acl] <strnewline> ▁ # ▁ Allow ▁ or ▁ deny ▁ access ▁ for ▁ incoming ▁ changes ▁ only ▁ if ▁ their ▁ source ▁ is <strnewline> ▁ # ▁ listed ▁ here, ▁ let ▁ them ▁ pass ▁ otherwise. ▁ Source ▁ is ▁"serve" ▁ for ▁ all <strnewline> ▁ # ▁ remote ▁ access ▁ (http ▁ or ▁ ssh), ▁"push", ▁"pull" ▁ or ▁"bundle" ▁ when ▁ the <strnewline> ▁ # ▁ related ▁ commands ▁ are ▁ run ▁ locally. <strnewline> ▁ # ▁ Default: ▁ serve <strnewline> ▁ sources ▁ = ▁ serve <strnewline> <strnewline> ▁ [acl.deny.branches] <strnewline> <strnewline> ▁ # ▁ Everyone ▁ is ▁ denied ▁ to ▁ the ▁ frozen ▁ branch: <strnewline> ▁ frozen-branch ▁ = ▁ * <strnewline> <strnewline> ▁ # ▁ A ▁ bad ▁ user ▁ is ▁ denied ▁ on ▁ all ▁ branches: <strnewline> ▁ * ▁ = ▁ bad-user <strnewline> <strnewline> ▁ [acl.allow.branches] <strnewline> <strnewline> ▁ # ▁ A ▁ few ▁ users ▁ are ▁ allowed ▁ on ▁ branch-a: <strnewline> ▁ branch-a ▁ = ▁ user-1, ▁ user-2, ▁ user-3 <strnewline> <strnewline> ▁ # ▁ Only ▁ one ▁ user ▁ is ▁ allowed ▁ on ▁ branch-b: <strnewline> ▁ branch-b ▁ = ▁ user-1 <strnewline> <strnewline> ▁ # ▁ The ▁ super ▁ user ▁ is ▁ allowed ▁ on ▁ any ▁ branch: <strnewline> ▁ * ▁ = ▁ super-user <strnewline> <strnewline> ▁ # ▁ Everyone ▁ is ▁ allowed ▁ on ▁ branch-for-tests: <strnewline> ▁ branch-for-tests ▁ = ▁ * <strnewline> <strnewline> ▁ [acl.deny] <strnewline> ▁ # ▁ This ▁ list ▁ is ▁ checked ▁ first. ▁ If ▁ a ▁ match ▁ is ▁ found, ▁ acl.allow ▁ is ▁ not <strnewline> ▁ # ▁ checked. ▁ All ▁ users ▁ are ▁ granted ▁ access ▁ if ▁ acl.deny ▁ is ▁ not ▁ present. <strnewline> ▁ # ▁ Format ▁ for ▁ both ▁ lists: ▁ glob ▁ pattern ▁ = ▁ user, ▁ ..., ▁ @group, ▁ ... <strnewline> <strnewline> ▁ # ▁ To ▁ match ▁ everyone, ▁ use ▁ an ▁ asterisk ▁ for ▁ the ▁ user: <strnewline> ▁ # ▁ my/glob/pattern ▁ = ▁ * <strnewline> <strnewline> ▁ # ▁ user6 ▁ will ▁ not ▁ have ▁ write ▁ access ▁ to ▁ any ▁ file: <strnewline> ▁ ** ▁ = ▁ user6 <strnewline> <strnewline> ▁ # ▁ Group ▁"hg-denied" ▁ will ▁ not ▁ have ▁ write ▁ access ▁ to ▁ any ▁ file: <strnewline> ▁ ** ▁ = ▁ @hg-denied <strnewline> <strnewline> ▁ # ▁ Nobody ▁ will ▁ be ▁ able ▁ to ▁ change ▁"DONT-TOUCH-THIS.txt", ▁ despite <strnewline> ▁ # ▁ everyone ▁ being ▁ able ▁ to ▁ change ▁ all ▁ other ▁ files. ▁ See ▁ below. <strnewline> ▁ src/main/resources/DONT-TOUCH-THIS.txt ▁ = ▁ * <strnewline> <strnewline> ▁ [acl.allow] <strnewline> ▁ # ▁ if ▁ acl.allow ▁ is ▁ not ▁ present, ▁ all ▁ users ▁ are ▁ allowed ▁ by ▁ default <strnewline> ▁ # ▁ empty ▁ acl.allow ▁ = ▁ no ▁ users ▁ allowed <strnewline> <strnewline> ▁ # ▁ User ▁"doc_writer" ▁ has ▁ write ▁ access ▁ to ▁ any ▁ file ▁ under ▁ the ▁"docs" <strnewline> ▁ # ▁ folder: <strnewline> ▁ docs/** ▁ = ▁ doc_writer <strnewline> <strnewline> ▁ # ▁ User ▁"jack" ▁ and ▁ group ▁"designers" ▁ have ▁ write ▁ access ▁ to ▁ any ▁ file <strnewline> ▁ # ▁ under ▁ the ▁"images" ▁ folder: <strnewline> ▁ images/** ▁ = ▁ jack, ▁ @designers <strnewline> <strnewline> ▁ # ▁ Everyone ▁ (except ▁ for ▁"user6" ▁ and ▁"@hg-denied" ▁ - ▁ see ▁ acl.deny ▁ above) <strnewline> ▁ # ▁ will ▁ have ▁ write ▁ access ▁ to ▁ any ▁ file ▁ under ▁ the ▁"resources" ▁ folder <strnewline> ▁ # ▁ (except ▁ for ▁ 1 ▁ file. ▁ See ▁ acl.deny): <strnewline> ▁ src/main/resources/** ▁ = ▁ * <strnewline> <strnewline> ▁ .hgtags ▁ = ▁ release_engineer <strnewline> <strnewline> Examples ▁ using ▁ the ▁"!" ▁ prefix <strnewline> ..... <strnewline> <strnewline> Suppose ▁ there's ▁ a ▁ branch ▁ that ▁ only ▁ a ▁ given ▁ user ▁ (or ▁ group) ▁ should ▁ be ▁ able ▁ to <strnewline> push ▁ to, ▁ and ▁ you ▁ don't ▁ want ▁ to ▁ restrict ▁ access ▁ to ▁ any ▁ other ▁ branch ▁ that ▁ may <strnewline> be ▁ created. <strnewline> <strnewline> The ▁"!" ▁ prefix ▁ allows ▁ you ▁ to ▁ prevent ▁ anyone ▁ except ▁ a ▁ given ▁ user ▁ or ▁ group ▁ to <strnewline> push ▁ changesets ▁ in ▁ a ▁ given ▁ branch ▁ or ▁ path. <strnewline> <strnewline> In ▁ the ▁ examples ▁ below, ▁ we ▁ will: <strnewline> 1) ▁ Deny ▁ access ▁ to ▁ branch ▁"ring" ▁ to ▁ anyone ▁ but ▁ user ▁"gollum" <strnewline> 2) ▁ Deny ▁ access ▁ to ▁ branch ▁"lake" ▁ to ▁ anyone ▁ but ▁ members ▁ of ▁ the ▁ group ▁"hobbit" <strnewline> 3) ▁ Deny ▁ access ▁ to ▁ a ▁ file ▁ to ▁ anyone ▁ but ▁ user ▁"gollum" <strnewline> <strnewline> :: <strnewline> <strnewline> ▁ [acl.allow.branches] <strnewline> ▁ # ▁ Empty <strnewline> <strnewline> ▁ [acl.deny.branches] <strnewline> <strnewline> ▁ # ▁ 1) ▁ only ▁'gollum' ▁ can ▁ commit ▁ to ▁ branch ▁'ring'; <strnewline> ▁ # ▁'gollum' ▁ and ▁ anyone ▁ else ▁ can ▁ still ▁ commit ▁ to ▁ any ▁ other ▁ branch. <strnewline> ▁ ring ▁ = ▁ !gollum <strnewline> <strnewline> ▁ # ▁ 2) ▁ only ▁ members ▁ of ▁ the ▁ group ▁'hobbit' ▁ can ▁ commit ▁ to ▁ branch ▁'lake'; <strnewline> ▁ # ▁'hobbit' ▁ members ▁ and ▁ anyone ▁ else ▁ can ▁ still ▁ commit ▁ to ▁ any ▁ other ▁ branch. <strnewline> ▁ lake ▁ = ▁ !@hobbit <strnewline> <strnewline> ▁ # ▁ You ▁ can ▁ also ▁ deny ▁ access ▁ based ▁ on ▁ file ▁ paths: <strnewline> <strnewline> ▁ [acl.allow] <strnewline> ▁ # ▁ Empty <strnewline> <strnewline> ▁ [acl.deny] <strnewline> ▁ # ▁ 3) ▁ only ▁'gollum' ▁ can ▁ change ▁ the ▁ file ▁ below; <strnewline> ▁ # ▁'gollum' ▁ and ▁ anyone ▁ else ▁ can ▁ still ▁ change ▁ any ▁ other ▁ file. <strnewline> ▁ /misty/mountains/cave/ring ▁ = ▁ !gollum <strnewline> <strnewline> '''  <newline> from mercurial . i18n import _ <newline> from mercurial import util , match <newline> import getpass , urllib <newline> testedwith = 'internal' <newline> def _getusers ( ui , group ) : <newline>  # ▁ First, ▁ try ▁ to ▁ use ▁ group ▁ definition ▁ from ▁ section ▁ [acl.groups] <encdom> <indent> hgrcusers = ui . configlist ( 'acl.groups' , group ) <newline> if hgrcusers : <newline> <indent> return hgrcusers <newline> <dedent> ui . debug ( 'acl: ▁"%s" ▁ not ▁ defined ▁ in ▁ [acl.groups] \n ' % group ) <newline>  # ▁ If ▁ no ▁ users ▁ found ▁ in ▁ group ▁ definition, ▁ get ▁ users ▁ from ▁ OS-level ▁ group <encdom> try : <newline> <indent> return util . groupmembers ( group ) <newline> <dedent> except KeyError : <newline> <indent> raise util . Abort ( _ ( "group ▁'%s' ▁ is ▁ undefined" ) % group ) <newline> <dedent> <dedent> def _usermatch ( ui , user , usersorgroups ) : <newline> <indent> if usersorgroups == '*' : <newline> <indent> return True <newline> <dedent> for ug in usersorgroups . replace ( ',' , ' ▁ ' ) . split ( ) : <newline> <indent> if ug . startswith ( '!' ) : <newline>  # ▁ Test ▁ for ▁ excluded ▁ user ▁ or ▁ group. ▁ Format: <encdom>  # ▁ if ▁ ug ▁ is ▁ a ▁ user ▁ name: ▁ !username <encdom>  # ▁ if ▁ ug ▁ is ▁ a ▁ group ▁ name: ▁ !@groupname <encdom> <indent> ug = ug [ 1 : ] <newline> if not ug . startswith ( '@' ) and user != ug or ug . startswith ( '@' ) and user not in _getusers ( ui , ug [ 1 : ] ) : <newline> <indent> return True <newline>  # ▁ Test ▁ for ▁ user ▁ or ▁ group. ▁ Format: <encdom>  # ▁ if ▁ ug ▁ is ▁ a ▁ user ▁ name: ▁ username <encdom>  # ▁ if ▁ ug ▁ is ▁ a ▁ group ▁ name: ▁ @groupname <encdom> <dedent> <dedent> elif user == ug or ug . startswith ( '@' ) and user in _getusers ( ui , ug [ 1 : ] ) : <newline> <indent> return True <newline> <dedent> <dedent> return False <newline> <dedent> def buildmatch ( ui , repo , user , key ) : <newline> <indent>  ''' return ▁ tuple ▁ of ▁ (match ▁ function, ▁ list ▁ enabled). '''  <newline> if not ui . has_section ( key ) : <newline> <indent> ui . debug ( 'acl: ▁ %s ▁ not ▁ enabled \n ' % key ) <newline> return None <newline> <dedent> pats = [ pat for pat , users in ui . configitems ( key ) if _usermatch ( ui , user , users ) ] <newline> ui . debug ( 'acl: ▁ %s ▁ enabled, ▁ %d ▁ entries ▁ for ▁ user ▁ %s \n ' % ( key , len ( pats ) , user ) ) <newline>  # ▁ Branch-based ▁ ACL <encdom> if not repo : <newline> <indent> if pats : <newline>  # ▁ If ▁ there's ▁ an ▁ asterisk ▁ (meaning ▁"any ▁ branch"), ▁ always ▁ return ▁ True; <encdom>  # ▁ Otherwise, ▁ test ▁ if ▁ b ▁ is ▁ in ▁ pats <encdom> <indent> if '*' in pats : <newline> <indent> return util . always <newline> <dedent> return lambda b : b in pats <newline> <dedent> return util . never <newline>  # ▁ Path-based ▁ ACL <encdom> <dedent> if pats : <newline> <indent> return match . match ( repo . root , '' , pats ) <newline> <dedent> return util . never <newline> <dedent> def hook ( ui , repo , hooktype , node = None , source = None , ** kwargs ) : <newline> <indent> if hooktype not in [ 'pretxnchangegroup' , 'pretxncommit' ] : <newline> <indent> raise util . Abort ( _ ( 'config ▁ error ▁ - ▁ hook ▁ type ▁"%s" ▁ cannot ▁ stop ▁ ' 'incoming ▁ changesets ▁ nor ▁ commits' ) % hooktype ) <newline> <dedent> if ( hooktype == 'pretxnchangegroup' and source not in ui . config ( 'acl' , 'sources' , 'serve' ) . split ( ) ) : <newline> <indent> ui . debug ( 'acl: ▁ changes ▁ have ▁ source ▁"%s" ▁ - ▁ skipping \n ' % source ) <newline> return <newline> <dedent> user = None <newline> if source == 'serve' and 'url' in kwargs : <newline> <indent> url = kwargs [ 'url' ] . split ( ':' ) <newline> if url [ 0 ] == 'remote' and url [ 1 ] . startswith ( 'http' ) : <newline> <indent> user = urllib . unquote ( url [ 3 ] ) <newline> <dedent> <dedent> if user is None : <newline> <indent> user = getpass . getuser ( ) <newline> <dedent> ui . debug ( 'acl: ▁ checking ▁ access ▁ for ▁ user ▁"%s" \n ' % user ) <newline> cfg = ui . config ( 'acl' , 'config' ) <newline> if cfg : <newline> <indent> ui . readconfig ( cfg , sections = [ 'acl.groups' , 'acl.allow.branches' , 'acl.deny.branches' , 'acl.allow' , 'acl.deny' ] ) <newline> <dedent> allowbranches = buildmatch ( ui , None , user , 'acl.allow.branches' ) <newline> denybranches = buildmatch ( ui , None , user , 'acl.deny.branches' ) <newline> allow = buildmatch ( ui , repo , user , 'acl.allow' ) <newline> deny = buildmatch ( ui , repo , user , 'acl.deny' ) <newline> for rev in xrange ( repo [ node ] , len ( repo ) ) : <newline> <indent> ctx = repo [ rev ] <newline> branch = ctx . branch ( ) <newline> if denybranches and denybranches ( branch ) : <newline> <indent> raise util . Abort ( _ ( 'acl: ▁ user ▁"%s" ▁ denied ▁ on ▁ branch ▁"%s"' ' ▁ (changeset ▁"%s")' ) % ( user , branch , ctx ) ) <newline> <dedent> if allowbranches and not allowbranches ( branch ) : <newline> <indent> raise util . Abort ( _ ( 'acl: ▁ user ▁"%s" ▁ not ▁ allowed ▁ on ▁ branch ▁"%s"' ' ▁ (changeset ▁"%s")' ) % ( user , branch , ctx ) ) <newline> <dedent> ui . debug ( 'acl: ▁ branch ▁ access ▁ granted: ▁"%s" ▁ on ▁ branch ▁"%s" \n ' % ( ctx , branch ) ) <newline> for f in ctx . files ( ) : <newline> <indent> if deny and deny ( f ) : <newline> <indent> raise util . Abort ( _ ( 'acl: ▁ user ▁"%s" ▁ denied ▁ on ▁"%s"' ' ▁ (changeset ▁"%s")' ) % ( user , f , ctx ) ) <newline> <dedent> if allow and not allow ( f ) : <newline> <indent> raise util . Abort ( _ ( 'acl: ▁ user ▁"%s" ▁ not ▁ allowed ▁ on ▁"%s"' ' ▁ (changeset ▁"%s")' ) % ( user , f , ctx ) ) <newline> <dedent> <dedent> ui . debug ( 'acl: ▁ path ▁ access ▁ granted: ▁"%s" \n ' % ctx ) <newline> <dedent> <dedent>
from haystack import indexes <newline> from spatial . models import Checkin <newline> class CheckinSearchIndex ( indexes . SearchIndex , indexes . Indexable ) : <newline> <indent> text = indexes . CharField ( document = True ) <newline> username = indexes . CharField ( model_attr = 'username' ) <newline> comment = indexes . CharField ( model_attr = 'comment' ) <newline>  # ▁ Again, ▁ if ▁ you ▁ were ▁ using ▁ GeoDjango, ▁ this ▁ could ▁ be ▁ just: <encdom>  # ▁ location ▁ = ▁ indexes.LocationField(model_attr='location') <encdom> location = indexes . LocationField ( model_attr = 'get_location' ) <newline> created = indexes . DateTimeField ( model_attr = 'created' ) <newline> def get_model ( self ) : <newline> <indent> return Checkin <newline> <dedent> def prepare_text ( self , obj ) : <newline>  # ▁ Because ▁ I ▁ don't ▁ feel ▁ like ▁ creating ▁ a ▁ template ▁ just ▁ for ▁ this. <encdom> <indent> return ' \n ' . join ( [ obj . comment , obj . username ] ) <newline> <dedent> <dedent>
 # ▁ Licensed ▁ under ▁ the ▁ Apache ▁ License, ▁ Version ▁ 2.0 ▁ (the ▁"License"); ▁ you ▁ may <encdom>  # ▁ not ▁ use ▁ this ▁ file ▁ except ▁ in ▁ compliance ▁ with ▁ the ▁ License. ▁ You ▁ may ▁ obtain <encdom>  # ▁ a ▁ copy ▁ of ▁ the ▁ License ▁ at <encdom>  # ▁ http://www.apache.org/licenses/LICENSE-2.0 <encdom>  # ▁ Unless ▁ required ▁ by ▁ applicable ▁ law ▁ or ▁ agreed ▁ to ▁ in ▁ writing, ▁ software <encdom>  # ▁ distributed ▁ under ▁ the ▁ License ▁ is ▁ distributed ▁ on ▁ an ▁"AS ▁ IS" ▁ BASIS, ▁ WITHOUT <encdom>  # ▁ WARRANTIES ▁ OR ▁ CONDITIONS ▁ OF ▁ ANY ▁ KIND, ▁ either ▁ express ▁ or ▁ implied. ▁ See ▁ the <encdom>  # ▁ License ▁ for ▁ the ▁ specific ▁ language ▁ governing ▁ permissions ▁ and ▁ limitations <encdom>  # ▁ under ▁ the ▁ License. <encdom>  """ <strnewline> :mod:`nova.console` ▁ -- ▁ Console ▁ Proxy ▁ to ▁ set ▁ up ▁ VM ▁ console ▁ access <strnewline> ▁ (i.e. ▁ with ▁ xvp) <strnewline> ===== <strnewline> <strnewline> .. ▁ automodule:: ▁ nova.console <strnewline> ▁ :platform: ▁ Unix <strnewline> ▁ :synopsis: ▁ Wrapper ▁ around ▁ console ▁ proxies ▁ such ▁ as ▁ xvp ▁ to ▁ set ▁ up <strnewline> ▁ multitenant ▁ VM ▁ console ▁ access <strnewline> """  <newline>
import pyaf . Bench . TS_datasets as tsds <newline> import tests . artificial . process_artificial_dataset as art <newline> art . process_dataset ( N = 32 , FREQ = 'D' , seed = 0 , trendtype = "PolyTrend" , cycle_length = 30 , transform = "Integration" , sigma = 0.0 , exog_count = 100 , ar_order = 0 ) ; <newline>
 # !/usr/bin/python <encdom>  # ▁ This ▁ file ▁ is ▁ part ▁ of ▁ Ansible <encdom>  # ▁ Ansible ▁ is ▁ free ▁ software: ▁ you ▁ can ▁ redistribute ▁ it ▁ and/or ▁ modify <encdom>  # ▁ it ▁ under ▁ the ▁ terms ▁ of ▁ the ▁ GNU ▁ General ▁ Public ▁ License ▁ as ▁ published ▁ by <encdom>  # ▁ the ▁ Free ▁ Software ▁ Foundation, ▁ either ▁ version ▁ 3 ▁ of ▁ the ▁ License, ▁ or <encdom>  # ▁ (at ▁ your ▁ option) ▁ any ▁ later ▁ version. <encdom>  # ▁ Ansible ▁ is ▁ distributed ▁ in ▁ the ▁ hope ▁ that ▁ it ▁ will ▁ be ▁ useful, <encdom>  # ▁ but ▁ WITHOUT ▁ ANY ▁ WARRANTY; ▁ without ▁ even ▁ the ▁ implied ▁ warranty ▁ of <encdom>  # ▁ MERCHANTABILITY ▁ or ▁ FITNESS ▁ FOR ▁ A ▁ PARTICULAR ▁ PURPOSE. ▁ See ▁ the <encdom>  # ▁ GNU ▁ General ▁ Public ▁ License ▁ for ▁ more ▁ details. <encdom>  # ▁ You ▁ should ▁ have ▁ received ▁ a ▁ copy ▁ of ▁ the ▁ GNU ▁ General ▁ Public ▁ License <encdom>  # ▁ along ▁ with ▁ Ansible. ▁ If ▁ not, ▁ see ▁ <http://www.gnu.org/licenses/>. <encdom>  # ▁ This ▁ is ▁ a ▁ DOCUMENTATION ▁ stub ▁ specific ▁ to ▁ this ▁ module, ▁ it ▁ extends <encdom>  # ▁ a ▁ documentation ▁ fragment ▁ located ▁ in ▁ ansible.utils.module_docs_fragments <encdom> DOCUMENTATION =  ''' <strnewline> --- <strnewline> module: ▁ rax_scaling_policy <strnewline> short_description: ▁ Manipulate ▁ Rackspace ▁ Cloud ▁ Autoscale ▁ Scaling ▁ Policy <strnewline> description: <strnewline> ▁ ▁ ▁ ▁ - ▁ Manipulate ▁ Rackspace ▁ Cloud ▁ Autoscale ▁ Scaling ▁ Policy <strnewline> version_added: ▁ 1.7 <strnewline> options: <strnewline> ▁ ▁ at: <strnewline> ▁ ▁ ▁ ▁ description: <strnewline> ▁ ▁ ▁ ▁ ▁ ▁ - ▁ The ▁ UTC ▁ time ▁ when ▁ this ▁ policy ▁ will ▁ be ▁ executed. ▁ The ▁ time ▁ must ▁ be <strnewline> ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ formatted ▁ according ▁ to ▁ C(yyyy-MM-dd'T'HH:mm:ss.SSS) ▁ such ▁ as <strnewline> ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ C(2013-05-19T08:07:08Z) <strnewline> ▁ ▁ change: <strnewline> ▁ ▁ ▁ ▁ description: <strnewline> ▁ ▁ ▁ ▁ ▁ ▁ - ▁ The ▁ change, ▁ either ▁ as ▁ a ▁ number ▁ of ▁ servers ▁ or ▁ as ▁ a ▁ percentage, ▁ to ▁ make <strnewline> ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ in ▁ the ▁ scaling ▁ group. ▁ If ▁ this ▁ is ▁ a ▁ percentage, ▁ you ▁ must ▁ set <strnewline> ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ I(is_percent) ▁ to ▁ C(true) ▁ also. <strnewline> ▁ ▁ cron: <strnewline> ▁ ▁ ▁ ▁ description: <strnewline> ▁ ▁ ▁ ▁ ▁ ▁ - ▁ The ▁ time ▁ when ▁ the ▁ policy ▁ will ▁ be ▁ executed, ▁ as ▁ a ▁ cron ▁ entry. ▁ For <strnewline> ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ example, ▁ if ▁ this ▁ is ▁ parameter ▁ is ▁ set ▁ to ▁ C(1 ▁ 0 ▁ * ▁ * ▁ *) <strnewline> ▁ ▁ cooldown: <strnewline> ▁ ▁ ▁ ▁ description: <strnewline> ▁ ▁ ▁ ▁ ▁ ▁ - ▁ The ▁ period ▁ of ▁ time, ▁ in ▁ seconds, ▁ that ▁ must ▁ pass ▁ before ▁ any ▁ scaling ▁ can <strnewline> ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ occur ▁ after ▁ the ▁ previous ▁ scaling. ▁ Must ▁ be ▁ an ▁ integer ▁ between ▁ 0 ▁ and <strnewline> ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ 86400 ▁ (24 ▁ hrs). <strnewline> ▁ ▁ desired_capacity: <strnewline> ▁ ▁ ▁ ▁ description: <strnewline> ▁ ▁ ▁ ▁ ▁ ▁ - ▁ The ▁ desired ▁ server ▁ capacity ▁ of ▁ the ▁ scaling ▁ the ▁ group; ▁ that ▁ is, ▁ how <strnewline> ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ many ▁ servers ▁ should ▁ be ▁ in ▁ the ▁ scaling ▁ group. <strnewline> ▁ ▁ is_percent: <strnewline> ▁ ▁ ▁ ▁ description: <strnewline> ▁ ▁ ▁ ▁ ▁ ▁ - ▁ Whether ▁ the ▁ value ▁ in ▁ I(change) ▁ is ▁ a ▁ percent ▁ value <strnewline> ▁ ▁ ▁ ▁ default: ▁ false <strnewline> ▁ ▁ name: <strnewline> ▁ ▁ ▁ ▁ description: <strnewline> ▁ ▁ ▁ ▁ ▁ ▁ - ▁ Name ▁ to ▁ give ▁ the ▁ policy <strnewline> ▁ ▁ ▁ ▁ required: ▁ true <strnewline> ▁ ▁ policy_type: <strnewline> ▁ ▁ ▁ ▁ description: <strnewline> ▁ ▁ ▁ ▁ ▁ ▁ - ▁ The ▁ type ▁ of ▁ policy ▁ that ▁ will ▁ be ▁ executed ▁ for ▁ the ▁ current ▁ release. <strnewline> ▁ ▁ ▁ ▁ choices: <strnewline> ▁ ▁ ▁ ▁ ▁ ▁ - ▁ webhook <strnewline> ▁ ▁ ▁ ▁ ▁ ▁ - ▁ schedule <strnewline> ▁ ▁ ▁ ▁ required: ▁ true <strnewline> ▁ ▁ scaling_group: <strnewline> ▁ ▁ ▁ ▁ description: <strnewline> ▁ ▁ ▁ ▁ ▁ ▁ - ▁ Name ▁ of ▁ the ▁ scaling ▁ group ▁ that ▁ this ▁ policy ▁ will ▁ be ▁ added ▁ to <strnewline> ▁ ▁ ▁ ▁ required: ▁ true <strnewline> ▁ ▁ state: <strnewline> ▁ ▁ ▁ ▁ description: <strnewline> ▁ ▁ ▁ ▁ ▁ ▁ - ▁ Indicate ▁ desired ▁ state ▁ of ▁ the ▁ resource <strnewline> ▁ ▁ ▁ ▁ choices: <strnewline> ▁ ▁ ▁ ▁ ▁ ▁ - ▁ present <strnewline> ▁ ▁ ▁ ▁ ▁ ▁ - ▁ absent <strnewline> ▁ ▁ ▁ ▁ default: ▁ present <strnewline> author: ▁"Matt ▁ Martz ▁ (@sivel)" <strnewline> extends_documentation_fragment: ▁ rackspace <strnewline> '''  <newline> EXAMPLES =  ''' <strnewline> --- <strnewline> - ▁ hosts: ▁ localhost <strnewline> ▁ ▁ gather_facts: ▁ false <strnewline> ▁ ▁ connection: ▁ local <strnewline> ▁ ▁ tasks: <strnewline> ▁ ▁ ▁ ▁ - ▁ rax_scaling_policy: <strnewline> ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ credentials: ▁ ~/.raxpub <strnewline> ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ region: ▁ ORD <strnewline> ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ at: ▁'2013-05-19T08:07:08Z' <strnewline> ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ change: ▁ 25 <strnewline> ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ cooldown: ▁ 300 <strnewline> ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ is_percent: ▁ true <strnewline> ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ name: ▁ ASG ▁ Test ▁ Policy ▁ - ▁ at <strnewline> ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ policy_type: ▁ schedule <strnewline> ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ scaling_group: ▁ ASG ▁ Test <strnewline> ▁ ▁ ▁ ▁ ▁ ▁ register: ▁ asps_at <strnewline> <strnewline> ▁ ▁ ▁ ▁ - ▁ rax_scaling_policy: <strnewline> ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ credentials: ▁ ~/.raxpub <strnewline> ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ region: ▁ ORD <strnewline> ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ cron: ▁'1 ▁ 0 ▁ * ▁ * ▁ *' <strnewline> ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ change: ▁ 25 <strnewline> ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ cooldown: ▁ 300 <strnewline> ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ is_percent: ▁ true <strnewline> ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ name: ▁ ASG ▁ Test ▁ Policy ▁ - ▁ cron <strnewline> ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ policy_type: ▁ schedule <strnewline> ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ scaling_group: ▁ ASG ▁ Test <strnewline> ▁ ▁ ▁ ▁ ▁ ▁ register: ▁ asp_cron <strnewline> <strnewline> ▁ ▁ ▁ ▁ - ▁ rax_scaling_policy: <strnewline> ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ credentials: ▁ ~/.raxpub <strnewline> ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ region: ▁ ORD <strnewline> ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ cooldown: ▁ 300 <strnewline> ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ desired_capacity: ▁ 5 <strnewline> ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ name: ▁ ASG ▁ Test ▁ Policy ▁ - ▁ webhook <strnewline> ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ policy_type: ▁ webhook <strnewline> ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ scaling_group: ▁ ASG ▁ Test <strnewline> ▁ ▁ ▁ ▁ ▁ ▁ register: ▁ asp_webhook <strnewline> '''  <newline> try : <newline> <indent> import pyrax <newline> HAS_PYRAX = True <newline> <dedent> except ImportError : <newline> <indent> HAS_PYRAX = False <newline> <dedent> def rax_asp ( module , at = None , change = 0 , cron = None , cooldown = 300 , desired_capacity = 0 , is_percent = False , name = None , policy_type = None , scaling_group = None , state = 'present' ) : <newline> <indent> changed = False <newline> au = pyrax . autoscale <newline> if not au : <newline> <indent> module . fail_json ( msg = 'Failed ▁ to ▁ instantiate ▁ client. ▁ This ▁ ' 'typically ▁ indicates ▁ an ▁ invalid ▁ region ▁ or ▁ an ▁ ' 'incorrectly ▁ capitalized ▁ region ▁ name.' ) <newline> <dedent> try : <newline> <indent> UUID ( scaling_group ) <newline> <dedent> except ValueError : <newline> <indent> try : <newline> <indent> sg = au . find ( name = scaling_group ) <newline> <dedent> except Exception as e : <newline> <indent> module . fail_json ( msg = '%s' % e . message ) <newline> <dedent> <dedent> else : <newline> <indent> try : <newline> <indent> sg = au . get ( scaling_group ) <newline> <dedent> except Exception as e : <newline> <indent> module . fail_json ( msg = '%s' % e . message ) <newline> <dedent> <dedent> if state == 'present' : <newline> <indent> policies = filter ( lambda p : name == p . name , sg . list_policies ( ) ) <newline> if len ( policies ) > 1 : <newline> <indent> module . fail_json ( msg = 'No ▁ unique ▁ policy ▁ match ▁ found ▁ by ▁ name' ) <newline> <dedent> if at : <newline> <indent> args = dict ( at = at ) <newline> <dedent> elif cron : <newline> <indent> args = dict ( cron = cron ) <newline> <dedent> else : <newline> <indent> args = None <newline> <dedent> if not policies : <newline> <indent> try : <newline> <indent> policy = sg . add_policy ( name , policy_type = policy_type , cooldown = cooldown , change = change , is_percent = is_percent , desired_capacity = desired_capacity , args = args ) <newline> changed = True <newline> <dedent> except Exception as e : <newline> <indent> module . fail_json ( msg = '%s' % e . message ) <newline> <dedent> <dedent> else : <newline> <indent> policy = policies [ 0 ] <newline> kwargs = { } <newline> if policy_type != policy . type : <newline> <indent> kwargs [ 'policy_type' ] = policy_type <newline> <dedent> if cooldown != policy . cooldown : <newline> <indent> kwargs [ 'cooldown' ] = cooldown <newline> <dedent> if hasattr ( policy , 'change' ) and change != policy . change : <newline> <indent> kwargs [ 'change' ] = change <newline> <dedent> if hasattr ( policy , 'changePercent' ) and is_percent is False : <newline> <indent> kwargs [ 'change' ] = change <newline> kwargs [ 'is_percent' ] = False <newline> <dedent> elif hasattr ( policy , 'change' ) and is_percent is True : <newline> <indent> kwargs [ 'change' ] = change <newline> kwargs [ 'is_percent' ] = True <newline> <dedent> if hasattr ( policy , 'desiredCapacity' ) and change : <newline> <indent> kwargs [ 'change' ] = change <newline> <dedent> elif ( ( hasattr ( policy , 'change' ) or hasattr ( policy , 'changePercent' ) ) and desired_capacity ) : <newline> <indent> kwargs [ 'desired_capacity' ] = desired_capacity <newline> <dedent> if hasattr ( policy , 'args' ) and args != policy . args : <newline> <indent> kwargs [ 'args' ] = args <newline> <dedent> if kwargs : <newline> <indent> policy . update ( ** kwargs ) <newline> changed = True <newline> <dedent> <dedent> policy . get ( ) <newline> module . exit_json ( changed = changed , autoscale_policy = rax_to_dict ( policy ) ) <newline> <dedent> else : <newline> <indent> try : <newline> <indent> policies = filter ( lambda p : name == p . name , sg . list_policies ( ) ) <newline> if len ( policies ) > 1 : <newline> <indent> module . fail_json ( msg = 'No ▁ unique ▁ policy ▁ match ▁ found ▁ by ▁ name' ) <newline> <dedent> elif not policies : <newline> <indent> policy = { } <newline> <dedent> else : <newline> <indent> policy . delete ( ) <newline> changed = True <newline> <dedent> <dedent> except Exception as e : <newline> <indent> module . fail_json ( msg = '%s' % e . message ) <newline> <dedent> module . exit_json ( changed = changed , autoscale_policy = rax_to_dict ( policy ) ) <newline> <dedent> <dedent> def main ( ) : <newline> <indent> argument_spec = rax_argument_spec ( ) <newline> argument_spec . update ( dict ( at = dict ( ) , change = dict ( type = 'int' ) , cron = dict ( ) , cooldown = dict ( type = 'int' , default = 300 ) , desired_capacity = dict ( type = 'int' ) , is_percent = dict ( type = 'bool' , default = False ) , name = dict ( required = True ) , policy_type = dict ( required = True , choices = [ 'webhook' , 'schedule' ] ) , scaling_group = dict ( required = True ) , state = dict ( default = 'present' , choices = [ 'present' , 'absent' ] ) , ) ) <newline> module = AnsibleModule ( argument_spec = argument_spec , required_together = rax_required_together ( ) , mutually_exclusive = [ [ 'cron' , 'at' ] , [ 'change' , 'desired_capacity' ] , ] ) <newline> if not HAS_PYRAX : <newline> <indent> module . fail_json ( msg = 'pyrax ▁ is ▁ required ▁ for ▁ this ▁ module' ) <newline> <dedent> at = module . params . get ( 'at' ) <newline> change = module . params . get ( 'change' ) <newline> cron = module . params . get ( 'cron' ) <newline> cooldown = module . params . get ( 'cooldown' ) <newline> desired_capacity = module . params . get ( 'desired_capacity' ) <newline> is_percent = module . params . get ( 'is_percent' ) <newline> name = module . params . get ( 'name' ) <newline> policy_type = module . params . get ( 'policy_type' ) <newline> scaling_group = module . params . get ( 'scaling_group' ) <newline> state = module . params . get ( 'state' ) <newline> if ( at or cron ) and policy_type == 'webhook' : <newline> <indent> module . fail_json ( msg = 'policy_type=schedule ▁ is ▁ required ▁ for ▁ a ▁ time ▁ ' 'based ▁ policy' ) <newline> <dedent> setup_rax_module ( module , pyrax ) <newline> rax_asp ( module , at = at , change = change , cron = cron , cooldown = cooldown , desired_capacity = desired_capacity , is_percent = is_percent , name = name , policy_type = policy_type , scaling_group = scaling_group , state = state ) <newline>  # ▁ import ▁ module ▁ snippets <encdom> <dedent> from ansible . module_utils . basic import * <newline> from ansible . module_utils . rax import * <newline>  # ▁ invoke ▁ the ▁ module <encdom> main ( ) <newline>
 # ▁ (c) ▁ 2014, ▁ Brian ▁ Coca ▁ <bcoca@ansible.com> <encdom>  # ▁ This ▁ file ▁ is ▁ part ▁ of ▁ Ansible <encdom>  # ▁ Ansible ▁ is ▁ free ▁ software: ▁ you ▁ can ▁ redistribute ▁ it ▁ and/or ▁ modify <encdom>  # ▁ it ▁ under ▁ the ▁ terms ▁ of ▁ the ▁ GNU ▁ General ▁ Public ▁ License ▁ as ▁ published ▁ by <encdom>  # ▁ the ▁ Free ▁ Software ▁ Foundation, ▁ either ▁ version ▁ 3 ▁ of ▁ the ▁ License, ▁ or <encdom>  # ▁ (at ▁ your ▁ option) ▁ any ▁ later ▁ version. <encdom>  # ▁ Ansible ▁ is ▁ distributed ▁ in ▁ the ▁ hope ▁ that ▁ it ▁ will ▁ be ▁ useful, <encdom>  # ▁ but ▁ WITHOUT ▁ ANY ▁ WARRANTY; ▁ without ▁ even ▁ the ▁ implied ▁ warranty ▁ of <encdom>  # ▁ MERCHANTABILITY ▁ or ▁ FITNESS ▁ FOR ▁ A ▁ PARTICULAR ▁ PURPOSE. ▁ See ▁ the <encdom>  # ▁ GNU ▁ General ▁ Public ▁ License ▁ for ▁ more ▁ details. <encdom>  # ▁ You ▁ should ▁ have ▁ received ▁ a ▁ copy ▁ of ▁ the ▁ GNU ▁ General ▁ Public ▁ License <encdom>  # ▁ along ▁ with ▁ Ansible. ▁ If ▁ not, ▁ see ▁ <http://www.gnu.org/licenses/>. <encdom> from __future__ import absolute_import <newline> import math <newline> import collections <newline> from ansible import errors <newline> def unique ( a ) : <newline> <indent> if isinstance ( a , collections . Hashable ) : <newline> <indent> c = set ( a ) <newline> <dedent> else : <newline> <indent> c = [ ] <newline> for x in a : <newline> <indent> if x not in c : <newline> <indent> c . append ( x ) <newline> <dedent> <dedent> <dedent> return c <newline> <dedent> def intersect ( a , b ) : <newline> <indent> if isinstance ( a , collections . Hashable ) and isinstance ( b , collections . Hashable ) : <newline> <indent> c = set ( a ) & set ( b ) <newline> <dedent> else : <newline> <indent> c = unique ( filter ( lambda x : x in b , a ) ) <newline> <dedent> return c <newline> <dedent> def difference ( a , b ) : <newline> <indent> if isinstance ( a , collections . Hashable ) and isinstance ( b , collections . Hashable ) : <newline> <indent> c = set ( a ) - set ( b ) <newline> <dedent> else : <newline> <indent> c = unique ( filter ( lambda x : x not in b , a ) ) <newline> <dedent> return c <newline> <dedent> def symmetric_difference ( a , b ) : <newline> <indent> if isinstance ( a , collections . Hashable ) and isinstance ( b , collections . Hashable ) : <newline> <indent> c = set ( a ) ^ set ( b ) <newline> <dedent> else : <newline> <indent> c = unique ( filter ( lambda x : x not in intersect ( a , b ) , union ( a , b ) ) ) <newline> <dedent> return c <newline> <dedent> def union ( a , b ) : <newline> <indent> if isinstance ( a , collections . Hashable ) and isinstance ( b , collections . Hashable ) : <newline> <indent> c = set ( a ) | set ( b ) <newline> <dedent> else : <newline> <indent> c = unique ( a + b ) <newline> <dedent> return c <newline> <dedent> def min ( a ) : <newline> <indent> _min = __builtins__ . get ( 'min' ) <newline> return _min ( a ) ; <newline> <dedent> def max ( a ) : <newline> <indent> _max = __builtins__ . get ( 'max' ) <newline> return _max ( a ) ; <newline> <dedent> def isnotanumber ( x ) : <newline> <indent> try : <newline> <indent> return math . isnan ( x ) <newline> <dedent> except TypeError : <newline> <indent> return False <newline> <dedent> <dedent> def logarithm ( x , base = math . e ) : <newline> <indent> try : <newline> <indent> if base == 10 : <newline> <indent> return math . log10 ( x ) <newline> <dedent> else : <newline> <indent> return math . log ( x , base ) <newline> <dedent> <dedent> except TypeError as e : <newline> <indent> raise errors . AnsibleFilterError ( 'log() ▁ can ▁ only ▁ be ▁ used ▁ on ▁ numbers: ▁ %s' % str ( e ) ) <newline> <dedent> <dedent> def power ( x , y ) : <newline> <indent> try : <newline> <indent> return math . pow ( x , y ) <newline> <dedent> except TypeError as e : <newline> <indent> raise errors . AnsibleFilterError ( 'pow() ▁ can ▁ only ▁ be ▁ used ▁ on ▁ numbers: ▁ %s' % str ( e ) ) <newline> <dedent> <dedent> def inversepower ( x , base = 2 ) : <newline> <indent> try : <newline> <indent> if base == 2 : <newline> <indent> return math . sqrt ( x ) <newline> <dedent> else : <newline> <indent> return math . pow ( x , 1.0 / float ( base ) ) <newline> <dedent> <dedent> except TypeError as e : <newline> <indent> raise errors . AnsibleFilterError ( 'root() ▁ can ▁ only ▁ be ▁ used ▁ on ▁ numbers: ▁ %s' % str ( e ) ) <newline> <dedent> <dedent> def human_readable ( size , isbits = False , unit = None ) : <newline> <indent> base = 'bits' if isbits else 'Bytes' <newline> suffix = '' <newline> ranges = ( ( 1 << 70 , 'Z' ) , ( 1 << 60 , 'E' ) , ( 1 << 50 , 'P' ) , ( 1 << 40 , 'T' ) , ( 1 << 30 , 'G' ) , ( 1 << 20 , 'M' ) , ( 1 << 10 , 'K' ) , ( 1 , base ) ) <newline> for limit , suffix in ranges : <newline> <indent> if ( unit is None and size >= limit ) or unit is not None and unit . upper ( ) == suffix : <newline> <indent> break <newline> <dedent> <dedent> if limit != 1 : <newline> <indent> suffix += base [ 0 ] <newline> <dedent> return '%.2f ▁ %s' % ( float ( size ) / limit , suffix ) <newline> <dedent> class FilterModule ( object ) : <newline> <indent>  ''' ▁ Ansible ▁ math ▁ jinja2 ▁ filters ▁ '''  <newline> def filters ( self ) : <newline> <indent> return {  # ▁ general ▁ math <encdom> 'isnan' : isnotanumber , 'min' : min , 'max' : max ,  # ▁ exponents ▁ and ▁ logarithms <encdom> 'log' : logarithm , 'pow' : power , 'root' : inversepower ,  # ▁ set ▁ theory <encdom> 'unique' : unique , 'intersect' : intersect , 'difference' : difference , 'symmetric_difference' : symmetric_difference , 'union' : union ,  # ▁ computer ▁ theory <encdom> 'human_readable' : human_readable , } <newline> <dedent> <dedent>
from django . utils . encoding import force_unicode <newline> import html5lib <newline> import jinja2 <newline> def truncate_text ( text , limit , killwords = False , end = '...' ) : <newline> <indent>  """ Return ▁ as ▁ many ▁ characters ▁ as ▁ possible ▁ without ▁ going ▁ over ▁ the ▁ limit. <strnewline> <strnewline> ▁ Return ▁ the ▁ truncated ▁ text ▁ and ▁ the ▁ characters ▁ left ▁ before ▁ the ▁ limit, ▁ if ▁ any. <strnewline> <strnewline> ▁ """  <newline> text = text . strip ( ) <newline> text_length = len ( text ) <newline> if text_length < limit : <newline> <indent> return text , limit - text_length <newline>  # ▁ Explicitly ▁ add ▁"end" ▁ in ▁ any ▁ case, ▁ as ▁ Jinja ▁ can't ▁ know ▁ we're ▁ truncating <encdom>  # ▁ for ▁ real ▁ here, ▁ even ▁ though ▁ we ▁ might ▁ be ▁ at ▁ the ▁ end ▁ of ▁ a ▁ word. <encdom> <dedent> text = jinja2 . filters . do_truncate ( text , limit , killwords , end = '' ) <newline> return text + end , 0 <newline> <dedent> def trim ( tree , limit , killwords , end ) : <newline> <indent>  """ Truncate ▁ the ▁ text ▁ of ▁ an ▁ html5lib ▁ tree. """  <newline> if tree . text :  # ▁ Root ▁ node's ▁ text. <encdom> <newline> <indent> tree . text , limit = truncate_text ( tree . text , limit , killwords , end ) <newline> <dedent> for child in tree :  # ▁ Immediate ▁ children. <encdom> <newline> <indent> if limit <= 0 : <newline>  # ▁ We ▁ reached ▁ the ▁ limit, ▁ remove ▁ all ▁ remaining ▁ children. <encdom> <indent> tree . remove ( child ) <newline> <dedent> else : <newline>  # ▁ Recurse ▁ on ▁ the ▁ current ▁ child. <encdom> <indent> _parsed_tree , limit = trim ( child , limit , killwords , end ) <newline> <dedent> <dedent> if tree . tail :  # ▁ Root ▁ node's ▁ tail ▁ text. <encdom> <newline> <indent> if limit <= 0 : <newline> <indent> tree . tail = '' <newline> <dedent> else : <newline> <indent> tree . tail , limit = truncate_text ( tree . tail , limit , killwords , end ) <newline> <dedent> <dedent> return tree , limit <newline> <dedent> def text_length ( tree ) : <newline> <indent>  """ Find ▁ the ▁ length ▁ of ▁ the ▁ text ▁ content, ▁ excluding ▁ markup. """  <newline> total = 0 <newline> for node in tree . getiterator ( ) :  # ▁ Traverse ▁ all ▁ the ▁ tree ▁ nodes. <encdom> <newline>  # ▁ In ▁ etree, ▁ a ▁ node ▁ has ▁ a ▁ text ▁ and ▁ tail ▁ attribute. <encdom>  # ▁ Eg: ▁"<b>inner ▁ text</b> ▁ tail ▁ text ▁ <em>inner ▁ text</em>". <encdom> <indent> if node . text : <newline> <indent> total += len ( node . text . strip ( ) ) <newline> <dedent> if node . tail : <newline> <indent> total += len ( node . tail . strip ( ) ) <newline> <dedent> <dedent> return total <newline> <dedent> def truncate ( html , length , killwords = False , end = '...' ) : <newline> <indent>  """ <strnewline> ▁ Return ▁ a ▁ slice ▁ of ▁ ``html`` ▁ <= ▁ length ▁ chars. <strnewline> <strnewline> ▁ killwords ▁ and ▁ end ▁ are ▁ currently ▁ ignored. <strnewline> <strnewline> ▁ ONLY ▁ USE ▁ FOR ▁ KNOWN-SAFE ▁ HTML. <strnewline> ▁ """  <newline> tree = html5lib . parseFragment ( html ) <newline> if text_length ( tree ) <= length : <newline> <indent> return jinja2 . Markup ( html ) <newline> <dedent> else : <newline>  # ▁ Get ▁ a ▁ truncated ▁ version ▁ of ▁ the ▁ tree. <encdom> <indent> short , _ = trim ( tree , length , killwords , end ) <newline>  # ▁ Serialize ▁ the ▁ parsed ▁ tree ▁ back ▁ to ▁ html. <encdom> walker = html5lib . treewalkers . getTreeWalker ( 'etree' ) <newline> stream = walker ( short ) <newline> serializer = html5lib . serializer . htmlserializer . HTMLSerializer ( quote_attr_values = True , omit_optional_tags = False ) <newline> return jinja2 . Markup ( force_unicode ( serializer . render ( stream ) ) ) <newline> <dedent> <dedent> def transfield_changed ( field , initial , data ) : <newline> <indent>  """ <strnewline> ▁ For ▁ forms, ▁ compares ▁ initial ▁ data ▁ against ▁ cleaned_data ▁ for ▁ TransFields. <strnewline> ▁ Returns ▁ True ▁ if ▁ data ▁ is ▁ the ▁ same. ▁ Returns ▁ False ▁ if ▁ data ▁ is ▁ different. <strnewline> <strnewline> ▁ Arguments: <strnewline> ▁ field ▁ -- ▁ name ▁ of ▁ the ▁ form ▁ field ▁ as-is. <strnewline> ▁ initial ▁ -- ▁ data ▁ in ▁ the ▁ form ▁ of ▁ {'description_en-us': ▁'x', <strnewline> ▁'description_en-br': ▁'y'} <strnewline> ▁ data ▁ -- ▁ cleaned ▁ data ▁ in ▁ the ▁ form ▁ of ▁ {'description': ▁ {'init': ▁'', <strnewline> ▁'en-us': ▁'x', <strnewline> ▁'en-br': ▁'y'} <strnewline> ▁ """  <newline> initial = [ ( k , v . localized_string ) for k , v in initial . iteritems ( ) if '%s_' % field in k and v is not None ] <newline> data = [ ( '%s_%s' % ( field , k ) , v ) for k , v in data [ field ] . iteritems ( ) if k != 'init' ] <newline> return set ( initial ) != set ( data ) <newline> <dedent>
 # # # # # ▁ BEGIN ▁ LICENSE ▁ BLOCK ▁ # # # # # <encdom>  # ▁ The ▁ Original ▁ Code ▁ is ▁ mozilla.org ▁ code. <encdom>  # ▁ The ▁ Initial ▁ Developer ▁ of ▁ the ▁ Original ▁ Code ▁ is <encdom>  # ▁ Netscape ▁ Communications ▁ Corporation. <encdom>  # ▁ Portions ▁ created ▁ by ▁ the ▁ Initial ▁ Developer ▁ are ▁ Copyright ▁ (C) ▁ 1998 <encdom>  # ▁ the ▁ Initial ▁ Developer. ▁ All ▁ Rights ▁ Reserved. <encdom>  # ▁ Contributor(s): <encdom>  # ▁ Mark ▁ Pilgrim ▁ - ▁ port ▁ to ▁ Python <encdom>  # ▁ This ▁ library ▁ is ▁ free ▁ software; ▁ you ▁ can ▁ redistribute ▁ it ▁ and/or <encdom>  # ▁ modify ▁ it ▁ under ▁ the ▁ terms ▁ of ▁ the ▁ GNU ▁ Lesser ▁ General ▁ Public <encdom>  # ▁ License ▁ as ▁ published ▁ by ▁ the ▁ Free ▁ Software ▁ Foundation; ▁ either <encdom>  # ▁ version ▁ 2.1 ▁ of ▁ the ▁ License, ▁ or ▁ (at ▁ your ▁ option) ▁ any ▁ later ▁ version. <encdom>  # ▁ This ▁ library ▁ is ▁ distributed ▁ in ▁ the ▁ hope ▁ that ▁ it ▁ will ▁ be ▁ useful, <encdom>  # ▁ but ▁ WITHOUT ▁ ANY ▁ WARRANTY; ▁ without ▁ even ▁ the ▁ implied ▁ warranty ▁ of <encdom>  # ▁ MERCHANTABILITY ▁ or ▁ FITNESS ▁ FOR ▁ A ▁ PARTICULAR ▁ PURPOSE. ▁ See ▁ the ▁ GNU <encdom>  # ▁ Lesser ▁ General ▁ Public ▁ License ▁ for ▁ more ▁ details. <encdom>  # ▁ You ▁ should ▁ have ▁ received ▁ a ▁ copy ▁ of ▁ the ▁ GNU ▁ Lesser ▁ General ▁ Public <encdom>  # ▁ License ▁ along ▁ with ▁ this ▁ library; ▁ if ▁ not, ▁ write ▁ to ▁ the ▁ Free ▁ Software <encdom>  # ▁ Foundation, ▁ Inc., ▁ 51 ▁ Franklin ▁ St, ▁ Fifth ▁ Floor, ▁ Boston, ▁ MA <encdom>  # ▁ 02110-1301 ▁ USA <encdom>  # # # # # ▁ END ▁ LICENSE ▁ BLOCK ▁ # # # # # <encdom> from . mbcharsetprober import MultiByteCharSetProber <newline> from . codingstatemachine import CodingStateMachine <newline> from . chardistribution import GB2312DistributionAnalysis <newline> from . mbcssm import GB2312SMModel <newline> class GB2312Prober ( MultiByteCharSetProber ) : <newline> <indent> def __init__ ( self ) : <newline> <indent> MultiByteCharSetProber . __init__ ( self ) <newline> self . _mCodingSM = CodingStateMachine ( GB2312SMModel ) <newline> self . _mDistributionAnalyzer = GB2312DistributionAnalysis ( ) <newline> self . reset ( ) <newline> <dedent> def get_charset_name ( self ) : <newline> <indent> return "GB2312" <newline> <dedent> <dedent>
 # !/usr/bin/env ▁ python <encdom>  # ▁ Copyright ▁ 2015 ▁ clowwindy <encdom>  # ▁ Licensed ▁ under ▁ the ▁ Apache ▁ License, ▁ Version ▁ 2.0 ▁ (the ▁"License"); ▁ you ▁ may <encdom>  # ▁ not ▁ use ▁ this ▁ file ▁ except ▁ in ▁ compliance ▁ with ▁ the ▁ License. ▁ You ▁ may ▁ obtain <encdom>  # ▁ a ▁ copy ▁ of ▁ the ▁ License ▁ at <encdom>  # ▁ http://www.apache.org/licenses/LICENSE-2.0 <encdom>  # ▁ Unless ▁ required ▁ by ▁ applicable ▁ law ▁ or ▁ agreed ▁ to ▁ in ▁ writing, ▁ software <encdom>  # ▁ distributed ▁ under ▁ the ▁ License ▁ is ▁ distributed ▁ on ▁ an ▁"AS ▁ IS" ▁ BASIS, ▁ WITHOUT <encdom>  # ▁ WARRANTIES ▁ OR ▁ CONDITIONS ▁ OF ▁ ANY ▁ KIND, ▁ either ▁ express ▁ or ▁ implied. ▁ See ▁ the <encdom>  # ▁ License ▁ for ▁ the ▁ specific ▁ language ▁ governing ▁ permissions ▁ and ▁ limitations <encdom>  # ▁ under ▁ the ▁ License. <encdom> from __future__ import absolute_import , division , print_function , with_statement <newline> from ctypes import c_char_p , c_int , c_long , byref , create_string_buffer , c_void_p <newline> from shadowsocks import common <newline> from shadowsocks . crypto import util <newline> __all__ = [ 'ciphers' ] <newline> libcrypto = None <newline> loaded = False <newline> buf_size = 2048 <newline> def load_openssl ( ) : <newline> <indent> global loaded , libcrypto , buf <newline> libcrypto = util . find_library ( ( 'crypto' , 'eay32' ) , 'EVP_get_cipherbyname' , 'libcrypto' ) <newline> if libcrypto is None : <newline> <indent> raise Exception ( 'libcrypto(OpenSSL) ▁ not ▁ found' ) <newline> <dedent> libcrypto . EVP_get_cipherbyname . restype = c_void_p <newline> libcrypto . EVP_CIPHER_CTX_new . restype = c_void_p <newline> libcrypto . EVP_CipherInit_ex . argtypes = ( c_void_p , c_void_p , c_char_p , c_char_p , c_char_p , c_int ) <newline> libcrypto . EVP_CipherUpdate . argtypes = ( c_void_p , c_void_p , c_void_p , c_char_p , c_int ) <newline> libcrypto . EVP_CIPHER_CTX_cleanup . argtypes = ( c_void_p , ) <newline> libcrypto . EVP_CIPHER_CTX_free . argtypes = ( c_void_p , ) <newline> if hasattr ( libcrypto , 'OpenSSL_add_all_ciphers' ) : <newline> <indent> libcrypto . OpenSSL_add_all_ciphers ( ) <newline> <dedent> buf = create_string_buffer ( buf_size ) <newline> loaded = True <newline> <dedent> def load_cipher ( cipher_name ) : <newline> <indent> func_name = 'EVP_' + cipher_name . replace ( '-' , '_' ) <newline> if bytes != str : <newline> <indent> func_name = str ( func_name , 'utf-8' ) <newline> <dedent> cipher = getattr ( libcrypto , func_name , None ) <newline> if cipher : <newline> <indent> cipher . restype = c_void_p <newline> return cipher ( ) <newline> <dedent> return None <newline> <dedent> class OpenSSLCrypto ( object ) : <newline> <indent> def __init__ ( self , cipher_name , key , iv , op ) : <newline> <indent> self . _ctx = None <newline> if not loaded : <newline> <indent> load_openssl ( ) <newline> <dedent> cipher_name = common . to_bytes ( cipher_name ) <newline> cipher = libcrypto . EVP_get_cipherbyname ( cipher_name ) <newline> if not cipher : <newline> <indent> cipher = load_cipher ( cipher_name ) <newline> <dedent> if not cipher : <newline> <indent> raise Exception ( 'cipher ▁ %s ▁ not ▁ found ▁ in ▁ libcrypto' % cipher_name ) <newline> <dedent> key_ptr = c_char_p ( key ) <newline> iv_ptr = c_char_p ( iv ) <newline> self . _ctx = libcrypto . EVP_CIPHER_CTX_new ( ) <newline> if not self . _ctx : <newline> <indent> raise Exception ( 'can ▁ not ▁ create ▁ cipher ▁ context' ) <newline> <dedent> r = libcrypto . EVP_CipherInit_ex ( self . _ctx , cipher , None , key_ptr , iv_ptr , c_int ( op ) ) <newline> if not r : <newline> <indent> self . clean ( ) <newline> raise Exception ( 'can ▁ not ▁ initialize ▁ cipher ▁ context' ) <newline> <dedent> <dedent> def update ( self , data ) : <newline> <indent> global buf_size , buf <newline> cipher_out_len = c_long ( 0 ) <newline> l = len ( data ) <newline> if buf_size < l : <newline> <indent> buf_size = l * 2 <newline> buf = create_string_buffer ( buf_size ) <newline> <dedent> libcrypto . EVP_CipherUpdate ( self . _ctx , byref ( buf ) , byref ( cipher_out_len ) , c_char_p ( data ) , l ) <newline>  # ▁ buf ▁ is ▁ copied ▁ to ▁ a ▁ str ▁ object ▁ when ▁ we ▁ access ▁ buf.raw <encdom> return buf . raw [ : cipher_out_len . value ] <newline> <dedent> def __del__ ( self ) : <newline> <indent> self . clean ( ) <newline> <dedent> def clean ( self ) : <newline> <indent> if self . _ctx : <newline> <indent> libcrypto . EVP_CIPHER_CTX_cleanup ( self . _ctx ) <newline> libcrypto . EVP_CIPHER_CTX_free ( self . _ctx ) <newline> <dedent> <dedent> <dedent> ciphers = { 'aes-128-cfb' : ( 16 , 16 , OpenSSLCrypto ) , 'aes-192-cfb' : ( 24 , 16 , OpenSSLCrypto ) , 'aes-256-cfb' : ( 32 , 16 , OpenSSLCrypto ) , 'aes-128-ofb' : ( 16 , 16 , OpenSSLCrypto ) , 'aes-192-ofb' : ( 24 , 16 , OpenSSLCrypto ) , 'aes-256-ofb' : ( 32 , 16 , OpenSSLCrypto ) , 'aes-128-ctr' : ( 16 , 16 , OpenSSLCrypto ) , 'aes-192-ctr' : ( 24 , 16 , OpenSSLCrypto ) , 'aes-256-ctr' : ( 32 , 16 , OpenSSLCrypto ) , 'aes-128-cfb8' : ( 16 , 16 , OpenSSLCrypto ) , 'aes-192-cfb8' : ( 24 , 16 , OpenSSLCrypto ) , 'aes-256-cfb8' : ( 32 , 16 , OpenSSLCrypto ) , 'aes-128-cfb1' : ( 16 , 16 , OpenSSLCrypto ) , 'aes-192-cfb1' : ( 24 , 16 , OpenSSLCrypto ) , 'aes-256-cfb1' : ( 32 , 16 , OpenSSLCrypto ) , 'bf-cfb' : ( 16 , 8 , OpenSSLCrypto ) , 'camellia-128-cfb' : ( 16 , 16 , OpenSSLCrypto ) , 'camellia-192-cfb' : ( 24 , 16 , OpenSSLCrypto ) , 'camellia-256-cfb' : ( 32 , 16 , OpenSSLCrypto ) , 'cast5-cfb' : ( 16 , 8 , OpenSSLCrypto ) , 'des-cfb' : ( 8 , 8 , OpenSSLCrypto ) , 'idea-cfb' : ( 16 , 8 , OpenSSLCrypto ) , 'rc2-cfb' : ( 16 , 8 , OpenSSLCrypto ) , 'rc4' : ( 16 , 0 , OpenSSLCrypto ) , 'seed-cfb' : ( 16 , 16 , OpenSSLCrypto ) , } <newline> def run_method ( method ) : <newline> <indent> cipher = OpenSSLCrypto ( method , b'k' * 32 , b'i' * 16 , 1 ) <newline> decipher = OpenSSLCrypto ( method , b'k' * 32 , b'i' * 16 , 0 ) <newline> util . run_cipher ( cipher , decipher ) <newline> <dedent> def test_aes_128_cfb ( ) : <newline> <indent> run_method ( 'aes-128-cfb' ) <newline> <dedent> def test_aes_256_cfb ( ) : <newline> <indent> run_method ( 'aes-256-cfb' ) <newline> <dedent> def test_aes_128_cfb8 ( ) : <newline> <indent> run_method ( 'aes-128-cfb8' ) <newline> <dedent> def test_aes_256_ofb ( ) : <newline> <indent> run_method ( 'aes-256-ofb' ) <newline> <dedent> def test_aes_256_ctr ( ) : <newline> <indent> run_method ( 'aes-256-ctr' ) <newline> <dedent> def test_bf_cfb ( ) : <newline> <indent> run_method ( 'bf-cfb' ) <newline> <dedent> def test_rc4 ( ) : <newline> <indent> run_method ( 'rc4' ) <newline> <dedent> if __name__ == '__main__' : <newline> <indent> test_aes_128_cfb ( ) <newline> <dedent>
 # ▁ coding=utf-8 <encdom> from __future__ import absolute_import <newline> __author__ = "Marc ▁ Hannappel ▁ <salandora@gmail.com>" <newline> __license__ = 'GNU ▁ Affero ▁ General ▁ Public ▁ License ▁ http://www.gnu.org/licenses/agpl.html' <newline> import octoprint . plugin <newline> class SystemCommandEditorPlugin ( octoprint . plugin . SettingsPlugin , octoprint . plugin . TemplatePlugin , octoprint . plugin . BlueprintPlugin , octoprint . plugin . AssetPlugin ) : <newline> <indent> def get_settings_defaults ( self ) : <newline> <indent> return dict ( actions = [ ] ) <newline> <dedent> def get_template_configs ( self ) : <newline> <indent> if "editorcollection" in self . _plugin_manager . enabled_plugins : <newline> <indent> return [ dict ( type = "plugin_editorcollection_EditorCollection" , template = "systemcommandeditor_hookedsettings.jinja2" , custom_bindings = True ) ] <newline> <dedent> else : <newline> <indent> return [ dict ( type = "settings" , template = "systemcommandeditor_hookedsettings.jinja2" , custom_bindings = True ) ] <newline> <dedent> <dedent> def on_settings_save ( self , data ) : <newline> <indent> pass <newline> <dedent> def get_assets ( self ) : <newline> <indent> return dict ( js = [ "js/jquery.ui.sortable.js" , "js/systemcommandeditor.js" , "js/systemcommandeditorDialog.js" ] , css = [ "css/systemcommandeditor.css" ] ) <newline> <dedent> def get_update_information ( self ) : <newline> <indent> return dict ( systemcommandeditor = dict ( displayName = "System ▁ Command ▁ Editor ▁ Plugin" , displayVersion = self . _plugin_version ,  # ▁ version ▁ check: ▁ github ▁ repository <encdom> type = "github_release" , user = "Salandora" , repo = "OctoPrint-SystemCommandEditor" , current = self . _plugin_version ,  # ▁ update ▁ method: ▁ pip <encdom> pip = "https://github.com/Salandora/OctoPrint-SystemCommandEditor/archive/{target_version}.zip" ) ) <newline> <dedent> <dedent> __plugin_name__ = "System ▁ Command ▁ Editor" <newline> __plugin_pythoncompat__ = ">=2.7,<4" <newline> def __plugin_load__ ( ) : <newline> <indent> global __plugin_implementation__ <newline> __plugin_implementation__ = SystemCommandEditorPlugin ( ) <newline> global __plugin_hooks__ <newline> __plugin_hooks__ = { "octoprint.plugin.softwareupdate.check_config" : __plugin_implementation__ . get_update_information } <newline> global __plugin_license__ <newline> __plugin_license__ = "AGPLv3" <newline> <dedent>
 # ▁ This ▁ program ▁ is ▁ free ▁ software; ▁ you ▁ can ▁ redistribute ▁ it ▁ and/or ▁ modify <encdom>  # ▁ it ▁ under ▁ the ▁ terms ▁ of ▁ the ▁ (LGPL) ▁ GNU ▁ Lesser ▁ General ▁ Public ▁ License ▁ as <encdom>  # ▁ published ▁ by ▁ the ▁ Free ▁ Software ▁ Foundation; ▁ either ▁ version ▁ 3 ▁ of ▁ the ▁ <encdom>  # ▁ License, ▁ or ▁ (at ▁ your ▁ option) ▁ any ▁ later ▁ version. <encdom>  # ▁ This ▁ program ▁ is ▁ distributed ▁ in ▁ the ▁ hope ▁ that ▁ it ▁ will ▁ be ▁ useful, <encdom>  # ▁ but ▁ WITHOUT ▁ ANY ▁ WARRANTY; ▁ without ▁ even ▁ the ▁ implied ▁ warranty ▁ of <encdom>  # ▁ MERCHANTABILITY ▁ or ▁ FITNESS ▁ FOR ▁ A ▁ PARTICULAR ▁ PURPOSE. ▁ See ▁ the <encdom>  # ▁ GNU ▁ Library ▁ Lesser ▁ General ▁ Public ▁ License ▁ for ▁ more ▁ details ▁ at <encdom>  # ▁ ( ▁ http://www.gnu.org/licenses/lgpl.html ▁ ). <encdom>  # ▁ You ▁ should ▁ have ▁ received ▁ a ▁ copy ▁ of ▁ the ▁ GNU ▁ Lesser ▁ General ▁ Public ▁ License <encdom>  # ▁ along ▁ with ▁ this ▁ program; ▁ if ▁ not, ▁ write ▁ to ▁ the ▁ Free ▁ Software <encdom>  # ▁ Foundation, ▁ Inc., ▁ 59 ▁ Temple ▁ Place ▁ - ▁ Suite ▁ 330, ▁ Boston, ▁ MA ▁ 02111-1307, ▁ USA. <encdom>  # ▁ written ▁ by: ▁ Jeff ▁ Ortel ▁ ( ▁ jortel@redhat.com ▁ ) <encdom>  """ <strnewline> Provides ▁ classes ▁ for ▁ the ▁ (WS) ▁ SOAP ▁ I{document/literal}. <strnewline> """  <newline> from logging import getLogger <newline> from suds import * <newline> from suds . bindings . binding import Binding <newline> from suds . sax . element import Element <newline> log = getLogger ( __name__ ) <newline> class Document ( Binding ) : <newline> <indent>  """ <strnewline> ▁ The ▁ document/literal ▁ style. ▁ Literal ▁ is ▁ the ▁ only ▁ (@use) ▁ supported <strnewline> ▁ since ▁ document/encoded ▁ is ▁ pretty ▁ much ▁ dead. <strnewline> ▁ Although ▁ the ▁ soap ▁ specification ▁ supports ▁ multiple ▁ documents ▁ within ▁ the ▁ soap <strnewline> ▁ <body/>, ▁ it ▁ is ▁ very ▁ uncommon. ▁ As ▁ such, ▁ suds ▁ presents ▁ an ▁ I{RPC} ▁ view ▁ of <strnewline> ▁ service ▁ methods ▁ defined ▁ with ▁ a ▁ single ▁ document ▁ parameter. ▁ This ▁ is ▁ done ▁ so ▁ <strnewline> ▁ that ▁ the ▁ user ▁ can ▁ pass ▁ individual ▁ parameters ▁ instead ▁ of ▁ one, ▁ single ▁ document. <strnewline> ▁ To ▁ support ▁ the ▁ complete ▁ specification, ▁ service ▁ methods ▁ defined ▁ with ▁ multiple ▁ documents <strnewline> ▁ (multiple ▁ message ▁ parts), ▁ must ▁ present ▁ a ▁ I{document} ▁ view ▁ for ▁ that ▁ method. <strnewline> ▁ """  <newline> def bodycontent ( self , method , args , kwargs ) : <newline>  # ▁ The ▁ I{wrapped} ▁ vs ▁ I{bare} ▁ style ▁ is ▁ detected ▁ in ▁ 2 ▁ ways. <encdom>  # ▁ If ▁ there ▁ is ▁ 2+ ▁ parts ▁ in ▁ the ▁ message ▁ then ▁ it ▁ is ▁ I{bare}. <encdom>  # ▁ If ▁ there ▁ is ▁ only ▁ (1) ▁ part ▁ and ▁ that ▁ part ▁ resolves ▁ to ▁ a ▁ builtin ▁ then <encdom>  # ▁ it ▁ is ▁ I{bare}. ▁ Otherwise, ▁ it ▁ is ▁ I{wrapped}. <encdom> <indent> if not len ( method . soap . input . body . parts ) : <newline> <indent> return ( ) <newline> <dedent> wrapped = method . soap . input . body . wrapped <newline> if wrapped : <newline> <indent> pts = self . bodypart_types ( method ) <newline> root = self . document ( pts [ 0 ] ) <newline> <dedent> else : <newline> <indent> root = [ ] <newline> <dedent> n = 0 <newline> for pd in self . param_defs ( method ) : <newline> <indent> if n < len ( args ) : <newline> <indent> value = args [ n ] <newline> <dedent> else : <newline> <indent> value = kwargs . get ( pd [ 0 ] ) <newline> <dedent> n += 1 <newline> p = self . mkparam ( method , pd , value ) <newline> if p is None : <newline> <indent> continue <newline> <dedent> if not wrapped : <newline> <indent> ns = pd [ 1 ] . namespace ( 'ns0' ) <newline> p . setPrefix ( ns [ 0 ] , ns [ 1 ] ) <newline> <dedent> root . append ( p ) <newline> <dedent> return root <newline> <dedent> def replycontent ( self , method , body ) : <newline> <indent> wrapped = method . soap . output . body . wrapped <newline> if wrapped : <newline> <indent> return body [ 0 ] . children <newline> <dedent> else : <newline> <indent> return body . children <newline> <dedent> <dedent> def document ( self , wrapper ) : <newline> <indent>  """ <strnewline> ▁ Get ▁ the ▁ document ▁ root. ▁ For ▁ I{document/literal}, ▁ this ▁ is ▁ the <strnewline> ▁ name ▁ of ▁ the ▁ wrapper ▁ element ▁ qualifed ▁ by ▁ the ▁ schema ▁ tns. <strnewline> ▁ @param ▁ wrapper: ▁ The ▁ method ▁ name. <strnewline> ▁ @type ▁ wrapper: ▁ L{xsd.sxbase.SchemaObject} <strnewline> ▁ @return: ▁ A ▁ root ▁ element. <strnewline> ▁ @rtype: ▁ L{Element} <strnewline> ▁ """  <newline> tag = wrapper [ 1 ] . name <newline> ns = wrapper [ 1 ] . namespace ( 'ns0' ) <newline> d = Element ( tag , ns = ns ) <newline> return d <newline> <dedent> def mkparam ( self , method , pdef , object ) : <newline>  # ▁ Expand ▁ list ▁ parameters ▁ into ▁ individual ▁ parameters <encdom>  # ▁ each ▁ with ▁ the ▁ type ▁ information. ▁ This ▁ is ▁ because ▁ in ▁ document <encdom>  # ▁ arrays ▁ are ▁ simply ▁ unbounded ▁ elements. <encdom> <indent> if isinstance ( object , ( list , tuple ) ) : <newline> <indent> tags = [ ] <newline> for item in object : <newline> <indent> tags . append ( self . mkparam ( method , pdef , item ) ) <newline> <dedent> return tags <newline> <dedent> else : <newline> <indent> return Binding . mkparam ( self , method , pdef , object ) <newline> <dedent> <dedent> def param_defs ( self , method ) : <newline>  # ▁ Get ▁ parameter ▁ definitions ▁ for ▁ document ▁ literal. <encdom>  # ▁ The ▁ I{wrapped} ▁ vs ▁ I{bare} ▁ style ▁ is ▁ detected ▁ in ▁ 2 ▁ ways. <encdom>  # ▁ If ▁ there ▁ is ▁ 2+ ▁ parts ▁ in ▁ the ▁ message ▁ then ▁ it ▁ is ▁ I{bare}. <encdom>  # ▁ If ▁ there ▁ is ▁ only ▁ (1) ▁ part ▁ and ▁ that ▁ part ▁ resolves ▁ to ▁ a ▁ builtin ▁ then <encdom>  # ▁ it ▁ is ▁ I{bare}. ▁ Otherwise, ▁ it ▁ is ▁ I{wrapped}. <encdom> <indent> pts = self . bodypart_types ( method ) <newline> wrapped = method . soap . input . body . wrapped <newline> if not wrapped : <newline> <indent> return pts <newline> <dedent> result = [ ] <newline>  # ▁ wrapped <encdom> for p in pts : <newline> <indent> resolved = p [ 1 ] . resolve ( ) <newline> for child , ancestry in resolved : <newline> <indent> if child . isattr ( ) : <newline> <indent> continue <newline> <dedent> if self . bychoice ( ancestry ) : <newline> <indent> log . debug ( '%s \n contained ▁ by ▁ <choice/>, ▁ excluded ▁ as ▁ param ▁ for ▁ %s()' , child , method . name ) <newline> continue <newline> <dedent> result . append ( ( child . name , child ) ) <newline> <dedent> <dedent> return result <newline> <dedent> def returned_types ( self , method ) : <newline> <indent> result = [ ] <newline> wrapped = method . soap . output . body . wrapped <newline> rts = self . bodypart_types ( method , input = False ) <newline> if wrapped : <newline> <indent> for pt in rts : <newline> <indent> resolved = pt . resolve ( nobuiltin = True ) <newline> for child , ancestry in resolved : <newline> <indent> result . append ( child ) <newline> <dedent> break <newline> <dedent> <dedent> else : <newline> <indent> result += rts <newline> <dedent> return result <newline> <dedent> def bychoice ( self , ancestry ) : <newline> <indent>  """ <strnewline> ▁ The ▁ ancestry ▁ contains ▁ a ▁ <choice/> <strnewline> ▁ @param ▁ ancestry: ▁ A ▁ list ▁ of ▁ ancestors. <strnewline> ▁ @type ▁ ancestry: ▁ list <strnewline> ▁ @return: ▁ True ▁ if ▁ contains ▁ <choice/> <strnewline> ▁ @rtype: ▁ boolean <strnewline> ▁ """  <newline> for x in ancestry : <newline> <indent> if x . choice ( ) : <newline> <indent> return True <newline> <dedent> <dedent> return False <newline> <dedent> <dedent>
 # ▁ Copyright ▁ 2013 ▁ OpenStack ▁ Foundation <encdom>  # ▁ All ▁ Rights ▁ Reserved. <encdom>  # ▁ Licensed ▁ under ▁ the ▁ Apache ▁ License, ▁ Version ▁ 2.0 ▁ (the ▁"License"); ▁ you ▁ may <encdom>  # ▁ not ▁ use ▁ this ▁ file ▁ except ▁ in ▁ compliance ▁ with ▁ the ▁ License. ▁ You ▁ may ▁ obtain <encdom>  # ▁ a ▁ copy ▁ of ▁ the ▁ License ▁ at <encdom>  # ▁ http://www.apache.org/licenses/LICENSE-2.0 <encdom>  # ▁ Unless ▁ required ▁ by ▁ applicable ▁ law ▁ or ▁ agreed ▁ to ▁ in ▁ writing, ▁ software <encdom>  # ▁ distributed ▁ under ▁ the ▁ License ▁ is ▁ distributed ▁ on ▁ an ▁"AS ▁ IS" ▁ BASIS, ▁ WITHOUT <encdom>  # ▁ WARRANTIES ▁ OR ▁ CONDITIONS ▁ OF ▁ ANY ▁ KIND, ▁ either ▁ express ▁ or ▁ implied. ▁ See ▁ the <encdom>  # ▁ License ▁ for ▁ the ▁ specific ▁ language ▁ governing ▁ permissions ▁ and ▁ limitations <encdom>  # ▁ under ▁ the ▁ License. <encdom> from mox3 import mox <newline> import six <newline> from nova import context <newline> from nova import test <newline> from nova . tests . unit . virt . xenapi import stubs <newline> from nova . virt . xenapi import driver as xenapi_conn <newline> from nova . virt . xenapi import fake <newline> from nova . virt . xenapi . image import bittorrent <newline> from nova . virt . xenapi import vm_utils <newline> class TestBittorrentStore ( stubs . XenAPITestBaseNoDB ) : <newline> <indent> def setUp ( self ) : <newline> <indent> super ( TestBittorrentStore , self ) . setUp ( ) <newline> self . store = bittorrent . BittorrentStore ( ) <newline> self . mox = mox . Mox ( ) <newline> self . flags ( torrent_base_url = 'http://foo' , connection_url = 'test_url' , connection_password = 'test_pass' , group = 'xenserver' ) <newline> self . context = context . RequestContext ( 'user' , 'project' , auth_token = 'foobar' ) <newline> fake . reset ( ) <newline> stubs . stubout_session ( self . stubs , fake . SessionBase ) <newline> driver = xenapi_conn . XenAPIDriver ( False ) <newline> self . session = driver . _session <newline> self . stubs . Set ( vm_utils , 'get_sr_path' , lambda * a , ** kw : '/fake/sr/path' ) <newline> <dedent> def test_download_image ( self ) : <newline> <indent> instance = { 'uuid' : '00000000-0000-0000-0000-000000007357' } <newline> params = { 'image_id' : 'fake_image_uuid' , 'sr_path' : '/fake/sr/path' , 'torrent_download_stall_cutoff' : 600 , 'torrent_listen_port_end' : 6891 , 'torrent_listen_port_start' : 6881 , 'torrent_max_last_accessed' : 86400 , 'torrent_max_seeder_processes_per_host' : 1 , 'torrent_seed_chance' : 1.0 , 'torrent_seed_duration' : 3600 , 'torrent_url' : 'http://foo/fake_image_uuid.torrent' , 'uuid_stack' : [ 'uuid1' ] } <newline> self . stubs . Set ( vm_utils , '_make_uuid_stack' , lambda * a , ** kw : [ 'uuid1' ] ) <newline> self . mox . StubOutWithMock ( self . session , 'call_plugin_serialized' ) <newline> self . session . call_plugin_serialized ( 'bittorrent' , 'download_vhd' , ** params ) <newline> self . mox . ReplayAll ( ) <newline> self . store . download_image ( self . context , self . session , instance , 'fake_image_uuid' ) <newline> self . mox . VerifyAll ( ) <newline> <dedent> def test_upload_image ( self ) : <newline> <indent> self . assertRaises ( NotImplementedError , self . store . upload_image , self . context , self . session , mox . IgnoreArg , 'fake_image_uuid' , [ 'fake_vdi_uuid' ] ) <newline> <dedent> <dedent> class LookupTorrentURLTestCase ( test . NoDBTestCase ) : <newline> <indent> def setUp ( self ) : <newline> <indent> super ( LookupTorrentURLTestCase , self ) . setUp ( ) <newline> self . store = bittorrent . BittorrentStore ( ) <newline> self . image_id = 'fakeimageid' <newline> <dedent> def test_default_fetch_url_no_base_url_set ( self ) : <newline> <indent> self . flags ( torrent_base_url = None , group = 'xenserver' ) <newline> exc = self . assertRaises ( RuntimeError , self . store . _lookup_torrent_url_fn ) <newline> self . assertEqual ( 'Cannot ▁ create ▁ default ▁ bittorrent ▁ URL ▁ without' ' ▁ xenserver.torrent_base_url ▁ configuration ▁ option' ' ▁ set.' , six . text_type ( exc ) ) <newline> <dedent> def test_default_fetch_url_base_url_is_set ( self ) : <newline> <indent> self . flags ( torrent_base_url = 'http://foo' , group = 'xenserver' ) <newline> lookup_fn = self . store . _lookup_torrent_url_fn ( ) <newline> self . assertEqual ( 'http://foo/fakeimageid.torrent' , lookup_fn ( self . image_id ) ) <newline> <dedent> def test_invalid_base_url_warning_logged ( self ) : <newline> <indent> self . flags ( torrent_base_url = 'www.foo.com' , group = 'xenserver' ) <newline>  # ▁ Make ▁ sure ▁ a ▁ warning ▁ is ▁ logged ▁ when ▁ an ▁ invalid ▁ base ▁ URL ▁ is ▁ set, <encdom>  # ▁ where ▁ invalid ▁ means ▁ it ▁ does ▁ not ▁ contain ▁ any ▁ slash ▁ characters <encdom> warnings = [ ] <newline> def fake_warn ( msg ) : <newline> <indent> warnings . append ( msg ) <newline> <dedent> self . stubs . Set ( bittorrent . LOG , 'warn' , fake_warn ) <newline> lookup_fn = self . store . _lookup_torrent_url_fn ( ) <newline> self . assertEqual ( 'fakeimageid.torrent' , lookup_fn ( self . image_id ) ) <newline> self . assertTrue ( any ( 'does ▁ not ▁ contain ▁ a ▁ slash ▁ character' in msg for msg in warnings ) , '_lookup_torrent_url_fn() ▁ did ▁ not ▁ log ▁ a ▁ warning ▁ ' 'message ▁ when ▁ the ▁ torrent_base_url ▁ did ▁ not ▁ contain ▁ a ▁ ' 'slash ▁ character.' ) <newline> <dedent> <dedent>
 # ▁ Copyright ▁ 2016 ▁ The ▁ TensorFlow ▁ Authors. ▁ All ▁ Rights ▁ Reserved. <encdom>  # ▁ Licensed ▁ under ▁ the ▁ Apache ▁ License, ▁ Version ▁ 2.0 ▁ (the ▁"License"); <encdom>  # ▁ you ▁ may ▁ not ▁ use ▁ this ▁ file ▁ except ▁ in ▁ compliance ▁ with ▁ the ▁ License. <encdom>  # ▁ You ▁ may ▁ obtain ▁ a ▁ copy ▁ of ▁ the ▁ License ▁ at <encdom>  # ▁ http://www.apache.org/licenses/LICENSE-2.0 <encdom>  # ▁ Unless ▁ required ▁ by ▁ applicable ▁ law ▁ or ▁ agreed ▁ to ▁ in ▁ writing, ▁ software <encdom>  # ▁ distributed ▁ under ▁ the ▁ License ▁ is ▁ distributed ▁ on ▁ an ▁"AS ▁ IS" ▁ BASIS, <encdom>  # ▁ WITHOUT ▁ WARRANTIES ▁ OR ▁ CONDITIONS ▁ OF ▁ ANY ▁ KIND, ▁ either ▁ express ▁ or ▁ implied. <encdom>  # ▁ See ▁ the ▁ License ▁ for ▁ the ▁ specific ▁ language ▁ governing ▁ permissions ▁ and <encdom>  # ▁ limitations ▁ under ▁ the ▁ License. <encdom>  """ @experimental ▁ tests. """  <newline>  # ▁ pylint: ▁ disable=unused-import <encdom> from __future__ import absolute_import <newline> from __future__ import division <newline> from __future__ import print_function <newline> from tensorflow . contrib . framework . python . framework import experimental <newline> from tensorflow . python . platform import test <newline> from tensorflow . python . platform import tf_logging as logging <newline> class ExperimentalTest ( test . TestCase ) : <newline> <indent> @ test . mock . patch . object ( logging , "warning" , autospec = True ) <newline> def test_warning ( self , mock_warning ) : <newline> <indent> @ experimental <newline> def _fn ( arg0 , arg1 ) : <newline> <indent>  """ fn ▁ doc. <strnewline> <strnewline> ▁ Args: <strnewline> ▁ arg0: ▁ Arg ▁ 0. <strnewline> ▁ arg1: ▁ Arg ▁ 1. <strnewline> <strnewline> ▁ Returns: <strnewline> ▁ Sum ▁ of ▁ args. <strnewline> ▁ """  <newline> return arg0 + arg1 <newline>  # ▁ Assert ▁ function ▁ docs ▁ are ▁ properly ▁ updated. <encdom> <dedent> self . assertEqual ( "_fn" , _fn . __name__ ) <newline> self . assertEqual ( "fn ▁ doc. ▁ (experimental)" " \n Warning: ▁ THIS ▁ FUNCTION ▁ IS ▁ EXPERIMENTAL. ▁ It ▁ may ▁ change ▁ " "or ▁ be ▁ removed ▁ at ▁ any ▁ time, ▁ and ▁ without ▁ warning." " \n Args:" " \n ▁ arg0: ▁ Arg ▁ 0." " \n ▁ arg1: ▁ Arg ▁ 1." " \n Returns:" " \n ▁ ▁ Sum ▁ of ▁ args." , _fn . __doc__ )  # ▁ Assert ▁ calling ▁ new ▁ fn ▁ issues ▁ log ▁ warning. <encdom> self . assertEqual ( 3 , _fn ( 1 , 2 ) ) <newline> self . assertEqual ( 1 , mock_warning . call_count ) <newline> ( args , _ ) = mock_warning . call_args <newline> self . assertRegexpMatches ( args [ 0 ] , r"is ▁ experimental ▁ and ▁ may ▁ change" ) <newline> <dedent> <dedent> if __name__ == "__main__" : <newline> <indent> test . main ( ) <newline> <dedent>
from django . db import models <newline> class CustomField ( models . Field ) : <newline> <indent> description = "A ▁ custom ▁ field ▁ type" <newline> <dedent> class DescriptionLackingField ( models . Field ) : <newline> <indent> pass <newline> <dedent>
import numpy as np <newline> coef_50_2_0 = np . array ( [ - 0.6748149 , 0.5219471 ] ) <newline> coef_50_2_1 = np . array ( [ - 0.3464841 , 0.211115 ] ) <newline> coef_100_5_0 = np . array ( [ - 0.4839566 , - 0.3130558 , - 0.1239565 , 0.3466049 , 0.5827503 ] ) <newline> coef_100_5_1 = np . array ( [ - 0.1314948 , 0 , 0 , 0.0324285 , 0.2364489 ] ) <newline>
 """ <strnewline> ===== <strnewline> phantom_import <strnewline> ===== <strnewline> <strnewline> Sphinx ▁ extension ▁ to ▁ make ▁ directives ▁ from ▁ ``sphinx.ext.autodoc`` ▁ and ▁ similar <strnewline> extensions ▁ to ▁ use ▁ docstrings ▁ loaded ▁ from ▁ an ▁ XML ▁ file. <strnewline> <strnewline> This ▁ extension ▁ loads ▁ an ▁ XML ▁ file ▁ in ▁ the ▁ Pydocweb ▁ format ▁ [1] ▁ and <strnewline> creates ▁ a ▁ dummy ▁ module ▁ that ▁ contains ▁ the ▁ specified ▁ docstrings. ▁ This <strnewline> can ▁ be ▁ used ▁ to ▁ get ▁ the ▁ current ▁ docstrings ▁ from ▁ a ▁ Pydocweb ▁ instance <strnewline> without ▁ needing ▁ to ▁ rebuild ▁ the ▁ documented ▁ module. <strnewline> <strnewline> .. ▁ [1] ▁ http://code.google.com/p/pydocweb <strnewline> <strnewline> """  <newline> import imp , sys , compiler , types , os , inspect , re <newline> def setup ( app ) : <newline> <indent> app . connect ( 'builder-inited' , initialize ) <newline> app . add_config_value ( 'phantom_import_file' , None , True ) <newline> <dedent> def initialize ( app ) : <newline> <indent> fn = app . config . phantom_import_file <newline> if ( fn and os . path . isfile ( fn ) ) : <newline> <indent> print "[numpydoc] ▁ Phantom ▁ importing ▁ modules ▁ from" , fn , "..." <newline> import_phantom_module ( fn ) <newline>  # ▁ Creating ▁'phantom' ▁ modules ▁ from ▁ an ▁ XML ▁ description <encdom> <dedent> <dedent> def import_phantom_module ( xml_file ) : <newline> <indent>  """ <strnewline> ▁ Insert ▁ a ▁ fake ▁ Python ▁ module ▁ to ▁ sys.modules, ▁ based ▁ on ▁ a ▁ XML ▁ file. <strnewline> <strnewline> ▁ The ▁ XML ▁ file ▁ is ▁ expected ▁ to ▁ conform ▁ to ▁ Pydocweb ▁ DTD. ▁ The ▁ fake <strnewline> ▁ module ▁ will ▁ contain ▁ dummy ▁ objects, ▁ which ▁ guarantee ▁ the ▁ following: <strnewline> <strnewline> ▁ - ▁ Docstrings ▁ are ▁ correct. <strnewline> ▁ - ▁ Class ▁ inheritance ▁ relationships ▁ are ▁ correct ▁ (if ▁ present ▁ in ▁ XML). <strnewline> ▁ - ▁ Function ▁ argspec ▁ is ▁ *NOT* ▁ correct ▁ (even ▁ if ▁ present ▁ in ▁ XML). <strnewline> ▁ Instead, ▁ the ▁ function ▁ signature ▁ is ▁ prepended ▁ to ▁ the ▁ function ▁ docstring. <strnewline> ▁ - ▁ Class ▁ attributes ▁ are ▁ *NOT* ▁ correct; ▁ instead, ▁ they ▁ are ▁ dummy ▁ objects. <strnewline> <strnewline> ▁ Parameters <strnewline> ▁ ----- <strnewline> ▁ xml_file ▁ : ▁ str <strnewline> ▁ Name ▁ of ▁ an ▁ XML ▁ file ▁ to ▁ read <strnewline> ▁ <strnewline> ▁ """  <newline> import lxml . etree as etree <newline> object_cache = { } <newline> tree = etree . parse ( xml_file ) <newline> root = tree . getroot ( ) <newline>  # ▁ Sort ▁ items ▁ so ▁ that <encdom>  # ▁ - ▁ Base ▁ classes ▁ come ▁ before ▁ classes ▁ inherited ▁ from ▁ them <encdom>  # ▁ - ▁ Modules ▁ come ▁ before ▁ their ▁ contents <encdom> all_nodes = dict ( [ ( n . attrib [ 'id' ] , n ) for n in root ] ) <newline> def _get_bases ( node , recurse = False ) : <newline> <indent> bases = [ x . attrib [ 'ref' ] for x in node . findall ( 'base' ) ] <newline> if recurse : <newline> <indent> j = 0 <newline> while True : <newline> <indent> try : <newline> <indent> b = bases [ j ] <newline> <dedent> except IndexError : break <newline> if b in all_nodes : <newline> <indent> bases . extend ( _get_bases ( all_nodes [ b ] ) ) <newline> <dedent> j += 1 <newline> <dedent> <dedent> return bases <newline> <dedent> type_index = [ 'module' , 'class' , 'callable' , 'object' ] <newline> def base_cmp ( a , b ) : <newline> <indent> x = cmp ( type_index . index ( a . tag ) , type_index . index ( b . tag ) ) <newline> if x != 0 : return x <newline> if a . tag == 'class' and b . tag == 'class' : <newline> <indent> a_bases = _get_bases ( a , recurse = True ) <newline> b_bases = _get_bases ( b , recurse = True ) <newline> x = cmp ( len ( a_bases ) , len ( b_bases ) ) <newline> if x != 0 : return x <newline> if a . attrib [ 'id' ] in b_bases : return - 1 <newline> if b . attrib [ 'id' ] in a_bases : return 1 <newline> <dedent> return cmp ( a . attrib [ 'id' ] . count ( '.' ) , b . attrib [ 'id' ] . count ( '.' ) ) <newline> <dedent> nodes = root . getchildren ( ) <newline> nodes . sort ( base_cmp ) <newline>  # ▁ Create ▁ phantom ▁ items <encdom> for node in nodes : <newline> <indent> name = node . attrib [ 'id' ] <newline> doc = ( node . text or '' ) . decode ( 'string-escape' ) + " \n " <newline> if doc == " \n " : doc = "" <newline>  # ▁ create ▁ parent, ▁ if ▁ missing <encdom> parent = name <newline> while True : <newline> <indent> parent = '.' . join ( parent . split ( '.' ) [ : - 1 ] ) <newline> if not parent : break <newline> if parent in object_cache : break <newline> obj = imp . new_module ( parent ) <newline> object_cache [ parent ] = obj <newline> sys . modules [ parent ] = obj <newline>  # ▁ create ▁ object <encdom> <dedent> if node . tag == 'module' : <newline> <indent> obj = imp . new_module ( name ) <newline> obj . __doc__ = doc <newline> sys . modules [ name ] = obj <newline> <dedent> elif node . tag == 'class' : <newline> <indent> bases = [ object_cache [ b ] for b in _get_bases ( node ) if b in object_cache ] <newline> bases . append ( object ) <newline> init = lambda self : None <newline> init . __doc__ = doc <newline> obj = type ( name , tuple ( bases ) , { '__doc__' : doc , '__init__' : init } ) <newline> obj . __name__ = name . split ( '.' ) [ - 1 ] <newline> <dedent> elif node . tag == 'callable' : <newline> <indent> funcname = node . attrib [ 'id' ] . split ( '.' ) [ - 1 ] <newline> argspec = node . attrib . get ( 'argspec' ) <newline> if argspec : <newline> <indent> argspec = re . sub ( '^[^(]*' , '' , argspec ) <newline> doc = "%s%s \n \n %s" % ( funcname , argspec , doc ) <newline> <dedent> obj = lambda : 0 <newline> obj . __argspec_is_invalid_ = True <newline> obj . func_name = funcname <newline> obj . __name__ = name <newline> obj . __doc__ = doc <newline> if inspect . isclass ( object_cache [ parent ] ) : <newline> <indent> obj . __objclass__ = object_cache [ parent ] <newline> <dedent> <dedent> else : <newline> <indent> class Dummy ( object ) : pass <newline> obj = Dummy ( ) <newline> obj . __name__ = name <newline> obj . __doc__ = doc <newline> if inspect . isclass ( object_cache [ parent ] ) : <newline> <indent> obj . __get__ = lambda : None <newline> <dedent> <dedent> object_cache [ name ] = obj <newline> if parent : <newline> <indent> if inspect . ismodule ( object_cache [ parent ] ) : <newline> <indent> obj . __module__ = parent <newline> setattr ( object_cache [ parent ] , name . split ( '.' ) [ - 1 ] , obj ) <newline>  # ▁ Populate ▁ items <encdom> <dedent> <dedent> <dedent> for node in root : <newline> <indent> obj = object_cache . get ( node . attrib [ 'id' ] ) <newline> if obj is None : continue <newline> for ref in node . findall ( 'ref' ) : <newline> <indent> if node . tag == 'class' : <newline> <indent> if ref . attrib [ 'ref' ] . startswith ( node . attrib [ 'id' ] + '.' ) : <newline> <indent> setattr ( obj , ref . attrib [ 'name' ] , object_cache . get ( ref . attrib [ 'ref' ] ) ) <newline> <dedent> <dedent> else : <newline> <indent> setattr ( obj , ref . attrib [ 'name' ] , object_cache . get ( ref . attrib [ 'ref' ] ) ) <newline> <dedent> <dedent> <dedent> <dedent>
 # ▁ -*- ▁ coding: ▁ utf-8 ▁ -*- <encdom>  """ <strnewline> Routines ▁ for ▁ quality ▁ control ▁ of ▁ GeoDanmark ▁ map ▁ data <strnewline> Copyright ▁ (C) ▁ 2016 <strnewline> Developed ▁ by ▁ Septima.dk ▁ for ▁ the ▁ Danish ▁ Agency ▁ for ▁ Data ▁ Supply ▁ and ▁ Efficiency <strnewline> <strnewline> This ▁ program ▁ is ▁ free ▁ software: ▁ you ▁ can ▁ redistribute ▁ it ▁ and/or ▁ modify <strnewline> it ▁ under ▁ the ▁ terms ▁ of ▁ the ▁ GNU ▁ General ▁ Public ▁ License ▁ as ▁ published ▁ by <strnewline> the ▁ Free ▁ Software ▁ Foundation, ▁ either ▁ version ▁ 3 ▁ of ▁ the ▁ License, ▁ or <strnewline> (at ▁ your ▁ option) ▁ any ▁ later ▁ version. <strnewline> <strnewline> This ▁ program ▁ is ▁ distributed ▁ in ▁ the ▁ hope ▁ that ▁ it ▁ will ▁ be ▁ useful, <strnewline> but ▁ WITHOUT ▁ ANY ▁ WARRANTY; ▁ without ▁ even ▁ the ▁ implied ▁ warranty ▁ of <strnewline> MERCHANTABILITY ▁ or ▁ FITNESS ▁ FOR ▁ A ▁ PARTICULAR ▁ PURPOSE. ▁ See ▁ the <strnewline> GNU ▁ General ▁ Public ▁ License ▁ for ▁ more ▁ details. <strnewline> <strnewline> You ▁ should ▁ have ▁ received ▁ a ▁ copy ▁ of ▁ the ▁ GNU ▁ General ▁ Public ▁ License <strnewline> along ▁ with ▁ this ▁ program. ▁ If ▁ not, ▁ see ▁ <http://www.gnu.org/licenses/>. <strnewline> """  <newline> from . singlelayerrule import SingleLayerRule <newline> from ... . geomutils . errorgeometry import createlinemarker <newline> class UniqueAttributeValue ( SingleLayerRule ) : <newline> <indent>  """ Check ▁ that ▁ all ▁ values ▁ for ▁ a ▁ given ▁ attribute ▁ are ▁ unique ▁ within ▁ the ▁ features. <strnewline> <strnewline> ▁ Parameters <strnewline> ▁ ----- <strnewline> ▁ name ▁ : ▁ str <strnewline> ▁ Name ▁ if ▁ this ▁ rule ▁ instance <strnewline> ▁ feature_type ▁ : ▁ fot.FeatureType <strnewline> ▁ Feature ▁ type ▁ to ▁ apply ▁ check ▁ to <strnewline> ▁ attributename ▁ : ▁ str <strnewline> ▁ Name ▁ of ▁ attribute ▁ which ▁ must ▁ be ▁ unique <strnewline> ▁ filter ▁ : ▁ str <strnewline> ▁ QGIS ▁ Filter ▁ Expression ▁ which ▁ is ▁ applied ▁ to ▁ features ▁ before ▁ evaluating ▁ this ▁ rule. <strnewline> <strnewline> ▁ """  <newline> def __init__ ( self , name , feature_type , attributename , filter = None ) : <newline> <indent> super ( UniqueAttributeValue , self ) . __init__ ( name , feature_type ) <newline> self . filter = filter <newline> self . attributesneeded = attributename <newline> self . attributename = attributename <newline> self . attributevalues = { } <newline> <dedent> def checkmany ( self , features , reporter , progressreporter ) : <newline> <indent> progressreporter . begintask ( self . name , len ( features ) ) <newline> for feature in features : <newline> <indent> try : <newline> <indent> value = feature [ self . attributename ] <newline> if value in self . attributevalues : <newline>  # ▁ Wooops ▁ not ▁ unique! <encdom> <indent> errorgeom = createlinemarker ( feature , self . attributevalues [ value ] ) <newline> reporter . error ( self . name , self . featuretype , self . attributename + '="' + unicode ( value ) + '" ▁ not ▁ unique' , errorgeom ) <newline> <dedent> else : <newline> <indent> self . attributevalues [ value ] = feature <newline> <dedent> <dedent> except Exception as e : <newline> <indent> reporter . error ( self . name , self . featuretype , "Error ▁ processing ▁ attribute: ▁ {0} ▁ Message: ▁ {1}" . format ( self . attributename , str ( e ) ) , feature ) <newline> <dedent> progressreporter . completed_one ( ) <newline> <dedent> <dedent> <dedent>
import decimal <newline> from datetime import datetime <newline> from django . conf import settings <newline> from django . conf . urls import url , include <newline> from pinax . stripe . forms import PlanForm <newline> from . base import ViewConfig <newline> invoices = [ dict ( date = datetime ( 2017 , 10 , 1 ) , subscription = dict ( plan = dict ( name = "Pro" ) ) , period_start = datetime ( 2017 , 10 , 1 ) , period_end = datetime ( 2017 , 10 , 31 ) , total = decimal . Decimal ( "9.99" ) , paid = False ) , dict ( date = datetime ( 2017 , 9 , 1 ) , subscription = dict ( plan = dict ( name = "Pro" ) ) , period_start = datetime ( 2017 , 9 , 1 ) , period_end = datetime ( 2017 , 9 , 30 ) , total = decimal . Decimal ( "9.99" ) , paid = True ) , dict ( date = datetime ( 2017 , 8 , 1 ) , subscription = dict ( plan = dict ( name = "Beginner" ) ) , period_start = datetime ( 2017 , 8 , 1 ) , period_end = datetime ( 2017 , 8 , 31 ) , total = decimal . Decimal ( "5.99" ) , paid = True ) , dict ( date = datetime ( 2017 , 7 , 1 ) , subscription = dict ( plan = dict ( name = "Beginner" ) ) , period_start = datetime ( 2017 , 7 , 1 ) , period_end = datetime ( 2017 , 7 , 30 ) , total = decimal . Decimal ( "5.99" ) , paid = True ) , ] <newline> card = dict ( pk = 1 , brand = "Visa" , last4 = "4242" , exp_month = "10" , exp_year = "2030" , created_at = datetime ( 2016 , 4 , 5 ) ) <newline> methods = [ card ] <newline> subscription = dict ( pk = 1 , current_period_start = datetime ( 2017 , 10 , 1 ) , current_period_end = datetime ( 2017 , 10 , 31 ) , plan = dict ( name = "Pro" ) , start = datetime ( 2017 , 10 , 1 ) , status = "active" , invoice_set = dict ( all = invoices ) ) <newline> subscriptions = [ subscription ] <newline> patch = "http://pinaxproject.com/pinax-design/patches/pinax-stripe.svg" <newline> label = "stripe" <newline> title = "Pinax ▁ Stripe" <newline> views = [ ViewConfig ( pattern = r"^invoices-empty/$" , template = "pinax/stripe/invoice_list.html" , name = "invoice_list_empty" , pattern_kwargs = { } , object_list = [ ] ) , ViewConfig ( pattern = r"^invoices/$" , template = "pinax/stripe/invoice_list.html" , name = "pinax_stripe_invoice_list" , pattern_kwargs = { } , object_list = invoices ) , ViewConfig ( pattern = r"^methods-empty/$" , template = "pinax/stripe/paymentmethod_list.html" , name = "method_list_empty" , pattern_kwargs = { } , object_list = [ ] ) , ViewConfig ( pattern = r"^methods/$" , template = "pinax/stripe/paymentmethod_list.html" , name = "pinax_stripe_payment_method_list" , pattern_kwargs = { } , object_list = methods ) , ViewConfig ( pattern = r"^methods/create/$" , template = "pinax/stripe/paymentmethod_create.html" , name = "pinax_stripe_payment_method_create" , pattern_kwargs = { } , PINAX_STRIPE_PUBLIC_KEY = settings . PINAX_STRIPE_PUBLIC_KEY ) , ViewConfig ( pattern = r"^methods/update/(?P<pk>\d+)/$" , template = "pinax/stripe/paymentmethod_update.html" , name = "pinax_stripe_payment_method_update" , pattern_kwargs = { "pk" : 1 } , object = card ) , ViewConfig ( pattern = r"^methods/delete/(?P<pk>\d+)/" , template = "pinax/stripe/paymentmethod_delete.html" , name = "pinax_stripe_payment_method_delete" , pattern_kwargs = { "pk" : 1 } , object = card ) , ViewConfig ( pattern = r"^subscriptions-empty/$" , template = "pinax/stripe/subscription_list.html" , name = "subscription_list_empty" , pattern_kwargs = { } , object_list = [ ] ) , ViewConfig ( pattern = r"^subscriptions/$" , template = "pinax/stripe/subscription_list.html" , name = "pinax_stripe_subscription_list" , pattern_kwargs = { } , object_list = subscriptions ) , ViewConfig ( pattern = r"^subscriptions/create/$" , template = "pinax/stripe/subscription_create.html" , name = "pinax_stripe_subscription_create" , pattern_kwargs = { } , form = PlanForm ( ) , request = dict ( user = dict ( customer = dict ( default_source = "foo" ) ) ) ) , ViewConfig ( pattern = r"^subscriptions/update/(?P<pk>\d+)/$" , template = "pinax/stripe/subscription_update.html" , name = "pinax_stripe_subscription_update" , pattern_kwargs = { "pk" : 1 } , object = subscription , form = PlanForm ( ) , PINAX_STRIPE_PUBLIC_KEY = settings . PINAX_STRIPE_PUBLIC_KEY ) , ViewConfig ( pattern = r"^subscriptions/delete/(?P<pk>\d+)/" , template = "pinax/stripe/subscription_delete.html" , name = "pinax_stripe_subscription_delete" , pattern_kwargs = { "pk" : 1 } , object = subscription ) , ] <newline> urlpatterns = [ view . url ( ) for view in views ] <newline> url = url ( r"payments/" , include ( "pinax_theme_tester.configs.stripe" ) ) <newline>
from myhdl import * <newline> def bin2gray ( B , G , width ) : <newline> <indent>  """ ▁ Gray ▁ encoder. <strnewline> <strnewline> ▁ B ▁ -- ▁ input ▁ intbv ▁ signal, ▁ binary ▁ encoded <strnewline> ▁ G ▁ -- ▁ output ▁ intbv ▁ signal, ▁ gray ▁ encoded <strnewline> ▁ width ▁ -- ▁ bit ▁ width <strnewline> ▁ """  <newline> @ always_comb <newline> def logic ( ) : <newline> <indent> for i in range ( width ) : <newline> <indent> G . next [ i ] = B [ i + 1 ] ^ B [ i ] <newline> <dedent> <dedent> return logic <newline> <dedent>
import tornado . testing <newline> import tornado . web <newline> import tornado . escape <newline> from tornado . options import options <newline> from urls import url_patterns <newline> from urllib import parse <newline> class TestBase ( tornado . testing . AsyncHTTPTestCase ) : <newline> <indent> def setUp ( self ) : <newline> <indent> super ( TestBase , self ) . setUp ( ) <newline> <dedent> def get_app ( self ) : <newline> <indent> self . app = tornado . web . Application ( handlers = url_patterns , xsrf_cookies = False ) <newline> <dedent> def get_http_port ( self ) : <newline> <indent> return options . port <newline> <dedent> def user_login ( self ) : <newline> <indent> login_url = '/auth/login/' <newline> post_args = { 'email' : 'test@test.co.jp' , 'password' : 'test' } <newline> response = self . fetch ( login_url , method = 'POST' , body = parse . urlencode ( post_args ) , follow_redirects = False ) <newline> return response <newline> <dedent> def user_logout ( self ) : <newline> <indent> test_url = '/auth/logout/' <newline> response = self . fetch ( test_url , method = 'GET' , follow_redirects = False ) <newline> return response <newline> <dedent> <dedent>
 # # # # # ▁ BEGIN ▁ LICENSE ▁ BLOCK ▁ # # # # # <encdom>  # ▁ The ▁ Original ▁ Code ▁ is ▁ Mozilla ▁ Communicator ▁ client ▁ code. <encdom>  # ▁ The ▁ Initial ▁ Developer ▁ of ▁ the ▁ Original ▁ Code ▁ is <encdom>  # ▁ Netscape ▁ Communications ▁ Corporation. <encdom>  # ▁ Portions ▁ created ▁ by ▁ the ▁ Initial ▁ Developer ▁ are ▁ Copyright ▁ (C) ▁ 1998 <encdom>  # ▁ the ▁ Initial ▁ Developer. ▁ All ▁ Rights ▁ Reserved. <encdom>  # ▁ Contributor(s): <encdom>  # ▁ Mark ▁ Pilgrim ▁ - ▁ port ▁ to ▁ Python <encdom>  # ▁ This ▁ library ▁ is ▁ free ▁ software; ▁ you ▁ can ▁ redistribute ▁ it ▁ and/or <encdom>  # ▁ modify ▁ it ▁ under ▁ the ▁ terms ▁ of ▁ the ▁ GNU ▁ Lesser ▁ General ▁ Public <encdom>  # ▁ License ▁ as ▁ published ▁ by ▁ the ▁ Free ▁ Software ▁ Foundation; ▁ either <encdom>  # ▁ version ▁ 2.1 ▁ of ▁ the ▁ License, ▁ or ▁ (at ▁ your ▁ option) ▁ any ▁ later ▁ version. <encdom>  # ▁ This ▁ library ▁ is ▁ distributed ▁ in ▁ the ▁ hope ▁ that ▁ it ▁ will ▁ be ▁ useful, <encdom>  # ▁ but ▁ WITHOUT ▁ ANY ▁ WARRANTY; ▁ without ▁ even ▁ the ▁ implied ▁ warranty ▁ of <encdom>  # ▁ MERCHANTABILITY ▁ or ▁ FITNESS ▁ FOR ▁ A ▁ PARTICULAR ▁ PURPOSE. ▁ See ▁ the ▁ GNU <encdom>  # ▁ Lesser ▁ General ▁ Public ▁ License ▁ for ▁ more ▁ details. <encdom>  # ▁ You ▁ should ▁ have ▁ received ▁ a ▁ copy ▁ of ▁ the ▁ GNU ▁ Lesser ▁ General ▁ Public <encdom>  # ▁ License ▁ along ▁ with ▁ this ▁ library; ▁ if ▁ not, ▁ write ▁ to ▁ the ▁ Free ▁ Software <encdom>  # ▁ Foundation, ▁ Inc., ▁ 51 ▁ Franklin ▁ St, ▁ Fifth ▁ Floor, ▁ Boston, ▁ MA <encdom>  # ▁ 02110-1301 ▁ USA <encdom>  # # # # # ▁ END ▁ LICENSE ▁ BLOCK ▁ # # # # # <encdom>  # ▁ 255: ▁ Control ▁ characters ▁ that ▁ usually ▁ does ▁ not ▁ exist ▁ in ▁ any ▁ text <encdom>  # ▁ 254: ▁ Carriage/Return <encdom>  # ▁ 253: ▁ symbol ▁ (punctuation) ▁ that ▁ does ▁ not ▁ belong ▁ to ▁ word <encdom>  # ▁ 252: ▁ 0 ▁ - ▁ 9 <encdom>  # ▁ Character ▁ Mapping ▁ Table: <encdom> Latin7_CharToOrderMap = ( 255 , 255 , 255 , 255 , 255 , 255 , 255 , 255 , 255 , 255 , 254 , 255 , 255 , 254 , 255 , 255 ,  # ▁ 00 <encdom> 255 , 255 , 255 , 255 , 255 , 255 , 255 , 255 , 255 , 255 , 255 , 255 , 255 , 255 , 255 , 255 ,  # ▁ 10 <encdom> 253 , 253 , 253 , 253 , 253 , 253 , 253 , 253 , 253 , 253 , 253 , 253 , 253 , 253 , 253 , 253 ,  # ▁ 20 <encdom> 252 , 252 , 252 , 252 , 252 , 252 , 252 , 252 , 252 , 252 , 253 , 253 , 253 , 253 , 253 , 253 ,  # ▁ 30 <encdom> 253 , 82 , 100 , 104 , 94 , 98 , 101 , 116 , 102 , 111 , 187 , 117 , 92 , 88 , 113 , 85 ,  # ▁ 40 <encdom> 79 , 118 , 105 , 83 , 67 , 114 , 119 , 95 , 99 , 109 , 188 , 253 , 253 , 253 , 253 , 253 ,  # ▁ 50 <encdom> 253 , 72 , 70 , 80 , 81 , 60 , 96 , 93 , 89 , 68 , 120 , 97 , 77 , 86 , 69 , 55 ,  # ▁ 60 <encdom> 78 , 115 , 65 , 66 , 58 , 76 , 106 , 103 , 87 , 107 , 112 , 253 , 253 , 253 , 253 , 253 ,  # ▁ 70 <encdom> 255 , 255 , 255 , 255 , 255 , 255 , 255 , 255 , 255 , 255 , 255 , 255 , 255 , 255 , 255 , 255 ,  # ▁ 80 <encdom> 255 , 255 , 255 , 255 , 255 , 255 , 255 , 255 , 255 , 255 , 255 , 255 , 255 , 255 , 255 , 255 ,  # ▁ 90 <encdom> 253 , 233 , 90 , 253 , 253 , 253 , 253 , 253 , 253 , 253 , 253 , 253 , 253 , 74 , 253 , 253 ,  # ▁ a0 <encdom> 253 , 253 , 253 , 253 , 247 , 248 , 61 , 36 , 46 , 71 , 73 , 253 , 54 , 253 , 108 , 123 ,  # ▁ b0 <encdom> 110 , 31 , 51 , 43 , 41 , 34 , 91 , 40 , 52 , 47 , 44 , 53 , 38 , 49 , 59 , 39 ,  # ▁ c0 <encdom> 35 , 48 , 250 , 37 , 33 , 45 , 56 , 50 , 84 , 57 , 120 , 121 , 17 , 18 , 22 , 15 ,  # ▁ d0 <encdom> 124 , 1 , 29 , 20 , 21 , 3 , 32 , 13 , 25 , 5 , 11 , 16 , 10 , 6 , 30 , 4 ,  # ▁ e0 <encdom> 9 , 8 , 14 , 7 , 2 , 12 , 28 , 23 , 42 , 24 , 64 , 75 , 19 , 26 , 27 , 253 ,  # ▁ f0 <encdom> ) <newline> win1253_CharToOrderMap = ( 255 , 255 , 255 , 255 , 255 , 255 , 255 , 255 , 255 , 255 , 254 , 255 , 255 , 254 , 255 , 255 ,  # ▁ 00 <encdom> 255 , 255 , 255 , 255 , 255 , 255 , 255 , 255 , 255 , 255 , 255 , 255 , 255 , 255 , 255 , 255 ,  # ▁ 10 <encdom> 253 , 253 , 253 , 253 , 253 , 253 , 253 , 253 , 253 , 253 , 253 , 253 , 253 , 253 , 253 , 253 ,  # ▁ 20 <encdom> 252 , 252 , 252 , 252 , 252 , 252 , 252 , 252 , 252 , 252 , 253 , 253 , 253 , 253 , 253 , 253 ,  # ▁ 30 <encdom> 253 , 82 , 100 , 104 , 94 , 98 , 101 , 116 , 102 , 111 , 187 , 117 , 92 , 88 , 113 , 85 ,  # ▁ 40 <encdom> 79 , 118 , 105 , 83 , 67 , 114 , 119 , 95 , 99 , 109 , 188 , 253 , 253 , 253 , 253 , 253 ,  # ▁ 50 <encdom> 253 , 72 , 70 , 80 , 81 , 60 , 96 , 93 , 89 , 68 , 120 , 97 , 77 , 86 , 69 , 55 ,  # ▁ 60 <encdom> 78 , 115 , 65 , 66 , 58 , 76 , 106 , 103 , 87 , 107 , 112 , 253 , 253 , 253 , 253 , 253 ,  # ▁ 70 <encdom> 255 , 255 , 255 , 255 , 255 , 255 , 255 , 255 , 255 , 255 , 255 , 255 , 255 , 255 , 255 , 255 ,  # ▁ 80 <encdom> 255 , 255 , 255 , 255 , 255 , 255 , 255 , 255 , 255 , 255 , 255 , 255 , 255 , 255 , 255 , 255 ,  # ▁ 90 <encdom> 253 , 233 , 61 , 253 , 253 , 253 , 253 , 253 , 253 , 253 , 253 , 253 , 253 , 74 , 253 , 253 ,  # ▁ a0 <encdom> 253 , 253 , 253 , 253 , 247 , 253 , 253 , 36 , 46 , 71 , 73 , 253 , 54 , 253 , 108 , 123 ,  # ▁ b0 <encdom> 110 , 31 , 51 , 43 , 41 , 34 , 91 , 40 , 52 , 47 , 44 , 53 , 38 , 49 , 59 , 39 ,  # ▁ c0 <encdom> 35 , 48 , 250 , 37 , 33 , 45 , 56 , 50 , 84 , 57 , 120 , 121 , 17 , 18 , 22 , 15 ,  # ▁ d0 <encdom> 124 , 1 , 29 , 20 , 21 , 3 , 32 , 13 , 25 , 5 , 11 , 16 , 10 , 6 , 30 , 4 ,  # ▁ e0 <encdom> 9 , 8 , 14 , 7 , 2 , 12 , 28 , 23 , 42 , 24 , 64 , 75 , 19 , 26 , 27 , 253 ,  # ▁ f0 <encdom> ) <newline>  # ▁ Model ▁ Table: <encdom>  # ▁ total ▁ sequences: ▁ 100% <encdom>  # ▁ first ▁ 512 ▁ sequences: ▁ 98.2851% <encdom>  # ▁ first ▁ 1024 ▁ sequences:1.7001% <encdom>  # ▁ rest ▁ sequences: ▁ 0.0359% <encdom>  # ▁ negative ▁ sequences: ▁ 0.0148% <encdom> GreekLangModel = ( 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 3 , 2 , 2 , 3 , 3 , 3 , 3 , 3 , 3 , 3 , 3 , 1 , 3 , 3 , 3 , 0 , 2 , 2 , 3 , 3 , 0 , 3 , 0 , 3 , 2 , 0 , 3 , 3 , 3 , 0 , 3 , 0 , 0 , 0 , 2 , 0 , 0 , 0 , 0 , 0 , 2 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 3 , 3 , 3 , 3 , 3 , 0 , 3 , 3 , 0 , 3 , 2 , 3 , 3 , 0 , 3 , 2 , 3 , 3 , 3 , 0 , 0 , 3 , 0 , 3 , 0 , 3 , 3 , 2 , 0 , 0 , 0 , 2 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 2 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 2 , 3 , 2 , 2 , 3 , 3 , 3 , 3 , 3 , 3 , 3 , 3 , 0 , 3 , 3 , 3 , 3 , 0 , 2 , 3 , 3 , 0 , 3 , 3 , 3 , 3 , 2 , 3 , 3 , 3 , 0 , 2 , 0 , 0 , 0 , 2 , 0 , 0 , 0 , 0 , 0 , 2 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 2 , 3 , 3 , 2 , 3 , 3 , 3 , 3 , 3 , 3 , 3 , 3 , 3 , 3 , 3 , 3 , 0 , 2 , 1 , 3 , 3 , 3 , 3 , 2 , 3 , 3 , 2 , 3 , 3 , 2 , 0 , 0 , 0 , 0 , 0 , 2 , 0 , 0 , 0 , 0 , 0 , 2 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 3 , 3 , 3 , 3 , 0 , 3 , 3 , 3 , 3 , 3 , 3 , 0 , 3 , 3 , 0 , 3 , 3 , 3 , 3 , 3 , 3 , 3 , 3 , 3 , 3 , 0 , 3 , 2 , 3 , 3 , 0 , 2 , 0 , 1 , 0 , 2 , 0 , 0 , 0 , 0 , 0 , 2 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 1 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 3 , 3 , 3 , 3 , 3 , 2 , 3 , 0 , 0 , 0 , 0 , 3 , 3 , 0 , 3 , 1 , 3 , 3 , 3 , 0 , 3 , 3 , 0 , 3 , 3 , 3 , 3 , 0 , 0 , 0 , 0 , 2 , 0 , 0 , 0 , 2 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 3 , 3 , 3 , 3 , 3 , 0 , 3 , 0 , 3 , 3 , 3 , 3 , 3 , 0 , 3 , 2 , 2 , 2 , 3 , 0 , 2 , 3 , 3 , 3 , 3 , 3 , 2 , 3 , 3 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 3 , 3 , 3 , 3 , 3 , 3 , 2 , 2 , 2 , 3 , 3 , 3 , 3 , 0 , 3 , 1 , 3 , 3 , 3 , 3 , 2 , 3 , 3 , 3 , 3 , 3 , 3 , 3 , 2 , 2 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 3 , 3 , 3 , 3 , 3 , 2 , 0 , 3 , 0 , 0 , 0 , 3 , 3 , 2 , 3 , 3 , 3 , 3 , 3 , 0 , 0 , 3 , 2 , 3 , 0 , 2 , 3 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 3 , 0 , 3 , 3 , 3 , 3 , 0 , 0 , 3 , 3 , 0 , 2 , 3 , 0 , 3 , 0 , 3 , 3 , 3 , 0 , 0 , 3 , 0 , 3 , 0 , 2 , 2 , 3 , 3 , 0 , 0 , 0 , 0 , 1 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 2 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 3 , 3 , 3 , 3 , 3 , 2 , 0 , 3 , 2 , 3 , 3 , 3 , 3 , 0 , 3 , 3 , 3 , 3 , 3 , 0 , 3 , 3 , 2 , 3 , 2 , 3 , 3 , 2 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 3 , 3 , 2 , 3 , 2 , 3 , 3 , 3 , 3 , 3 , 3 , 0 , 2 , 3 , 2 , 3 , 2 , 2 , 2 , 3 , 2 , 3 , 3 , 2 , 3 , 0 , 2 , 2 , 2 , 3 , 0 , 2 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 2 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 3 , 0 , 0 , 0 , 3 , 3 , 3 , 2 , 3 , 3 , 0 , 0 , 3 , 0 , 3 , 0 , 0 , 0 , 3 , 2 , 0 , 3 , 0 , 3 , 0 , 0 , 2 , 0 , 2 , 0 , 0 , 0 , 0 , 0 , 2 , 0 , 0 , 0 , 0 , 0 , 2 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 2 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 3 , 3 , 3 , 3 , 0 , 3 , 3 , 3 , 3 , 3 , 3 , 0 , 3 , 3 , 0 , 3 , 0 , 0 , 0 , 3 , 3 , 0 , 3 , 3 , 3 , 0 , 0 , 1 , 2 , 3 , 0 , 3 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 2 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 3 , 3 , 3 , 3 , 3 , 2 , 0 , 0 , 3 , 2 , 2 , 3 , 3 , 0 , 3 , 3 , 3 , 3 , 3 , 2 , 1 , 3 , 0 , 3 , 2 , 3 , 3 , 2 , 1 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 3 , 3 , 0 , 2 , 3 , 3 , 3 , 3 , 3 , 3 , 0 , 0 , 3 , 0 , 3 , 0 , 0 , 0 , 3 , 3 , 0 , 3 , 2 , 3 , 0 , 0 , 3 , 3 , 3 , 0 , 3 , 0 , 0 , 0 , 2 , 0 , 0 , 0 , 0 , 0 , 3 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 3 , 3 , 3 , 3 , 0 , 3 , 3 , 3 , 3 , 3 , 3 , 0 , 0 , 3 , 0 , 3 , 0 , 0 , 0 , 3 , 2 , 0 , 3 , 2 , 3 , 0 , 0 , 3 , 2 , 3 , 0 , 2 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 3 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 3 , 1 , 2 , 2 , 3 , 3 , 3 , 3 , 3 , 3 , 0 , 2 , 3 , 0 , 3 , 0 , 0 , 0 , 3 , 3 , 0 , 3 , 0 , 2 , 0 , 0 , 2 , 3 , 1 , 0 , 2 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 2 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 3 , 0 , 3 , 3 , 3 , 3 , 0 , 3 , 0 , 3 , 3 , 2 , 3 , 0 , 3 , 3 , 3 , 3 , 3 , 3 , 0 , 3 , 3 , 3 , 0 , 2 , 3 , 0 , 0 , 3 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 3 , 0 , 3 , 3 , 3 , 0 , 0 , 3 , 0 , 0 , 0 , 3 , 3 , 0 , 3 , 0 , 2 , 3 , 3 , 0 , 0 , 3 , 0 , 3 , 0 , 3 , 3 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 3 , 0 , 0 , 0 , 3 , 3 , 3 , 3 , 3 , 3 , 0 , 0 , 3 , 0 , 2 , 0 , 0 , 0 , 3 , 3 , 0 , 3 , 0 , 3 , 0 , 0 , 2 , 0 , 2 , 0 , 0 , 0 , 0 , 0 , 1 , 0 , 0 , 0 , 0 , 0 , 2 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 3 , 3 , 3 , 3 , 3 , 3 , 0 , 3 , 0 , 2 , 0 , 3 , 2 , 0 , 3 , 2 , 3 , 2 , 3 , 0 , 0 , 3 , 2 , 3 , 2 , 3 , 3 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 3 , 0 , 0 , 2 , 3 , 3 , 3 , 3 , 3 , 0 , 0 , 0 , 3 , 0 , 2 , 1 , 0 , 0 , 3 , 2 , 2 , 2 , 0 , 3 , 0 , 0 , 2 , 2 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 3 , 0 , 3 , 3 , 3 , 2 , 0 , 3 , 0 , 3 , 0 , 3 , 3 , 0 , 2 , 1 , 2 , 3 , 3 , 0 , 0 , 3 , 0 , 3 , 0 , 3 , 3 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 2 , 3 , 3 , 3 , 0 , 3 , 3 , 3 , 3 , 3 , 3 , 0 , 2 , 3 , 0 , 3 , 0 , 0 , 0 , 2 , 1 , 0 , 2 , 2 , 3 , 0 , 0 , 2 , 2 , 2 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 2 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 3 , 0 , 0 , 2 , 3 , 3 , 3 , 2 , 3 , 0 , 0 , 1 , 3 , 0 , 2 , 0 , 0 , 0 , 0 , 3 , 0 , 1 , 0 , 2 , 0 , 0 , 1 , 1 , 1 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 3 , 3 , 3 , 3 , 3 , 1 , 0 , 3 , 0 , 0 , 0 , 3 , 2 , 0 , 3 , 2 , 3 , 3 , 3 , 0 , 0 , 3 , 0 , 3 , 2 , 2 , 2 , 1 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 3 , 0 , 3 , 3 , 3 , 0 , 0 , 3 , 0 , 0 , 0 , 0 , 2 , 0 , 2 , 3 , 3 , 2 , 2 , 2 , 2 , 3 , 0 , 2 , 0 , 2 , 2 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 3 , 3 , 3 , 3 , 2 , 0 , 0 , 0 , 0 , 0 , 0 , 2 , 3 , 0 , 2 , 0 , 2 , 3 , 2 , 0 , 0 , 3 , 0 , 3 , 0 , 3 , 1 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 3 , 2 , 3 , 3 , 2 , 2 , 3 , 0 , 2 , 0 , 3 , 0 , 0 , 0 , 2 , 0 , 0 , 0 , 0 , 1 , 2 , 0 , 2 , 0 , 2 , 0 , 0 , 2 , 0 , 2 , 0 , 2 , 2 , 0 , 0 , 1 , 0 , 2 , 2 , 2 , 0 , 2 , 2 , 2 , 0 , 2 , 2 , 2 , 0 , 0 , 2 , 0 , 0 , 1 , 0 , 0 , 0 , 0 , 0 , 2 , 0 , 3 , 3 , 2 , 0 , 0 , 0 , 0 , 0 , 0 , 1 , 3 , 0 , 2 , 0 , 2 , 2 , 2 , 0 , 0 , 2 , 0 , 3 , 0 , 0 , 2 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 3 , 0 , 2 , 3 , 2 , 0 , 2 , 2 , 0 , 2 , 0 , 2 , 2 , 0 , 2 , 0 , 2 , 2 , 2 , 0 , 0 , 0 , 0 , 0 , 0 , 2 , 3 , 0 , 0 , 0 , 2 , 0 , 1 , 2 , 0 , 0 , 0 , 0 , 2 , 2 , 0 , 0 , 0 , 2 , 1 , 0 , 2 , 2 , 0 , 0 , 0 , 0 , 0 , 0 , 1 , 0 , 2 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 2 , 1 , 0 , 2 , 3 , 2 , 2 , 3 , 2 , 3 , 2 , 0 , 0 , 3 , 3 , 3 , 0 , 0 , 3 , 2 , 0 , 0 , 0 , 1 , 1 , 0 , 2 , 0 , 2 , 2 , 0 , 2 , 0 , 2 , 0 , 2 , 2 , 0 , 0 , 2 , 0 , 2 , 2 , 2 , 0 , 2 , 2 , 2 , 2 , 0 , 0 , 2 , 0 , 0 , 0 , 2 , 0 , 1 , 0 , 0 , 0 , 0 , 0 , 3 , 0 , 3 , 3 , 2 , 2 , 0 , 3 , 0 , 0 , 0 , 2 , 2 , 0 , 2 , 2 , 2 , 1 , 2 , 0 , 0 , 1 , 2 , 2 , 0 , 0 , 3 , 0 , 0 , 0 , 2 , 0 , 1 , 2 , 0 , 0 , 0 , 1 , 2 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 2 , 2 , 0 , 1 , 0 , 0 , 2 , 0 , 0 , 0 , 2 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 2 , 3 , 3 , 2 , 2 , 0 , 0 , 0 , 2 , 0 , 2 , 3 , 3 , 0 , 2 , 0 , 0 , 0 , 0 , 0 , 0 , 2 , 2 , 2 , 0 , 2 , 2 , 0 , 2 , 0 , 2 , 0 , 2 , 2 , 0 , 0 , 2 , 2 , 2 , 2 , 1 , 0 , 0 , 2 , 2 , 0 , 2 , 0 , 0 , 2 , 0 , 0 , 0 , 0 , 0 , 0 , 2 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 2 , 0 , 3 , 2 , 3 , 0 , 0 , 0 , 3 , 0 , 0 , 2 , 2 , 0 , 2 , 0 , 2 , 2 , 2 , 0 , 0 , 2 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 2 , 0 , 0 , 2 , 2 , 0 , 0 , 2 , 2 , 2 , 0 , 0 , 0 , 0 , 0 , 0 , 2 , 0 , 0 , 0 , 2 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 2 , 0 , 0 , 3 , 2 , 0 , 2 , 2 , 2 , 2 , 2 , 0 , 0 , 0 , 2 , 0 , 0 , 0 , 0 , 2 , 0 , 1 , 0 , 0 , 2 , 0 , 1 , 0 , 0 , 0 , 0 , 2 , 2 , 2 , 0 , 2 , 2 , 0 , 1 , 2 , 0 , 2 , 2 , 2 , 0 , 2 , 2 , 2 , 2 , 1 , 2 , 2 , 0 , 0 , 2 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 1 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 2 , 0 , 0 , 0 , 0 , 0 , 0 , 1 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 2 , 0 , 2 , 0 , 2 , 2 , 0 , 0 , 0 , 0 , 1 , 2 , 1 , 0 , 0 , 2 , 2 , 0 , 0 , 2 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 3 , 2 , 3 , 0 , 0 , 2 , 0 , 0 , 0 , 2 , 2 , 0 , 2 , 0 , 0 , 0 , 1 , 0 , 0 , 2 , 0 , 2 , 0 , 2 , 2 , 0 , 0 , 0 , 0 , 0 , 0 , 2 , 0 , 0 , 0 , 0 , 2 , 2 , 0 , 0 , 0 , 0 , 0 , 0 , 2 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 2 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 2 , 2 , 3 , 2 , 2 , 0 , 0 , 0 , 0 , 0 , 0 , 1 , 3 , 0 , 2 , 0 , 2 , 2 , 0 , 0 , 0 , 1 , 0 , 2 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 2 , 0 , 2 , 0 , 3 , 2 , 0 , 2 , 0 , 0 , 0 , 0 , 0 , 0 , 2 , 2 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 1 , 0 , 0 , 2 , 0 , 0 , 0 , 0 , 1 , 1 , 0 , 0 , 2 , 1 , 2 , 0 , 2 , 2 , 0 , 1 , 0 , 0 , 1 , 0 , 0 , 0 , 2 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 3 , 0 , 2 , 2 , 2 , 0 , 0 , 2 , 0 , 0 , 0 , 2 , 0 , 0 , 0 , 2 , 3 , 0 , 2 , 0 , 0 , 0 , 0 , 0 , 0 , 2 , 2 , 0 , 0 , 0 , 2 , 0 , 1 , 2 , 0 , 0 , 0 , 1 , 2 , 2 , 1 , 0 , 0 , 0 , 2 , 0 , 0 , 2 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 1 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 3 , 0 , 0 , 0 , 0 , 0 , 0 , 2 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 2 , 1 , 2 , 0 , 2 , 2 , 0 , 2 , 0 , 0 , 2 , 0 , 0 , 0 , 0 , 1 , 2 , 1 , 0 , 2 , 1 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 2 , 0 , 0 , 0 , 3 , 1 , 2 , 2 , 0 , 2 , 0 , 0 , 0 , 0 , 2 , 0 , 0 , 0 , 2 , 0 , 0 , 3 , 0 , 0 , 0 , 0 , 2 , 2 , 2 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 2 , 1 , 0 , 2 , 0 , 1 , 2 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 2 , 0 , 0 , 1 , 0 , 0 , 0 , 0 , 0 , 0 , 2 , 0 , 2 , 2 , 0 , 0 , 2 , 2 , 2 , 2 , 2 , 0 , 1 , 2 , 0 , 0 , 0 , 2 , 2 , 0 , 1 , 0 , 2 , 0 , 0 , 2 , 2 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 1 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 3 , 0 , 0 , 2 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 2 , 0 , 2 , 0 , 0 , 0 , 0 , 2 , 0 , 1 , 2 , 0 , 0 , 0 , 0 , 2 , 2 , 1 , 0 , 1 , 0 , 1 , 0 , 2 , 2 , 2 , 1 , 0 , 0 , 0 , 0 , 0 , 0 , 1 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 2 , 0 , 1 , 2 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 2 , 0 , 0 , 2 , 2 , 0 , 0 , 0 , 0 , 1 , 0 , 0 , 0 , 0 , 0 , 0 , 2 , 0 , 2 , 2 , 0 , 0 , 0 , 0 , 2 , 2 , 0 , 0 , 0 , 0 , 0 , 0 , 2 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 2 , 0 , 0 , 2 , 0 , 0 , 0 , 0 , 2 , 2 , 2 , 2 , 0 , 0 , 0 , 3 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 2 , 0 , 0 , 0 , 0 , 0 , 0 , 2 , 0 , 0 , 0 , 0 , 0 , 0 , 1 , 0 , 0 , 2 , 0 , 0 , 0 , 0 , 1 , 2 , 0 , 0 , 0 , 0 , 0 , 0 , 2 , 2 , 1 , 1 , 0 , 0 , 0 , 0 , 0 , 0 , 1 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 2 , 0 , 2 , 2 , 2 , 0 , 0 , 2 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 2 , 2 , 2 , 0 , 0 , 0 , 2 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 2 , 0 , 0 , 1 , 0 , 0 , 0 , 0 , 2 , 1 , 0 , 0 , 0 , 0 , 0 , 0 , 1 , 0 , 0 , 0 , 0 , 0 , 1 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 3 , 0 , 2 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 2 , 0 , 0 , 0 , 0 , 0 , 2 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 2 , 0 , 0 , 0 , 0 , 2 , 0 , 0 , 2 , 0 , 0 , 0 , 0 , 2 , 2 , 0 , 0 , 0 , 0 , 1 , 0 , 0 , 1 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 2 , 0 , 2 , 2 , 1 , 0 , 0 , 0 , 0 , 0 , 0 , 2 , 0 , 0 , 2 , 0 , 2 , 2 , 2 , 0 , 0 , 0 , 0 , 0 , 0 , 2 , 0 , 0 , 0 , 0 , 2 , 0 , 0 , 2 , 0 , 0 , 2 , 0 , 2 , 2 , 0 , 0 , 0 , 0 , 2 , 0 , 2 , 0 , 0 , 0 , 0 , 0 , 2 , 0 , 0 , 0 , 2 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 3 , 0 , 0 , 0 , 2 , 2 , 0 , 2 , 2 , 0 , 0 , 0 , 0 , 0 , 2 , 0 , 0 , 0 , 0 , 0 , 0 , 2 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 1 , 0 , 0 , 0 , 0 , 0 , 1 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 1 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 2 , 0 , 0 , 2 , 0 , 0 , 0 , 0 , 0 , 0 , 2 , 2 , 2 , 2 , 2 , 0 , 0 , 0 , 0 , 0 , 0 , 2 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 1 , 1 , 0 , 0 , 0 , 1 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 2 , 1 , 0 , 0 , 0 , 0 , 0 , 0 , 2 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 2 , 2 , 0 , 0 , 0 , 0 , 0 , 2 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 1 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 2 , 0 , 0 , 0 , 2 , 0 , 0 , 0 , 0 , 0 , 1 , 0 , 0 , 0 , 0 , 2 , 2 , 0 , 0 , 0 , 1 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 1 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 2 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 1 , 0 , 0 , 1 , 0 , 2 , 0 , 0 , 0 , 0 , 2 , 0 , 2 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 2 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 1 , 0 , 0 , 0 , 0 , 1 , 1 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 1 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 1 , 0 , 0 , 0 , 0 , 1 , 0 , 0 , 2 , 0 , 2 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 2 , 1 , 0 , 0 , 0 , 0 , 0 , 0 , 2 , 0 , 0 , 0 , 1 , 2 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , ) <newline> Latin7GreekModel = { 'charToOrderMap' : Latin7_CharToOrderMap , 'precedenceMatrix' : GreekLangModel , 'mTypicalPositiveRatio' : 0.982851 , 'keepEnglishLetter' : False , 'charsetName' : "ISO-8859-7" } <newline> Win1253GreekModel = { 'charToOrderMap' : win1253_CharToOrderMap , 'precedenceMatrix' : GreekLangModel , 'mTypicalPositiveRatio' : 0.982851 , 'keepEnglishLetter' : False , 'charsetName' : "windows-1253" } <newline>  # ▁ flake8: ▁ noqa <encdom>
 # ▁ -*- ▁ coding: ▁ utf-8 ▁ -*- <encdom>  # ▁ OpenERP, ▁ Open ▁ Source ▁ Management ▁ Solution <encdom>  # ▁ Copyright ▁ (C) ▁ 2004-2009 ▁ Tiny ▁ SPRL ▁ (<http://tiny.be>). <encdom>  # ▁ Copyright ▁ (C) ▁ 2010, ▁ 2014 ▁ OpenERP ▁ s.a. ▁ (<http://openerp.com>). <encdom>  # ▁ This ▁ program ▁ is ▁ free ▁ software: ▁ you ▁ can ▁ redistribute ▁ it ▁ and/or ▁ modify <encdom>  # ▁ it ▁ under ▁ the ▁ terms ▁ of ▁ the ▁ GNU ▁ Affero ▁ General ▁ Public ▁ License ▁ as <encdom>  # ▁ published ▁ by ▁ the ▁ Free ▁ Software ▁ Foundation, ▁ either ▁ version ▁ 3 ▁ of ▁ the <encdom>  # ▁ License, ▁ or ▁ (at ▁ your ▁ option) ▁ any ▁ later ▁ version. <encdom>  # ▁ This ▁ program ▁ is ▁ distributed ▁ in ▁ the ▁ hope ▁ that ▁ it ▁ will ▁ be ▁ useful, <encdom>  # ▁ but ▁ WITHOUT ▁ ANY ▁ WARRANTY; ▁ without ▁ even ▁ the ▁ implied ▁ warranty ▁ of <encdom>  # ▁ MERCHANTABILITY ▁ or ▁ FITNESS ▁ FOR ▁ A ▁ PARTICULAR ▁ PURPOSE. ▁ See ▁ the <encdom>  # ▁ GNU ▁ Affero ▁ General ▁ Public ▁ License ▁ for ▁ more ▁ details. <encdom>  # ▁ You ▁ should ▁ have ▁ received ▁ a ▁ copy ▁ of ▁ the ▁ GNU ▁ Affero ▁ General ▁ Public ▁ License <encdom>  # ▁ along ▁ with ▁ this ▁ program. ▁ If ▁ not, ▁ see ▁ <http://www.gnu.org/licenses/>. <encdom> __all__ = [ 'synchronized' , 'lazy_property' , 'classproperty' , 'conditional' ] <newline> from functools import wraps <newline> from inspect import getsourcefile <newline> class lazy_property ( object ) : <newline> <indent>  """ ▁ Decorator ▁ for ▁ a ▁ lazy ▁ property ▁ of ▁ an ▁ object, ▁ i.e., ▁ an ▁ object ▁ attribute <strnewline> ▁ that ▁ is ▁ determined ▁ by ▁ the ▁ result ▁ of ▁ a ▁ method ▁ call ▁ evaluated ▁ once. ▁ To <strnewline> ▁ reevaluate ▁ the ▁ property, ▁ simply ▁ delete ▁ the ▁ attribute ▁ on ▁ the ▁ object, ▁ and <strnewline> ▁ get ▁ it ▁ again. <strnewline> ▁ """  <newline> def __init__ ( self , fget ) : <newline> <indent> self . fget = fget <newline> <dedent> def __get__ ( self , obj , cls ) : <newline> <indent> if obj is None : <newline> <indent> return self <newline> <dedent> value = self . fget ( obj ) <newline> setattr ( obj , self . fget . __name__ , value ) <newline> return value <newline> <dedent> @ property <newline> def __doc__ ( self ) : <newline> <indent> return self . fget . __doc__ <newline> <dedent> @ staticmethod <newline> def reset_all ( obj ) : <newline> <indent>  """ ▁ Reset ▁ all ▁ lazy ▁ properties ▁ on ▁ the ▁ instance ▁ `obj`. ▁ """  <newline> cls = type ( obj ) <newline> obj_dict = vars ( obj ) <newline> for name in obj_dict . keys ( ) : <newline> <indent> if isinstance ( getattr ( cls , name , None ) , lazy_property ) : <newline> <indent> obj_dict . pop ( name ) <newline> <dedent> <dedent> <dedent> <dedent> def conditional ( condition , decorator ) : <newline> <indent>  """ ▁ Decorator ▁ for ▁ a ▁ conditionally ▁ applied ▁ decorator. <strnewline> <strnewline> ▁ Example: <strnewline> <strnewline> ▁ @conditional(get_config('use_cache'), ▁ ormcache) <strnewline> ▁ def ▁ fn(): <strnewline> ▁ pass <strnewline> ▁ """  <newline> if condition : <newline> <indent> return decorator <newline> <dedent> else : <newline> <indent> return lambda fn : fn <newline> <dedent> <dedent> def synchronized ( lock_attr = '_lock' ) : <newline> <indent> def decorator ( func ) : <newline> <indent> @ wraps ( func ) <newline> def wrapper ( self , * args , ** kwargs ) : <newline> <indent> lock = getattr ( self , lock_attr ) <newline> try : <newline> <indent> lock . acquire ( ) <newline> return func ( self , * args , ** kwargs ) <newline> <dedent> finally : <newline> <indent> lock . release ( ) <newline> <dedent> <dedent> return wrapper <newline> <dedent> return decorator <newline> <dedent> def frame_codeinfo ( fframe , back = 0 ) : <newline> <indent>  """ ▁ Return ▁ a ▁ (filename, ▁ line) ▁ pair ▁ for ▁ a ▁ previous ▁ frame ▁ . <strnewline> ▁ @return ▁ (filename, ▁ lineno) ▁ where ▁ lineno ▁ is ▁ either ▁ int ▁ or ▁ string=='' <strnewline> ▁ """  <newline> try : <newline> <indent> if not fframe : <newline> <indent> return "<unknown>" , '' <newline> <dedent> for i in range ( back ) : <newline> <indent> fframe = fframe . f_back <newline> <dedent> try : <newline> <indent> fname = getsourcefile ( fframe ) <newline> <dedent> except TypeError : <newline> <indent> fname = '<builtin>' <newline> <dedent> lineno = fframe . f_lineno or '' <newline> return fname , lineno <newline> <dedent> except Exception : <newline> <indent> return "<unknown>" , '' <newline> <dedent> <dedent> def compose ( a , b ) : <newline> <indent>  """ ▁ Composes ▁ the ▁ callables ▁ ``a`` ▁ and ▁ ``b``. ▁ ``compose(a, ▁ b)(*args)`` ▁ is <strnewline> ▁ equivalent ▁ to ▁ ``a(b(*args))``. <strnewline> <strnewline> ▁ Can ▁ be ▁ used ▁ as ▁ a ▁ decorator ▁ by ▁ partially ▁ applying ▁ ``a``:: <strnewline> <strnewline> ▁ @partial(compose, ▁ a) <strnewline> ▁ def ▁ b(): <strnewline> ▁ ... <strnewline> ▁ """  <newline> @ wraps ( b ) <newline> def wrapper ( * args , ** kwargs ) : <newline> <indent> return a ( b ( * args , ** kwargs ) ) <newline> <dedent> return wrapper <newline> <dedent> class _ClassProperty ( property ) : <newline> <indent> def __get__ ( self , cls , owner ) : <newline> <indent> return self . fget . __get__ ( None , owner ) ( ) <newline> <dedent> <dedent> def classproperty ( func ) : <newline> <indent> return _ClassProperty ( classmethod ( func ) ) <newline> <dedent>
from io import BytesIO <newline> from django . core . handlers . wsgi import WSGIRequest <newline> from django . core . servers . basehttp import WSGIRequestHandler <newline> from django . test import SimpleTestCase <newline> from django . test . client import RequestFactory <newline> from django . test . utils import captured_stderr <newline> class Stub ( object ) : <newline> <indent> def __init__ ( self , ** kwargs ) : <newline> <indent> self . __dict__ . update ( kwargs ) <newline> <dedent> <dedent> class WSGIRequestHandlerTestCase ( SimpleTestCase ) : <newline> <indent> def test_log_message ( self ) : <newline> <indent> request = WSGIRequest ( RequestFactory ( ) . get ( '/' ) . environ ) <newline> request . makefile = lambda * args , ** kwargs : BytesIO ( ) <newline> handler = WSGIRequestHandler ( request , '192.168.0.2' , None ) <newline> with captured_stderr ( ) as stderr : <newline> <indent> handler . log_message ( 'GET ▁ %s ▁ %s' , 'A' , 'B' ) <newline> <dedent> self . assertIn ( '] ▁ GET ▁ A ▁ B' , stderr . getvalue ( ) ) <newline> <dedent> def test_https ( self ) : <newline> <indent> request = WSGIRequest ( RequestFactory ( ) . get ( '/' ) . environ ) <newline> request . makefile = lambda * args , ** kwargs : BytesIO ( ) <newline> handler = WSGIRequestHandler ( request , '192.168.0.2' , None ) <newline> with captured_stderr ( ) as stderr : <newline> <indent> handler . log_message ( "GET ▁ %s ▁ %s" , str ( '\x16\x03' ) , "4" ) <newline> self . assertIn ( "You're ▁ accessing ▁ the ▁ development ▁ server ▁ over ▁ HTTPS, ▁ " "but ▁ it ▁ only ▁ supports ▁ HTTP." , stderr . getvalue ( ) ) <newline> <dedent> <dedent> def test_strips_underscore_headers ( self ) : <newline> <indent>  """ WSGIRequestHandler ▁ ignores ▁ headers ▁ containing ▁ underscores. <strnewline> <strnewline> ▁ This ▁ follows ▁ the ▁ lead ▁ of ▁ nginx ▁ and ▁ Apache ▁ 2.4, ▁ and ▁ is ▁ to ▁ avoid <strnewline> ▁ ambiguity ▁ between ▁ dashes ▁ and ▁ underscores ▁ in ▁ mapping ▁ to ▁ WSGI ▁ environ, <strnewline> ▁ which ▁ can ▁ have ▁ security ▁ implications. <strnewline> ▁ """  <newline> def test_app ( environ , start_response ) : <newline> <indent>  """ A ▁ WSGI ▁ app ▁ that ▁ just ▁ reflects ▁ its ▁ HTTP ▁ environ. """  <newline> start_response ( '200 ▁ OK' , [ ] ) <newline> http_environ_items = sorted ( '%s:%s' % ( k , v ) for k , v in environ . items ( ) if k . startswith ( 'HTTP_' ) ) <newline> yield ( ',' . join ( http_environ_items ) ) . encode ( 'utf-8' ) <newline> <dedent> rfile = BytesIO ( ) <newline> rfile . write ( b"GET ▁ / ▁ HTTP/1.0 \n " ) <newline> rfile . write ( b"Some-Header: ▁ good \n " ) <newline> rfile . write ( b"Some_Header: ▁ bad \n " ) <newline> rfile . write ( b"Other_Header: ▁ bad \n " ) <newline> rfile . seek ( 0 ) <newline>  # ▁ WSGIRequestHandler ▁ closes ▁ the ▁ output ▁ file; ▁ we ▁ need ▁ to ▁ make ▁ this ▁ a <encdom>  # ▁ no-op ▁ so ▁ we ▁ can ▁ still ▁ read ▁ its ▁ contents. <encdom> class UnclosableBytesIO ( BytesIO ) : <newline> <indent> def close ( self ) : <newline> <indent> pass <newline> <dedent> <dedent> wfile = UnclosableBytesIO ( ) <newline> def makefile ( mode , * a , ** kw ) : <newline> <indent> if mode == 'rb' : <newline> <indent> return rfile <newline> <dedent> elif mode == 'wb' : <newline> <indent> return wfile <newline> <dedent> <dedent> request = Stub ( makefile = makefile ) <newline> server = Stub ( base_environ = { } , get_app = lambda : test_app ) <newline>  # ▁ We ▁ don't ▁ need ▁ to ▁ check ▁ stderr, ▁ but ▁ we ▁ don't ▁ want ▁ it ▁ in ▁ test ▁ output <encdom> with captured_stderr ( ) : <newline>  # ▁ instantiating ▁ a ▁ handler ▁ runs ▁ the ▁ request ▁ as ▁ side ▁ effect <encdom> <indent> WSGIRequestHandler ( request , '192.168.0.2' , server ) <newline> <dedent> wfile . seek ( 0 ) <newline> body = list ( wfile . readlines ( ) ) [ - 1 ] <newline> self . assertEqual ( body , b'HTTP_SOME_HEADER:good' ) <newline> <dedent> <dedent>
 # ▁ -*- ▁ coding: ▁ utf-8 ▁ -*- <encdom> { 'name' : 'test-uninstall' , 'version' : '0.1' , 'category' : 'Tests' , 'description' :  """ A ▁ module ▁ to ▁ test ▁ the ▁ uninstall ▁ feature. """  , 'author' : 'OpenERP ▁ SA' , 'maintainer' : 'OpenERP ▁ SA' , 'website' : 'http://www.openerp.com' , 'depends' : [ 'base' ] , 'data' : [ 'ir.model.access.csv' ] , 'installable' : True , 'auto_install' : False , } <newline>  # ▁ vim:expandtab:smartindent:tabstop=4:softtabstop=4:shiftwidth=4: <encdom>
 """ Macintosh ▁ binhex ▁ compression/decompression. <strnewline> <strnewline> easy ▁ interface: <strnewline> binhex(inputfilename, ▁ outputfilename) <strnewline> hexbin(inputfilename, ▁ outputfilename) <strnewline> """  <newline>  # ▁ Jack ▁ Jansen, ▁ CWI, ▁ August ▁ 1995. <encdom>  # ▁ The ▁ module ▁ is ▁ supposed ▁ to ▁ be ▁ as ▁ compatible ▁ as ▁ possible. ▁ Especially ▁ the <encdom>  # ▁ easy ▁ interface ▁ should ▁ work ▁"as ▁ expected" ▁ on ▁ any ▁ platform. <encdom>  # ▁ XXXX ▁ Note: ▁ currently, ▁ textfiles ▁ appear ▁ in ▁ mac-form ▁ on ▁ all ▁ platforms. <encdom>  # ▁ We ▁ seem ▁ to ▁ lack ▁ a ▁ simple ▁ character-translate ▁ in ▁ python. <encdom>  # ▁ (we ▁ should ▁ probably ▁ use ▁ ISO-Latin-1 ▁ on ▁ all ▁ but ▁ the ▁ mac ▁ platform). <encdom>  # ▁ XXXX ▁ The ▁ simple ▁ routines ▁ are ▁ too ▁ simple: ▁ they ▁ expect ▁ to ▁ hold ▁ the ▁ complete <encdom>  # ▁ files ▁ in-core. ▁ Should ▁ be ▁ fixed. <encdom>  # ▁ XXXX ▁ It ▁ would ▁ be ▁ nice ▁ to ▁ handle ▁ AppleDouble ▁ format ▁ on ▁ unix <encdom>  # ▁ (for ▁ servers ▁ serving ▁ macs). <encdom>  # ▁ XXXX ▁ I ▁ don't ▁ understand ▁ what ▁ happens ▁ when ▁ you ▁ get ▁ 0x90 ▁ times ▁ the ▁ same ▁ byte ▁ on <encdom>  # ▁ input. ▁ The ▁ resulting ▁ code ▁ (xx ▁ 90 ▁ 90) ▁ would ▁ appear ▁ to ▁ be ▁ interpreted ▁ as ▁ an <encdom>  # ▁ escaped ▁ *value* ▁ of ▁ 0x90. ▁ All ▁ coders ▁ I've ▁ seen ▁ appear ▁ to ▁ ignore ▁ this ▁ nicety... <encdom> import sys <newline> import os <newline> import struct <newline> import binascii <newline> __all__ = [ "binhex" , "hexbin" , "Error" ] <newline> class Error ( Exception ) : <newline> <indent> pass <newline>  # ▁ States ▁ (what ▁ have ▁ we ▁ written) <encdom> <dedent> [ _DID_HEADER , _DID_DATA , _DID_RSRC ] = range ( 3 ) <newline>  # ▁ Various ▁ constants <encdom> REASONABLY_LARGE = 32768  # ▁ Minimal ▁ amount ▁ we ▁ pass ▁ the ▁ rle-coder <encdom> <newline> LINELEN = 64 <newline> RUNCHAR = chr ( 0x90 )  # ▁ run-length ▁ introducer <encdom> <newline>  # ▁ This ▁ code ▁ is ▁ no ▁ longer ▁ byte-order ▁ dependent <encdom>  # ▁ Workarounds ▁ for ▁ non-mac ▁ machines. <encdom> try : <newline> <indent> from Carbon . File import FSSpec , FInfo <newline> from MacOS import openrf <newline> def getfileinfo ( name ) : <newline> <indent> finfo = FSSpec ( name ) . FSpGetFInfo ( ) <newline> dir , file = os . path . split ( name ) <newline>  # ▁ XXX ▁ Get ▁ resource/data ▁ sizes <encdom> fp = open ( name , 'rb' ) <newline> fp . seek ( 0 , 2 ) <newline> dlen = fp . tell ( ) <newline> fp = openrf ( name , '*rb' ) <newline> fp . seek ( 0 , 2 ) <newline> rlen = fp . tell ( ) <newline> return file , finfo , dlen , rlen <newline> <dedent> def openrsrc ( name , * mode ) : <newline> <indent> if not mode : <newline> <indent> mode = '*rb' <newline> <dedent> else : <newline> <indent> mode = '*' + mode [ 0 ] <newline> <dedent> return openrf ( name , mode ) <newline> <dedent> <dedent> except ImportError : <newline>  # ▁ Glue ▁ code ▁ for ▁ non-macintosh ▁ usage <encdom> <indent> class FInfo : <newline> <indent> def __init__ ( self ) : <newline> <indent> self . Type = '????' <newline> self . Creator = '????' <newline> self . Flags = 0 <newline> <dedent> <dedent> def getfileinfo ( name ) : <newline> <indent> finfo = FInfo ( ) <newline>  # ▁ Quick ▁ check ▁ for ▁ textfile <encdom> fp = open ( name ) <newline> data = open ( name ) . read ( 256 ) <newline> for c in data : <newline> <indent> if not c . isspace ( ) and ( c < ' ▁ ' or ord ( c ) > 0x7f ) : <newline> <indent> break <newline> <dedent> <dedent> else : <newline> <indent> finfo . Type = 'TEXT' <newline> <dedent> fp . seek ( 0 , 2 ) <newline> dsize = fp . tell ( ) <newline> fp . close ( ) <newline> dir , file = os . path . split ( name ) <newline> file = file . replace ( ':' , '-' , 1 ) <newline> return file , finfo , dsize , 0 <newline> <dedent> class openrsrc : <newline> <indent> def __init__ ( self , * args ) : <newline> <indent> pass <newline> <dedent> def read ( self , * args ) : <newline> <indent> return '' <newline> <dedent> def write ( self , * args ) : <newline> <indent> pass <newline> <dedent> def close ( self ) : <newline> <indent> pass <newline> <dedent> <dedent> <dedent> class _Hqxcoderengine : <newline> <indent>  """ Write ▁ data ▁ to ▁ the ▁ coder ▁ in ▁ 3-byte ▁ chunks """  <newline> def __init__ ( self , ofp ) : <newline> <indent> self . ofp = ofp <newline> self . data = '' <newline> self . hqxdata = '' <newline> self . linelen = LINELEN - 1 <newline> <dedent> def write ( self , data ) : <newline> <indent> self . data = self . data + data <newline> datalen = len ( self . data ) <newline> todo = ( datalen // 3 ) * 3 <newline> data = self . data [ : todo ] <newline> self . data = self . data [ todo : ] <newline> if not data : <newline> <indent> return <newline> <dedent> self . hqxdata = self . hqxdata + binascii . b2a_hqx ( data ) <newline> self . _flush ( 0 ) <newline> <dedent> def _flush ( self , force ) : <newline> <indent> first = 0 <newline> while first <= len ( self . hqxdata ) - self . linelen : <newline> <indent> last = first + self . linelen <newline> self . ofp . write ( self . hqxdata [ first : last ] + ' \n ' ) <newline> self . linelen = LINELEN <newline> first = last <newline> <dedent> self . hqxdata = self . hqxdata [ first : ] <newline> if force : <newline> <indent> self . ofp . write ( self . hqxdata + ': \n ' ) <newline> <dedent> <dedent> def close ( self ) : <newline> <indent> if self . data : <newline> <indent> self . hqxdata = self . hqxdata + binascii . b2a_hqx ( self . data ) <newline> <dedent> self . _flush ( 1 ) <newline> self . ofp . close ( ) <newline> del self . ofp <newline> <dedent> <dedent> class _Rlecoderengine : <newline> <indent>  """ Write ▁ data ▁ to ▁ the ▁ RLE-coder ▁ in ▁ suitably ▁ large ▁ chunks """  <newline> def __init__ ( self , ofp ) : <newline> <indent> self . ofp = ofp <newline> self . data = '' <newline> <dedent> def write ( self , data ) : <newline> <indent> self . data = self . data + data <newline> if len ( self . data ) < REASONABLY_LARGE : <newline> <indent> return <newline> <dedent> rledata = binascii . rlecode_hqx ( self . data ) <newline> self . ofp . write ( rledata ) <newline> self . data = '' <newline> <dedent> def close ( self ) : <newline> <indent> if self . data : <newline> <indent> rledata = binascii . rlecode_hqx ( self . data ) <newline> self . ofp . write ( rledata ) <newline> <dedent> self . ofp . close ( ) <newline> del self . ofp <newline> <dedent> <dedent> class BinHex : <newline> <indent> def __init__ ( self , name_finfo_dlen_rlen , ofp ) : <newline> <indent> name , finfo , dlen , rlen = name_finfo_dlen_rlen <newline> if type ( ofp ) == type ( '' ) : <newline> <indent> ofname = ofp <newline> ofp = open ( ofname , 'w' ) <newline> <dedent> ofp . write ( '(This ▁ file ▁ must ▁ be ▁ converted ▁ with ▁ BinHex ▁ 4.0) \n \n :' ) <newline> hqxer = _Hqxcoderengine ( ofp ) <newline> self . ofp = _Rlecoderengine ( hqxer ) <newline> self . crc = 0 <newline> if finfo is None : <newline> <indent> finfo = FInfo ( ) <newline> <dedent> self . dlen = dlen <newline> self . rlen = rlen <newline> self . _writeinfo ( name , finfo ) <newline> self . state = _DID_HEADER <newline> <dedent> def _writeinfo ( self , name , finfo ) : <newline> <indent> nl = len ( name ) <newline> if nl > 63 : <newline> <indent> raise Error , 'Filename ▁ too ▁ long' <newline> <dedent> d = chr ( nl ) + name + '\0' <newline> d2 = finfo . Type + finfo . Creator <newline>  # ▁ Force ▁ all ▁ structs ▁ to ▁ be ▁ packed ▁ with ▁ big-endian <encdom> d3 = struct . pack ( '>h' , finfo . Flags ) <newline> d4 = struct . pack ( '>ii' , self . dlen , self . rlen ) <newline> info = d + d2 + d3 + d4 <newline> self . _write ( info ) <newline> self . _writecrc ( ) <newline> <dedent> def _write ( self , data ) : <newline> <indent> self . crc = binascii . crc_hqx ( data , self . crc ) <newline> self . ofp . write ( data ) <newline> <dedent> def _writecrc ( self ) : <newline>  # ▁ XXXX ▁ Should ▁ this ▁ be ▁ here?? <encdom>  # ▁ self.crc ▁ = ▁ binascii.crc_hqx('\0\0', ▁ self.crc) <encdom> <indent> if self . crc < 0 : <newline> <indent> fmt = '>h' <newline> <dedent> else : <newline> <indent> fmt = '>H' <newline> <dedent> self . ofp . write ( struct . pack ( fmt , self . crc ) ) <newline> self . crc = 0 <newline> <dedent> def write ( self , data ) : <newline> <indent> if self . state != _DID_HEADER : <newline> <indent> raise Error , 'Writing ▁ data ▁ at ▁ the ▁ wrong ▁ time' <newline> <dedent> self . dlen = self . dlen - len ( data ) <newline> self . _write ( data ) <newline> <dedent> def close_data ( self ) : <newline> <indent> if self . dlen != 0 : <newline> <indent> raise Error , 'Incorrect ▁ data ▁ size, ▁ diff=%r' % ( self . rlen , ) <newline> <dedent> self . _writecrc ( ) <newline> self . state = _DID_DATA <newline> <dedent> def write_rsrc ( self , data ) : <newline> <indent> if self . state < _DID_DATA : <newline> <indent> self . close_data ( ) <newline> <dedent> if self . state != _DID_DATA : <newline> <indent> raise Error , 'Writing ▁ resource ▁ data ▁ at ▁ the ▁ wrong ▁ time' <newline> <dedent> self . rlen = self . rlen - len ( data ) <newline> self . _write ( data ) <newline> <dedent> def close ( self ) : <newline> <indent> if self . state < _DID_DATA : <newline> <indent> self . close_data ( ) <newline> <dedent> if self . state != _DID_DATA : <newline> <indent> raise Error , 'Close ▁ at ▁ the ▁ wrong ▁ time' <newline> <dedent> if self . rlen != 0 : <newline> <indent> raise Error , "Incorrect ▁ resource-datasize, ▁ diff=%r" % ( self . rlen , ) <newline> <dedent> self . _writecrc ( ) <newline> self . ofp . close ( ) <newline> self . state = None <newline> del self . ofp <newline> <dedent> <dedent> def binhex ( inp , out ) : <newline> <indent>  """ (infilename, ▁ outfilename) ▁ - ▁ Create ▁ binhex-encoded ▁ copy ▁ of ▁ a ▁ file """  <newline> finfo = getfileinfo ( inp ) <newline> ofp = BinHex ( finfo , out ) <newline> ifp = open ( inp , 'rb' ) <newline>  # ▁ XXXX ▁ Do ▁ textfile ▁ translation ▁ on ▁ non-mac ▁ systems <encdom> while 1 : <newline> <indent> d = ifp . read ( 128000 ) <newline> if not d : break <newline> ofp . write ( d ) <newline> <dedent> ofp . close_data ( ) <newline> ifp . close ( ) <newline> ifp = openrsrc ( inp , 'rb' ) <newline> while 1 : <newline> <indent> d = ifp . read ( 128000 ) <newline> if not d : break <newline> ofp . write_rsrc ( d ) <newline> <dedent> ofp . close ( ) <newline> ifp . close ( ) <newline> <dedent> class _Hqxdecoderengine : <newline> <indent>  """ Read ▁ data ▁ via ▁ the ▁ decoder ▁ in ▁ 4-byte ▁ chunks """  <newline> def __init__ ( self , ifp ) : <newline> <indent> self . ifp = ifp <newline> self . eof = 0 <newline> <dedent> def read ( self , totalwtd ) : <newline> <indent>  """ Read ▁ at ▁ least ▁ wtd ▁ bytes ▁ (or ▁ until ▁ EOF) """  <newline> decdata = '' <newline> wtd = totalwtd <newline>  # ▁ The ▁ loop ▁ here ▁ is ▁ convoluted, ▁ since ▁ we ▁ don't ▁ really ▁ now ▁ how <encdom>  # ▁ much ▁ to ▁ decode: ▁ there ▁ may ▁ be ▁ newlines ▁ in ▁ the ▁ incoming ▁ data. <encdom> while wtd > 0 : <newline> <indent> if self . eof : return decdata <newline> wtd = ( ( wtd + 2 ) // 3 ) * 4 <newline> data = self . ifp . read ( wtd ) <newline>  # ▁ Next ▁ problem: ▁ there ▁ may ▁ not ▁ be ▁ a ▁ complete ▁ number ▁ of <encdom>  # ▁ bytes ▁ in ▁ what ▁ we ▁ pass ▁ to ▁ a2b. ▁ Solve ▁ by ▁ yet ▁ another <encdom>  # ▁ loop. <encdom> while 1 : <newline> <indent> try : <newline> <indent> decdatacur , self . eof = binascii . a2b_hqx ( data ) <newline> break <newline> <dedent> except binascii . Incomplete : <newline> <indent> pass <newline> <dedent> newdata = self . ifp . read ( 1 ) <newline> if not newdata : <newline> <indent> raise Error , 'Premature ▁ EOF ▁ on ▁ binhex ▁ file' <newline> <dedent> data = data + newdata <newline> <dedent> decdata = decdata + decdatacur <newline> wtd = totalwtd - len ( decdata ) <newline> if not decdata and not self . eof : <newline> <indent> raise Error , 'Premature ▁ EOF ▁ on ▁ binhex ▁ file' <newline> <dedent> <dedent> return decdata <newline> <dedent> def close ( self ) : <newline> <indent> self . ifp . close ( ) <newline> <dedent> <dedent> class _Rledecoderengine : <newline> <indent>  """ Read ▁ data ▁ via ▁ the ▁ RLE-coder """  <newline> def __init__ ( self , ifp ) : <newline> <indent> self . ifp = ifp <newline> self . pre_buffer = '' <newline> self . post_buffer = '' <newline> self . eof = 0 <newline> <dedent> def read ( self , wtd ) : <newline> <indent> if wtd > len ( self . post_buffer ) : <newline> <indent> self . _fill ( wtd - len ( self . post_buffer ) ) <newline> <dedent> rv = self . post_buffer [ : wtd ] <newline> self . post_buffer = self . post_buffer [ wtd : ] <newline> return rv <newline> <dedent> def _fill ( self , wtd ) : <newline> <indent> self . pre_buffer = self . pre_buffer + self . ifp . read ( wtd + 4 ) <newline> if self . ifp . eof : <newline> <indent> self . post_buffer = self . post_buffer + binascii . rledecode_hqx ( self . pre_buffer ) <newline> self . pre_buffer = '' <newline> return <newline>  # ▁ Obfuscated ▁ code ▁ ahead. ▁ We ▁ have ▁ to ▁ take ▁ care ▁ that ▁ we ▁ don't <encdom>  # ▁ end ▁ up ▁ with ▁ an ▁ orphaned ▁ RUNCHAR ▁ later ▁ on. ▁ So, ▁ we ▁ keep ▁ a ▁ couple <encdom>  # ▁ of ▁ bytes ▁ in ▁ the ▁ buffer, ▁ depending ▁ on ▁ what ▁ the ▁ end ▁ of <encdom>  # ▁ the ▁ buffer ▁ looks ▁ like: <encdom>  # ▁'\220\0\220' ▁ - ▁ Keep ▁ 3 ▁ bytes: ▁ repeated ▁ \220 ▁ (escaped ▁ as ▁ \220\0) <encdom>  # ▁'?\220' ▁ - ▁ Keep ▁ 2 ▁ bytes: ▁ repeated ▁ something-else <encdom>  # ▁'\220\0' ▁ - ▁ Escaped ▁ \220: ▁ Keep ▁ 2 ▁ bytes. <encdom>  # ▁'?\220?' ▁ - ▁ Complete ▁ repeat ▁ sequence: ▁ decode ▁ all <encdom>  # ▁ otherwise: ▁ keep ▁ 1 ▁ byte. <encdom> <dedent> mark = len ( self . pre_buffer ) <newline> if self . pre_buffer [ - 3 : ] == RUNCHAR + '\0' + RUNCHAR : <newline> <indent> mark = mark - 3 <newline> <dedent> elif self . pre_buffer [ - 1 ] == RUNCHAR : <newline> <indent> mark = mark - 2 <newline> <dedent> elif self . pre_buffer [ - 2 : ] == RUNCHAR + '\0' : <newline> <indent> mark = mark - 2 <newline> <dedent> elif self . pre_buffer [ - 2 ] == RUNCHAR : <newline> <indent> pass  # ▁ Decode ▁ all <encdom> <newline> <dedent> else : <newline> <indent> mark = mark - 1 <newline> <dedent> self . post_buffer = self . post_buffer + binascii . rledecode_hqx ( self . pre_buffer [ : mark ] ) <newline> self . pre_buffer = self . pre_buffer [ mark : ] <newline> <dedent> def close ( self ) : <newline> <indent> self . ifp . close ( ) <newline> <dedent> <dedent> class HexBin : <newline> <indent> def __init__ ( self , ifp ) : <newline> <indent> if type ( ifp ) == type ( '' ) : <newline> <indent> ifp = open ( ifp ) <newline>  # ▁ Find ▁ initial ▁ colon. <encdom> <dedent> while 1 : <newline> <indent> ch = ifp . read ( 1 ) <newline> if not ch : <newline> <indent> raise Error , "No ▁ binhex ▁ data ▁ found" <newline>  # ▁ Cater ▁ for ▁ \n ▁ terminated ▁ lines ▁ (which ▁ show ▁ up ▁ as ▁ \n , ▁ hence <encdom>  # ▁ all ▁ lines ▁ start ▁ with ▁ ) <encdom> <dedent> if ch == '' : <newline> <indent> continue <newline> <dedent> if ch == ':' : <newline> <indent> break <newline> <dedent> if ch != ' \n ' : <newline> <indent> dummy = ifp . readline ( ) <newline> <dedent> <dedent> hqxifp = _Hqxdecoderengine ( ifp ) <newline> self . ifp = _Rledecoderengine ( hqxifp ) <newline> self . crc = 0 <newline> self . _readheader ( ) <newline> <dedent> def _read ( self , len ) : <newline> <indent> data = self . ifp . read ( len ) <newline> self . crc = binascii . crc_hqx ( data , self . crc ) <newline> return data <newline> <dedent> def _checkcrc ( self ) : <newline> <indent> filecrc = struct . unpack ( '>h' , self . ifp . read ( 2 ) ) [ 0 ] & 0xffff <newline>  # self.crc ▁ = ▁ binascii.crc_hqx('\0\0', ▁ self.crc) <encdom>  # ▁ XXXX ▁ Is ▁ this ▁ needed?? <encdom> self . crc = self . crc & 0xffff <newline> if filecrc != self . crc : <newline> <indent> raise Error , 'CRC ▁ error, ▁ computed ▁ %x, ▁ read ▁ %x' % ( self . crc , filecrc ) <newline> <dedent> self . crc = 0 <newline> <dedent> def _readheader ( self ) : <newline> <indent> len = self . _read ( 1 ) <newline> fname = self . _read ( ord ( len ) ) <newline> rest = self . _read ( 1 + 4 + 4 + 2 + 4 + 4 ) <newline> self . _checkcrc ( ) <newline> type = rest [ 1 : 5 ] <newline> creator = rest [ 5 : 9 ] <newline> flags = struct . unpack ( '>h' , rest [ 9 : 11 ] ) [ 0 ] <newline> self . dlen = struct . unpack ( '>l' , rest [ 11 : 15 ] ) [ 0 ] <newline> self . rlen = struct . unpack ( '>l' , rest [ 15 : 19 ] ) [ 0 ] <newline> self . FName = fname <newline> self . FInfo = FInfo ( ) <newline> self . FInfo . Creator = creator <newline> self . FInfo . Type = type <newline> self . FInfo . Flags = flags <newline> self . state = _DID_HEADER <newline> <dedent> def read ( self , * n ) : <newline> <indent> if self . state != _DID_HEADER : <newline> <indent> raise Error , 'Read ▁ data ▁ at ▁ wrong ▁ time' <newline> <dedent> if n : <newline> <indent> n = n [ 0 ] <newline> n = min ( n , self . dlen ) <newline> <dedent> else : <newline> <indent> n = self . dlen <newline> <dedent> rv = '' <newline> while len ( rv ) < n : <newline> <indent> rv = rv + self . _read ( n - len ( rv ) ) <newline> <dedent> self . dlen = self . dlen - n <newline> return rv <newline> <dedent> def close_data ( self ) : <newline> <indent> if self . state != _DID_HEADER : <newline> <indent> raise Error , 'close_data ▁ at ▁ wrong ▁ time' <newline> <dedent> if self . dlen : <newline> <indent> dummy = self . _read ( self . dlen ) <newline> <dedent> self . _checkcrc ( ) <newline> self . state = _DID_DATA <newline> <dedent> def read_rsrc ( self , * n ) : <newline> <indent> if self . state == _DID_HEADER : <newline> <indent> self . close_data ( ) <newline> <dedent> if self . state != _DID_DATA : <newline> <indent> raise Error , 'Read ▁ resource ▁ data ▁ at ▁ wrong ▁ time' <newline> <dedent> if n : <newline> <indent> n = n [ 0 ] <newline> n = min ( n , self . rlen ) <newline> <dedent> else : <newline> <indent> n = self . rlen <newline> <dedent> self . rlen = self . rlen - n <newline> return self . _read ( n ) <newline> <dedent> def close ( self ) : <newline> <indent> if self . rlen : <newline> <indent> dummy = self . read_rsrc ( self . rlen ) <newline> <dedent> self . _checkcrc ( ) <newline> self . state = _DID_RSRC <newline> self . ifp . close ( ) <newline> <dedent> <dedent> def hexbin ( inp , out ) : <newline> <indent>  """ (infilename, ▁ outfilename) ▁ - ▁ Decode ▁ binhexed ▁ file """  <newline> ifp = HexBin ( inp ) <newline> finfo = ifp . FInfo <newline> if not out : <newline> <indent> out = ifp . FName <newline> <dedent> ofp = open ( out , 'wb' ) <newline>  # ▁ XXXX ▁ Do ▁ translation ▁ on ▁ non-mac ▁ systems <encdom> while 1 : <newline> <indent> d = ifp . read ( 128000 ) <newline> if not d : break <newline> ofp . write ( d ) <newline> <dedent> ofp . close ( ) <newline> ifp . close_data ( ) <newline> d = ifp . read_rsrc ( 128000 ) <newline> if d : <newline> <indent> ofp = openrsrc ( out , 'wb' ) <newline> ofp . write ( d ) <newline> while 1 : <newline> <indent> d = ifp . read_rsrc ( 128000 ) <newline> if not d : break <newline> ofp . write ( d ) <newline> <dedent> ofp . close ( ) <newline> <dedent> ifp . close ( ) <newline> <dedent> def _test ( ) : <newline> <indent> fname = sys . argv [ 1 ] <newline> binhex ( fname , fname + '.hqx' ) <newline> hexbin ( fname + '.hqx' , fname + '.viahqx' ) <newline>  # hexbin(fname, ▁ fname+'.unpacked') <encdom> sys . exit ( 1 ) <newline> <dedent> if __name__ == '__main__' : <newline> <indent> _test ( ) <newline> <dedent>
 # ▁ (c) ▁ 2017, ▁ Toshio ▁ Kuratomi ▁ <tkuratomi@ansible.com> <encdom>  # ▁ This ▁ file ▁ is ▁ part ▁ of ▁ Ansible <encdom>  # ▁ Ansible ▁ is ▁ free ▁ software: ▁ you ▁ can ▁ redistribute ▁ it ▁ and/or ▁ modify <encdom>  # ▁ it ▁ under ▁ the ▁ terms ▁ of ▁ the ▁ GNU ▁ General ▁ Public ▁ License ▁ as ▁ published ▁ by <encdom>  # ▁ the ▁ Free ▁ Software ▁ Foundation, ▁ either ▁ version ▁ 3 ▁ of ▁ the ▁ License, ▁ or <encdom>  # ▁ (at ▁ your ▁ option) ▁ any ▁ later ▁ version. <encdom>  # ▁ Ansible ▁ is ▁ distributed ▁ in ▁ the ▁ hope ▁ that ▁ it ▁ will ▁ be ▁ useful, <encdom>  # ▁ but ▁ WITHOUT ▁ ANY ▁ WARRANTY; ▁ without ▁ even ▁ the ▁ implied ▁ warranty ▁ of <encdom>  # ▁ MERCHANTABILITY ▁ or ▁ FITNESS ▁ FOR ▁ A ▁ PARTICULAR ▁ PURPOSE. ▁ See ▁ the <encdom>  # ▁ GNU ▁ General ▁ Public ▁ License ▁ for ▁ more ▁ details. <encdom>  # ▁ You ▁ should ▁ have ▁ received ▁ a ▁ copy ▁ of ▁ the ▁ GNU ▁ General ▁ Public ▁ License <encdom>  # ▁ along ▁ with ▁ Ansible. ▁ If ▁ not, ▁ see ▁ <http://www.gnu.org/licenses/>. <encdom>  # ▁ Make ▁ coding ▁ more ▁ python3-ish <encdom> from __future__ import ( absolute_import , division , print_function ) <newline> __metaclass__ = type <newline> import imp <newline> import zipfile <newline> from collections import namedtuple <newline> from functools import partial <newline> from io import BytesIO , StringIO <newline> import pytest <newline> import ansible . errors <newline> from ansible . compat . six import PY2 <newline> from ansible . compat . six . moves import builtins <newline> from ansible . executor . module_common import recursive_finder <newline> original_find_module = imp . find_module <newline> @ pytest . fixture <newline> def finder_containers ( ) : <newline> <indent> FinderContainers = namedtuple ( 'FinderContainers' , [ 'py_module_names' , 'py_module_cache' , 'zf' ] ) <newline> py_module_names = set ( ) <newline>  # py_module_cache ▁ = ▁ {('__init__',): ▁ b''} <encdom> py_module_cache = { } <newline> zipoutput = BytesIO ( ) <newline> zf = zipfile . ZipFile ( zipoutput , mode = 'w' , compression = zipfile . ZIP_STORED ) <newline>  # zf.writestr('ansible/__init__.py', ▁ b'') <encdom> return FinderContainers ( py_module_names , py_module_cache , zf ) <newline> <dedent> def find_module_foo ( module_utils_data , * args , ** kwargs ) : <newline> <indent> if args [ 0 ] == 'foo' : <newline> <indent> return ( module_utils_data , '/usr/lib/python2.7/site-packages/ansible/module_utils/foo.py' , ( '.py' , 'r' , imp . PY_SOURCE ) ) <newline> <dedent> return original_find_module ( * args , ** kwargs ) <newline> <dedent> def find_package_foo ( module_utils_data , * args , ** kwargs ) : <newline> <indent> if args [ 0 ] == 'foo' : <newline> <indent> return ( module_utils_data , '/usr/lib/python2.7/site-packages/ansible/module_utils/foo' , ( '' , '' , imp . PKG_DIRECTORY ) ) <newline> <dedent> return original_find_module ( * args , ** kwargs ) <newline> <dedent> class TestRecursiveFinder ( object ) : <newline> <indent> def test_no_module_utils ( self , finder_containers ) : <newline> <indent> name = 'ping' <newline> data = b' # !/usr/bin/python \n return ▁ \'{\"changed\": ▁ false}\'' <newline> recursive_finder ( name , data , * finder_containers ) <newline> assert finder_containers . py_module_names == set ( ( ) ) <newline> assert finder_containers . py_module_cache == { } <newline> assert frozenset ( finder_containers . zf . namelist ( ) ) == frozenset ( ) <newline> <dedent> def test_from_import_toplevel_package ( self , finder_containers , mocker ) : <newline> <indent> if PY2 : <newline> <indent> module_utils_data = BytesIO ( b' # ▁ License \n def ▁ do_something(): \n ▁ ▁ ▁ ▁ pass \n ' ) <newline> <dedent> else : <newline> <indent> module_utils_data = StringIO ( u' # ▁ License \n def ▁ do_something(): \n ▁ ▁ ▁ ▁ pass \n ' ) <newline> <dedent> mocker . patch ( 'imp.find_module' , side_effect = partial ( find_package_foo , module_utils_data ) ) <newline> mocker . patch ( 'ansible.executor.module_common._slurp' , side_effect = lambda x : b' # ▁ License \n def ▁ do_something(): \n ▁ ▁ ▁ ▁ pass \n ' ) <newline> name = 'ping' <newline> data = b' # !/usr/bin/python \n from ▁ ansible.module_utils ▁ import ▁ foo' <newline> recursive_finder ( name , data , * finder_containers ) <newline> mocker . stopall ( ) <newline> assert finder_containers . py_module_names == set ( ( ( 'foo' , '__init__' ) , ) ) <newline> assert finder_containers . py_module_cache == { } <newline> assert frozenset ( finder_containers . zf . namelist ( ) ) == frozenset ( ( 'ansible/module_utils/foo/__init__.py' , ) ) <newline> <dedent> def test_from_import_toplevel_module ( self , finder_containers , mocker ) : <newline> <indent> if PY2 : <newline> <indent> module_utils_data = BytesIO ( b' # ▁ License \n def ▁ do_something(): \n ▁ ▁ ▁ ▁ pass \n ' ) <newline> <dedent> else : <newline> <indent> module_utils_data = StringIO ( u' # ▁ License \n def ▁ do_something(): \n ▁ ▁ ▁ ▁ pass \n ' ) <newline> <dedent> mocker . patch ( 'imp.find_module' , side_effect = partial ( find_module_foo , module_utils_data ) ) <newline> name = 'ping' <newline> data = b' # !/usr/bin/python \n from ▁ ansible.module_utils ▁ import ▁ foo' <newline> recursive_finder ( name , data , * finder_containers ) <newline> mocker . stopall ( ) <newline> assert finder_containers . py_module_names == set ( ( ( 'foo' , ) , ) ) <newline> assert finder_containers . py_module_cache == { } <newline> assert frozenset ( finder_containers . zf . namelist ( ) ) == frozenset ( ( 'ansible/module_utils/foo.py' , ) ) <newline>  # ▁ Test ▁ importing ▁ six ▁ with ▁ many ▁ permutations ▁ because ▁ it ▁ is ▁ not ▁ a ▁ normal ▁ module <encdom> <dedent> def test_from_import_six ( self , finder_containers ) : <newline> <indent> name = 'ping' <newline> data = b' # !/usr/bin/python \n from ▁ ansible.module_utils ▁ import ▁ six' <newline> recursive_finder ( name , data , * finder_containers ) <newline> assert finder_containers . py_module_names == set ( ( ( 'six' , ) , ) ) <newline> assert finder_containers . py_module_cache == { } <newline> assert frozenset ( finder_containers . zf . namelist ( ) ) == frozenset ( ( 'ansible/module_utils/six.py' , ) ) <newline> <dedent> def test_import_six ( self , finder_containers ) : <newline> <indent> name = 'ping' <newline> data = b' # !/usr/bin/python \n import ▁ ansible.module_utils.six' <newline> recursive_finder ( name , data , * finder_containers ) <newline> assert finder_containers . py_module_names == set ( ( ( 'six' , ) , ) ) <newline> assert finder_containers . py_module_cache == { } <newline> assert frozenset ( finder_containers . zf . namelist ( ) ) == frozenset ( ( 'ansible/module_utils/six.py' , ) ) <newline> <dedent> def test_import_six_from_many_submodules ( self , finder_containers ) : <newline> <indent> name = 'ping' <newline> data = b' # !/usr/bin/python \n from ▁ ansible.module_utils.six.moves.urllib.parse ▁ import ▁ urlparse' <newline> recursive_finder ( name , data , * finder_containers ) <newline> assert finder_containers . py_module_names == set ( ( ( 'six' , ) , ) ) <newline> assert finder_containers . py_module_cache == { } <newline> assert frozenset ( finder_containers . zf . namelist ( ) ) == frozenset ( ( 'ansible/module_utils/six.py' , ) ) <newline> <dedent> <dedent>
 # ▁ -*- ▁ coding: ▁ utf-8 ▁ -*- <encdom>  # ▁ V. ▁ Kuleshov ▁ and ▁ P. ▁ S. ▁ Liang, ▁ “Calibrated ▁ Structured ▁ Prediction,” ▁ in ▁ NIPS, ▁ 2015, ▁ pp. ▁ 3474–3482 ▁ [Online]. ▁ <encdom>  # Available: ▁ http://papers.nips.cc/paper/5658-calibrated-structured-prediction.pdf <encdom> import numpy as np <newline> import matplotlib . pyplot as plt <newline> import os <newline> eps = 0.01  # ▁ we ▁ make ▁ this ▁ non-zero ▁ for ▁ plotting ▁ purposes <encdom> <newline> ptrue = [ eps , 1 , 0.5 ]  # ▁ expect[y|x] <encdom> <newline> Fcal = [ 0.5 , 0.5 , 0.5 ] <newline> Funcal = [ 0.2 , 0.8 , 0.4 ] <newline> Fbal = [ eps , 0.75 , 0.75 ] <newline>  # https://matplotlib.org/examples/api/barchart_demo.html <encdom> width = 0.2 <newline> fig , ax = plt . subplots ( ) <newline> X = np . arange ( 3 ) <newline> bar_true = ax . bar ( X , ptrue , width , color = 'r' ) <newline> bar_cal = ax . bar ( X + width , Fcal , width , color = 'g' ) <newline> bar_uncal = ax . bar ( X + 2 * width , Funcal , width , color = 'b' ) <newline> bar_bal = ax . bar ( X + 3 * width , Fbal , width , color = 'k' ) <newline> ax . set_ylabel ( 'probability' ) <newline> ax . set_xticks ( X + width ) <newline> ax . set_xticklabels ( X ) <newline> ax . legend ( ( bar_true [ 0 ] , bar_cal [ 0 ] , bar_uncal [ 0 ] , bar_bal [ 0 ] ) , ( 'true' , 'cal' , 'uncal' , 'bal' ) ) <newline> plt . show ( ) <newline> plt . savefig ( os . path . join ( 'figures' , 'calibration' ) ) <newline>  # # # ▁ Plot ▁ error <encdom> eps = 0 <newline> ptrue = np . array ( [ eps , 1 , 0.5 ] ) <newline> Fcal = np . array ( [ 0.5 , 0.5 , 0.5 ] ) <newline> Funcal = np . array ( [ 0.2 , 0.8 , 0.4 ] ) <newline> Fbal = np . array ( [ eps , 0.75 , 0.75 ] ) <newline> err_cal = ( ptrue - Fcal ) <newline> err_uncal = ( ptrue - Funcal ) <newline> err_bal = ( ptrue - Fbal ) <newline> fig , ax = plt . subplots ( ) <newline> X = np . arange ( 3 ) <newline> bar_cal = ax . bar ( X + width , err_cal , width , color = 'g' ) <newline> bar_uncal = ax . bar ( X + 2 * width , err_uncal , width , color = 'b' ) <newline> bar_bal = ax . bar ( X + 3 * width , err_bal , width , color = 'k' ) <newline> ax . set_ylabel ( 'error' ) <newline> ax . set_xticks ( X + width ) <newline> ax . set_xticklabels ( X ) <newline> ax . legend ( ( bar_cal [ 0 ] , bar_uncal [ 0 ] , bar_bal [ 0 ] ) , ( 'cal' , 'uncal' , 'bal' ) ) <newline> plt . show ( ) <newline> plt . savefig ( os . path . join ( 'figures' , 'calibration_err' ) ) <newline>
 # ▁ Copyright ▁ 2016 ▁ The ▁ TensorFlow ▁ Authors. ▁ All ▁ Rights ▁ Reserved. <encdom>  # ▁ Licensed ▁ under ▁ the ▁ Apache ▁ License, ▁ Version ▁ 2.0 ▁ (the ▁"License"); <encdom>  # ▁ you ▁ may ▁ not ▁ use ▁ this ▁ file ▁ except ▁ in ▁ compliance ▁ with ▁ the ▁ License. <encdom>  # ▁ You ▁ may ▁ obtain ▁ a ▁ copy ▁ of ▁ the ▁ License ▁ at <encdom>  # ▁ http://www.apache.org/licenses/LICENSE-2.0 <encdom>  # ▁ Unless ▁ required ▁ by ▁ applicable ▁ law ▁ or ▁ agreed ▁ to ▁ in ▁ writing, ▁ software <encdom>  # ▁ distributed ▁ under ▁ the ▁ License ▁ is ▁ distributed ▁ on ▁ an ▁"AS ▁ IS" ▁ BASIS, <encdom>  # ▁ WITHOUT ▁ WARRANTIES ▁ OR ▁ CONDITIONS ▁ OF ▁ ANY ▁ KIND, ▁ either ▁ express ▁ or ▁ implied. <encdom>  # ▁ See ▁ the ▁ License ▁ for ▁ the ▁ specific ▁ language ▁ governing ▁ permissions ▁ and <encdom>  # ▁ limitations ▁ under ▁ the ▁ License. <encdom>  """ Library ▁ for ▁ getting ▁ system ▁ information ▁ during ▁ TensorFlow ▁ tests. """  <newline> from __future__ import absolute_import <newline> from __future__ import division <newline> from __future__ import print_function <newline> import glob <newline> import multiprocessing <newline> import platform <newline> import re <newline> import socket <newline>  # ▁ pylint: ▁ disable=g-bad-import-order <encdom>  # ▁ Note: ▁ cpuinfo ▁ and ▁ psutil ▁ are ▁ not ▁ installed ▁ for ▁ you ▁ in ▁ the ▁ TensorFlow <encdom>  # ▁ OSS ▁ tree. ▁ They ▁ are ▁ installable ▁ via ▁ pip. <encdom> import cpuinfo <newline> import psutil <newline>  # ▁ pylint: ▁ enable=g-bad-import-order <encdom> from tensorflow . core . util import test_log_pb2 <newline> from tensorflow . python . client import device_lib <newline> from tensorflow . python . framework import errors <newline> from tensorflow . python . platform import gfile <newline> from tensorflow . tools . test import gpu_info_lib <newline> def gather_machine_configuration ( ) : <newline> <indent>  """ Gather ▁ Machine ▁ Configuration. ▁ This ▁ is ▁ the ▁ top ▁ level ▁ fn ▁ of ▁ this ▁ library. """  <newline> config = test_log_pb2 . MachineConfiguration ( ) <newline> config . cpu_info . CopyFrom ( gather_cpu_info ( ) ) <newline> config . platform_info . CopyFrom ( gather_platform_info ( ) ) <newline>  # ▁ gather_available_device_info ▁ must ▁ come ▁ before ▁ gather_gpu_devices <encdom>  # ▁ because ▁ the ▁ latter ▁ may ▁ access ▁ libcudart ▁ directly, ▁ which ▁ confuses <encdom>  # ▁ TensorFlow ▁ StreamExecutor. <encdom> for d in gather_available_device_info ( ) : <newline> <indent> config . available_device_info . add ( ) . CopyFrom ( d ) <newline> <dedent> for gpu in gpu_info_lib . gather_gpu_devices ( ) : <newline> <indent> config . device_info . add ( ) . Pack ( gpu ) <newline> <dedent> config . memory_info . CopyFrom ( gather_memory_info ( ) ) <newline> config . hostname = gather_hostname ( ) <newline> return config <newline> <dedent> def gather_hostname ( ) : <newline> <indent> return socket . gethostname ( ) <newline> <dedent> def gather_memory_info ( ) : <newline> <indent>  """ Gather ▁ memory ▁ info. """  <newline> mem_info = test_log_pb2 . MemoryInfo ( ) <newline> vmem = psutil . virtual_memory ( ) <newline> mem_info . total = vmem . total <newline> mem_info . available = vmem . available <newline> return mem_info <newline> <dedent> def gather_cpu_info ( ) : <newline> <indent>  """ Gather ▁ CPU ▁ Information. ▁ Assumes ▁ all ▁ CPUs ▁ are ▁ the ▁ same. """  <newline> cpu_info = test_log_pb2 . CPUInfo ( ) <newline> cpu_info . num_cores = multiprocessing . cpu_count ( ) <newline>  # ▁ Gather ▁ num_cores_allowed <encdom> try : <newline> <indent> with gfile . GFile ( '/proc/self/status' , 'rb' ) as fh : <newline> <indent> nc = re . search ( r'(?m)^Cpus_allowed:\s*(.*)$' , fh . read ( ) ) <newline> <dedent> if nc :  # ▁ e.g. ▁'ff' ▁ => ▁ 8, ▁'fff' ▁ => ▁ 12 <encdom> <newline> <indent> cpu_info . num_cores_allowed = ( bin ( int ( nc . group ( 1 ) . replace ( ',' , '' ) , 16 ) ) . count ( '1' ) ) <newline> <dedent> <dedent> except errors . OpError : <newline> <indent> pass <newline> <dedent> finally : <newline> <indent> if cpu_info . num_cores_allowed == 0 : <newline> <indent> cpu_info . num_cores_allowed = cpu_info . num_cores <newline>  # ▁ Gather ▁ the ▁ rest <encdom> <dedent> <dedent> info = cpuinfo . get_cpu_info ( ) <newline> cpu_info . cpu_info = info [ 'brand' ] <newline> cpu_info . num_cores = info [ 'count' ] <newline> cpu_info . mhz_per_cpu = info [ 'hz_advertised_raw' ] [ 0 ] / 1.0e6 <newline> l2_cache_size = re . match ( r'(\d+)' , str ( info . get ( 'l2_cache_size' , '' ) ) ) <newline> if l2_cache_size : <newline>  # ▁ If ▁ a ▁ value ▁ is ▁ returned, ▁ it's ▁ in ▁ KB <encdom> <indent> cpu_info . cache_size [ 'L2' ] = int ( l2_cache_size . group ( 0 ) ) * 1024 <newline>  # ▁ Try ▁ to ▁ get ▁ the ▁ CPU ▁ governor <encdom> <dedent> try : <newline> <indent> cpu_governors = set ( [ gfile . GFile ( f , 'r' ) . readline ( ) . rstrip ( ) for f in glob . glob ( '/sys/devices/system/cpu/cpu*/cpufreq/scaling_governor' ) ] ) <newline> if cpu_governors : <newline> <indent> if len ( cpu_governors ) > 1 : <newline> <indent> cpu_info . cpu_governor = 'mixed' <newline> <dedent> else : <newline> <indent> cpu_info . cpu_governor = list ( cpu_governors ) [ 0 ] <newline> <dedent> <dedent> <dedent> except errors . OpError : <newline> <indent> pass <newline> <dedent> return cpu_info <newline> <dedent> def gather_available_device_info ( ) : <newline> <indent>  """ Gather ▁ list ▁ of ▁ devices ▁ available ▁ to ▁ TensorFlow. <strnewline> <strnewline> ▁ Returns: <strnewline> ▁ A ▁ list ▁ of ▁ test_log_pb2.AvailableDeviceInfo ▁ messages. <strnewline> ▁ """  <newline> device_info_list = [ ] <newline> devices = device_lib . list_local_devices ( ) <newline> for d in devices : <newline> <indent> device_info = test_log_pb2 . AvailableDeviceInfo ( ) <newline> device_info . name = d . name <newline> device_info . type = d . device_type <newline> device_info . memory_limit = d . memory_limit <newline> device_info . physical_description = d . physical_device_desc <newline> device_info_list . append ( device_info ) <newline> <dedent> return device_info_list <newline> <dedent> def gather_platform_info ( ) : <newline> <indent>  """ Gather ▁ platform ▁ info. """  <newline> platform_info = test_log_pb2 . PlatformInfo ( ) <newline> ( platform_info . bits , platform_info . linkage ) = platform . architecture ( ) <newline> platform_info . machine = platform . machine ( ) <newline> platform_info . release = platform . release ( ) <newline> platform_info . system = platform . system ( ) <newline> platform_info . version = platform . version ( ) <newline> return platform_info <newline> <dedent>
from esc import NUL , blank <newline> import escargs <newline> import esccmd <newline> import escio <newline> from esctypes import Point , Rect <newline> from escutil import AssertEQ , AssertScreenCharsInRectEqual , GetCursorPosition , knownBug <newline> class DECSELTests ( object ) : <newline> <indent> def prepare ( self ) : <newline> <indent>  """ Initializes ▁ the ▁ screen ▁ to ▁ abcdefghij ▁ on ▁ the ▁ first ▁ line ▁ with ▁ the ▁ cursor <strnewline> ▁ on ▁ the ▁'e'. """  <newline> esccmd . CUP ( Point ( 1 , 1 ) ) <newline> escio . Write ( "abcdefghij" ) <newline> esccmd . CUP ( Point ( 5 , 1 ) ) <newline> <dedent> @ knownBug ( terminal = "iTerm2" , reason = "Not ▁ implemented" ) <newline> def test_DECSEL_Default ( self ) : <newline> <indent>  """ Should ▁ erase ▁ to ▁ right ▁ of ▁ cursor. """  <newline> self . prepare ( ) <newline> esccmd . DECSEL ( ) <newline> AssertScreenCharsInRectEqual ( Rect ( 1 , 1 , 10 , 1 ) , [ "abcd" + 6 * NUL ] ) <newline> <dedent> @ knownBug ( terminal = "iTerm2" , reason = "Not ▁ implemented" ) <newline> def test_DECSEL_0 ( self ) : <newline> <indent>  """ Should ▁ erase ▁ to ▁ right ▁ of ▁ cursor. """  <newline> self . prepare ( ) <newline> esccmd . DECSEL ( 0 ) <newline> AssertScreenCharsInRectEqual ( Rect ( 1 , 1 , 10 , 1 ) , [ "abcd" + 6 * NUL ] ) <newline> <dedent> @ knownBug ( terminal = "iTerm2" , reason = "Not ▁ implemented" ) <newline> def test_DECSEL_1 ( self ) : <newline> <indent>  """ Should ▁ erase ▁ to ▁ left ▁ of ▁ cursor. """  <newline> self . prepare ( ) <newline> esccmd . DECSEL ( 1 ) <newline> AssertScreenCharsInRectEqual ( Rect ( 1 , 1 , 10 , 1 ) , [ 5 * blank ( ) + "fghij" ] ) <newline> <dedent> @ knownBug ( terminal = "iTerm2" , reason = "Not ▁ implemented" ) <newline> def test_DECSEL_2 ( self ) : <newline> <indent>  """ Should ▁ erase ▁ whole ▁ line. """  <newline> self . prepare ( ) <newline> esccmd . DECSEL ( 2 ) <newline> AssertScreenCharsInRectEqual ( Rect ( 1 , 1 , 10 , 1 ) , [ 10 * NUL ] ) <newline> <dedent> @ knownBug ( terminal = "iTerm2" , reason = "Not ▁ implemented" ) <newline> def test_DECSEL_IgnoresScrollRegion ( self ) : <newline> <indent>  """ Should ▁ erase ▁ whole ▁ line. """  <newline> self . prepare ( ) <newline> esccmd . DECSET ( esccmd . DECLRMM ) <newline> esccmd . DECSLRM ( 2 , 4 ) <newline> esccmd . CUP ( Point ( 5 , 1 ) ) <newline> esccmd . DECSEL ( 2 ) <newline> esccmd . DECRESET ( esccmd . DECLRMM ) <newline> AssertScreenCharsInRectEqual ( Rect ( 1 , 1 , 10 , 1 ) , [ 10 * NUL ] ) <newline> <dedent> @ knownBug ( terminal = "iTerm2" , reason = "Not ▁ implemented" ) <newline> def test_DECSEL_Default_Protection ( self ) : <newline> <indent>  """ Should ▁ erase ▁ to ▁ right ▁ of ▁ cursor. """  <newline> esccmd . DECSCA ( 1 ) <newline> self . prepare ( ) <newline>  # ▁ Write ▁ an ▁ X ▁ at ▁ 1,1 ▁ without ▁ protection <encdom> esccmd . DECSCA ( 0 ) <newline> esccmd . CUP ( Point ( 10 , 1 ) ) <newline> escio . Write ( "X" ) <newline> esccmd . CUP ( Point ( 5 , 1 ) ) <newline> esccmd . DECSEL ( ) <newline> AssertScreenCharsInRectEqual ( Rect ( 1 , 1 , 10 , 1 ) , [ "abcdefghi" + NUL ] ) <newline> <dedent> @ knownBug ( terminal = "iTerm2" , reason = "Not ▁ implemented" ) <newline> def test_DECSEL_0_Protection ( self ) : <newline> <indent>  """ All ▁ letters ▁ are ▁ protected ▁ so ▁ nothing ▁ should ▁ happen. """  <newline> esccmd . DECSCA ( 1 ) <newline> self . prepare ( ) <newline>  # ▁ Write ▁ an ▁ X ▁ at ▁ 1,1 ▁ without ▁ protection <encdom> esccmd . DECSCA ( 0 ) <newline> esccmd . CUP ( Point ( 10 , 1 ) ) <newline> escio . Write ( "X" ) <newline> esccmd . CUP ( Point ( 5 , 1 ) ) <newline> esccmd . DECSEL ( 0 ) <newline> AssertScreenCharsInRectEqual ( Rect ( 1 , 1 , 10 , 1 ) , [ "abcdefghi" + NUL ] ) <newline> <dedent> @ knownBug ( terminal = "iTerm2" , reason = "Not ▁ implemented" ) <newline> def test_DECSEL_1_Protection ( self ) : <newline> <indent>  """ All ▁ letters ▁ are ▁ protected ▁ so ▁ nothing ▁ should ▁ happen. """  <newline> esccmd . DECSCA ( 1 ) <newline> self . prepare ( ) <newline>  # ▁ Write ▁ an ▁ X ▁ at ▁ 1,1 ▁ without ▁ protection <encdom> esccmd . DECSCA ( 0 ) <newline> esccmd . CUP ( Point ( 1 , 1 ) ) <newline> escio . Write ( "X" ) <newline> esccmd . CUP ( Point ( 5 , 1 ) ) <newline> esccmd . DECSEL ( 1 ) <newline> AssertScreenCharsInRectEqual ( Rect ( 1 , 1 , 10 , 1 ) , [ blank ( ) + "bcdefghij" ] ) <newline> <dedent> @ knownBug ( terminal = "iTerm2" , reason = "Not ▁ implemented" ) <newline> def test_DECSEL_2_Protection ( self ) : <newline> <indent>  """ All ▁ letters ▁ are ▁ protected ▁ so ▁ nothing ▁ should ▁ happen. """  <newline> esccmd . DECSCA ( 1 ) <newline> self . prepare ( ) <newline>  # ▁ Write ▁ an ▁ X ▁ at ▁ 1,1 ▁ without ▁ protection <encdom> esccmd . DECSCA ( 0 ) <newline> esccmd . CUP ( Point ( 1 , 1 ) ) <newline> escio . Write ( "X" ) <newline> esccmd . DECSEL ( 2 ) <newline> AssertScreenCharsInRectEqual ( Rect ( 1 , 1 , 10 , 1 ) , [ blank ( ) + "bcdefghij" ] ) <newline> <dedent> @ knownBug ( terminal = "iTerm2" , reason = "Not ▁ implemented" ) <newline> def test_DECSEL_IgnoresScrollRegion_Protection ( self ) : <newline> <indent>  """ All ▁ letters ▁ are ▁ protected ▁ so ▁ nothing ▁ should ▁ happen. """  <newline> esccmd . DECSCA ( 1 ) <newline> self . prepare ( ) <newline>  # ▁ Write ▁ an ▁ X ▁ at ▁ 1,1 ▁ without ▁ protection <encdom> esccmd . DECSCA ( 0 ) <newline> esccmd . CUP ( Point ( 1 , 1 ) ) <newline> escio . Write ( "X" ) <newline> esccmd . DECSET ( esccmd . DECLRMM ) <newline> esccmd . DECSLRM ( 2 , 4 ) <newline> esccmd . CUP ( Point ( 5 , 1 ) ) <newline> esccmd . DECSEL ( 2 ) <newline> esccmd . DECRESET ( esccmd . DECLRMM ) <newline> AssertScreenCharsInRectEqual ( Rect ( 1 , 1 , 10 , 1 ) , [ blank ( ) + "bcdefghij" ] ) <newline> <dedent> @ knownBug ( terminal = "xterm" , reason = "DECSEL ▁ respects ▁ ISO ▁ protection ▁ for ▁ backward ▁ compatibility ▁ reasons, ▁ per ▁ email ▁ from ▁ Thomas" ) <newline> @ knownBug ( terminal = "iTerm2" , reason = "DECSED ▁ not ▁ implemented" ) <newline> def test_DECSEL_doesNotRespectISOProtect ( self ) : <newline> <indent>  """ DECSEL ▁ does ▁ not ▁ respect ▁ ISO ▁ protection. """  <newline> escio . Write ( "a" ) <newline> esccmd . SPA ( ) <newline> escio . Write ( "b" ) <newline> esccmd . EPA ( ) <newline> esccmd . DECSEL ( 2 ) <newline> AssertScreenCharsInRectEqual ( Rect ( 1 , 1 , 2 , 1 ) , [ blank ( ) * 2 ] ) <newline> <dedent> <dedent>
 # ▁ -*- ▁ coding: ▁ utf-8 ▁ -*- <encdom> import os <newline> import sys <newline> sys . path . insert ( 0 , os . path . abspath ( os . path . join ( os . path . dirname ( __file__ ) , '..' ) ) ) <newline> import core <newline>
 # ▁ Copyright ▁ 2017 ▁ The ▁ TensorFlow ▁ Authors. ▁ All ▁ Rights ▁ Reserved. <encdom>  # ▁ Licensed ▁ under ▁ the ▁ Apache ▁ License, ▁ Version ▁ 2.0 ▁ (the ▁'License'); <encdom>  # ▁ you ▁ may ▁ not ▁ use ▁ this ▁ file ▁ except ▁ in ▁ compliance ▁ with ▁ the ▁ License. <encdom>  # ▁ You ▁ may ▁ obtain ▁ a ▁ copy ▁ of ▁ the ▁ License ▁ at <encdom>  # ▁ http://www.apache.org/licenses/LICENSE-2.0 <encdom>  # ▁ Unless ▁ required ▁ by ▁ applicable ▁ law ▁ or ▁ agreed ▁ to ▁ in ▁ writing, ▁ software <encdom>  # ▁ distributed ▁ under ▁ the ▁ License ▁ is ▁ distributed ▁ on ▁ an ▁'AS ▁ IS' ▁ BASIS, <encdom>  # ▁ WITHOUT ▁ WARRANTIES ▁ OR ▁ CONDITIONS ▁ OF ▁ ANY ▁ KIND, ▁ either ▁ express ▁ or ▁ implied. <encdom>  # ▁ See ▁ the ▁ License ▁ for ▁ the ▁ specific ▁ language ▁ governing ▁ permissions ▁ and <encdom>  # ▁ limitations ▁ under ▁ the ▁ License. <encdom>  """ Tests ▁ for ▁ pprof_profiler. """  <newline> from __future__ import absolute_import <newline> from __future__ import division <newline> from __future__ import print_function <newline> import gzip <newline> from proto import profile_pb2 <newline> from tensorflow . core . framework import step_stats_pb2 <newline> from tensorflow . core . protobuf import config_pb2 <newline> from tensorflow . python . framework import constant_op <newline> from tensorflow . python . ops import control_flow_ops <newline> from tensorflow . python . ops import math_ops <newline> from tensorflow . python . platform import test <newline> from tensorflow . python . profiler import pprof_profiler <newline> class PprofProfilerTest ( test . TestCase ) : <newline> <indent> def testDataEmpty ( self ) : <newline> <indent> output_dir = test . get_temp_dir ( ) <newline> run_metadata = config_pb2 . RunMetadata ( ) <newline> graph = test . mock . MagicMock ( ) <newline> graph . get_operations . return_value = [ ] <newline> profiles = pprof_profiler . get_profiles ( graph , run_metadata ) <newline> self . assertEquals ( 0 , len ( profiles ) ) <newline> profile_files = pprof_profiler . profile ( graph , run_metadata , output_dir ) <newline> self . assertEquals ( 0 , len ( profile_files ) ) <newline> <dedent> def testRunMetadataEmpty ( self ) : <newline> <indent> output_dir = test . get_temp_dir ( ) <newline> run_metadata = config_pb2 . RunMetadata ( ) <newline> graph = test . mock . MagicMock ( ) <newline> op1 = test . mock . MagicMock ( ) <newline> op1 . name = 'Add/123' <newline> op1 . traceback = [ ( 'a/b/file1' , 10 , 'some_var' ) ] <newline> op1 . type = 'add' <newline> graph . get_operations . return_value = [ op1 ] <newline> profiles = pprof_profiler . get_profiles ( graph , run_metadata ) <newline> self . assertEquals ( 0 , len ( profiles ) ) <newline> profile_files = pprof_profiler . profile ( graph , run_metadata , output_dir ) <newline> self . assertEquals ( 0 , len ( profile_files ) ) <newline> <dedent> def testValidProfile ( self ) : <newline> <indent> output_dir = test . get_temp_dir ( ) <newline> run_metadata = config_pb2 . RunMetadata ( ) <newline> node1 = step_stats_pb2 . NodeExecStats ( node_name = 'Add/123' , op_start_rel_micros = 3 , op_end_rel_micros = 5 , all_end_rel_micros = 4 ) <newline> run_metadata = config_pb2 . RunMetadata ( ) <newline> device1 = run_metadata . step_stats . dev_stats . add ( ) <newline> device1 . device = 'deviceA' <newline> device1 . node_stats . extend ( [ node1 ] ) <newline> graph = test . mock . MagicMock ( ) <newline> op1 = test . mock . MagicMock ( ) <newline> op1 . name = 'Add/123' <newline> op1 . traceback = [ ( 'a/b/file1' , 10 , 'apply_op' , 'abc' ) , ( 'a/c/file2' , 12 , 'my_op' , 'def' ) ] <newline> op1 . type = 'add' <newline> graph . get_operations . return_value = [ op1 ] <newline> expected_proto =  """ sample_type ▁ { <strnewline> ▁ ▁ type: ▁ 5 <strnewline> ▁ ▁ unit: ▁ 5 <strnewline> } <strnewline> sample_type ▁ { <strnewline> ▁ ▁ type: ▁ 6 <strnewline> ▁ ▁ unit: ▁ 7 <strnewline> } <strnewline> sample_type ▁ { <strnewline> ▁ ▁ type: ▁ 8 <strnewline> ▁ ▁ unit: ▁ 7 <strnewline> } <strnewline> sample ▁ { <strnewline> ▁ ▁ value: ▁ 1 <strnewline> ▁ ▁ value: ▁ 4 <strnewline> ▁ ▁ value: ▁ 2 <strnewline> ▁ ▁ label ▁ { <strnewline> ▁ ▁ ▁ ▁ key: ▁ 1 <strnewline> ▁ ▁ ▁ ▁ str: ▁ 2 <strnewline> ▁ ▁ } <strnewline> ▁ ▁ label ▁ { <strnewline> ▁ ▁ ▁ ▁ key: ▁ 3 <strnewline> ▁ ▁ ▁ ▁ str: ▁ 4 <strnewline> ▁ ▁ } <strnewline> } <strnewline> string_table: ▁"" <strnewline> string_table: ▁"node_name" <strnewline> string_table: ▁"Add/123" <strnewline> string_table: ▁"op_type" <strnewline> string_table: ▁"add" <strnewline> string_table: ▁"count" <strnewline> string_table: ▁"all_time" <strnewline> string_table: ▁"nanoseconds" <strnewline> string_table: ▁"op_time" <strnewline> string_table: ▁"Device ▁ 1 ▁ of ▁ 1: ▁ deviceA" <strnewline> comment: ▁ 9 <strnewline> """  <newline>  # ▁ Test ▁ with ▁ protos <encdom> profiles = pprof_profiler . get_profiles ( graph , run_metadata ) <newline> self . assertEquals ( 1 , len ( profiles ) ) <newline> self . assertTrue ( 'deviceA' in profiles ) <newline> self . assertEquals ( expected_proto , str ( profiles [ 'deviceA' ] ) ) <newline>  # ▁ Test ▁ with ▁ files <encdom> profile_files = pprof_profiler . profile ( graph , run_metadata , output_dir ) <newline> self . assertEquals ( 1 , len ( profile_files ) ) <newline> with gzip . open ( profile_files [ 0 ] ) as profile_file : <newline> <indent> profile_contents = profile_file . read ( ) <newline> profile = profile_pb2 . Profile ( ) <newline> profile . ParseFromString ( profile_contents ) <newline> self . assertEquals ( expected_proto , str ( profile ) ) <newline> <dedent> <dedent> def testProfileWithWhileLoop ( self ) : <newline> <indent> options = config_pb2 . RunOptions ( ) <newline> options . trace_level = config_pb2 . RunOptions . FULL_TRACE <newline> run_metadata = config_pb2 . RunMetadata ( ) <newline> num_iters = 5 <newline> with self . test_session ( ) as sess : <newline> <indent> i = constant_op . constant ( 0 ) <newline> c = lambda i : math_ops . less ( i , num_iters ) <newline> b = lambda i : math_ops . add ( i , 1 ) <newline> r = control_flow_ops . while_loop ( c , b , [ i ] ) <newline> sess . run ( r , options = options , run_metadata = run_metadata ) <newline> profiles = pprof_profiler . get_profiles ( sess . graph , run_metadata ) <newline> self . assertEquals ( 1 , len ( profiles ) ) <newline> profile = next ( iter ( profiles . values ( ) ) ) <newline> add_samples = [ ]  # ▁ Samples ▁ for ▁ the ▁ while/Add ▁ node <encdom> <newline> for sample in profile . sample : <newline> <indent> if profile . string_table [ sample . label [ 0 ] . str ] == 'while/Add' : <newline> <indent> add_samples . append ( sample ) <newline>  # ▁ Values ▁ for ▁ same ▁ nodes ▁ are ▁ aggregated. <encdom> <dedent> <dedent> self . assertEquals ( 1 , len ( add_samples ) ) <newline>  # ▁ Value ▁ of ▁"count" ▁ should ▁ be ▁ equal ▁ to ▁ number ▁ of ▁ iterations. <encdom> self . assertEquals ( num_iters , add_samples [ 0 ] . value [ 0 ] ) <newline> <dedent> <dedent> <dedent> if __name__ == '__main__' : <newline> <indent> test . main ( ) <newline> <dedent>
 """ <strnewline> Ecuador-specific ▁ form ▁ helpers. <strnewline> """  <newline> from __future__ import absolute_import <newline> from django . contrib . localflavor . ec . ec_provinces import PROVINCE_CHOICES <newline> from django . forms . fields import Select <newline> class ECProvinceSelect ( Select ) : <newline> <indent>  """ <strnewline> ▁ A ▁ Select ▁ widget ▁ that ▁ uses ▁ a ▁ list ▁ of ▁ Ecuador ▁ provinces ▁ as ▁ its ▁ choices. <strnewline> ▁ """  <newline> def __init__ ( self , attrs = None ) : <newline> <indent> super ( ECProvinceSelect , self ) . __init__ ( attrs , choices = PROVINCE_CHOICES ) <newline> <dedent> <dedent>
 # !/usr/local/bin/python2.7 <encdom> import sys <newline> import os <newline> import time <newline> import logging <newline> import smtplib <newline> import socket <newline> from sitel . environment import ActiveMQ <newline> from sitel . environment import proxy_email <newline> from stompest . config import StompConfig <newline> from stompest . protocol import StompSpec <newline> from stompest . sync import Stomp <newline> from subprocess import call <newline> from daemon import runner <newline> from logging . handlers import TimedRotatingFileHandler <newline>  # ▁ HOST ▁ = ▁"localhost" <encdom>  # ▁ PORT ▁ = ▁ 61613 <encdom>  # ▁ TOPIC ▁ = ▁"filesync" <encdom>  # ▁ SRCDIR ▁ = ▁"/mnt/nfs_files" <encdom>  # ▁ DSTDIR ▁ = ▁"/var/www/files" <encdom> LOGFILE = '/var/log/lms2/daemon_nfssync.log' <newline> PIDFILE = '/tmp/nfssync.pid' <newline> STDIN = '/dev/null' <newline> STDOUT = '/dev/tty' <newline> STDERR = '/dev/tty' <newline> TIMEOUT = 5 <newline> processgid = 0  # ▁ 1048 ▁ apache, ▁ run ▁ as ▁ root ▁ for ▁ now <encdom> <newline> processuid = 0  # ▁ 1048 ▁ apache, ▁ run ▁ as ▁ root ▁ for ▁ now <encdom> <newline> hostname = socket . gethostname ( ) <newline> email_subject_warning = "NFSSYNC ▁ warning ▁ on ▁ %s" % hostname <newline> email_subject_error = "NFSSYNC ▁ error ▁ on ▁ %s" % hostname <newline> class LmsSync ( ) : <newline> <indent> def __init__ ( self ) : <newline> <indent> self . stdin_path = STDIN <newline> self . stdout_path = STDOUT <newline> self . stderr_path = STDERR <newline> self . pidfile_path = PIDFILE <newline> self . pidfile_timeout = TIMEOUT <newline> <dedent> def run ( self ) : <newline> <indent> if ( processgid > 0 ) : os . setgid ( processgid ) <newline> if ( processuid > 0 ) : os . setuid ( processuid ) <newline> config = StompConfig ( 'tcp://%(HOST)s:%(PORT)s' % ActiveMQ ) <newline> topic = "/topic/%(FILESYNCTOPIC)s" % ActiveMQ <newline> client = Stomp ( config ) <newline> self . logger = logging . getLogger ( 'nfssync' ) <newline> self . logger . setLevel ( logging . DEBUG ) <newline> handler = TimedRotatingFileHandler ( LOGFILE , when = 'midnight' , interval = 1 , backupCount = 30 ) <newline> formatter = logging . Formatter ( '%(asctime)s ▁ - ▁ %(name)s ▁ - ▁ %(levelname)s ▁ - ▁ %(message)s' ) <newline> handler . setFormatter ( formatter ) <newline> self . logger . addHandler ( handler ) <newline> try : <newline> <indent> client . connect ( ) <newline> client . subscribe ( topic , { StompSpec . ACK_HEADER : StompSpec . ACK_CLIENT_INDIVIDUAL } ) <newline> while True : <newline> <indent> frame = client . receiveFrame ( ) <newline> subdir = frame . body <newline> srcpath = os . path . join ( ActiveMQ [ 'SRCDIR' ] , subdir ) <newline> dstpath = os . path . dirname ( os . path . join ( ActiveMQ [ 'DSTDIR' ] , subdir ) ) <newline> self . logger . info ( "Syncing ▁ %s ▁ to ▁ %s" % ( srcpath , dstpath ) ) <newline> if ( not os . path . exists ( srcpath ) ) : <newline> <indent> msg = "Source ▁ %s ▁ does ▁ not ▁ exist" % srcpath <newline> self . logger . error ( msg ) <newline> proxy_email ( email_subject_error , msg ) <newline> client . ack ( frame ) <newline> continue <newline> <dedent> elif ( not os . path . isdir ( srcpath ) ) : <newline> <indent> msg = "Source ▁ %s ▁ is ▁ not ▁ a ▁ directory" % srcpath <newline> self . logger . error ( msg ) <newline> proxy_email ( email_subject_error , msg ) <newline> client . ack ( frame ) <newline> continue <newline> <dedent> elif ( not os . path . exists ( dstpath ) ) : <newline> <indent> msg = "Destination ▁ %s ▁ does ▁ not ▁ exist" % dstpath <newline> self . logger . warning ( msg ) <newline> proxy_email ( email_subject_warning , msg ) <newline> os . umask ( 0 ) <newline> os . makedirs ( dstpath , 0 777 ) <newline> <dedent> cmd = "rsync ▁ -avzq ▁ --delete ▁ %s ▁ %s" % ( srcpath , dstpath ) <newline> if ( call ( cmd , shell = True ) > 0 ) : <newline> <indent> msg = "Sync ▁ %s ▁ failed" % cmd <newline> self . logger . error ( msg ) <newline> proxy_email ( email_subject , msg ) <newline> <dedent> client . ack ( frame ) <newline> <dedent> <dedent> except Exception , e : <newline> <indent> msg = "Exception ▁ in ▁ %s: ▁ %s" % ( sys . argv [ 0 ] , str ( e ) ) <newline> self . logger . error ( msg ) <newline> proxy_email ( email_subject_error , msg ) <newline> exit ( 1 ) <newline> <dedent> <dedent> <dedent> if ( sys . argv [ 1 ] == "status" ) : <newline> <indent> if ( os . path . exists ( PIDFILE ) ) : <newline> <indent> pid = int ( open ( PIDFILE , "r" ) . read ( ) ) <newline> try : <newline> <indent> os . kill ( pid , 0 ) <newline> exit ( 0 ) <newline> <dedent> except Exception , e : <newline> <indent> exit ( 1 ) <newline> <dedent> <dedent> else : <newline> <indent> exit ( 1 ) <newline> <dedent> <dedent> app = LmsSync ( ) <newline> daemon_runner = runner . DaemonRunner ( app ) <newline> daemon_runner . do_action ( ) <newline>
 """ <strnewline> Testing ▁ some ▁ internals ▁ of ▁ the ▁ template ▁ processing. ▁ These ▁ are ▁ *not* ▁ examples ▁ to ▁ be ▁ copied ▁ in ▁ user ▁ code. <strnewline> """  <newline> from __future__ import unicode_literals <newline> from unittest import TestCase <newline> from django . template import ( TokenParser , FilterExpression , Parser , Variable , Template , TemplateSyntaxError , Library ) <newline> from django . test import override_settings <newline> from django . utils import six <newline> class ParserTests ( TestCase ) : <newline> <indent> def test_token_parsing ( self ) : <newline>  # ▁ Tests ▁ for ▁ TokenParser ▁ behavior ▁ in ▁ the ▁ face ▁ of ▁ quoted ▁ strings ▁ with <encdom>  # ▁ spaces. <encdom> <indent> p = TokenParser ( "tag ▁ thevar|filter ▁ sometag" ) <newline> self . assertEqual ( p . tagname , "tag" ) <newline> self . assertEqual ( p . value ( ) , "thevar|filter" ) <newline> self . assertTrue ( p . more ( ) ) <newline> self . assertEqual ( p . tag ( ) , "sometag" ) <newline> self . assertFalse ( p . more ( ) ) <newline> p = TokenParser ( 'tag ▁"a ▁ value"|filter ▁ sometag' ) <newline> self . assertEqual ( p . tagname , "tag" ) <newline> self . assertEqual ( p . value ( ) , '"a ▁ value"|filter' ) <newline> self . assertTrue ( p . more ( ) ) <newline> self . assertEqual ( p . tag ( ) , "sometag" ) <newline> self . assertFalse ( p . more ( ) ) <newline> p = TokenParser ( "tag ▁'a ▁ value'|filter ▁ sometag" ) <newline> self . assertEqual ( p . tagname , "tag" ) <newline> self . assertEqual ( p . value ( ) , "'a ▁ value'|filter" ) <newline> self . assertTrue ( p . more ( ) ) <newline> self . assertEqual ( p . tag ( ) , "sometag" ) <newline> self . assertFalse ( p . more ( ) ) <newline> <dedent> def test_filter_parsing ( self ) : <newline> <indent> c = { "article" : { "section" : "News" } } <newline> p = Parser ( "" ) <newline> def fe_test ( s , val ) : <newline> <indent> self . assertEqual ( FilterExpression ( s , p ) . resolve ( c ) , val ) <newline> <dedent> fe_test ( "article.section" , "News" ) <newline> fe_test ( "article.section|upper" , "NEWS" ) <newline> fe_test ( '"News"' , "News" ) <newline> fe_test ( "'News'" , "News" ) <newline> fe_test ( r'"Some ▁ \"Good\" ▁ News"' , 'Some ▁"Good" ▁ News' ) <newline> fe_test ( r'"Some ▁ \"Good\" ▁ News"' , 'Some ▁"Good" ▁ News' ) <newline> fe_test ( r"'Some ▁ \'Bad\' ▁ News'" , "Some ▁'Bad' ▁ News" ) <newline> fe = FilterExpression ( r'"Some ▁ \"Good\" ▁ News"' , p ) <newline> self . assertEqual ( fe . filters , [ ] ) <newline> self . assertEqual ( fe . var , 'Some ▁"Good" ▁ News' ) <newline>  # ▁ Filtered ▁ variables ▁ should ▁ reject ▁ access ▁ of ▁ attributes ▁ beginning ▁ with <encdom>  # ▁ underscores. <encdom> self . assertRaises ( TemplateSyntaxError , FilterExpression , "article._hidden|upper" , p ) <newline> <dedent> def test_variable_parsing ( self ) : <newline> <indent> c = { "article" : { "section" : "News" } } <newline> self . assertEqual ( Variable ( "article.section" ) . resolve ( c ) , "News" ) <newline> self . assertEqual ( Variable ( '"News"' ) . resolve ( c ) , "News" ) <newline> self . assertEqual ( Variable ( "'News'" ) . resolve ( c ) , "News" ) <newline>  # ▁ Translated ▁ strings ▁ are ▁ handled ▁ correctly. <encdom> self . assertEqual ( Variable ( "_(article.section)" ) . resolve ( c ) , "News" ) <newline> self . assertEqual ( Variable ( '_("Good ▁ News")' ) . resolve ( c ) , "Good ▁ News" ) <newline> self . assertEqual ( Variable ( "_('Better ▁ News')" ) . resolve ( c ) , "Better ▁ News" ) <newline>  # ▁ Escaped ▁ quotes ▁ work ▁ correctly ▁ as ▁ well. <encdom> self . assertEqual ( Variable ( r'"Some ▁ \"Good\" ▁ News"' ) . resolve ( c ) , 'Some ▁"Good" ▁ News' ) <newline> self . assertEqual ( Variable ( r"'Some ▁ \'Better\' ▁ News'" ) . resolve ( c ) , "Some ▁'Better' ▁ News" ) <newline>  # ▁ Variables ▁ should ▁ reject ▁ access ▁ of ▁ attributes ▁ beginning ▁ with <encdom>  # ▁ underscores. <encdom> self . assertRaises ( TemplateSyntaxError , Variable , "article._hidden" ) <newline>  # ▁ Variables ▁ should ▁ raise ▁ on ▁ non ▁ string ▁ type <encdom> with six . assertRaisesRegex ( self , TypeError , "Variable ▁ must ▁ be ▁ a ▁ string ▁ or ▁ number, ▁ got ▁ <(class|type) ▁'dict'>" ) : <newline> <indent> Variable ( { } ) <newline> <dedent> <dedent> @ override_settings ( DEBUG = True , TEMPLATE_DEBUG = True ) <newline> def test_compile_filter_error ( self ) : <newline>  # ▁ regression ▁ test ▁ for ▁ # 19819 <encdom> <indent> msg = "Could ▁ not ▁ parse ▁ the ▁ remainder: ▁'@bar' ▁ from ▁'foo@bar'" <newline> with six . assertRaisesRegex ( self , TemplateSyntaxError , msg ) as cm : <newline> <indent> Template ( "{% ▁ if ▁ 1 ▁ %}{{ ▁ foo@bar ▁ }}{% ▁ endif ▁ %}" ) <newline> <dedent> self . assertEqual ( cm . exception . django_template_source [ 1 ] , ( 10 , 23 ) ) <newline> <dedent> def test_filter_args_count ( self ) : <newline> <indent> p = Parser ( "" ) <newline> l = Library ( ) <newline> @ l . filter <newline> def no_arguments ( value ) : <newline> <indent> pass <newline> <dedent> @ l . filter <newline> def one_argument ( value , arg ) : <newline> <indent> pass <newline> <dedent> @ l . filter <newline> def one_opt_argument ( value , arg = False ) : <newline> <indent> pass <newline> <dedent> @ l . filter <newline> def two_arguments ( value , arg , arg2 ) : <newline> <indent> pass <newline> <dedent> @ l . filter <newline> def two_one_opt_arg ( value , arg , arg2 = False ) : <newline> <indent> pass <newline> <dedent> p . add_library ( l ) <newline> for expr in ( '1|no_arguments:"1"' , '1|two_arguments' , '1|two_arguments:"1"' , '1|two_one_opt_arg' , ) : <newline> <indent> with self . assertRaises ( TemplateSyntaxError ) : <newline> <indent> FilterExpression ( expr , p ) <newline> <dedent> <dedent> for expr in (  # ▁ Correct ▁ number ▁ of ▁ arguments <encdom> '1|no_arguments' , '1|one_argument:"1"' ,  # ▁ One ▁ optional <encdom> '1|one_opt_argument' , '1|one_opt_argument:"1"' ,  # ▁ Not ▁ supplying ▁ all <encdom> '1|two_one_opt_arg:"1"' , ) : <newline> <indent> FilterExpression ( expr , p ) <newline> <dedent> <dedent> <dedent>
import unittest <newline> from django . contrib . messages . middleware import MessageMiddleware <newline> from django . http import HttpRequest , HttpResponse <newline> class MiddlewareTests ( unittest . TestCase ) : <newline> <indent> def setUp ( self ) : <newline> <indent> self . middleware = MessageMiddleware ( ) <newline> <dedent> def test_response_without_messages ( self ) : <newline> <indent>  """ <strnewline> ▁ MessageMiddleware ▁ is ▁ tolerant ▁ of ▁ messages ▁ not ▁ existing ▁ on ▁ request. <strnewline> ▁ """  <newline> request = HttpRequest ( ) <newline> response = HttpResponse ( ) <newline> self . middleware . process_response ( request , response ) <newline> <dedent> <dedent>
 # # # # # ▁ BEGIN ▁ LICENSE ▁ BLOCK ▁ # # # # # <encdom>  # ▁ The ▁ Original ▁ Code ▁ is ▁ Mozilla ▁ Communicator ▁ client ▁ code. <encdom>  # ▁ The ▁ Initial ▁ Developer ▁ of ▁ the ▁ Original ▁ Code ▁ is <encdom>  # ▁ Netscape ▁ Communications ▁ Corporation. <encdom>  # ▁ Portions ▁ created ▁ by ▁ the ▁ Initial ▁ Developer ▁ are ▁ Copyright ▁ (C) ▁ 1998 <encdom>  # ▁ the ▁ Initial ▁ Developer. ▁ All ▁ Rights ▁ Reserved. <encdom>  # ▁ Contributor(s): <encdom>  # ▁ Mark ▁ Pilgrim ▁ - ▁ port ▁ to ▁ Python <encdom>  # ▁ This ▁ library ▁ is ▁ free ▁ software; ▁ you ▁ can ▁ redistribute ▁ it ▁ and/or <encdom>  # ▁ modify ▁ it ▁ under ▁ the ▁ terms ▁ of ▁ the ▁ GNU ▁ Lesser ▁ General ▁ Public <encdom>  # ▁ License ▁ as ▁ published ▁ by ▁ the ▁ Free ▁ Software ▁ Foundation; ▁ either <encdom>  # ▁ version ▁ 2.1 ▁ of ▁ the ▁ License, ▁ or ▁ (at ▁ your ▁ option) ▁ any ▁ later ▁ version. <encdom>  # ▁ This ▁ library ▁ is ▁ distributed ▁ in ▁ the ▁ hope ▁ that ▁ it ▁ will ▁ be ▁ useful, <encdom>  # ▁ but ▁ WITHOUT ▁ ANY ▁ WARRANTY; ▁ without ▁ even ▁ the ▁ implied ▁ warranty ▁ of <encdom>  # ▁ MERCHANTABILITY ▁ or ▁ FITNESS ▁ FOR ▁ A ▁ PARTICULAR ▁ PURPOSE. ▁ See ▁ the ▁ GNU <encdom>  # ▁ Lesser ▁ General ▁ Public ▁ License ▁ for ▁ more ▁ details. <encdom>  # ▁ You ▁ should ▁ have ▁ received ▁ a ▁ copy ▁ of ▁ the ▁ GNU ▁ Lesser ▁ General ▁ Public <encdom>  # ▁ License ▁ along ▁ with ▁ this ▁ library; ▁ if ▁ not, ▁ write ▁ to ▁ the ▁ Free ▁ Software <encdom>  # ▁ Foundation, ▁ Inc., ▁ 51 ▁ Franklin ▁ St, ▁ Fifth ▁ Floor, ▁ Boston, ▁ MA <encdom>  # ▁ 02110-1301 ▁ USA <encdom>  # # # # # ▁ END ▁ LICENSE ▁ BLOCK ▁ # # # # # <encdom> from . euctwfreq import ( EUCTW_CHAR_TO_FREQ_ORDER , EUCTW_TABLE_SIZE , EUCTW_TYPICAL_DISTRIBUTION_RATIO ) <newline> from . euckrfreq import ( EUCKR_CHAR_TO_FREQ_ORDER , EUCKR_TABLE_SIZE , EUCKR_TYPICAL_DISTRIBUTION_RATIO ) <newline> from . gb2312freq import ( GB2312_CHAR_TO_FREQ_ORDER , GB2312_TABLE_SIZE , GB2312_TYPICAL_DISTRIBUTION_RATIO ) <newline> from . big5freq import ( BIG5_CHAR_TO_FREQ_ORDER , BIG5_TABLE_SIZE , BIG5_TYPICAL_DISTRIBUTION_RATIO ) <newline> from . jisfreq import ( JIS_CHAR_TO_FREQ_ORDER , JIS_TABLE_SIZE , JIS_TYPICAL_DISTRIBUTION_RATIO ) <newline> class CharDistributionAnalysis ( object ) : <newline> <indent> ENOUGH_DATA_THRESHOLD = 1024 <newline> SURE_YES = 0.99 <newline> SURE_NO = 0.01 <newline> MINIMUM_DATA_THRESHOLD = 3 <newline> def __init__ ( self ) : <newline>  # ▁ Mapping ▁ table ▁ to ▁ get ▁ frequency ▁ order ▁ from ▁ char ▁ order ▁ (get ▁ from <encdom>  # ▁ GetOrder()) <encdom> <indent> self . _char_to_freq_order = None <newline> self . _table_size = None  # ▁ Size ▁ of ▁ above ▁ table <encdom> <newline>  # ▁ This ▁ is ▁ a ▁ constant ▁ value ▁ which ▁ varies ▁ from ▁ language ▁ to ▁ language, <encdom>  # ▁ used ▁ in ▁ calculating ▁ confidence. ▁ See <encdom>  # ▁ http://www.mozilla.org/projects/intl/UniversalCharsetDetection.html <encdom>  # ▁ for ▁ further ▁ detail. <encdom> self . typical_distribution_ratio = None <newline> self . _done = None <newline> self . _total_chars = None <newline> self . _freq_chars = None <newline> self . reset ( ) <newline> <dedent> def reset ( self ) : <newline> <indent>  """ reset ▁ analyser, ▁ clear ▁ any ▁ state """  <newline>  # ▁ If ▁ this ▁ flag ▁ is ▁ set ▁ to ▁ True, ▁ detection ▁ is ▁ done ▁ and ▁ conclusion ▁ has <encdom>  # ▁ been ▁ made <encdom> self . _done = False <newline> self . _total_chars = 0  # ▁ Total ▁ characters ▁ encountered <encdom> <newline>  # ▁ The ▁ number ▁ of ▁ characters ▁ whose ▁ frequency ▁ order ▁ is ▁ less ▁ than ▁ 512 <encdom> self . _freq_chars = 0 <newline> <dedent> def feed ( self , char , char_len ) : <newline> <indent>  """ feed ▁ a ▁ character ▁ with ▁ known ▁ length """  <newline> if char_len == 2 : <newline>  # ▁ we ▁ only ▁ care ▁ about ▁ 2-bytes ▁ character ▁ in ▁ our ▁ distribution ▁ analysis <encdom> <indent> order = self . get_order ( char ) <newline> <dedent> else : <newline> <indent> order = - 1 <newline> <dedent> if order >= 0 : <newline> <indent> self . _total_chars += 1 <newline>  # ▁ order ▁ is ▁ valid <encdom> if order < self . _table_size : <newline> <indent> if 512 > self . _char_to_freq_order [ order ] : <newline> <indent> self . _freq_chars += 1 <newline> <dedent> <dedent> <dedent> <dedent> def get_confidence ( self ) : <newline> <indent>  """ return ▁ confidence ▁ based ▁ on ▁ existing ▁ data """  <newline>  # ▁ if ▁ we ▁ didn't ▁ receive ▁ any ▁ character ▁ in ▁ our ▁ consideration ▁ range, <encdom>  # ▁ return ▁ negative ▁ answer <encdom> if self . _total_chars <= 0 or self . _freq_chars <= self . MINIMUM_DATA_THRESHOLD : <newline> <indent> return self . SURE_NO <newline> <dedent> if self . _total_chars != self . _freq_chars : <newline> <indent> r = ( self . _freq_chars / ( ( self . _total_chars - self . _freq_chars ) * self . typical_distribution_ratio ) ) <newline> if r < self . SURE_YES : <newline> <indent> return r <newline>  # ▁ normalize ▁ confidence ▁ (we ▁ don't ▁ want ▁ to ▁ be ▁ 100% ▁ sure) <encdom> <dedent> <dedent> return self . SURE_YES <newline> <dedent> def got_enough_data ( self ) : <newline>  # ▁ It ▁ is ▁ not ▁ necessary ▁ to ▁ receive ▁ all ▁ data ▁ to ▁ draw ▁ conclusion. <encdom>  # ▁ For ▁ charset ▁ detection, ▁ certain ▁ amount ▁ of ▁ data ▁ is ▁ enough <encdom> <indent> return self . _total_chars > self . ENOUGH_DATA_THRESHOLD <newline> <dedent> def get_order ( self , byte_str ) : <newline>  # ▁ We ▁ do ▁ not ▁ handle ▁ characters ▁ based ▁ on ▁ the ▁ original ▁ encoding ▁ string, <encdom>  # ▁ but ▁ convert ▁ this ▁ encoding ▁ string ▁ to ▁ a ▁ number, ▁ here ▁ called ▁ order. <encdom>  # ▁ This ▁ allows ▁ multiple ▁ encodings ▁ of ▁ a ▁ language ▁ to ▁ share ▁ one ▁ frequency <encdom>  # ▁ table. <encdom> <indent> return - 1 <newline> <dedent> <dedent> class EUCTWDistributionAnalysis ( CharDistributionAnalysis ) : <newline> <indent> def __init__ ( self ) : <newline> <indent> super ( EUCTWDistributionAnalysis , self ) . __init__ ( ) <newline> self . _char_to_freq_order = EUCTW_CHAR_TO_FREQ_ORDER <newline> self . _table_size = EUCTW_TABLE_SIZE <newline> self . typical_distribution_ratio = EUCTW_TYPICAL_DISTRIBUTION_RATIO <newline> <dedent> def get_order ( self , byte_str ) : <newline>  # ▁ for ▁ euc-TW ▁ encoding, ▁ we ▁ are ▁ interested <encdom>  # ▁ first ▁ byte ▁ range: ▁ 0xc4 ▁ -- ▁ 0xfe <encdom>  # ▁ second ▁ byte ▁ range: ▁ 0xa1 ▁ -- ▁ 0xfe <encdom>  # ▁ no ▁ validation ▁ needed ▁ here. ▁ State ▁ machine ▁ has ▁ done ▁ that <encdom> <indent> first_char = byte_str [ 0 ] <newline> if first_char >= 0xC4 : <newline> <indent> return 94 * ( first_char - 0xC4 ) + byte_str [ 1 ] - 0xA1 <newline> <dedent> else : <newline> <indent> return - 1 <newline> <dedent> <dedent> <dedent> class EUCKRDistributionAnalysis ( CharDistributionAnalysis ) : <newline> <indent> def __init__ ( self ) : <newline> <indent> super ( EUCKRDistributionAnalysis , self ) . __init__ ( ) <newline> self . _char_to_freq_order = EUCKR_CHAR_TO_FREQ_ORDER <newline> self . _table_size = EUCKR_TABLE_SIZE <newline> self . typical_distribution_ratio = EUCKR_TYPICAL_DISTRIBUTION_RATIO <newline> <dedent> def get_order ( self , byte_str ) : <newline>  # ▁ for ▁ euc-KR ▁ encoding, ▁ we ▁ are ▁ interested <encdom>  # ▁ first ▁ byte ▁ range: ▁ 0xb0 ▁ -- ▁ 0xfe <encdom>  # ▁ second ▁ byte ▁ range: ▁ 0xa1 ▁ -- ▁ 0xfe <encdom>  # ▁ no ▁ validation ▁ needed ▁ here. ▁ State ▁ machine ▁ has ▁ done ▁ that <encdom> <indent> first_char = byte_str [ 0 ] <newline> if first_char >= 0xB0 : <newline> <indent> return 94 * ( first_char - 0xB0 ) + byte_str [ 1 ] - 0xA1 <newline> <dedent> else : <newline> <indent> return - 1 <newline> <dedent> <dedent> <dedent> class GB2312DistributionAnalysis ( CharDistributionAnalysis ) : <newline> <indent> def __init__ ( self ) : <newline> <indent> super ( GB2312DistributionAnalysis , self ) . __init__ ( ) <newline> self . _char_to_freq_order = GB2312_CHAR_TO_FREQ_ORDER <newline> self . _table_size = GB2312_TABLE_SIZE <newline> self . typical_distribution_ratio = GB2312_TYPICAL_DISTRIBUTION_RATIO <newline> <dedent> def get_order ( self , byte_str ) : <newline>  # ▁ for ▁ GB2312 ▁ encoding, ▁ we ▁ are ▁ interested <encdom>  # ▁ first ▁ byte ▁ range: ▁ 0xb0 ▁ -- ▁ 0xfe <encdom>  # ▁ second ▁ byte ▁ range: ▁ 0xa1 ▁ -- ▁ 0xfe <encdom>  # ▁ no ▁ validation ▁ needed ▁ here. ▁ State ▁ machine ▁ has ▁ done ▁ that <encdom> <indent> first_char , second_char = byte_str [ 0 ] , byte_str [ 1 ] <newline> if ( first_char >= 0xB0 ) and ( second_char >= 0xA1 ) : <newline> <indent> return 94 * ( first_char - 0xB0 ) + second_char - 0xA1 <newline> <dedent> else : <newline> <indent> return - 1 <newline> <dedent> <dedent> <dedent> class Big5DistributionAnalysis ( CharDistributionAnalysis ) : <newline> <indent> def __init__ ( self ) : <newline> <indent> super ( Big5DistributionAnalysis , self ) . __init__ ( ) <newline> self . _char_to_freq_order = BIG5_CHAR_TO_FREQ_ORDER <newline> self . _table_size = BIG5_TABLE_SIZE <newline> self . typical_distribution_ratio = BIG5_TYPICAL_DISTRIBUTION_RATIO <newline> <dedent> def get_order ( self , byte_str ) : <newline>  # ▁ for ▁ big5 ▁ encoding, ▁ we ▁ are ▁ interested <encdom>  # ▁ first ▁ byte ▁ range: ▁ 0xa4 ▁ -- ▁ 0xfe <encdom>  # ▁ second ▁ byte ▁ range: ▁ 0x40 ▁ -- ▁ 0x7e ▁ , ▁ 0xa1 ▁ -- ▁ 0xfe <encdom>  # ▁ no ▁ validation ▁ needed ▁ here. ▁ State ▁ machine ▁ has ▁ done ▁ that <encdom> <indent> first_char , second_char = byte_str [ 0 ] , byte_str [ 1 ] <newline> if first_char >= 0xA4 : <newline> <indent> if second_char >= 0xA1 : <newline> <indent> return 157 * ( first_char - 0xA4 ) + second_char - 0xA1 + 63 <newline> <dedent> else : <newline> <indent> return 157 * ( first_char - 0xA4 ) + second_char - 0x40 <newline> <dedent> <dedent> else : <newline> <indent> return - 1 <newline> <dedent> <dedent> <dedent> class SJISDistributionAnalysis ( CharDistributionAnalysis ) : <newline> <indent> def __init__ ( self ) : <newline> <indent> super ( SJISDistributionAnalysis , self ) . __init__ ( ) <newline> self . _char_to_freq_order = JIS_CHAR_TO_FREQ_ORDER <newline> self . _table_size = JIS_TABLE_SIZE <newline> self . typical_distribution_ratio = JIS_TYPICAL_DISTRIBUTION_RATIO <newline> <dedent> def get_order ( self , byte_str ) : <newline>  # ▁ for ▁ sjis ▁ encoding, ▁ we ▁ are ▁ interested <encdom>  # ▁ first ▁ byte ▁ range: ▁ 0x81 ▁ -- ▁ 0x9f ▁ , ▁ 0xe0 ▁ -- ▁ 0xfe <encdom>  # ▁ second ▁ byte ▁ range: ▁ 0x40 ▁ -- ▁ 0x7e, ▁ 0x81 ▁ -- ▁ oxfe <encdom>  # ▁ no ▁ validation ▁ needed ▁ here. ▁ State ▁ machine ▁ has ▁ done ▁ that <encdom> <indent> first_char , second_char = byte_str [ 0 ] , byte_str [ 1 ] <newline> if ( first_char >= 0x81 ) and ( first_char <= 0x9F ) : <newline> <indent> order = 188 * ( first_char - 0x81 ) <newline> <dedent> elif ( first_char >= 0xE0 ) and ( first_char <= 0xEF ) : <newline> <indent> order = 188 * ( first_char - 0xE0 + 31 ) <newline> <dedent> else : <newline> <indent> return - 1 <newline> <dedent> order = order + second_char - 0x40 <newline> if second_char > 0x7F : <newline> <indent> order = - 1 <newline> <dedent> return order <newline> <dedent> <dedent> class EUCJPDistributionAnalysis ( CharDistributionAnalysis ) : <newline> <indent> def __init__ ( self ) : <newline> <indent> super ( EUCJPDistributionAnalysis , self ) . __init__ ( ) <newline> self . _char_to_freq_order = JIS_CHAR_TO_FREQ_ORDER <newline> self . _table_size = JIS_TABLE_SIZE <newline> self . typical_distribution_ratio = JIS_TYPICAL_DISTRIBUTION_RATIO <newline> <dedent> def get_order ( self , byte_str ) : <newline>  # ▁ for ▁ euc-JP ▁ encoding, ▁ we ▁ are ▁ interested <encdom>  # ▁ first ▁ byte ▁ range: ▁ 0xa0 ▁ -- ▁ 0xfe <encdom>  # ▁ second ▁ byte ▁ range: ▁ 0xa1 ▁ -- ▁ 0xfe <encdom>  # ▁ no ▁ validation ▁ needed ▁ here. ▁ State ▁ machine ▁ has ▁ done ▁ that <encdom> <indent> char = byte_str [ 0 ] <newline> if char >= 0xA0 : <newline> <indent> return 94 * ( char - 0xA1 ) + byte_str [ 1 ] - 0xa1 <newline> <dedent> else : <newline> <indent> return - 1 <newline> <dedent> <dedent> <dedent>
 # ▁ Copyright ▁ (c) ▁ 2017 ▁ Ansible ▁ Project <encdom>  # ▁ GNU ▁ General ▁ Public ▁ License ▁ v3.0+ ▁ (see ▁ COPYING ▁ or ▁ https://www.gnu.org/licenses/gpl-3.0.txt) <encdom>  # ▁ Make ▁ coding ▁ more ▁ python3-ish <encdom> from __future__ import ( absolute_import , division , print_function ) <newline> __metaclass__ = type <newline> class ConfigData ( object ) : <newline> <indent> def __init__ ( self ) : <newline> <indent> self . _global_settings = { } <newline> self . _plugins = { } <newline> <dedent> def get_setting ( self , name , plugin = None ) : <newline> <indent> setting = None <newline> if plugin is None : <newline> <indent> setting = self . _global_settings . get ( name ) <newline> <dedent> elif plugin . type in self . _plugins and plugin . name in self . _plugins [ plugin . type ] : <newline> <indent> setting = self . _plugins [ plugin . type ] [ plugin . name ] . get ( name ) <newline> <dedent> return setting <newline> <dedent> def get_settings ( self , plugin = None ) : <newline> <indent> settings = [ ] <newline> if plugin is None : <newline> <indent> settings = [ self . _global_settings [ k ] for k in self . _global_settings ] <newline> <dedent> elif plugin . type in self . _plugins and plugin . name in self . _plugins [ plugin . type ] : <newline> <indent> settings = [ self . _plugins [ plugin . type ] [ plugin . name ] [ k ] for k in self . _plugins [ plugin . type ] [ plugin . name ] ] <newline> <dedent> return settings <newline> <dedent> def update_setting ( self , setting , plugin = None ) : <newline> <indent> if plugin is None : <newline> <indent> self . _global_settings [ setting . name ] = setting <newline> <dedent> else : <newline> <indent> if plugin . type not in self . _plugins : <newline> <indent> self . _plugins [ plugin . type ] = { } <newline> <dedent> if plugin . name not in self . _plugins [ plugin . type ] : <newline> <indent> self . _plugins [ plugin . type ] [ plugin . name ] = { } <newline> <dedent> self . _plugins [ plugin . type ] [ plugin . name ] [ setting . name ] = setting <newline> <dedent> <dedent> <dedent>
 # !/usr/bin/python <encdom> import os <newline> import subprocess <newline> import re <newline> def runCommand ( command ) : <newline> <indent> p = subprocess . Popen ( command , stdout = subprocess . PIPE , stderr = subprocess . STDOUT ) <newline> p . wait ( ) <newline> return iter ( p . stdout . readline , b'' ) <newline> <dedent> def dumpRunCommand ( command , dump_file_name , postfix ) : <newline> <indent> dumpFile = open ( dump_file_name + postfix , "w+" ) <newline> dumpFile . write ( command + " \n " ) <newline> for line in runCommand ( command . split ( ) ) : <newline> <indent> dumpFile . write ( line ) <newline> <dedent> <dedent> def rmFile ( file_name ) : <newline> <indent> cmd = "rm ▁ -rf ▁ " + file_name <newline> runCommand ( cmd . split ( ) ) <newline> <dedent> def rnm_ir ( file_name ) : <newline>  # ▁ Append ▁ all ▁ unnamed ▁ variable ▁ with ▁ prefix ▁'tmp_' <encdom> <indent> ir_file_name = file_name + ".ll" <newline> if os . path . isfile ( ir_file_name ) : <newline> <indent> fo = open ( ir_file_name , "rw+" ) <newline> lines = fo . readlines ( ) <newline> fo . seek ( 0 ) <newline> fo . truncate ( ) <newline> for line in lines : <newline>  # ▁ Add ▁ entry ▁ block ▁ identifier <encdom> <indent> if "define" in line : <newline> <indent> line += "entry: \n " <newline>  # ▁ Rename ▁ all ▁ unnamed ▁ variables <encdom> <dedent> line = re . sub ( '\%([0-9]+)' , r'%tmp_\1' , line . rstrip ( ) ) <newline>  # ▁ Also ▁ rename ▁ branch ▁ name <encdom> line = re . sub ( '(\;\ ▁ \<label\>\:)([0-9]+)' , r'tmp_\2:' , line . rstrip ( ) ) <newline> fo . write ( line + ' \n ' ) <newline> <dedent> <dedent> <dedent> def gen_ir ( file_name ) : <newline>  # ▁ Directories <encdom> <indent> root_dir = '../../../' <newline> header_dir = root_dir + "inc/" <newline>  # ▁ Headers <encdom> header = " ▁ -I ▁ " + header_dir <newline> header += " ▁ -include ▁ " + header_dir + "m2c_buildin_fix.h ▁ " <newline> header += " ▁ -include ▁ " + header_dir + "clc/clc.h ▁ " <newline> header += " ▁ -D ▁ cl_clang_storage_class_specifiers ▁ " <newline> gen_ir = "clang ▁ -S ▁ -emit-llvm ▁ -O0 ▁ -target ▁ r600-- ▁ -mcpu=verde ▁ " <newline> cmd_gen_ir = gen_ir + header + file_name + ".cl" <newline> dumpRunCommand ( cmd_gen_ir , file_name , ".clang.log" ) <newline> <dedent> def asm_ir ( file_name ) : <newline> <indent> if os . path . isfile ( file_name + ".ll" ) : <newline>  # ▁ Command ▁ to ▁ assemble ▁ IR ▁ to ▁ bitcode <encdom> <indent> gen_bc = "llvm-as ▁ " <newline> gen_bc_src = file_name + ".ll" <newline> gen_bc_dst = file_name + ".bc" <newline> cmd_gen_bc = gen_bc + gen_bc_src + " ▁ -o ▁ " + gen_bc_dst <newline> runCommand ( cmd_gen_bc . split ( ) ) <newline> <dedent> <dedent> def opt_bc ( file_name ) : <newline> <indent> if os . path . isfile ( file_name + ".bc" ) : <newline>  # ▁ Command ▁ to ▁ optmize ▁ bitcode <encdom> <indent> opt_bc = "opt ▁ --mem2reg ▁ " <newline> opt_ir_src = file_name + ".bc" <newline> opt_ir_dst = file_name + ".opt.bc" <newline> cmd_opt_bc = opt_bc + opt_ir_src + " ▁ -o ▁ " + opt_ir_dst <newline> runCommand ( cmd_opt_bc . split ( ) ) <newline> <dedent> <dedent> def dis_bc ( file_name ) : <newline> <indent> if os . path . isfile ( file_name + ".bc" ) : <newline>  # ▁ Command ▁ to ▁ disassemble ▁ bitcode <encdom> <indent> dis_bc = "llvm-dis ▁ " <newline> dis_ir_src = file_name + ".opt.bc" <newline> dis_ir_dst = file_name + ".opt.ll" <newline> cmd_dis_bc = dis_bc + dis_ir_src + " ▁ -o ▁ " + dis_ir_dst <newline> runCommand ( cmd_dis_bc . split ( ) ) <newline> <dedent> <dedent> def m2c_gen ( file_name ) : <newline> <indent> if os . path . isfile ( file_name + ".opt.bc" ) : <newline>  # ▁ Command ▁ to ▁ disassemble ▁ bitcode <encdom> <indent> m2c_gen = "m2c ▁ --llvm2si ▁ " <newline> m2c_gen_src = file_name + ".opt.bc" <newline> cmd_m2c_gen = m2c_gen + m2c_gen_src <newline> dumpRunCommand ( cmd_m2c_gen , file_name , ".m2c.llvm2si.log" ) <newline>  # ▁ Remove ▁ file ▁ if ▁ size ▁ is ▁ 0 <encdom> <dedent> if os . path . isfile ( file_name + ".opt.s" ) : <newline> <indent> if os . path . getsize ( file_name + ".opt.s" ) == 0 : <newline> <indent> rmFile ( file_name + ".opt.s" ) <newline> <dedent> <dedent> <dedent> def m2c_bin ( file_name ) : <newline> <indent> if os . path . isfile ( file_name + ".opt.s" ) : <newline>  # ▁ Command ▁ to ▁ disassemble ▁ bitcode <encdom> <indent> m2c_bin = "m2c ▁ --si2bin ▁ " <newline> m2c_bin_src = file_name + ".opt.s" <newline> cmd_m2c_bin = m2c_bin + m2c_bin_src <newline> dumpRunCommand ( cmd_m2c_bin , file_name , ".m2c.si2bin.log" ) <newline> <dedent> <dedent> def main ( ) : <newline>  # ▁ Commands <encdom> <indent> for file in os . listdir ( "./" ) : <newline> <indent> if file . endswith ( ".cl" ) : <newline> <indent> file_name = os . path . splitext ( file ) [ 0 ] <newline>  # ▁ Execute ▁ commands <encdom> gen_ir ( file_name ) <newline> rnm_ir ( file_name ) <newline> asm_ir ( file_name ) <newline> opt_bc ( file_name ) <newline> dis_bc ( file_name ) <newline> m2c_gen ( file_name ) <newline> m2c_bin ( file_name ) <newline> <dedent> <dedent> <dedent> if __name__ == "__main__" : <newline> <indent> main ( ) <newline> <dedent>
 """ An ▁ XML ▁ Reader ▁ is ▁ the ▁ SAX ▁ 2 ▁ name ▁ for ▁ an ▁ XML ▁ parser. ▁ XML ▁ Parsers <strnewline> should ▁ be ▁ based ▁ on ▁ this ▁ code. ▁ """  <newline> from . import handler <newline> from . _exceptions import SAXNotSupportedException , SAXNotRecognizedException <newline>  # ▁ ===== ▁ XMLREADER ▁ ===== <encdom> class XMLReader : <newline> <indent>  """ Interface ▁ for ▁ reading ▁ an ▁ XML ▁ document ▁ using ▁ callbacks. <strnewline> <strnewline> ▁ XMLReader ▁ is ▁ the ▁ interface ▁ that ▁ an ▁ XML ▁ parser's ▁ SAX2 ▁ driver ▁ must <strnewline> ▁ implement. ▁ This ▁ interface ▁ allows ▁ an ▁ application ▁ to ▁ set ▁ and ▁ query <strnewline> ▁ features ▁ and ▁ properties ▁ in ▁ the ▁ parser, ▁ to ▁ register ▁ event ▁ handlers <strnewline> ▁ for ▁ document ▁ processing, ▁ and ▁ to ▁ initiate ▁ a ▁ document ▁ parse. <strnewline> <strnewline> ▁ All ▁ SAX ▁ interfaces ▁ are ▁ assumed ▁ to ▁ be ▁ synchronous: ▁ the ▁ parse <strnewline> ▁ methods ▁ must ▁ not ▁ return ▁ until ▁ parsing ▁ is ▁ complete, ▁ and ▁ readers <strnewline> ▁ must ▁ wait ▁ for ▁ an ▁ event-handler ▁ callback ▁ to ▁ return ▁ before ▁ reporting <strnewline> ▁ the ▁ next ▁ event. """  <newline> def __init__ ( self ) : <newline> <indent> self . _cont_handler = handler . ContentHandler ( ) <newline> self . _dtd_handler = handler . DTDHandler ( ) <newline> self . _ent_handler = handler . EntityResolver ( ) <newline> self . _err_handler = handler . ErrorHandler ( ) <newline> <dedent> def parse ( self , source ) : <newline> <indent> "Parse ▁ an ▁ XML ▁ document ▁ from ▁ a ▁ system ▁ identifier ▁ or ▁ an ▁ InputSource." <newline> raise NotImplementedError ( "This ▁ method ▁ must ▁ be ▁ implemented!" ) <newline> <dedent> def getContentHandler ( self ) : <newline> <indent> "Returns ▁ the ▁ current ▁ ContentHandler." <newline> return self . _cont_handler <newline> <dedent> def setContentHandler ( self , handler ) : <newline> <indent> "Registers ▁ a ▁ new ▁ object ▁ to ▁ receive ▁ document ▁ content ▁ events." <newline> self . _cont_handler = handler <newline> <dedent> def getDTDHandler ( self ) : <newline> <indent> "Returns ▁ the ▁ current ▁ DTD ▁ handler." <newline> return self . _dtd_handler <newline> <dedent> def setDTDHandler ( self , handler ) : <newline> <indent> "Register ▁ an ▁ object ▁ to ▁ receive ▁ basic ▁ DTD-related ▁ events." <newline> self . _dtd_handler = handler <newline> <dedent> def getEntityResolver ( self ) : <newline> <indent> "Returns ▁ the ▁ current ▁ EntityResolver." <newline> return self . _ent_handler <newline> <dedent> def setEntityResolver ( self , resolver ) : <newline> <indent> "Register ▁ an ▁ object ▁ to ▁ resolve ▁ external ▁ entities." <newline> self . _ent_handler = resolver <newline> <dedent> def getErrorHandler ( self ) : <newline> <indent> "Returns ▁ the ▁ current ▁ ErrorHandler." <newline> return self . _err_handler <newline> <dedent> def setErrorHandler ( self , handler ) : <newline> <indent> "Register ▁ an ▁ object ▁ to ▁ receive ▁ error-message ▁ events." <newline> self . _err_handler = handler <newline> <dedent> def setLocale ( self , locale ) : <newline> <indent>  """ Allow ▁ an ▁ application ▁ to ▁ set ▁ the ▁ locale ▁ for ▁ errors ▁ and ▁ warnings. <strnewline> <strnewline> ▁ SAX ▁ parsers ▁ are ▁ not ▁ required ▁ to ▁ provide ▁ localization ▁ for ▁ errors <strnewline> ▁ and ▁ warnings; ▁ if ▁ they ▁ cannot ▁ support ▁ the ▁ requested ▁ locale, <strnewline> ▁ however, ▁ they ▁ must ▁ raise ▁ a ▁ SAX ▁ exception. ▁ Applications ▁ may <strnewline> ▁ request ▁ a ▁ locale ▁ change ▁ in ▁ the ▁ middle ▁ of ▁ a ▁ parse. """  <newline> raise SAXNotSupportedException ( "Locale ▁ support ▁ not ▁ implemented" ) <newline> <dedent> def getFeature ( self , name ) : <newline> <indent> "Looks ▁ up ▁ and ▁ returns ▁ the ▁ state ▁ of ▁ a ▁ SAX2 ▁ feature." <newline> raise SAXNotRecognizedException ( "Feature ▁'%s' ▁ not ▁ recognized" % name ) <newline> <dedent> def setFeature ( self , name , state ) : <newline> <indent> "Sets ▁ the ▁ state ▁ of ▁ a ▁ SAX2 ▁ feature." <newline> raise SAXNotRecognizedException ( "Feature ▁'%s' ▁ not ▁ recognized" % name ) <newline> <dedent> def getProperty ( self , name ) : <newline> <indent> "Looks ▁ up ▁ and ▁ returns ▁ the ▁ value ▁ of ▁ a ▁ SAX2 ▁ property." <newline> raise SAXNotRecognizedException ( "Property ▁'%s' ▁ not ▁ recognized" % name ) <newline> <dedent> def setProperty ( self , name , value ) : <newline> <indent> "Sets ▁ the ▁ value ▁ of ▁ a ▁ SAX2 ▁ property." <newline> raise SAXNotRecognizedException ( "Property ▁'%s' ▁ not ▁ recognized" % name ) <newline> <dedent> <dedent> class IncrementalParser ( XMLReader ) : <newline> <indent>  """ This ▁ interface ▁ adds ▁ three ▁ extra ▁ methods ▁ to ▁ the ▁ XMLReader <strnewline> ▁ interface ▁ that ▁ allow ▁ XML ▁ parsers ▁ to ▁ support ▁ incremental <strnewline> ▁ parsing. ▁ Support ▁ for ▁ this ▁ interface ▁ is ▁ optional, ▁ since ▁ not ▁ all <strnewline> ▁ underlying ▁ XML ▁ parsers ▁ support ▁ this ▁ functionality. <strnewline> <strnewline> ▁ When ▁ the ▁ parser ▁ is ▁ instantiated ▁ it ▁ is ▁ ready ▁ to ▁ begin ▁ accepting <strnewline> ▁ data ▁ from ▁ the ▁ feed ▁ method ▁ immediately. ▁ After ▁ parsing ▁ has ▁ been <strnewline> ▁ finished ▁ with ▁ a ▁ call ▁ to ▁ close ▁ the ▁ reset ▁ method ▁ must ▁ be ▁ called ▁ to <strnewline> ▁ make ▁ the ▁ parser ▁ ready ▁ to ▁ accept ▁ new ▁ data, ▁ either ▁ from ▁ feed ▁ or <strnewline> ▁ using ▁ the ▁ parse ▁ method. <strnewline> <strnewline> ▁ Note ▁ that ▁ these ▁ methods ▁ must ▁ _not_ ▁ be ▁ called ▁ during ▁ parsing, ▁ that <strnewline> ▁ is, ▁ after ▁ parse ▁ has ▁ been ▁ called ▁ and ▁ before ▁ it ▁ returns. <strnewline> <strnewline> ▁ By ▁ default, ▁ the ▁ class ▁ also ▁ implements ▁ the ▁ parse ▁ method ▁ of ▁ the ▁ XMLReader <strnewline> ▁ interface ▁ using ▁ the ▁ feed, ▁ close ▁ and ▁ reset ▁ methods ▁ of ▁ the <strnewline> ▁ IncrementalParser ▁ interface ▁ as ▁ a ▁ convenience ▁ to ▁ SAX ▁ 2.0 ▁ driver <strnewline> ▁ writers. """  <newline> def __init__ ( self , bufsize = 2 ** 16 ) : <newline> <indent> self . _bufsize = bufsize <newline> XMLReader . __init__ ( self ) <newline> <dedent> def parse ( self , source ) : <newline> <indent> from . import saxutils <newline> source = saxutils . prepare_input_source ( source ) <newline> self . prepareParser ( source ) <newline> file = source . getCharacterStream ( ) <newline> if file is None : <newline> <indent> file = source . getByteStream ( ) <newline> <dedent> buffer = file . read ( self . _bufsize ) <newline> while buffer : <newline> <indent> self . feed ( buffer ) <newline> buffer = file . read ( self . _bufsize ) <newline> <dedent> self . close ( ) <newline> <dedent> def feed ( self , data ) : <newline> <indent>  """ This ▁ method ▁ gives ▁ the ▁ raw ▁ XML ▁ data ▁ in ▁ the ▁ data ▁ parameter ▁ to <strnewline> ▁ the ▁ parser ▁ and ▁ makes ▁ it ▁ parse ▁ the ▁ data, ▁ emitting ▁ the <strnewline> ▁ corresponding ▁ events. ▁ It ▁ is ▁ allowed ▁ for ▁ XML ▁ constructs ▁ to ▁ be <strnewline> ▁ split ▁ across ▁ several ▁ calls ▁ to ▁ feed. <strnewline> <strnewline> ▁ feed ▁ may ▁ raise ▁ SAXException. """  <newline> raise NotImplementedError ( "This ▁ method ▁ must ▁ be ▁ implemented!" ) <newline> <dedent> def prepareParser ( self , source ) : <newline> <indent>  """ This ▁ method ▁ is ▁ called ▁ by ▁ the ▁ parse ▁ implementation ▁ to ▁ allow <strnewline> ▁ the ▁ SAX ▁ 2.0 ▁ driver ▁ to ▁ prepare ▁ itself ▁ for ▁ parsing. """  <newline> raise NotImplementedError ( "prepareParser ▁ must ▁ be ▁ overridden!" ) <newline> <dedent> def close ( self ) : <newline> <indent>  """ This ▁ method ▁ is ▁ called ▁ when ▁ the ▁ entire ▁ XML ▁ document ▁ has ▁ been <strnewline> ▁ passed ▁ to ▁ the ▁ parser ▁ through ▁ the ▁ feed ▁ method, ▁ to ▁ notify ▁ the <strnewline> ▁ parser ▁ that ▁ there ▁ are ▁ no ▁ more ▁ data. ▁ This ▁ allows ▁ the ▁ parser ▁ to <strnewline> ▁ do ▁ the ▁ final ▁ checks ▁ on ▁ the ▁ document ▁ and ▁ empty ▁ the ▁ internal <strnewline> ▁ data ▁ buffer. <strnewline> <strnewline> ▁ The ▁ parser ▁ will ▁ not ▁ be ▁ ready ▁ to ▁ parse ▁ another ▁ document ▁ until <strnewline> ▁ the ▁ reset ▁ method ▁ has ▁ been ▁ called. <strnewline> <strnewline> ▁ close ▁ may ▁ raise ▁ SAXException. """  <newline> raise NotImplementedError ( "This ▁ method ▁ must ▁ be ▁ implemented!" ) <newline> <dedent> def reset ( self ) : <newline> <indent>  """ This ▁ method ▁ is ▁ called ▁ after ▁ close ▁ has ▁ been ▁ called ▁ to ▁ reset <strnewline> ▁ the ▁ parser ▁ so ▁ that ▁ it ▁ is ▁ ready ▁ to ▁ parse ▁ new ▁ documents. ▁ The <strnewline> ▁ results ▁ of ▁ calling ▁ parse ▁ or ▁ feed ▁ after ▁ close ▁ without ▁ calling <strnewline> ▁ reset ▁ are ▁ undefined. """  <newline> raise NotImplementedError ( "This ▁ method ▁ must ▁ be ▁ implemented!" ) <newline>  # ▁ ===== ▁ LOCATOR ▁ ===== <encdom> <dedent> <dedent> class Locator : <newline> <indent>  """ Interface ▁ for ▁ associating ▁ a ▁ SAX ▁ event ▁ with ▁ a ▁ document <strnewline> ▁ location. ▁ A ▁ locator ▁ object ▁ will ▁ return ▁ valid ▁ results ▁ only ▁ during <strnewline> ▁ calls ▁ to ▁ DocumentHandler ▁ methods; ▁ at ▁ any ▁ other ▁ time, ▁ the <strnewline> ▁ results ▁ are ▁ unpredictable. """  <newline> def getColumnNumber ( self ) : <newline> <indent> "Return ▁ the ▁ column ▁ number ▁ where ▁ the ▁ current ▁ event ▁ ends." <newline> return - 1 <newline> <dedent> def getLineNumber ( self ) : <newline> <indent> "Return ▁ the ▁ line ▁ number ▁ where ▁ the ▁ current ▁ event ▁ ends." <newline> return - 1 <newline> <dedent> def getPublicId ( self ) : <newline> <indent> "Return ▁ the ▁ public ▁ identifier ▁ for ▁ the ▁ current ▁ event." <newline> return None <newline> <dedent> def getSystemId ( self ) : <newline> <indent> "Return ▁ the ▁ system ▁ identifier ▁ for ▁ the ▁ current ▁ event." <newline> return None <newline>  # ▁ ===== ▁ INPUTSOURCE ▁ ===== <encdom> <dedent> <dedent> class InputSource : <newline> <indent>  """ Encapsulation ▁ of ▁ the ▁ information ▁ needed ▁ by ▁ the ▁ XMLReader ▁ to <strnewline> ▁ read ▁ entities. <strnewline> <strnewline> ▁ This ▁ class ▁ may ▁ include ▁ information ▁ about ▁ the ▁ public ▁ identifier, <strnewline> ▁ system ▁ identifier, ▁ byte ▁ stream ▁ (possibly ▁ with ▁ character ▁ encoding <strnewline> ▁ information) ▁ and/or ▁ the ▁ character ▁ stream ▁ of ▁ an ▁ entity. <strnewline> <strnewline> ▁ Applications ▁ will ▁ create ▁ objects ▁ of ▁ this ▁ class ▁ for ▁ use ▁ in ▁ the <strnewline> ▁ XMLReader.parse ▁ method ▁ and ▁ for ▁ returning ▁ from <strnewline> ▁ EntityResolver.resolveEntity. <strnewline> <strnewline> ▁ An ▁ InputSource ▁ belongs ▁ to ▁ the ▁ application, ▁ the ▁ XMLReader ▁ is ▁ not <strnewline> ▁ allowed ▁ to ▁ modify ▁ InputSource ▁ objects ▁ passed ▁ to ▁ it ▁ from ▁ the <strnewline> ▁ application, ▁ although ▁ it ▁ may ▁ make ▁ copies ▁ and ▁ modify ▁ those. """  <newline> def __init__ ( self , system_id = None ) : <newline> <indent> self . __system_id = system_id <newline> self . __public_id = None <newline> self . __encoding = None <newline> self . __bytefile = None <newline> self . __charfile = None <newline> <dedent> def setPublicId ( self , public_id ) : <newline> <indent> "Sets ▁ the ▁ public ▁ identifier ▁ of ▁ this ▁ InputSource." <newline> self . __public_id = public_id <newline> <dedent> def getPublicId ( self ) : <newline> <indent> "Returns ▁ the ▁ public ▁ identifier ▁ of ▁ this ▁ InputSource." <newline> return self . __public_id <newline> <dedent> def setSystemId ( self , system_id ) : <newline> <indent> "Sets ▁ the ▁ system ▁ identifier ▁ of ▁ this ▁ InputSource." <newline> self . __system_id = system_id <newline> <dedent> def getSystemId ( self ) : <newline> <indent> "Returns ▁ the ▁ system ▁ identifier ▁ of ▁ this ▁ InputSource." <newline> return self . __system_id <newline> <dedent> def setEncoding ( self , encoding ) : <newline> <indent>  """ Sets ▁ the ▁ character ▁ encoding ▁ of ▁ this ▁ InputSource. <strnewline> <strnewline> ▁ The ▁ encoding ▁ must ▁ be ▁ a ▁ string ▁ acceptable ▁ for ▁ an ▁ XML ▁ encoding <strnewline> ▁ declaration ▁ (see ▁ section ▁ 4.3.3 ▁ of ▁ the ▁ XML ▁ recommendation). <strnewline> <strnewline> ▁ The ▁ encoding ▁ attribute ▁ of ▁ the ▁ InputSource ▁ is ▁ ignored ▁ if ▁ the <strnewline> ▁ InputSource ▁ also ▁ contains ▁ a ▁ character ▁ stream. """  <newline> self . __encoding = encoding <newline> <dedent> def getEncoding ( self ) : <newline> <indent> "Get ▁ the ▁ character ▁ encoding ▁ of ▁ this ▁ InputSource." <newline> return self . __encoding <newline> <dedent> def setByteStream ( self , bytefile ) : <newline> <indent>  """ Set ▁ the ▁ byte ▁ stream ▁ (a ▁ Python ▁ file-like ▁ object ▁ which ▁ does <strnewline> ▁ not ▁ perform ▁ byte-to-character ▁ conversion) ▁ for ▁ this ▁ input <strnewline> ▁ source. <strnewline> <strnewline> ▁ The ▁ SAX ▁ parser ▁ will ▁ ignore ▁ this ▁ if ▁ there ▁ is ▁ also ▁ a ▁ character <strnewline> ▁ stream ▁ specified, ▁ but ▁ it ▁ will ▁ use ▁ a ▁ byte ▁ stream ▁ in ▁ preference <strnewline> ▁ to ▁ opening ▁ a ▁ URI ▁ connection ▁ itself. <strnewline> <strnewline> ▁ If ▁ the ▁ application ▁ knows ▁ the ▁ character ▁ encoding ▁ of ▁ the ▁ byte <strnewline> ▁ stream, ▁ it ▁ should ▁ set ▁ it ▁ with ▁ the ▁ setEncoding ▁ method. """  <newline> self . __bytefile = bytefile <newline> <dedent> def getByteStream ( self ) : <newline> <indent>  """ Get ▁ the ▁ byte ▁ stream ▁ for ▁ this ▁ input ▁ source. <strnewline> <strnewline> ▁ The ▁ getEncoding ▁ method ▁ will ▁ return ▁ the ▁ character ▁ encoding ▁ for <strnewline> ▁ this ▁ byte ▁ stream, ▁ or ▁ None ▁ if ▁ unknown. """  <newline> return self . __bytefile <newline> <dedent> def setCharacterStream ( self , charfile ) : <newline> <indent>  """ Set ▁ the ▁ character ▁ stream ▁ for ▁ this ▁ input ▁ source. ▁ (The ▁ stream <strnewline> ▁ must ▁ be ▁ a ▁ Python ▁ 2.0 ▁ Unicode-wrapped ▁ file-like ▁ that ▁ performs <strnewline> ▁ conversion ▁ to ▁ Unicode ▁ strings.) <strnewline> <strnewline> ▁ If ▁ there ▁ is ▁ a ▁ character ▁ stream ▁ specified, ▁ the ▁ SAX ▁ parser ▁ will <strnewline> ▁ ignore ▁ any ▁ byte ▁ stream ▁ and ▁ will ▁ not ▁ attempt ▁ to ▁ open ▁ a ▁ URI <strnewline> ▁ connection ▁ to ▁ the ▁ system ▁ identifier. """  <newline> self . __charfile = charfile <newline> <dedent> def getCharacterStream ( self ) : <newline> <indent> "Get ▁ the ▁ character ▁ stream ▁ for ▁ this ▁ input ▁ source." <newline> return self . __charfile <newline>  # ▁ ===== ▁ ATTRIBUTESIMPL ▁ ===== <encdom> <dedent> <dedent> class AttributesImpl : <newline> <indent> def __init__ ( self , attrs ) : <newline> <indent>  """ Non-NS-aware ▁ implementation. <strnewline> <strnewline> ▁ attrs ▁ should ▁ be ▁ of ▁ the ▁ form ▁ {name ▁ : ▁ value}. """  <newline> self . _attrs = attrs <newline> <dedent> def getLength ( self ) : <newline> <indent> return len ( self . _attrs ) <newline> <dedent> def getType ( self , name ) : <newline> <indent> return "CDATA" <newline> <dedent> def getValue ( self , name ) : <newline> <indent> return self . _attrs [ name ] <newline> <dedent> def getValueByQName ( self , name ) : <newline> <indent> return self . _attrs [ name ] <newline> <dedent> def getNameByQName ( self , name ) : <newline> <indent> if name not in self . _attrs : <newline> <indent> raise KeyError ( name ) <newline> <dedent> return name <newline> <dedent> def getQNameByName ( self , name ) : <newline> <indent> if name not in self . _attrs : <newline> <indent> raise KeyError ( name ) <newline> <dedent> return name <newline> <dedent> def getNames ( self ) : <newline> <indent> return list ( self . _attrs . keys ( ) ) <newline> <dedent> def getQNames ( self ) : <newline> <indent> return list ( self . _attrs . keys ( ) ) <newline> <dedent> def __len__ ( self ) : <newline> <indent> return len ( self . _attrs ) <newline> <dedent> def __getitem__ ( self , name ) : <newline> <indent> return self . _attrs [ name ] <newline> <dedent> def keys ( self ) : <newline> <indent> return list ( self . _attrs . keys ( ) ) <newline> <dedent> def __contains__ ( self , name ) : <newline> <indent> return name in self . _attrs <newline> <dedent> def get ( self , name , alternative = None ) : <newline> <indent> return self . _attrs . get ( name , alternative ) <newline> <dedent> def copy ( self ) : <newline> <indent> return self . __class__ ( self . _attrs ) <newline> <dedent> def items ( self ) : <newline> <indent> return list ( self . _attrs . items ( ) ) <newline> <dedent> def values ( self ) : <newline> <indent> return list ( self . _attrs . values ( ) ) <newline>  # ▁ ===== ▁ ATTRIBUTESNSIMPL ▁ ===== <encdom> <dedent> <dedent> class AttributesNSImpl ( AttributesImpl ) : <newline> <indent> def __init__ ( self , attrs , qnames ) : <newline> <indent>  """ NS-aware ▁ implementation. <strnewline> <strnewline> ▁ attrs ▁ should ▁ be ▁ of ▁ the ▁ form ▁ {(ns_uri, ▁ lname): ▁ value, ▁ ...}. <strnewline> ▁ qnames ▁ of ▁ the ▁ form ▁ {(ns_uri, ▁ lname): ▁ qname, ▁ ...}. """  <newline> self . _attrs = attrs <newline> self . _qnames = qnames <newline> <dedent> def getValueByQName ( self , name ) : <newline> <indent> for ( nsname , qname ) in self . _qnames . items ( ) : <newline> <indent> if qname == name : <newline> <indent> return self . _attrs [ nsname ] <newline> <dedent> <dedent> raise KeyError ( name ) <newline> <dedent> def getNameByQName ( self , name ) : <newline> <indent> for ( nsname , qname ) in self . _qnames . items ( ) : <newline> <indent> if qname == name : <newline> <indent> return nsname <newline> <dedent> <dedent> raise KeyError ( name ) <newline> <dedent> def getQNameByName ( self , name ) : <newline> <indent> return self . _qnames [ name ] <newline> <dedent> def getQNames ( self ) : <newline> <indent> return list ( self . _qnames . values ( ) ) <newline> <dedent> def copy ( self ) : <newline> <indent> return self . __class__ ( self . _attrs , self . _qnames ) <newline> <dedent> <dedent> def _test ( ) : <newline> <indent> XMLReader ( ) <newline> IncrementalParser ( ) <newline> Locator ( ) <newline> <dedent> if __name__ == "__main__" : <newline> <indent> _test ( ) <newline> <dedent>
 # ▁ -*- ▁ coding: ▁ utf-8 ▁ -*- <encdom>  """ Example ▁ Mendeley ▁ local ▁ settings ▁ file. ▁ Copy ▁ this ▁ file ▁ to ▁ local.py ▁ and ▁ change <strnewline> these ▁ settings. <strnewline> """  <newline>  # ▁ Get ▁ an ▁ app ▁ key ▁ and ▁ secret ▁ at ▁ http://dev.mendeley.com/ <encdom> MENDELEY_CLIENT_ID = 'changeme' <newline> MENDELEY_CLIENT_SECRET = 'changeme' <newline>
import datetime <newline> from django . test import TestCase <newline> from django . utils import timezone <newline> from polls . models import Question , Choice <newline> class QuestionModelTest ( TestCase ) : <newline> <indent> def setUp ( self ) : <newline> <indent> self . q1 = Question ( ) <newline> self . q1 . question_text = "What ▁ is ▁ your ▁ question?" <newline> self . q1 . pub_date = timezone . now ( ) <newline> self . q1 . save ( ) <newline> self . q2 = Question ( ) <newline> self . q2 . question_text = "What ▁ is ▁ your ▁ next ▁ question?" <newline> self . q2 . pub_date = timezone . now ( ) <newline> self . q2 . save ( ) <newline> <dedent> def tearDown ( self ) : <newline> <indent> pass <newline> <dedent> def test_save_and_retrieve_Question ( self ) : <newline> <indent> saved_items = Question . objects . all ( ) <newline> self . assertEqual ( saved_items . count ( ) , 2 ) <newline> self . assertEqual ( saved_items [ 0 ] . question_text , self . q1 . question_text ) <newline> self . assertEqual ( saved_items [ 1 ] . question_text , self . q2 . question_text ) <newline> <dedent> def test_save_and_retrieve_Choice ( self ) : <newline> <indent> self . q1 . choice_set . create ( choice_text = 'Choice ▁ 1' , votes = 0 ) <newline> self . q1 . choice_set . create ( choice_text = "Choice ▁ 2" , votes = 1 ) <newline> saved_items = Choice . objects . all ( ) <newline> self . assertEqual ( saved_items . count ( ) , 2 ) <newline> self . assertEqual ( saved_items [ 0 ] . choice_text , "Choice ▁ 1" ) <newline> self . assertEqual ( saved_items [ 1 ] . choice_text , "Choice ▁ 2" ) <newline> <dedent> <dedent>
 # ▁ Licensed ▁ to ▁ the ▁ Apache ▁ Software ▁ Foundation ▁ (ASF) ▁ under ▁ one <encdom>  # ▁ or ▁ more ▁ contributor ▁ license ▁ agreements. ▁ See ▁ the ▁ NOTICE ▁ file <encdom>  # ▁ distributed ▁ with ▁ this ▁ work ▁ for ▁ additional ▁ information <encdom>  # ▁ regarding ▁ copyright ▁ ownership. ▁ The ▁ ASF ▁ licenses ▁ this ▁ file <encdom>  # ▁ to ▁ you ▁ under ▁ the ▁ Apache ▁ License, ▁ Version ▁ 2.0 ▁ (the <encdom>  # ▁"License"); ▁ you ▁ may ▁ not ▁ use ▁ this ▁ file ▁ except ▁ in ▁ compliance <encdom>  # ▁ with ▁ the ▁ License. ▁ You ▁ may ▁ obtain ▁ a ▁ copy ▁ of ▁ the ▁ License ▁ at <encdom>  # ▁ http://www.apache.org/licenses/LICENSE-2.0 <encdom>  # ▁ Unless ▁ required ▁ by ▁ applicable ▁ law ▁ or ▁ agreed ▁ to ▁ in ▁ writing, <encdom>  # ▁ software ▁ distributed ▁ under ▁ the ▁ License ▁ is ▁ distributed ▁ on ▁ an <encdom>  # ▁"AS ▁ IS" ▁ BASIS, ▁ WITHOUT ▁ WARRANTIES ▁ OR ▁ CONDITIONS ▁ OF ▁ ANY <encdom>  # ▁ KIND, ▁ either ▁ express ▁ or ▁ implied. ▁ See ▁ the ▁ License ▁ for ▁ the <encdom>  # ▁ specific ▁ language ▁ governing ▁ permissions ▁ and ▁ limitations <encdom>  # ▁ under ▁ the ▁ License. <encdom>  # ▁ pylint: ▁ disable=invalid-name,consider-using-enumerate,unused-argument,len-as-condition <encdom>  """ Elementwise ▁ operators """  <newline> from __future__ import absolute_import as _abs <newline> from . import cpp <newline> def elemwise_sum ( xs ) : <newline> <indent>  """ Perform ▁ element-wise ▁ sum ▁ on ▁ inputs <strnewline> <strnewline> ▁ Parameters <strnewline> ▁ ----- <strnewline> ▁ xs ▁ : ▁ list ▁ of ▁ tvm.te.Tensor <strnewline> ▁ Input ▁ arguments. <strnewline> <strnewline> ▁ Returns <strnewline> ▁ ----- <strnewline> ▁ y ▁ : ▁ tvm.te.Tensor <strnewline> ▁ The ▁ result. <strnewline> ▁ """  <newline> return cpp . elemwise_sum ( xs ) <newline> <dedent> def full ( shape , dtype , fill_value ) : <newline> <indent>  """ Fill ▁ tensor ▁ with ▁ fill_value <strnewline> <strnewline> ▁ Parameters <strnewline> ▁ ----- <strnewline> ▁ shape ▁ : ▁ tuple <strnewline> ▁ Input ▁ tensor ▁ shape. <strnewline> ▁ dtype ▁ : ▁ str <strnewline> ▁ Data ▁ type <strnewline> ▁ fill_value ▁ : ▁ float <strnewline> ▁ Value ▁ to ▁ be ▁ filled <strnewline> <strnewline> ▁ Returns <strnewline> ▁ ----- <strnewline> ▁ y ▁ : ▁ tvm.te.Tensor <strnewline> ▁ The ▁ result. <strnewline> ▁ """  <newline> return cpp . full ( shape , dtype , fill_value ) <newline> <dedent> def full_like ( x , fill_value ) : <newline> <indent>  """ Construct ▁ a ▁ tensor ▁ with ▁ same ▁ shape ▁ as ▁ input ▁ tensor, <strnewline> ▁ then ▁ fill ▁ tensor ▁ with ▁ fill_value. <strnewline> <strnewline> ▁ Parameters <strnewline> ▁ ----- <strnewline> ▁ x ▁ : ▁ tvm.te.Tensor <strnewline> ▁ Input ▁ argument. <strnewline> ▁ fill_value ▁ : ▁ float <strnewline> ▁ Value ▁ to ▁ be ▁ filled <strnewline> <strnewline> ▁ Returns <strnewline> ▁ ----- <strnewline> ▁ y ▁ : ▁ tvm.te.Tensor <strnewline> ▁ The ▁ result. <strnewline> ▁ """  <newline> return cpp . full_like ( x , fill_value ) <newline> <dedent>
 # ▁ Copyright ▁ 2016 ▁ The ▁ TensorFlow ▁ Authors. ▁ All ▁ Rights ▁ Reserved. <encdom>  # ▁ Licensed ▁ under ▁ the ▁ Apache ▁ License, ▁ Version ▁ 2.0 ▁ (the ▁"License"); <encdom>  # ▁ you ▁ may ▁ not ▁ use ▁ this ▁ file ▁ except ▁ in ▁ compliance ▁ with ▁ the ▁ License. <encdom>  # ▁ You ▁ may ▁ obtain ▁ a ▁ copy ▁ of ▁ the ▁ License ▁ at <encdom>  # ▁ http://www.apache.org/licenses/LICENSE-2.0 <encdom>  # ▁ Unless ▁ required ▁ by ▁ applicable ▁ law ▁ or ▁ agreed ▁ to ▁ in ▁ writing, ▁ software <encdom>  # ▁ distributed ▁ under ▁ the ▁ License ▁ is ▁ distributed ▁ on ▁ an ▁"AS ▁ IS" ▁ BASIS, <encdom>  # ▁ WITHOUT ▁ WARRANTIES ▁ OR ▁ CONDITIONS ▁ OF ▁ ANY ▁ KIND, ▁ either ▁ express ▁ or ▁ implied. <encdom>  # ▁ See ▁ the ▁ License ▁ for ▁ the ▁ specific ▁ language ▁ governing ▁ permissions ▁ and <encdom>  # ▁ limitations ▁ under ▁ the ▁ License. <encdom>  """ TensorSignature ▁ class ▁ and ▁ utilities. """  <newline> from __future__ import absolute_import <newline> from __future__ import division <newline> from __future__ import print_function <newline> import collections <newline> from tensorflow . python . framework import dtypes <newline> from tensorflow . python . framework import sparse_tensor <newline> from tensorflow . python . framework import tensor_shape <newline> from tensorflow . python . ops import array_ops <newline> from tensorflow . python . ops import math_ops <newline> from tensorflow . python . ops import parsing_ops <newline> class TensorSignature ( collections . namedtuple ( "TensorSignature" , [ "dtype" , "shape" , "is_sparse" ] ) ) : <newline> <indent>  """ Signature ▁ of ▁ the ▁ `Tensor` ▁ object. <strnewline> <strnewline> ▁ Useful ▁ to ▁ check ▁ compatibility ▁ of ▁ tensors. <strnewline> <strnewline> ▁ Example: <strnewline> <strnewline> ▁ ```python <strnewline> ▁ examples ▁ = ▁ tf.placeholder(...) <strnewline> ▁ inputs ▁ = ▁ {'a': ▁ var_a, ▁'b': ▁ var_b} <strnewline> ▁ signatures ▁ = ▁ tensor_signature.create_signatures(inputs) <strnewline> ▁ result ▁ = ▁ tensor_signature.create_example_parser_from_signatures( <strnewline> ▁ signatures, ▁ examples) <strnewline> ▁ self.assertTrue(tensor_signature.tensors_compatible(result, ▁ signatures)) <strnewline> ▁ ``` <strnewline> <strnewline> ▁ Attributes: <strnewline> ▁ dtype: ▁ `DType` ▁ object. <strnewline> ▁ shape: ▁ `TensorShape` ▁ object. <strnewline> ▁ """  <newline> def __new__ ( cls , tensor ) : <newline> <indent> if isinstance ( tensor , sparse_tensor . SparseTensor ) : <newline> <indent> return super ( TensorSignature , cls ) . __new__ ( cls , dtype = tensor . values . dtype , shape = None , is_sparse = True ) <newline> <dedent> return super ( TensorSignature , cls ) . __new__ ( cls , dtype = tensor . dtype , shape = tensor . get_shape ( ) , is_sparse = False ) <newline> <dedent> def is_compatible_with ( self , other ) : <newline> <indent>  """ Returns ▁ True ▁ if ▁ signatures ▁ are ▁ compatible. """  <newline> def _shape_is_compatible_0dim ( this , other ) : <newline> <indent>  """ Checks ▁ that ▁ shapes ▁ are ▁ compatible ▁ skipping ▁ dim ▁ 0. """  <newline> other = tensor_shape . as_shape ( other ) <newline>  # ▁ If ▁ shapes ▁ are ▁ None ▁ (unknown) ▁ they ▁ may ▁ be ▁ compatible. <encdom> if this . dims is None or other . dims is None : <newline> <indent> return True <newline> <dedent> if this . ndims != other . ndims : <newline> <indent> return False <newline> <dedent> for dim , ( x_dim , y_dim ) in enumerate ( zip ( this . dims , other . dims ) ) : <newline> <indent> if dim == 0 : <newline> <indent> continue <newline> <dedent> if not x_dim . is_compatible_with ( y_dim ) : <newline> <indent> return False <newline> <dedent> <dedent> return True <newline> <dedent> if other . is_sparse : <newline> <indent> return self . is_sparse and self . dtype . is_compatible_with ( other . dtype ) <newline> <dedent> return ( self . dtype . is_compatible_with ( other . dtype ) and _shape_is_compatible_0dim ( self . shape , other . shape ) and not self . is_sparse ) <newline> <dedent> def get_placeholder ( self ) : <newline> <indent> if self . is_sparse : <newline> <indent> return array_ops . sparse_placeholder ( dtype = self . dtype ) <newline> <dedent> return array_ops . placeholder ( dtype = self . dtype , shape = [ None ] + list ( self . shape [ 1 : ] ) ) <newline> <dedent> def get_feature_spec ( self ) : <newline> <indent> dtype = self . dtype <newline>  # ▁ Convert, ▁ because ▁ example ▁ parser ▁ only ▁ supports ▁ float32, ▁ int64 ▁ and ▁ string. <encdom> if dtype == dtypes . int32 : <newline> <indent> dtype = dtypes . int64 <newline> <dedent> if dtype == dtypes . float64 : <newline> <indent> dtype = dtypes . float32 <newline> <dedent> if self . is_sparse : <newline> <indent> return parsing_ops . VarLenFeature ( dtype = dtype ) <newline> <dedent> return parsing_ops . FixedLenFeature ( shape = self . shape [ 1 : ] , dtype = dtype ) <newline> <dedent> <dedent> def tensors_compatible ( tensors , signatures ) : <newline> <indent>  """ Check ▁ that ▁ tensors ▁ are ▁ compatible ▁ with ▁ signatures. <strnewline> <strnewline> ▁ Args: <strnewline> ▁ tensors: ▁ Dict ▁ of ▁ `Tensor` ▁ objects ▁ or ▁ single ▁ `Tensor` ▁ object. <strnewline> ▁ signatures: ▁ Dict ▁ of ▁ `TensorSignature` ▁ objects ▁ or <strnewline> ▁ single ▁ `TensorSignature` ▁ object. <strnewline> <strnewline> ▁ Returns: <strnewline> ▁ True ▁ if ▁ all ▁ tensors ▁ are ▁ compatible, ▁ False ▁ otherwise. <strnewline> ▁ """  <newline>  # ▁ Dict ▁ of ▁ Tensors ▁ as ▁ input. <encdom> if tensors is None : <newline> <indent> return signatures is None <newline> <dedent> if isinstance ( tensors , dict ) : <newline> <indent> if not isinstance ( signatures , dict ) : <newline> <indent> return False <newline> <dedent> for key in signatures : <newline> <indent> if key not in tensors : <newline> <indent> return False <newline> <dedent> if not TensorSignature ( tensors [ key ] ) . is_compatible_with ( signatures [ key ] ) : <newline> <indent> return False <newline> <dedent> <dedent> return True <newline>  # ▁ Single ▁ tensor ▁ as ▁ input. <encdom> <dedent> if signatures is None or isinstance ( signatures , dict ) : <newline> <indent> return False <newline> <dedent> return TensorSignature ( tensors ) . is_compatible_with ( signatures ) <newline> <dedent> def create_signatures ( tensors ) : <newline> <indent>  """ Creates ▁ TensorSignature ▁ objects ▁ for ▁ given ▁ tensors. <strnewline> <strnewline> ▁ Args: <strnewline> ▁ tensors: ▁ Dict ▁ of ▁ `Tensor` ▁ objects ▁ or ▁ single ▁ `Tensor`. <strnewline> <strnewline> ▁ Returns: <strnewline> ▁ Dict ▁ of ▁ `TensorSignature` ▁ objects ▁ or ▁ single ▁ `TensorSignature`. <strnewline> ▁ """  <newline> if isinstance ( tensors , dict ) : <newline> <indent> return { key : TensorSignature ( tensors [ key ] ) for key in tensors } <newline> <dedent> if tensors is None : <newline> <indent> return None <newline> <dedent> return TensorSignature ( tensors ) <newline> <dedent> def create_placeholders_from_signatures ( signatures ) : <newline> <indent>  """ Creates ▁ placeholders ▁ from ▁ given ▁ signatures. <strnewline> <strnewline> ▁ Args: <strnewline> ▁ signatures: ▁ Dict ▁ of ▁ `TensorSignature` ▁ objects ▁ or ▁ single ▁ `TensorSignature`, <strnewline> ▁ or ▁ `None`. <strnewline> <strnewline> ▁ Returns: <strnewline> ▁ Dict ▁ of ▁ `tf.placeholder` ▁ objects ▁ or ▁ single ▁ `tf.placeholder`, ▁ or ▁ `None`. <strnewline> ▁ """  <newline> if signatures is None : <newline> <indent> return None <newline> <dedent> if not isinstance ( signatures , dict ) : <newline> <indent> return signatures . get_placeholder ( ) <newline> <dedent> return { key : signatures [ key ] . get_placeholder ( ) for key in signatures } <newline> <dedent> def create_example_parser_from_signatures ( signatures , examples_batch , single_feature_name = "feature" ) : <newline> <indent>  """ Creates ▁ example ▁ parser ▁ from ▁ given ▁ signatures. <strnewline> <strnewline> ▁ Args: <strnewline> ▁ signatures: ▁ Dict ▁ of ▁ `TensorSignature` ▁ objects ▁ or ▁ single ▁ `TensorSignature`. <strnewline> ▁ examples_batch: ▁ string ▁ `Tensor` ▁ of ▁ serialized ▁ `Example` ▁ proto. <strnewline> ▁ single_feature_name: ▁ string, ▁ single ▁ feature ▁ name. <strnewline> <strnewline> ▁ Returns: <strnewline> ▁ features: ▁ `Tensor` ▁ or ▁ `dict` ▁ of ▁ `Tensor` ▁ objects. <strnewline> ▁ """  <newline> feature_spec = { } <newline> if not isinstance ( signatures , dict ) : <newline> <indent> feature_spec [ single_feature_name ] = signatures . get_feature_spec ( ) <newline> <dedent> else : <newline> <indent> feature_spec = { key : signatures [ key ] . get_feature_spec ( ) for key in signatures } <newline> <dedent> features = parsing_ops . parse_example ( examples_batch , feature_spec ) <newline> if not isinstance ( signatures , dict ) : <newline>  # ▁ Returns ▁ single ▁ feature, ▁ casts ▁ if ▁ needed. <encdom> <indent> features = features [ single_feature_name ] <newline> if not signatures . dtype . is_compatible_with ( features . dtype ) : <newline> <indent> features = math_ops . cast ( features , signatures . dtype ) <newline> <dedent> return features <newline>  # ▁ Returns ▁ dict ▁ of ▁ features, ▁ casts ▁ if ▁ needed. <encdom> <dedent> for name in features : <newline> <indent> if not signatures [ name ] . dtype . is_compatible_with ( features [ name ] . dtype ) : <newline> <indent> features [ name ] = math_ops . cast ( features [ name ] , signatures [ name ] . dtype ) <newline> <dedent> <dedent> return features <newline> <dedent>