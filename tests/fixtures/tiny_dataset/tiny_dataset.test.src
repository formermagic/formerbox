def getdefaultlocale ( ) : <newline> <indent> return __BRYTHON__ . language , None <newline> <dedent> def localeconv ( ) : <newline> <indent>  """ ▁ localeconv() ▁ -> ▁ dict. <strnewline> ▁ Returns ▁ numeric ▁ and ▁ monetary ▁ locale-specific ▁ parameters. <strnewline> ▁ """  <newline>  # ▁'C' ▁ locale ▁ default ▁ values <encdom> return { 'grouping' : [ 127 ] , 'currency_symbol' : '' , 'n_sign_posn' : 127 , 'p_cs_precedes' : 127 , 'n_cs_precedes' : 127 , 'mon_grouping' : [ ] , 'n_sep_by_space' : 127 , 'decimal_point' : '.' , 'negative_sign' : '' , 'positive_sign' : '' , 'p_sep_by_space' : 127 , 'decimal_point' : '.' , 'negative_sign' : '' , 'positive_sign' : '' , 'p_sep_by_space' : 127 , 'int_curr_symbol' : '' , 'p_sign_posn' : 127 , 'thousands_sep' : '' , 'mon_thousands_sep' : '' , 'frac_digits' : 127 , 'mon_decimal_point' : '' , 'int_frac_digits' : 127 } <newline> <dedent> def setlocale ( category , value = None ) : <newline> <indent>  """ ▁ setlocale(integer,string=None) ▁ -> ▁ string. <strnewline> ▁ Activates/queries ▁ locale ▁ processing. <strnewline> ▁ """  <newline> if value not in ( None , '' , 'C' ) : <newline> <indent> raise Error ( '_locale ▁ emulation ▁ only ▁ supports ▁"C" ▁ locale' ) <newline> <dedent> return 'C' <newline> <dedent> CHAR_MAX = 127 <newline> LC_ALL = 6 <newline> LC_COLLATE = 3 <newline> LC_CTYPE = 0 <newline> LC_MESSAGES = 5 <newline> LC_MONETARY = 4 <newline> LC_NUMERIC = 1 <newline> LC_TIME = 2 <newline> Error = ValueError <newline> def getlocale ( category = LC_CTYPE ) : <newline> <indent>  """ ▁ Returns ▁ the ▁ current ▁ setting ▁ for ▁ the ▁ given ▁ locale ▁ category ▁ as <strnewline> ▁ tuple ▁ (language ▁ code, ▁ encoding). <strnewline> <strnewline> ▁ category ▁ may ▁ be ▁ one ▁ of ▁ the ▁ LC_* ▁ value ▁ except ▁ LC_ALL. ▁ It <strnewline> ▁ defaults ▁ to ▁ LC_CTYPE. <strnewline> <strnewline> ▁ Except ▁ for ▁ the ▁ code ▁'C', ▁ the ▁ language ▁ code ▁ corresponds ▁ to ▁ RFC <strnewline> ▁ 1766. ▁ code ▁ and ▁ encoding ▁ can ▁ be ▁ None ▁ in ▁ case ▁ the ▁ values ▁ cannot <strnewline> ▁ be ▁ determined. <strnewline> <strnewline> ▁ """  <newline> return None , None <newline> <dedent>
 """ Model ▁ definition ▁ for ▁ base ▁ class ▁ for ▁ Linear ▁ Time-varying ▁ systems <strnewline> @author: ▁ Jerker ▁ Nordh <strnewline> """  <newline> from pyparticleest . interfaces import FFBSi , ParticleFiltering <newline> try : <newline> <indent> import pyparticleest . utils . ckalman as kalman <newline> import pyparticleest . utils . cmlnlg_compute as mlnlg_compute <newline> <dedent> except ImportError : <newline> <indent> print ( "Falling ▁ back ▁ to ▁ pure ▁ python ▁ implementaton, ▁ expect ▁ horrible ▁ performance" ) <newline> import pyparticleest . utils . kalman as kalman <newline> import pyparticleest . utils . mlnlg_compute as mlnlg_compute <newline> <dedent> import numpy <newline> import scipy . linalg <newline> from builtins import range <newline> class LTV ( FFBSi , ParticleFiltering ) : <newline> <indent>  """ <strnewline> ▁ Base ▁ class ▁ for ▁ particles ▁ of ▁ the ▁ type ▁ linear ▁ time ▁ varying ▁ with ▁ additive ▁ gaussian ▁ noise. <strnewline> <strnewline> ▁ Implement ▁ this ▁ type ▁ of ▁ system ▁ by ▁ extending ▁ this ▁ class ▁ and ▁ provide ▁ the ▁ methods ▁ for ▁ returning <strnewline> ▁ the ▁ system ▁ matrices ▁ at ▁ each ▁ time ▁ instant <strnewline> <strnewline> ▁ z_{t+1} ▁ = ▁ A*z_t ▁ + ▁ f ▁ + ▁ v, ▁ v ▁ ~ ▁ N(0, ▁ Q) <strnewline> ▁ y_t ▁ = ▁ C*z_t ▁ + ▁ h ▁ + ▁ e, ▁ e ▁ ~ ▁ N(0,R) <strnewline> <strnewline> ▁ Args: <strnewline> ▁ - ▁ z0: ▁ Initial ▁ mean ▁ value ▁ of ▁ the ▁ state ▁ estimate <strnewline> ▁ - ▁ P0: ▁ Coviariance ▁ of ▁ initial ▁ z ▁ estimate <strnewline> ▁ - ▁ A ▁ (array-like): ▁ A ▁ matrix ▁ (if ▁ constant) <strnewline> ▁ - ▁ C ▁ (array-like): ▁ C ▁ matrix ▁ (if ▁ constant) <strnewline> ▁ - ▁ Q ▁ (array-like): ▁ Q ▁ matrix ▁ (if ▁ constant) <strnewline> ▁ - ▁ R ▁ (array-like): ▁ R ▁ matrix ▁ (if ▁ constant) <strnewline> ▁ - ▁ f ▁ (array-like): ▁ f ▁ vector ▁ (if ▁ constant) <strnewline> ▁ - ▁ h ▁ (array-like): ▁ h ▁ vector ▁ (if ▁ constant) <strnewline> ▁ - ▁ params ▁ (array-like): ▁ model ▁ parameters ▁ (if ▁ any) <strnewline> ▁ """  <newline> def __init__ ( self , z0 , P0 , A = None , C = None , Q = None , R = None , f = None , h = None , params = None , ** kwargs ) : <newline> <indent> self . z0 = numpy . copy ( z0 ) . reshape ( ( - 1 , 1 ) ) <newline> self . P0 = numpy . copy ( P0 ) <newline> if ( f is None ) : <newline> <indent> f = numpy . zeros_like ( self . z0 ) <newline> <dedent> self . kf = kalman . KalmanSmoother ( lz = len ( self . z0 ) , A = A , C = C , Q = Q , R = R , f_k = f , h_k = h ) <newline> super ( LTV , self ) . __init__ ( ** kwargs ) <newline> <dedent> def create_initial_estimate ( self , N ) : <newline> <indent>  """ Sample ▁ particles ▁ from ▁ initial ▁ distribution <strnewline> <strnewline> ▁ Args: <strnewline> ▁ - ▁ N ▁ (int): ▁ Number ▁ of ▁ particles ▁ to ▁ sample, ▁ since ▁ the ▁ estimate ▁ is <strnewline> ▁ deterministic ▁ there ▁ is ▁ no ▁ reason ▁ for ▁ N ▁ > ▁ 1 <strnewline> <strnewline> ▁ Returns: <strnewline> ▁ (array-like) ▁ with ▁ first ▁ dimension ▁ = ▁ N, ▁ model ▁ specific ▁ representation <strnewline> ▁ of ▁ all ▁ particles ▁ """  <newline> if ( N > 1 ) : <newline> <indent> print ( "N ▁ > ▁ 1 ▁ redundamt ▁ for ▁ LTV ▁ system ▁ (N={0})" . format ( N ) , ) <newline> <dedent> lz = len ( self . z0 ) <newline> dim = lz + lz * lz <newline> particles = numpy . empty ( ( N , dim ) ) <newline> for i in range ( N ) : <newline> <indent> particles [ i , : lz ] = numpy . copy ( self . z0 ) . ravel ( ) <newline> particles [ i , lz : ] = numpy . copy ( self . P0 ) . ravel ( ) <newline> <dedent> return particles <newline> <dedent> def set_states ( self , particles , z_list , P_list ) : <newline> <indent>  """ <strnewline> ▁ Set ▁ the ▁ estimate ▁ of ▁ the ▁ states <strnewline> <strnewline> ▁ Args: <strnewline> ▁ - ▁ particles ▁ (array-like): ▁ Model ▁ specific ▁ representation <strnewline> ▁ of ▁ all ▁ particles, ▁ with ▁ first ▁ dimension ▁ = ▁ N ▁ (number ▁ of ▁ particles) <strnewline> ▁ - ▁ z_list ▁ (list): ▁ list ▁ of ▁ mean ▁ values ▁ for ▁ z ▁ for ▁ each ▁ particle <strnewline> ▁ - ▁ P_list ▁ (list): ▁ list ▁ of ▁ covariance ▁ matrices ▁ for ▁ z ▁ for ▁ each ▁ particle <strnewline> ▁ """  <newline> lz = len ( self . z0 ) <newline> N = len ( particles ) <newline> for i in range ( N ) : <newline> <indent> particles [ i , : lz ] = z_list [ i ] . ravel ( ) <newline> lzP = lz + lz * lz <newline> particles [ i , lz : lzP ] = P_list [ i ] . ravel ( ) <newline> <dedent> <dedent> def get_states ( self , particles ) : <newline> <indent>  """ <strnewline> ▁ Return ▁ the ▁ estimates ▁ contained ▁ in ▁ the ▁ particles ▁ array <strnewline> <strnewline> ▁ Args: <strnewline> ▁ - ▁ particles ▁ (array-like): ▁ Model ▁ specific ▁ representation <strnewline> ▁ of ▁ all ▁ particles, ▁ with ▁ first ▁ dimension ▁ = ▁ N ▁ (number ▁ of ▁ particles) <strnewline> <strnewline> ▁ Returns <strnewline> ▁ (zl, ▁ Pl): <strnewline> ▁ - ▁ zl: ▁ list ▁ of ▁ mean ▁ values ▁ for ▁ z <strnewline> ▁ - ▁ Pl: ▁ list ▁ of ▁ covariance ▁ matrices ▁ for ▁ z <strnewline> ▁ """  <newline> N = len ( particles ) <newline> zl = list ( ) <newline> Pl = list ( ) <newline> lz = len ( self . z0 ) <newline> for i in range ( N ) : <newline> <indent> zl . append ( particles [ i , : lz ] . reshape ( - 1 , 1 ) ) <newline> lzP = lz + lz * lz <newline> Pl . append ( particles [ i , lz : lzP ] . reshape ( self . P0 . shape ) ) <newline> <dedent> return ( zl , Pl ) <newline> <dedent> def get_pred_dynamics ( self , u , t ) : <newline> <indent>  """ <strnewline> ▁ Return ▁ matrices ▁ describing ▁ affine ▁ relation ▁ of ▁ next <strnewline> ▁ nonlinear ▁ state ▁ conditioned ▁ on ▁ the ▁ current ▁ time ▁ and ▁ input ▁ signal <strnewline> <strnewline> ▁ z_{t+1} ▁ = ▁ A*z_t ▁ + ▁ f ▁ + ▁ v, ▁ v ▁ ~ ▁ N(0, ▁ Q) <strnewline> <strnewline> ▁ Args: <strnewline> ▁ - ▁ particles ▁ (array-like): ▁ Model ▁ specific ▁ representation <strnewline> ▁ of ▁ all ▁ particles, ▁ with ▁ first ▁ dimension ▁ = ▁ N ▁ (number ▁ of ▁ particles) <strnewline> ▁ - ▁ u ▁ (array-like): ▁ input ▁ signal <strnewline> ▁ - ▁ t ▁ (float): ▁ time ▁ stamp <strnewline> <strnewline> ▁ Returns: <strnewline> ▁ (A, ▁ f, ▁ Q) ▁ where ▁ each ▁ element ▁ is ▁ a ▁ list <strnewline> ▁ with ▁ the ▁ corresponding ▁ matrix ▁ for ▁ each ▁ particle. ▁ None ▁ indicates <strnewline> ▁ that ▁ the ▁ matrix ▁ is ▁ identical ▁ for ▁ all ▁ particles ▁ and ▁ the ▁ value ▁ stored <strnewline> ▁ in ▁ this ▁ class ▁ should ▁ be ▁ used ▁ instead <strnewline> ▁ """  <newline> return ( None , None , None ) <newline> <dedent> def update ( self , particles , u , t , noise ) : <newline> <indent>  """ ▁ Propagate ▁ estimate ▁ forward ▁ in ▁ time <strnewline> <strnewline> ▁ Args: <strnewline> <strnewline> ▁ - ▁ particles ▁ (array-like): ▁ Model ▁ specific ▁ representation <strnewline> ▁ of ▁ all ▁ particles, ▁ with ▁ first ▁ dimension ▁ = ▁ N ▁ (number ▁ of ▁ particles) <strnewline> ▁ - ▁ u ▁ (array-like): ▁ input ▁ signal <strnewline> ▁ - ▁ t ▁ (float): ▁ time-stamp <strnewline> ▁ - ▁ noise: ▁ Unused ▁ for ▁ this ▁ type ▁ of ▁ model <strnewline> <strnewline> ▁ Returns: <strnewline> ▁ (array-like) ▁ with ▁ first ▁ dimension ▁ = ▁ N, ▁ particle ▁ estimate ▁ at ▁ time ▁ t+1 <strnewline> ▁ """  <newline>  # ▁ Update ▁ linear ▁ estimate ▁ with ▁ data ▁ from ▁ measurement ▁ of ▁ next ▁ non-linear <encdom>  # ▁ state <encdom> ( zl , Pl ) = self . get_states ( particles ) <newline> ( A , f , Q ) = self . get_pred_dynamics ( u = u , t = t ) <newline> self . kf . set_dynamics ( A = A , Q = Q , f_k = f ) <newline> for i in range ( len ( zl ) ) : <newline>  # ▁ Predict ▁ z_{t+1} <encdom> <indent> ( zl [ i ] , Pl [ i ] ) = self . kf . predict ( zl [ i ] , Pl [ i ] ) <newline>  # ▁ Predict ▁ next ▁ states ▁ conditioned ▁ on ▁ eta_next <encdom> <dedent> self . set_states ( particles , zl , Pl ) <newline> return particles <newline> <dedent> def get_meas_dynamics ( self , y , t ) : <newline> <indent>  """ <strnewline> ▁ Return ▁ matrices ▁ describing ▁ affine ▁ relation ▁ of ▁ measurement ▁ and ▁ current <strnewline> ▁ state ▁ estimates <strnewline> <strnewline> ▁ y_t ▁ = ▁ C*z_t ▁ + ▁ h ▁ + ▁ e, ▁ e ▁ ~ ▁ N(0,R) <strnewline> <strnewline> ▁ Args: <strnewline> ▁ - ▁ particles ▁ (array-like): ▁ Model ▁ specific ▁ representation <strnewline> ▁ of ▁ all ▁ particles, ▁ with ▁ first ▁ dimension ▁ = ▁ N ▁ (number ▁ of ▁ particles) <strnewline> ▁ - ▁ y ▁ (array-like): ▁ measurement <strnewline> ▁ - ▁ t ▁ (float): ▁ time ▁ stamp <strnewline> <strnewline> ▁ Returns: <strnewline> ▁ (y, ▁ C, ▁ h, ▁ R): ▁ y ▁ is ▁ a ▁ preprocessed ▁ measurement, ▁ the ▁ rest ▁ are ▁ lists <strnewline> ▁ with ▁ the ▁ corresponding ▁ matrix ▁ for ▁ each ▁ particle. ▁ None ▁ indicates <strnewline> ▁ that ▁ the ▁ matrix ▁ is ▁ identical ▁ for ▁ all ▁ particles ▁ and ▁ the ▁ value ▁ stored <strnewline> ▁ in ▁ this ▁ class ▁ should ▁ be ▁ used ▁ instead <strnewline> ▁ """  <newline> return ( y , None , None , None ) <newline> <dedent> def measure ( self , particles , y , t ) : <newline> <indent>  """ <strnewline> ▁ Return ▁ the ▁ log-pdf ▁ value ▁ of ▁ the ▁ measurement ▁ and ▁ update ▁ the ▁ statistics <strnewline> ▁ for ▁ the ▁ states <strnewline> <strnewline> ▁ Args: <strnewline> <strnewline> ▁ - ▁ particles ▁ (array-like): ▁ Model ▁ specific ▁ representation <strnewline> ▁ of ▁ all ▁ particles, ▁ with ▁ first ▁ dimension ▁ = ▁ N ▁ (number ▁ of ▁ particles) <strnewline> ▁ - ▁ y ▁ (array-like): ▁ measurement <strnewline> ▁ - ▁ t ▁ (float): ▁ time-stamp <strnewline> <strnewline> ▁ Returns: <strnewline> ▁ (array-like) ▁ with ▁ first ▁ dimension ▁ = ▁ N, ▁ logp(y|x^i) <strnewline> ▁ """  <newline> ( zl , Pl ) = self . get_states ( particles ) <newline> ( y , C , h , R ) = self . get_meas_dynamics ( y = y , t = t ) <newline> self . kf . set_dynamics ( C = C , R = R , h_k = h ) <newline> lyz = numpy . empty ( ( len ( particles ) ) ) <newline> for i in range ( len ( zl ) ) : <newline>  # ▁ Predict ▁ z_{t+1} <encdom> <indent> lyz [ i ] = self . kf . measure ( y , zl [ i ] , Pl [ i ] ) <newline> <dedent> self . set_states ( particles , zl , Pl ) <newline> return lyz <newline> <dedent> def logp_xnext ( self , particles , next_part , u , t ) : <newline> <indent>  """ <strnewline> ▁ Return ▁ the ▁ log-pdf ▁ value ▁ for ▁ the ▁ possible ▁ future ▁ state ▁'next' <strnewline> ▁ given ▁ input ▁ u. <strnewline> <strnewline> ▁ Always ▁ returns ▁ zeros ▁ since ▁ all ▁ particles ▁ are ▁ always ▁ equivalent ▁ for ▁ this <strnewline> ▁ type ▁ of ▁ model <strnewline> <strnewline> ▁ Args: <strnewline> <strnewline> ▁ - ▁ particles ▁ (array-like): ▁ Model ▁ specific ▁ representation <strnewline> ▁ of ▁ all ▁ particles, ▁ with ▁ first ▁ dimension ▁ = ▁ N ▁ (number ▁ of ▁ particles) <strnewline> ▁ - ▁ next_part: ▁ Unused <strnewline> ▁ - ▁ u: ▁ Unused <strnewline> ▁ - ▁ t: ▁ Unused <strnewline> <strnewline> ▁ Returns: <strnewline> ▁ (array-like) ▁ with ▁ first ▁ dimension ▁ = ▁ N, ▁ numpu.zeros((N,)) <strnewline> ▁ """  <newline>  # ▁ Not ▁ needed ▁ for ▁ Linear ▁ Gaussian ▁ models, ▁ always ▁ return ▁ 0 ▁ (all ▁ particles ▁ will ▁ be ▁ identical ▁ anyhow) <encdom> N = len ( particles ) <newline> return numpy . zeros ( ( N , ) ) <newline> <dedent> def sample_process_noise ( self , particles , u , t ) : <newline> <indent>  """ <strnewline> ▁ There ▁ is ▁ no ▁ need ▁ to ▁ sample ▁ noise ▁ for ▁ this ▁ type ▁ of ▁ model <strnewline> <strnewline> ▁ Args: <strnewline> <strnewline> ▁ - ▁ particles: ▁ Unused <strnewline> ▁ - ▁ next_part: ▁ Unused <strnewline> ▁ - ▁ u: ▁ Unused <strnewline> ▁ - ▁ t: ▁ Unused <strnewline> <strnewline> ▁ Returns: <strnewline> ▁ None <strnewline> ▁ """  <newline> return None <newline> <dedent> def sample_smooth ( self , part , ptraj , anc , future_trajs , find , ut , yt , tt , cur_ind ) : <newline> <indent>  """ <strnewline> ▁ Update ▁ sufficient ▁ statistics ▁ based ▁ on ▁ the ▁ future ▁ states <strnewline> <strnewline> ▁ Args: <strnewline> ▁ - ▁ part ▁ (array-like): ▁ Model ▁ specific ▁ representation <strnewline> ▁ of ▁ all ▁ particles, ▁ with ▁ first ▁ dimension ▁ = ▁ N ▁ (number ▁ of ▁ particles) <strnewline> ▁ - ▁ ptraj: ▁ array ▁ of ▁ trajectory ▁ step ▁ objects ▁ from ▁ previous ▁ time-steps, <strnewline> ▁ last ▁ index ▁ is ▁ step ▁ just ▁ before ▁ the ▁ current <strnewline> ▁ - ▁ anc ▁ (array-like): ▁ index ▁ of ▁ the ▁ ancestor ▁ of ▁ each ▁ particle ▁ in ▁ part <strnewline> ▁ - ▁ future_trajs ▁ (array-like): ▁ particle ▁ estimate ▁ for ▁ {t+1:T} <strnewline> ▁ - ▁ find ▁ (array-like): ▁ index ▁ in ▁ future_trajs ▁ corresponding ▁ to ▁ each <strnewline> ▁ particle ▁ in ▁ part <strnewline> ▁ - ▁ ut ▁ (array-like): ▁ input ▁ signals ▁ for ▁ {0:T} <strnewline> ▁ - ▁ yt ▁ (array-like): ▁ measurements ▁ for ▁ {0:T} <strnewline> ▁ - ▁ tt ▁ (array-like): ▁ time ▁ stamps ▁ for ▁ {0:T} <strnewline> ▁ - ▁ cur_ind ▁ (int): ▁ index ▁ of ▁ current ▁ timestep ▁ (in ▁ ut, ▁ yt ▁ and ▁ tt) <strnewline> <strnewline> ▁ Returns: <strnewline> ▁ (array-like) ▁ with ▁ first ▁ dimension ▁ = ▁ N <strnewline> ▁ """  <newline> ( zl , Pl ) = self . get_states ( part ) <newline> M = len ( part ) <newline> lz = len ( self . z0 ) <newline> lzP = lz + lz * lz <newline> res = numpy . empty ( ( M , lz + 2 * lz ** 2 ) ) <newline> for j in range ( M ) : <newline> <indent> if ( future_trajs is not None ) : <newline> <indent> zn = future_trajs [ 0 ] . pa . part [ j , : lz ] . reshape ( ( lz , 1 ) ) <newline> Pn = future_trajs [ 0 ] . pa . part [ j , lz : lzP ] . reshape ( ( lz , lz ) ) <newline> ( A , f , Q ) = self . get_pred_dynamics ( u = ut [ 0 ] , t = tt [ 0 ] ) <newline> self . kf . set_dynamics ( A = A , Q = Q , f_k = f ) <newline> ( zs , Ps , Ms ) = self . kf . smooth ( zl [ 0 ] , Pl [ 0 ] , zn , Pn , self . kf . A , self . kf . f_k , self . kf . Q ) <newline> <dedent> else : <newline> <indent> zs = zl [ j ] <newline> Ps = Pl [ j ] <newline> Ms = numpy . zeros_like ( Ps ) <newline> <dedent> res [ j ] = numpy . hstack ( ( zs . ravel ( ) , Ps . ravel ( ) , Ms . ravel ( ) ) ) <newline> <dedent> return res <newline> <dedent> def fwd_peak_density ( self , u , t ) : <newline> <indent>  """ <strnewline> ▁ No ▁ need ▁ for ▁ rejections ▁ sampling ▁ for ▁ this ▁ type ▁ of ▁ model, ▁ always ▁ returns <strnewline> ▁ 0.0 ▁ since ▁ all ▁ particles ▁ are ▁ equivalent <strnewline> <strnewline> ▁ Args: <strnewline> ▁ - ▁ u: ▁ Unused <strnewline> ▁ - ▁ t: ▁ Unused <strnewline> <strnewline> ▁ Returns <strnewline> ▁ (float) ▁ 0.0 <strnewline> ▁ """  <newline> return 0.0 <newline> <dedent> def eval_logp_x0 ( self , particles , t ) : <newline> <indent>  """ <strnewline> ▁ Evaluate ▁ sum ▁ log ▁ p(x_0) <strnewline> <strnewline> ▁ Args: <strnewline> ▁ - ▁ particles ▁ (array-like): ▁ Model ▁ specific ▁ representation <strnewline> ▁ of ▁ all ▁ particles, ▁ with ▁ first ▁ dimension ▁ = ▁ N ▁ (number ▁ of ▁ particles) <strnewline> ▁ - ▁ t ▁ (float): ▁ time ▁ stamp <strnewline> ▁ """  <newline>  # ▁ Calculate ▁ l1 ▁ according ▁ to ▁ (19a) <encdom> N = len ( particles ) <newline> ( zl , Pl ) = self . get_states ( particles ) <newline> lpz0 = numpy . empty ( N ) <newline> for i in range ( N ) : <newline> <indent> l1 = self . calc_l1 ( zl [ i ] , Pl [ i ] , self . z0 , self . P0 ) <newline> ( _tmp , ld ) = numpy . linalg . slogdet ( self . P0 ) <newline> tmp = numpy . linalg . solve ( self . P0 , l1 ) <newline> lpz0 [ i ] = - 0.5 * ( ld + numpy . trace ( tmp ) ) <newline> <dedent> return lpz0 <newline> <dedent> def eval_logp_x0_val_grad ( self , particles , t ) : <newline> <indent>  """ <strnewline> ▁ Evaluate ▁ gradient ▁ of ▁ sum ▁ log ▁ p(x_0) <strnewline> <strnewline> ▁ Args: <strnewline> ▁ - ▁ particles ▁ (array-like): ▁ Model ▁ specific ▁ representation <strnewline> ▁ of ▁ all ▁ particles, ▁ with ▁ first ▁ dimension ▁ = ▁ N ▁ (number ▁ of ▁ particles) <strnewline> ▁ - ▁ t ▁ (float): ▁ time ▁ stamp <strnewline> ▁ """  <newline>  # ▁ Calculate ▁ l1 ▁ according ▁ to ▁ (19a) <encdom> N = len ( particles ) <newline> lparam = len ( self . params ) <newline> lpz0_grad = numpy . zeros ( lparam ) <newline> ( zl , Pl ) = self . get_states ( particles ) <newline> ( z0_grad , P0_grad ) = self . get_initial_grad ( ) <newline> if ( z0_grad is None and P0_grad is None ) : <newline> <indent> lpz0 = self . eval_logp_x0 ( particles , t ) <newline> <dedent> else : <newline> <indent> lpz0 = 0.0 <newline> P0cho = scipy . linalg . cho_factor ( self . P0 ) <newline> ld = numpy . sum ( numpy . log ( numpy . diagonal ( P0cho [ 0 ] ) ) ) * 2 <newline> for i in range ( N ) : <newline> <indent> ( l1 , l1_grad ) = self . calc_l1_grad ( zl [ i ] , Pl [ i ] , self . z0 , self . P0 , z0_grad ) <newline> tmp = scipy . linalg . cho_solve ( P0cho , l1 ) <newline> lpz0 += - 0.5 * ( ld + numpy . trace ( tmp ) ) <newline> for j in range ( len ( self . params ) ) : <newline> <indent> lpz0_grad [ j ] -= 0.5 * mlnlg_compute . compute_logprod_derivative ( P0cho , P0_grad [ j ] , l1 , l1_grad [ j ] ) <newline> <dedent> <dedent> <dedent> return ( lpz0 , lpz0_grad ) <newline> <dedent> def eval_logp_xnext ( self , particles , x_next , u , t ) : <newline> <indent>  """ <strnewline> ▁ Evaluate ▁ log ▁ p(x_{t+1}|x_t) <strnewline> <strnewline> ▁ Args: <strnewline> ▁ - ▁ particles ▁ (array-like): ▁ Model ▁ specific ▁ representation <strnewline> ▁ of ▁ all ▁ particles, ▁ with ▁ first ▁ dimension ▁ = ▁ N ▁ (number ▁ of ▁ particles) <strnewline> ▁ - ▁ x_next ▁ (array-like): ▁ future ▁ states <strnewline> ▁ - ▁ t ▁ (float): ▁ time ▁ stamp <strnewline> <strnewline> ▁ Returns: ▁ (array-like) <strnewline> ▁ """  <newline>  # ▁ Calculate ▁ l2 ▁ according ▁ to ▁ (16) <encdom> N = len ( particles ) <newline> ( zl , Pl ) = self . get_states ( particles ) <newline> ( zn , Pn ) = self . get_states ( x_next ) <newline> ( A , f , Q ) = self . get_pred_dynamics ( u = u , t = t ) <newline> self . kf . set_dynamics ( A = A , Q = Q , f_k = f ) <newline> self . t = t <newline> lpxn = numpy . empty ( N ) <newline> for k in range ( N ) : <newline> <indent> lz = len ( self . z0 ) <newline> lzP = lz + lz * lz <newline> Mz = particles [ k ] [ lzP : ] . reshape ( ( lz , lz ) ) <newline> ( l2 , _A , _M_ext , _predict_err ) = self . calc_l2 ( zn [ k ] , Pn [ k ] , zl [ k ] , Pl [ k ] , self . kf . A , self . kf . f_k , Mz ) <newline> ( _tmp , ld ) = numpy . linalg . slogdet ( self . kf . Q ) <newline> tmp = numpy . linalg . solve ( self . kf . Q , l2 ) <newline> lpxn [ k ] = - 0.5 * ( ld + numpy . trace ( tmp ) ) <newline> <dedent> return lpxn <newline> <dedent> def eval_logp_xnext_val_grad ( self , particles , x_next , u , t ) : <newline> <indent>  """ <strnewline> ▁ Evaluate ▁ value ▁ and ▁ gradient ▁ of ▁ log ▁ p(x_{t+1}|x_t) <strnewline> <strnewline> ▁ Args: <strnewline> ▁ - ▁ particles ▁ (array-like): ▁ Model ▁ specific ▁ representation <strnewline> ▁ of ▁ all ▁ particles, ▁ with ▁ first ▁ dimension ▁ = ▁ N ▁ (number ▁ of ▁ particles) <strnewline> ▁ - ▁ x_next ▁ (array-like): ▁ future ▁ states <strnewline> ▁ - ▁ t ▁ (float): ▁ time ▁ stamp <strnewline> <strnewline> ▁ Returns: ▁ ((array-like), ▁ (array-like)) <strnewline> ▁ """  <newline>  # ▁ Calculate ▁ l2 ▁ according ▁ to ▁ (16) <encdom> N = len ( particles ) <newline> lparam = len ( self . params ) <newline> ( zl , Pl ) = self . get_states ( particles ) <newline> ( zn , Pn ) = self . get_states ( x_next ) <newline> ( A , f , Q ) = self . get_pred_dynamics ( u = u , t = t ) <newline> ( A_grad , f_grad , Q_grad ) = self . get_pred_dynamics_grad ( u = u , t = t ) <newline> lpxn_grad = numpy . zeros ( lparam ) <newline> if ( A_grad is None and f_grad is None and Q_grad is None ) : <newline> <indent> lpxn = self . eval_logp_xnext ( particles , x_next , u , t ) <newline> <dedent> else : <newline> <indent> self . kf . set_dynamics ( A = A , Q = Q , f_k = f ) <newline> lpxn = 0.0 <newline> Qcho = scipy . linalg . cho_factor ( self . kf . Q , check_finite = False ) <newline> ld = numpy . sum ( numpy . log ( numpy . diagonal ( Qcho [ 0 ] ) ) ) * 2 <newline> if ( Q_grad is None ) : <newline> <indent> Q_grad = numpy . zeros ( ( len ( self . params ) , self . kf . lz , self . kf . lz ) ) <newline> <dedent> for k in range ( N ) : <newline> <indent> lz = len ( self . z0 ) <newline> lzP = lz + lz * lz <newline> Mz = particles [ k ] [ lzP : ] . reshape ( ( lz , lz ) ) <newline> ( l2 , l2_grad ) = self . calc_l2_grad ( zn [ k ] , Pn [ k ] , zl [ k ] , Pl [ k ] , self . kf . A , self . kf . f_k , Mz , A_grad , f_grad ) <newline> tmp = scipy . linalg . cho_solve ( Qcho , l2 ) <newline> lpxn += - 0.5 * ( ld + numpy . trace ( tmp ) ) <newline> for j in range ( len ( self . params ) ) : <newline> <indent> lpxn_grad [ j ] -= 0.5 * mlnlg_compute . compute_logprod_derivative ( Qcho , Q_grad [ j ] , l2 , l2_grad [ j ] ) <newline> <dedent> <dedent> <dedent> return ( lpxn , lpxn_grad ) <newline> <dedent> def eval_logp_y ( self , particles , y , t ) : <newline> <indent>  """ <strnewline> ▁ Evaluate ▁ value ▁ of ▁ log ▁ p(y_t|x_t) <strnewline> <strnewline> ▁ Args: <strnewline> ▁ - ▁ particles ▁ (array-like): ▁ Model ▁ specific ▁ representation <strnewline> ▁ of ▁ all ▁ particles, ▁ with ▁ first ▁ dimension ▁ = ▁ N ▁ (number ▁ of ▁ particles) <strnewline> ▁ - ▁ y ▁ (array-like): ▁ measurement <strnewline> ▁ - ▁ t ▁ (float): ▁ time ▁ stamp <strnewline> <strnewline> ▁ Returns: ▁ (array-like) <strnewline> ▁ """  <newline> N = len ( particles ) <newline> self . t = t <newline> ( y , C , h , R ) = self . get_meas_dynamics ( y = y , t = t ) <newline> self . kf . set_dynamics ( C = C , R = R , h_k = h ) <newline> ( zl , Pl ) = self . get_states ( particles ) <newline> logpy = numpy . empty ( N ) <newline> for i in range ( N ) : <newline>  # ▁ Calculate ▁ l3 ▁ according ▁ to ▁ (19b) <encdom> <indent> l3 = self . calc_l3 ( y , zl [ i ] , Pl [ i ] ) <newline> ( _tmp , ld ) = numpy . linalg . slogdet ( self . kf . R ) <newline> tmp = numpy . linalg . solve ( self . kf . R , l3 ) <newline> logpy [ i ] = - 0.5 * ( ld + numpy . trace ( tmp ) ) <newline> <dedent> return logpy <newline> <dedent> def eval_logp_y_val_grad ( self , particles , y , t ) : <newline> <indent>  """ <strnewline> ▁ Evaluate ▁ value ▁ and ▁ gradient ▁ of ▁ log ▁ p(y_t|x_t) <strnewline> <strnewline> ▁ Args: <strnewline> ▁ - ▁ particles ▁ (array-like): ▁ Model ▁ specific ▁ representation <strnewline> ▁ of ▁ all ▁ particles, ▁ with ▁ first ▁ dimension ▁ = ▁ N ▁ (number ▁ of ▁ particles) <strnewline> ▁ - ▁ y ▁ (array-like): ▁ measurement <strnewline> ▁ - ▁ t ▁ (float): ▁ time ▁ stamp <strnewline> <strnewline> ▁ Returns: ▁ ((array-like), ▁ (array-like)) <strnewline> ▁ """  <newline> N = len ( particles ) <newline> lparam = len ( self . params ) <newline> ( y , C , h , R ) = self . get_meas_dynamics ( y = y , t = t ) <newline> ( C_grad , h_grad , R_grad ) = self . get_meas_dynamics_grad ( y = y , t = t ) <newline> logpy_grad = numpy . zeros ( lparam ) <newline> if ( C_grad is None and h_grad is None and R_grad is None ) : <newline> <indent> logpy = self . eval_logp_y ( particles , y , t ) <newline> <dedent> else : <newline> <indent> self . kf . set_dynamics ( C = C , R = R , h_k = h ) <newline> Rcho = scipy . linalg . cho_factor ( self . kf . R , check_finite = False ) <newline> ld = numpy . sum ( numpy . log ( numpy . diagonal ( Rcho [ 0 ] ) ) ) * 2 <newline> ( zl , Pl ) = self . get_states ( particles ) <newline> logpy = 0.0 <newline> if ( R_grad is None ) : <newline> <indent> R_grad = numpy . zeros ( ( len ( self . params ) , len ( y ) , len ( y ) ) ) <newline> <dedent> for i in range ( N ) : <newline>  # ▁ Calculate ▁ l3 ▁ according ▁ to ▁ (19b) <encdom> <indent> ( l3 , l3_grad ) = self . calc_l3_grad ( y , zl [ i ] , Pl [ i ] ) <newline> tmp = scipy . linalg . cho_solve ( Rcho , l3 ) <newline> logpy += - 0.5 * ( ld + numpy . trace ( tmp ) ) <newline> for j in range ( len ( self . params ) ) : <newline> <indent> logpy_grad [ j ] -= 0.5 * mlnlg_compute . compute_logprod_derivative ( Rcho , R_grad [ j ] , l3 , l3_grad [ j ] ) <newline> <dedent> <dedent> <dedent> return ( logpy , logpy_grad ) <newline> <dedent> def get_pred_dynamics_grad ( self , u , t ) : <newline> <indent>  """ <strnewline> ▁ Override ▁ this ▁ method ▁ if ▁ (A, ▁ f, ▁ Q) ▁ depends ▁ on ▁ the ▁ parameters <strnewline> <strnewline> ▁ Args: <strnewline> ▁ - ▁ particles ▁ (array-like): ▁ Model ▁ specific ▁ representation <strnewline> ▁ of ▁ all ▁ particles, ▁ with ▁ first ▁ dimension ▁ = ▁ N ▁ (number ▁ of ▁ particles) <strnewline> ▁ - ▁ u ▁ (array-like): ▁ input ▁ signal <strnewline> ▁ - ▁ t ▁ (float): ▁ time ▁ stamps <strnewline> <strnewline> ▁ Returns: <strnewline> ▁ (A_grad, ▁ f_grad, ▁ Q_grad): ▁ Element-wise ▁ gradients ▁ with ▁ respect ▁ to ▁ all <strnewline> ▁ the ▁ parameters ▁ for ▁ the ▁ system ▁ matrices <strnewline> ▁ """  <newline> return ( None , None , None ) <newline> <dedent> def get_meas_dynamics_grad ( self , y , t ) : <newline> <indent>  """ <strnewline> ▁ Override ▁ this ▁ method ▁ if ▁ (C, ▁ h, ▁ R) ▁ depends ▁ on ▁ the ▁ parameters <strnewline> <strnewline> ▁ Args: <strnewline> ▁ - ▁ particles ▁ (array-like): ▁ Model ▁ specific ▁ representation <strnewline> ▁ of ▁ all ▁ particles, ▁ with ▁ first ▁ dimension ▁ = ▁ N ▁ (number ▁ of ▁ particles) <strnewline> ▁ - ▁ y ▁ (array-like): ▁ measurment <strnewline> ▁ - ▁ t ▁ (float): ▁ time ▁ stamps <strnewline> <strnewline> ▁ Returns: <strnewline> ▁ (C_grad, ▁ h_grad, ▁ R_grad): ▁ Element-wise ▁ gradients ▁ with ▁ respect ▁ to ▁ all <strnewline> ▁ the ▁ parameters ▁ for ▁ the ▁ system ▁ matrices <strnewline> ▁ """  <newline> return ( None , None , None ) <newline> <dedent> def get_initial_grad ( self ) : <newline> <indent>  """ <strnewline> ▁ Default ▁ implementation ▁ has ▁ no ▁ dependence ▁ on ▁ xi, ▁ override ▁ if ▁ needed <strnewline> <strnewline> ▁ Calculate ▁ gradient ▁ estimate ▁ of ▁ initial ▁ state ▁ for ▁ linear ▁ state ▁ condition ▁ on ▁ the <strnewline> ▁ nonlinear ▁ estimate <strnewline> <strnewline> ▁ Args: <strnewline> ▁ - ▁ xi0 ▁ (array-like): ▁ Initial ▁ xi ▁ states <strnewline> <strnewline> ▁ Returns: <strnewline> ▁ (z,P): ▁ z ▁ is ▁ a ▁ list ▁ of ▁ element-wise ▁ gradients ▁ for ▁ the ▁ inital ▁ mean ▁ values, <strnewline> ▁ P ▁ is ▁ a ▁ list ▁ of ▁ element-wise ▁ gradients ▁ for ▁ the ▁ covariance ▁ matrices <strnewline> ▁ """  <newline> lparam = len ( self . params ) <newline> return ( numpy . zeros ( ( lparam , self . kf . lz , 1 ) ) , numpy . zeros ( ( lparam , self . kf . lz , self . kf . lz ) ) ) <newline> <dedent> def calc_l1 ( self , z , P , z0 , P0 ) : <newline> <indent>  """ ▁ internal ▁ helper ▁ function ▁ """  <newline> z0_diff = z - z0 <newline> l1 = z0_diff . dot ( z0_diff . T ) + P <newline> return l1 <newline> <dedent> def calc_l1_grad ( self , z , P , z0 , P0 , z0_grad ) : <newline> <indent>  """ ▁ internal ▁ helper ▁ function ▁ """  <newline> lparams = len ( self . params ) <newline> z0_diff = z - z0 <newline> l1 = z0_diff . dot ( z0_diff . T ) + P <newline> l1_diff = numpy . zeros ( ( lparams , self . kf . lz , self . kf . lz ) ) <newline> if ( z0_grad is not None ) : <newline> <indent> for j in range ( lparams ) : <newline> <indent> tmp = - z0_grad [ j ] . dot ( z0_diff . T ) <newline> l1_diff [ j ] += tmp + tmp . T <newline> <dedent> <dedent> return ( l1 , l1_diff ) <newline> <dedent> def calc_l2 ( self , zn , Pn , z , P , A , f , M ) : <newline> <indent>  """ ▁ internal ▁ helper ▁ function ▁ """  <newline> predict_err = zn - f - A . dot ( z ) <newline> AM = A . dot ( M ) <newline> l2 = predict_err . dot ( predict_err . T ) <newline> l2 += Pn + A . dot ( P ) . dot ( A . T ) - AM . T - AM <newline> return ( l2 , A , M , predict_err ) <newline> <dedent> def calc_l2_grad ( self , zn , Pn , z , P , A , f , M , A_grad , f_grad ) : <newline> <indent>  """ ▁ internal ▁ helper ▁ function ▁ """  <newline> lparam = len ( self . params ) <newline> predict_err = zn - f - A . dot ( z ) <newline> AM = A . dot ( M ) <newline> l2 = predict_err . dot ( predict_err . T ) <newline> l2 += Pn + A . dot ( P ) . dot ( A . T ) - AM . T - AM <newline> l2_grad = numpy . zeros ( ( lparam , self . kf . lz , self . kf . lz ) ) <newline> if ( f_grad is not None ) : <newline> <indent> for j in range ( lparam ) : <newline> <indent> tmp = - f_grad [ j ] . dot ( predict_err . T ) <newline> l2_grad [ j ] += tmp + tmp . T <newline> <dedent> <dedent> if ( A_grad is not None ) : <newline> <indent> for j in range ( lparam ) : <newline> <indent> tmp = - A_grad [ j ] . dot ( z ) . dot ( predict_err . T ) <newline> l2_grad [ j ] += tmp + tmp . T <newline> tmp = A_grad [ j ] . dot ( P ) . dot ( A . T ) <newline> l2_grad [ j ] += tmp + tmp . T <newline> tmp = - A_grad [ j ] . dot ( M ) <newline> l2_grad [ j ] += tmp + tmp . T <newline> <dedent> <dedent> return ( l2 , l2_grad ) <newline> <dedent> def calc_l3 ( self , y , z , P ) : <newline> <indent>  """ ▁ internal ▁ helper ▁ function ▁ """  <newline> meas_diff = self . kf . measurement_diff ( y . reshape ( ( - 1 , 1 ) ) , z , C = self . kf . C , h_k = self . kf . h_k ) <newline> l3 = meas_diff . dot ( meas_diff . T ) <newline> l3 += self . kf . C . dot ( P ) . dot ( self . kf . C . T ) <newline> return l3 <newline> <dedent> def calc_l3_grad ( self , y , z , P , C_grad , h_grad ) : <newline> <indent>  """ ▁ internal ▁ helper ▁ function ▁ """  <newline> lparam = len ( self . params ) <newline> meas_diff = self . kf . measurement_diff ( y . reshape ( ( - 1 , 1 ) ) , z , C = self . kf . C , h_k = self . kf . h_k ) <newline> l3 = meas_diff . dot ( meas_diff . T ) <newline> l3 += self . kf . C . dot ( P ) . dot ( self . kf . C . T ) <newline> l3_grad = numpy . zeros ( ( lparam , len ( y ) , len ( y ) ) ) <newline> if ( h_grad is not None ) : <newline> <indent> for j in range ( lparam ) : <newline> <indent> tmp = - h_grad [ j ] . dot ( meas_diff ) <newline> l3_grad [ j ] += tmp + tmp . T <newline> <dedent> <dedent> if ( C_grad is not None ) : <newline> <indent> for j in range ( lparam ) : <newline> <indent> tmp = - C_grad [ j ] . dot ( z ) . dot ( meas_diff ) <newline> l3_grad [ j ] += tmp + tmp . T <newline> tmp = C_grad [ j ] . dot ( P ) . dot ( self . kf . C ) <newline> l3_grad [ j ] += tmp + tmp . T <newline> <dedent> <dedent> return ( l3 , l3_grad ) <newline> <dedent> <dedent>
 """ Test ▁ the ▁ NO-IP ▁ component. """  <newline> import asyncio <newline> from datetime import timedelta <newline> import pytest <newline> from homeassistant . setup import async_setup_component <newline> from homeassistant . components import no_ip <newline> from homeassistant . util . dt import utcnow <newline> from tests . common import async_fire_time_changed <newline> DOMAIN = 'test.example.com' <newline> PASSWORD = 'xyz789' <newline> UPDATE_URL = no_ip . UPDATE_URL <newline> USERNAME = 'abc@123.com' <newline> @ pytest . fixture <newline> def setup_no_ip ( hass , aioclient_mock ) : <newline> <indent>  """ Fixture ▁ that ▁ sets ▁ up ▁ NO-IP. """  <newline> aioclient_mock . get ( UPDATE_URL , params = { 'hostname' : DOMAIN } , text = 'good ▁ 0.0.0.0' ) <newline> hass . loop . run_until_complete ( async_setup_component ( hass , no_ip . DOMAIN , { no_ip . DOMAIN : { 'domain' : DOMAIN , 'username' : USERNAME , 'password' : PASSWORD , } } ) ) <newline> <dedent> @ asyncio . coroutine <newline> def test_setup ( hass , aioclient_mock ) : <newline> <indent>  """ Test ▁ setup ▁ works ▁ if ▁ update ▁ passes. """  <newline> aioclient_mock . get ( UPDATE_URL , params = { 'hostname' : DOMAIN } , text = 'nochg ▁ 0.0.0.0' ) <newline> result = yield from async_setup_component ( hass , no_ip . DOMAIN , { no_ip . DOMAIN : { 'domain' : DOMAIN , 'username' : USERNAME , 'password' : PASSWORD , } } ) <newline> assert result <newline> assert aioclient_mock . call_count == 1 <newline> async_fire_time_changed ( hass , utcnow ( ) + timedelta ( minutes = 5 ) ) <newline> yield from hass . async_block_till_done ( ) <newline> assert aioclient_mock . call_count == 2 <newline> <dedent> @ asyncio . coroutine <newline> def test_setup_fails_if_update_fails ( hass , aioclient_mock ) : <newline> <indent>  """ Test ▁ setup ▁ fails ▁ if ▁ first ▁ update ▁ fails. """  <newline> aioclient_mock . get ( UPDATE_URL , params = { 'hostname' : DOMAIN } , text = 'nohost' ) <newline> result = yield from async_setup_component ( hass , no_ip . DOMAIN , { no_ip . DOMAIN : { 'domain' : DOMAIN , 'username' : USERNAME , 'password' : PASSWORD , } } ) <newline> assert not result <newline> assert aioclient_mock . call_count == 1 <newline> <dedent> @ asyncio . coroutine <newline> def test_setup_fails_if_wrong_auth ( hass , aioclient_mock ) : <newline> <indent>  """ Test ▁ setup ▁ fails ▁ if ▁ first ▁ update ▁ fails ▁ through ▁ wrong ▁ authentication. """  <newline> aioclient_mock . get ( UPDATE_URL , params = { 'hostname' : DOMAIN } , text = 'badauth' ) <newline> result = yield from async_setup_component ( hass , no_ip . DOMAIN , { no_ip . DOMAIN : { 'domain' : DOMAIN , 'username' : USERNAME , 'password' : PASSWORD , } } ) <newline> assert not result <newline> assert aioclient_mock . call_count == 1 <newline> <dedent>
 # ▁ coding: ▁ utf-8 <encdom> from __future__ import unicode_literals <newline> import re <newline> from . common import InfoExtractor <newline> class WeiboIE ( InfoExtractor ) : <newline> <indent>  """ <strnewline> ▁ The ▁ videos ▁ in ▁ Weibo ▁ come ▁ from ▁ different ▁ sites, ▁ this ▁ IE ▁ just ▁ finds ▁ the ▁ link <strnewline> ▁ to ▁ the ▁ external ▁ video ▁ and ▁ returns ▁ it. <strnewline> ▁ """  <newline> _VALID_URL = r'https?://video\.weibo\.com/v/weishipin/t_(?P<id>.+?)\.htm' <newline> _TEST = { 'url' : 'http://video.weibo.com/v/weishipin/t_zjUw2kZ.htm' , 'info_dict' : { 'id' : '98322879' , 'ext' : 'flv' , 'title' : '魔声耳机最新广告“All ▁ Eyes ▁ On ▁ Us”' , } , 'params' : { 'skip_download' : True , } , 'add_ie' : [ 'Sina' ] , } <newline>  # ▁ Additional ▁ example ▁ videos ▁ from ▁ different ▁ sites <encdom>  # ▁ Youku: ▁ http://video.weibo.com/v/weishipin/t_zQGDWQ8.htm <encdom>  # ▁ 56.com: ▁ http://video.weibo.com/v/weishipin/t_zQ44HxN.htm <encdom> def _real_extract ( self , url ) : <newline> <indent> mobj = re . match ( self . _VALID_URL , url , flags = re . VERBOSE ) <newline> video_id = mobj . group ( 'id' ) <newline> info_url = 'http://video.weibo.com/?s=v&a=play_list&format=json&mix_video_id=t_%s' % video_id <newline> info = self . _download_json ( info_url , video_id ) <newline> videos_urls = map ( lambda v : v [ 'play_page_url' ] , info [ 'result' ] [ 'data' ] ) <newline>  # ▁ Prefer ▁ sina ▁ video ▁ since ▁ they ▁ have ▁ thumbnails <encdom> videos_urls = sorted ( videos_urls , key = lambda u : 'video.sina.com' in u ) <newline> player_url = videos_urls [ - 1 ] <newline> m_sina = re . match ( r'https?://video\.sina\.com\.cn/v/b/(\d+)-\d+\.html' , player_url ) <newline> if m_sina is not None : <newline> <indent> self . to_screen ( 'Sina ▁ video ▁ detected' ) <newline> sina_id = m_sina . group ( 1 ) <newline> player_url = 'http://you.video.sina.com.cn/swf/quotePlayer.swf?vid=%s' % sina_id <newline> <dedent> return self . url_result ( player_url ) <newline> <dedent> <dedent>
 # ▁ Created ▁ for ▁ aenea ▁ using ▁ libraries ▁ from ▁ the ▁ Dictation ▁ Toolbox <encdom>  # ▁ https://github.com/dictation-toolbox/dragonfly-scripts <encdom>  # ▁ Commands ▁ for ▁ writing ▁ SQL ▁ queries <encdom>  # ▁ Author: ▁ Tony ▁ Grosinger <encdom>  # ▁ Licensed ▁ under ▁ LGPL <encdom> import aenea <newline> import aenea . configuration <newline> from aenea import Choice <newline> from aenea . lax import Text <newline> import dragonfly <newline> sql_map = { "update" : "UPDATE ▁ " , "select" : "SELECT ▁ " , "from" : "FROM ▁ " , "count" : "COUNT ▁ " , "values" : "VALUES ▁ " , "as" : "AS ▁ " , "when" : "WHEN ▁ " , "in" : "IN ▁ " , "into" : "INTO ▁ " , "and" : "AND ▁ " , "all" : "ALL ▁ " , "similar ▁ to" : "SIMILAR ▁ TO ▁ " , "like" : "LIKE ▁ " , "set" : "SET ▁ " , } <newline> sql_mapping = aenea . configuration . make_grammar_commands ( 'sql' , { '<sqlKeyword>' : Text ( "%(text)s" ) , } ) <newline> class SQL ( dragonfly . MappingRule ) : <newline> <indent> mapping = sql_mapping <newline> extras = [ Choice ( 'sqlKeyword' , sql_map , ) ] <newline> <dedent> def get_grammar ( context ) : <newline> <indent> sql_grammar = dragonfly . Grammar ( 'sql' , context = context ) <newline> sql_grammar . add_rule ( SQL ( ) ) <newline> return sql_grammar <newline> <dedent>
 # !/usr/bin/env ▁ python <encdom>  """ VIC ▁ test ▁ archiving ▁ command ▁ line ▁ interface """  <newline> import argparse <newline> from collections import OrderedDict <newline> from datetime import datetime <newline> from . run_tests import epilog , description , CustomFormatter <newline> def main ( ) : <newline> <indent>  """ <strnewline> ▁ Archive ▁ VIC ▁ tests <strnewline> ▁ """  <newline>  # ▁ Parse ▁ arguments <encdom> test_results = OrderedDict ( ) <newline> parser = argparse . ArgumentParser ( description = description , epilog = epilog , formatter_class = CustomFormatter ) <newline> parser . add_argument ( "tests" , type = str , help = "Test ▁ sets ▁ to ▁ run" , choices = [ 'all' , 'unit' , 'system' , 'science' , 'examples' , 'release' ] , default = [ 'unit' , 'system' , 'science' ] , nargs = '+' ) <newline> parser . add_argument ( "--output_dir" , type = str , help = "directory ▁ to ▁ get ▁ test ▁ output" , default = "$WORKDIR/VIC_tests_{0}" . format ( datetime . datetime . now ( ) . strftime ( "%Y%m%d" ) ) ) <newline> parser . add_argument ( "--data_dir" , type = str , help = "directory ▁ to ▁ put ▁ test ▁ data" , default = 'test_data/VIC.4.1.2' ) <newline> args = parser . parse_args ( ) <newline> print ( test_results , args ) <newline> return <newline> <dedent> if __name__ == "__main__" : <newline> <indent> main ( ) <newline> <dedent>
from __future__ import unicode_literals <newline> from datetime import date <newline> import traceback <newline> import warnings <newline> from django . db import IntegrityError , DatabaseError <newline> from django . utils . encoding import DjangoUnicodeDecodeError <newline> from django . test import TestCase , TransactionTestCase <newline> from . models import DefaultPerson , Person , ManualPrimaryKeyTest , Profile , Tag , Thing <newline> class GetOrCreateTests ( TestCase ) : <newline> <indent> def test_get_or_create ( self ) : <newline> <indent> p = Person . objects . create ( first_name = 'John' , last_name = 'Lennon' , birthday = date ( 1940 , 10 , 9 ) ) <newline> p , created = Person . objects . get_or_create ( first_name = "John" , last_name = "Lennon" , defaults = { "birthday" : date ( 1940 , 10 , 9 ) } ) <newline> self . assertFalse ( created ) <newline> self . assertEqual ( Person . objects . count ( ) , 1 ) <newline> p , created = Person . objects . get_or_create ( first_name = 'George' , last_name = 'Harrison' , defaults = { 'birthday' : date ( 1943 , 2 , 25 ) } ) <newline> self . assertTrue ( created ) <newline> self . assertEqual ( Person . objects . count ( ) , 2 ) <newline>  # ▁ If ▁ we ▁ execute ▁ the ▁ exact ▁ same ▁ statement, ▁ it ▁ won't ▁ create ▁ a ▁ Person. <encdom> p , created = Person . objects . get_or_create ( first_name = 'George' , last_name = 'Harrison' , defaults = { 'birthday' : date ( 1943 , 2 , 25 ) } ) <newline> self . assertFalse ( created ) <newline> self . assertEqual ( Person . objects . count ( ) , 2 ) <newline>  # ▁ If ▁ you ▁ don't ▁ specify ▁ a ▁ value ▁ or ▁ default ▁ value ▁ for ▁ all ▁ required <encdom>  # ▁ fields, ▁ you ▁ will ▁ get ▁ an ▁ error. <encdom> self . assertRaises ( IntegrityError , Person . objects . get_or_create , first_name = "Tom" , last_name = "Smith" ) <newline>  # ▁ If ▁ you ▁ specify ▁ an ▁ existing ▁ primary ▁ key, ▁ but ▁ different ▁ other ▁ fields, <encdom>  # ▁ then ▁ you ▁ will ▁ get ▁ an ▁ error ▁ and ▁ data ▁ will ▁ not ▁ be ▁ updated. <encdom> ManualPrimaryKeyTest . objects . create ( id = 1 , data = "Original" ) <newline> self . assertRaises ( IntegrityError , ManualPrimaryKeyTest . objects . get_or_create , id = 1 , data = "Different" ) <newline> self . assertEqual ( ManualPrimaryKeyTest . objects . get ( id = 1 ) . data , "Original" ) <newline>  # ▁ get_or_create ▁ should ▁ raise ▁ IntegrityErrors ▁ with ▁ the ▁ full ▁ traceback. <encdom>  # ▁ This ▁ is ▁ tested ▁ by ▁ checking ▁ that ▁ a ▁ known ▁ method ▁ call ▁ is ▁ in ▁ the ▁ traceback. <encdom>  # ▁ We ▁ cannot ▁ use ▁ assertRaises/assertRaises ▁ here ▁ because ▁ we ▁ need ▁ to ▁ inspect <encdom>  # ▁ the ▁ actual ▁ traceback. ▁ Refs ▁ # 16340. <encdom> try : <newline> <indent> ManualPrimaryKeyTest . objects . get_or_create ( id = 1 , data = "Different" ) <newline> <dedent> except IntegrityError : <newline> <indent> formatted_traceback = traceback . format_exc ( ) <newline> self . assertIn ( str ( 'obj.save' ) , formatted_traceback ) <newline> <dedent> <dedent> def test_savepoint_rollback ( self ) : <newline>  # ▁ Regression ▁ test ▁ for ▁ # 20463: ▁ the ▁ database ▁ connection ▁ should ▁ still ▁ be <encdom>  # ▁ usable ▁ after ▁ a ▁ DataError ▁ or ▁ ProgrammingError ▁ in ▁ .get_or_create(). <encdom> <indent> try : <newline>  # ▁ Hide ▁ warnings ▁ when ▁ broken ▁ data ▁ is ▁ saved ▁ with ▁ a ▁ warning ▁ (MySQL). <encdom> <indent> with warnings . catch_warnings ( ) : <newline> <indent> warnings . simplefilter ( 'ignore' ) <newline> Person . objects . get_or_create ( birthday = date ( 1970 , 1 , 1 ) , defaults = { 'first_name' : b"\xff" , 'last_name' : b"\xff" } ) <newline> <dedent> <dedent> except ( DatabaseError , DjangoUnicodeDecodeError ) : <newline> <indent> Person . objects . create ( first_name = "Bob" , last_name = "Ross" , birthday = date ( 1950 , 1 , 1 ) ) <newline> <dedent> else : <newline> <indent> self . skipTest ( "This ▁ backend ▁ accepts ▁ broken ▁ utf-8." ) <newline> <dedent> <dedent> def test_get_or_create_empty ( self ) : <newline>  # ▁ Regression ▁ test ▁ for ▁ # 16137: ▁ get_or_create ▁ does ▁ not ▁ require ▁ kwargs. <encdom> <indent> try : <newline> <indent> DefaultPerson . objects . get_or_create ( ) <newline> <dedent> except AssertionError : <newline> <indent> self . fail ( "If ▁ all ▁ the ▁ attributes ▁ on ▁ a ▁ model ▁ have ▁ defaults, ▁ we ▁ " "shouldn't ▁ need ▁ to ▁ pass ▁ any ▁ arguments." ) <newline> <dedent> <dedent> <dedent> class GetOrCreateTransactionTests ( TransactionTestCase ) : <newline> <indent> available_apps = [ 'get_or_create' ] <newline> def test_get_or_create_integrityerror ( self ) : <newline>  # ▁ Regression ▁ test ▁ for ▁ # 15117. ▁ Requires ▁ a ▁ TransactionTestCase ▁ on <encdom>  # ▁ databases ▁ that ▁ delay ▁ integrity ▁ checks ▁ until ▁ the ▁ end ▁ of ▁ transactions, <encdom>  # ▁ otherwise ▁ the ▁ exception ▁ is ▁ never ▁ raised. <encdom> <indent> try : <newline> <indent> Profile . objects . get_or_create ( person = Person ( id = 1 ) ) <newline> <dedent> except IntegrityError : <newline> <indent> pass <newline> <dedent> else : <newline> <indent> self . skipTest ( "This ▁ backend ▁ does ▁ not ▁ support ▁ integrity ▁ checks." ) <newline> <dedent> <dedent> <dedent> class GetOrCreateThroughManyToMany ( TestCase ) : <newline> <indent> def test_get_get_or_create ( self ) : <newline> <indent> tag = Tag . objects . create ( text = 'foo' ) <newline> a_thing = Thing . objects . create ( name = 'a' ) <newline> a_thing . tags . add ( tag ) <newline> obj , created = a_thing . tags . get_or_create ( text = 'foo' ) <newline> self . assertFalse ( created ) <newline> self . assertEqual ( obj . pk , tag . pk ) <newline> <dedent> def test_create_get_or_create ( self ) : <newline> <indent> a_thing = Thing . objects . create ( name = 'a' ) <newline> obj , created = a_thing . tags . get_or_create ( text = 'foo' ) <newline> self . assertTrue ( created ) <newline> self . assertEqual ( obj . text , 'foo' ) <newline> self . assertIn ( obj , a_thing . tags . all ( ) ) <newline> <dedent> def test_something ( self ) : <newline> <indent> Tag . objects . create ( text = 'foo' ) <newline> a_thing = Thing . objects . create ( name = 'a' ) <newline> self . assertRaises ( IntegrityError , a_thing . tags . get_or_create , text = 'foo' ) <newline> <dedent> <dedent> class UpdateOrCreateTests ( TestCase ) : <newline> <indent> def test_update ( self ) : <newline> <indent> Person . objects . create ( first_name = 'John' , last_name = 'Lennon' , birthday = date ( 1940 , 10 , 9 ) ) <newline> p , created = Person . objects . update_or_create ( first_name = 'John' , last_name = 'Lennon' , defaults = { 'birthday' : date ( 1940 , 10 , 10 ) } ) <newline> self . assertFalse ( created ) <newline> self . assertEqual ( p . first_name , 'John' ) <newline> self . assertEqual ( p . last_name , 'Lennon' ) <newline> self . assertEqual ( p . birthday , date ( 1940 , 10 , 10 ) ) <newline> <dedent> def test_create ( self ) : <newline> <indent> p , created = Person . objects . update_or_create ( first_name = 'John' , last_name = 'Lennon' , defaults = { 'birthday' : date ( 1940 , 10 , 10 ) } ) <newline> self . assertTrue ( created ) <newline> self . assertEqual ( p . first_name , 'John' ) <newline> self . assertEqual ( p . last_name , 'Lennon' ) <newline> self . assertEqual ( p . birthday , date ( 1940 , 10 , 10 ) ) <newline> <dedent> def test_create_twice ( self ) : <newline> <indent> params = { 'first_name' : 'John' , 'last_name' : 'Lennon' , 'birthday' : date ( 1940 , 10 , 10 ) , } <newline> Person . objects . update_or_create ( ** params ) <newline>  # ▁ If ▁ we ▁ execute ▁ the ▁ exact ▁ same ▁ statement, ▁ it ▁ won't ▁ create ▁ a ▁ Person. <encdom> p , created = Person . objects . update_or_create ( ** params ) <newline> self . assertFalse ( created ) <newline> <dedent> def test_integrity ( self ) : <newline>  # ▁ If ▁ you ▁ don't ▁ specify ▁ a ▁ value ▁ or ▁ default ▁ value ▁ for ▁ all ▁ required <encdom>  # ▁ fields, ▁ you ▁ will ▁ get ▁ an ▁ error. <encdom> <indent> self . assertRaises ( IntegrityError , Person . objects . update_or_create , first_name = "Tom" , last_name = "Smith" ) <newline> <dedent> def test_manual_primary_key_test ( self ) : <newline>  # ▁ If ▁ you ▁ specify ▁ an ▁ existing ▁ primary ▁ key, ▁ but ▁ different ▁ other ▁ fields, <encdom>  # ▁ then ▁ you ▁ will ▁ get ▁ an ▁ error ▁ and ▁ data ▁ will ▁ not ▁ be ▁ updated. <encdom> <indent> ManualPrimaryKeyTest . objects . create ( id = 1 , data = "Original" ) <newline> self . assertRaises ( IntegrityError , ManualPrimaryKeyTest . objects . update_or_create , id = 1 , data = "Different" ) <newline> self . assertEqual ( ManualPrimaryKeyTest . objects . get ( id = 1 ) . data , "Original" ) <newline> <dedent> def test_error_contains_full_traceback ( self ) : <newline>  # ▁ update_or_create ▁ should ▁ raise ▁ IntegrityErrors ▁ with ▁ the ▁ full ▁ traceback. <encdom>  # ▁ This ▁ is ▁ tested ▁ by ▁ checking ▁ that ▁ a ▁ known ▁ method ▁ call ▁ is ▁ in ▁ the ▁ traceback. <encdom>  # ▁ We ▁ cannot ▁ use ▁ assertRaises/assertRaises ▁ here ▁ because ▁ we ▁ need ▁ to ▁ inspect <encdom>  # ▁ the ▁ actual ▁ traceback. ▁ Refs ▁ # 16340. <encdom> <indent> try : <newline> <indent> ManualPrimaryKeyTest . objects . update_or_create ( id = 1 , data = "Different" ) <newline> <dedent> except IntegrityError : <newline> <indent> formatted_traceback = traceback . format_exc ( ) <newline> self . assertIn ( 'obj.save' , formatted_traceback ) <newline> <dedent> <dedent> <dedent>
from datetime import date <newline> from factory import Sequence , post_generation , SubFactory <newline> from factory . alchemy import SQLAlchemyModelFactory <newline> from factory . fuzzy import FuzzyChoice , FuzzyText , FuzzyDate , FuzzyInteger <newline> from lemur . database import db <newline> from lemur . authorities . models import Authority <newline> from lemur . certificates . models import Certificate <newline> from lemur . destinations . models import Destination <newline> from lemur . sources . models import Source <newline> from lemur . notifications . models import Notification <newline> from lemur . pending_certificates . models import PendingCertificate <newline> from lemur . users . models import User <newline> from lemur . roles . models import Role <newline> from lemur . endpoints . models import Policy , Endpoint <newline> from lemur . policies . models import RotationPolicy <newline> from lemur . api_keys . models import ApiKey <newline> from . vectors import ( SAN_CERT_STR , SAN_CERT_KEY , CSR_STR , INTERMEDIATE_CERT_STR , ROOTCA_CERT_STR , INTERMEDIATE_KEY , WILDCARD_CERT_KEY , INVALID_CERT_STR , ) <newline> class BaseFactory ( SQLAlchemyModelFactory ) : <newline> <indent>  """ Base ▁ factory. """  <newline> class Meta : <newline> <indent>  """ Factory ▁ configuration. """  <newline> abstract = True <newline> sqlalchemy_session = db . session <newline> <dedent> <dedent> class RotationPolicyFactory ( BaseFactory ) : <newline> <indent>  """ Rotation ▁ Factory. """  <newline> name = Sequence ( lambda n : "policy{0}" . format ( n ) ) <newline> days = 30 <newline> class Meta : <newline> <indent>  """ Factory ▁ configuration. """  <newline> model = RotationPolicy <newline> <dedent> <dedent> class CertificateFactory ( BaseFactory ) : <newline> <indent>  """ Certificate ▁ factory. """  <newline> name = Sequence ( lambda n : "certificate{0}" . format ( n ) ) <newline> chain = INTERMEDIATE_CERT_STR <newline> body = SAN_CERT_STR <newline> private_key = SAN_CERT_KEY <newline> owner = "joe@example.com" <newline> status = FuzzyChoice ( [ "valid" , "revoked" , "unknown" ] ) <newline> deleted = False <newline> description = FuzzyText ( length = 128 ) <newline> active = True <newline> date_created = FuzzyDate ( date ( 2016 , 1 , 1 ) , date ( 2020 , 1 , 1 ) ) <newline> rotation_policy = SubFactory ( RotationPolicyFactory ) <newline> class Meta : <newline> <indent>  """ Factory ▁ Configuration. """  <newline> model = Certificate <newline> <dedent> @ post_generation <newline> def user ( self , create , extracted , ** kwargs ) : <newline> <indent> if not create : <newline> <indent> return <newline> <dedent> if extracted : <newline> <indent> self . user_id = extracted . id <newline> <dedent> <dedent> @ post_generation <newline> def authority ( self , create , extracted , ** kwargs ) : <newline> <indent> if not create : <newline> <indent> return <newline> <dedent> if extracted : <newline> <indent> self . authority_id = extracted . id <newline> <dedent> <dedent> @ post_generation <newline> def notifications ( self , create , extracted , ** kwargs ) : <newline> <indent> if not create : <newline> <indent> return <newline> <dedent> if extracted : <newline> <indent> for notification in extracted : <newline> <indent> self . notifications . append ( notification ) <newline> <dedent> <dedent> <dedent> @ post_generation <newline> def destinations ( self , create , extracted , ** kwargs ) : <newline> <indent> if not create : <newline> <indent> return <newline> <dedent> if extracted : <newline> <indent> for destination in extracted : <newline> <indent> self . destintations . append ( destination ) <newline> <dedent> <dedent> <dedent> @ post_generation <newline> def replaces ( self , create , extracted , ** kwargs ) : <newline> <indent> if not create : <newline> <indent> return <newline> <dedent> if extracted : <newline> <indent> for replace in extracted : <newline> <indent> self . replaces . append ( replace ) <newline> <dedent> <dedent> <dedent> @ post_generation <newline> def sources ( self , create , extracted , ** kwargs ) : <newline> <indent> if not create : <newline> <indent> return <newline> <dedent> if extracted : <newline> <indent> for source in extracted : <newline> <indent> self . sources . append ( source ) <newline> <dedent> <dedent> <dedent> @ post_generation <newline> def domains ( self , create , extracted , ** kwargs ) : <newline> <indent> if not create : <newline> <indent> return <newline> <dedent> if extracted : <newline> <indent> for domain in extracted : <newline> <indent> self . domains . append ( domain ) <newline> <dedent> <dedent> <dedent> @ post_generation <newline> def roles ( self , create , extracted , ** kwargs ) : <newline> <indent> if not create : <newline> <indent> return <newline> <dedent> if extracted : <newline> <indent> for domain in extracted : <newline> <indent> self . roles . append ( domain ) <newline> <dedent> <dedent> <dedent> <dedent> class CACertificateFactory ( CertificateFactory ) : <newline> <indent> chain = ROOTCA_CERT_STR <newline> body = INTERMEDIATE_CERT_STR <newline> private_key = INTERMEDIATE_KEY <newline> <dedent> class InvalidCertificateFactory ( CertificateFactory ) : <newline> <indent> body = INVALID_CERT_STR <newline> private_key = "" <newline> chain = "" <newline> <dedent> class AuthorityFactory ( BaseFactory ) : <newline> <indent>  """ Authority ▁ factory. """  <newline> name = Sequence ( lambda n : "authority{0}" . format ( n ) ) <newline> owner = "joe@example.com" <newline> plugin = { "slug" : "test-issuer" } <newline> description = FuzzyText ( length = 128 ) <newline> authority_certificate = SubFactory ( CACertificateFactory ) <newline> class Meta : <newline> <indent>  """ Factory ▁ configuration. """  <newline> model = Authority <newline> <dedent> @ post_generation <newline> def roles ( self , create , extracted , ** kwargs ) : <newline> <indent> if not create : <newline> <indent> return <newline> <dedent> if extracted : <newline> <indent> for role in extracted : <newline> <indent> self . roles . append ( role ) <newline> <dedent> <dedent> <dedent> <dedent> class AsyncAuthorityFactory ( AuthorityFactory ) : <newline> <indent>  """ Async ▁ Authority ▁ factory. """  <newline> name = Sequence ( lambda n : "authority{0}" . format ( n ) ) <newline> owner = "joe@example.com" <newline> plugin = { "slug" : "test-issuer-async" } <newline> description = FuzzyText ( length = 128 ) <newline> authority_certificate = SubFactory ( CertificateFactory ) <newline> <dedent> class CryptoAuthorityFactory ( AuthorityFactory ) : <newline> <indent>  """ Authority ▁ factory ▁ based ▁ on ▁'cryptography' ▁ plugin. """  <newline> plugin = { "slug" : "cryptography-issuer" } <newline> <dedent> class DestinationFactory ( BaseFactory ) : <newline> <indent>  """ Destination ▁ factory. """  <newline> plugin_name = "test-destination" <newline> label = Sequence ( lambda n : "destination{0}" . format ( n ) ) <newline> class Meta : <newline> <indent>  """ Factory ▁ Configuration. """  <newline> model = Destination <newline> <dedent> <dedent> class SourceFactory ( BaseFactory ) : <newline> <indent>  """ Source ▁ factory. """  <newline> plugin_name = "test-source" <newline> label = Sequence ( lambda n : "source{0}" . format ( n ) ) <newline> class Meta : <newline> <indent>  """ Factory ▁ Configuration. """  <newline> model = Source <newline> <dedent> <dedent> class NotificationFactory ( BaseFactory ) : <newline> <indent>  """ Notification ▁ factory. """  <newline> plugin_name = "test-notification" <newline> label = Sequence ( lambda n : "notification{0}" . format ( n ) ) <newline> class Meta : <newline> <indent>  """ Factory ▁ Configuration. """  <newline> model = Notification <newline> <dedent> <dedent> class RoleFactory ( BaseFactory ) : <newline> <indent>  """ Role ▁ factory. """  <newline> name = Sequence ( lambda n : "role{0}" . format ( n ) ) <newline> class Meta : <newline> <indent>  """ Factory ▁ Configuration. """  <newline> model = Role <newline> <dedent> @ post_generation <newline> def users ( self , create , extracted , ** kwargs ) : <newline> <indent> if not create : <newline> <indent> return <newline> <dedent> if extracted : <newline> <indent> for user in extracted : <newline> <indent> self . users . append ( user ) <newline> <dedent> <dedent> <dedent> <dedent> class UserFactory ( BaseFactory ) : <newline> <indent>  """ User ▁ Factory. """  <newline> username = Sequence ( lambda n : "user{0}" . format ( n ) ) <newline> email = Sequence ( lambda n : "user{0}@example.com" . format ( n ) ) <newline> active = True <newline> password = FuzzyText ( length = 24 ) <newline> certificates = [ ] <newline> class Meta : <newline> <indent>  """ Factory ▁ Configuration. """  <newline> model = User <newline> <dedent> @ post_generation <newline> def roles ( self , create , extracted , ** kwargs ) : <newline> <indent> if not create : <newline> <indent> return <newline> <dedent> if extracted : <newline> <indent> for role in extracted : <newline> <indent> self . roles . append ( role ) <newline> <dedent> <dedent> <dedent> @ post_generation <newline> def certificates ( self , create , extracted , ** kwargs ) : <newline> <indent> if not create : <newline> <indent> return <newline> <dedent> if extracted : <newline> <indent> for cert in extracted : <newline> <indent> self . certificates . append ( cert ) <newline> <dedent> <dedent> <dedent> @ post_generation <newline> def authorities ( self , create , extracted , ** kwargs ) : <newline> <indent> if not create : <newline> <indent> return <newline> <dedent> if extracted : <newline> <indent> for authority in extracted : <newline> <indent> self . authorities . append ( authority ) <newline> <dedent> <dedent> <dedent> <dedent> class PolicyFactory ( BaseFactory ) : <newline> <indent>  """ Policy ▁ Factory. """  <newline> name = Sequence ( lambda n : "endpoint{0}" . format ( n ) ) <newline> class Meta : <newline> <indent>  """ Factory ▁ Configuration. """  <newline> model = Policy <newline> <dedent> <dedent> class EndpointFactory ( BaseFactory ) : <newline> <indent>  """ Endpoint ▁ Factory. """  <newline> owner = "joe@example.com" <newline> name = Sequence ( lambda n : "endpoint{0}" . format ( n ) ) <newline> type = FuzzyChoice ( [ "elb" ] ) <newline> active = True <newline> port = FuzzyInteger ( 0 , high = 65535 ) <newline> dnsname = "endpoint.example.com" <newline> policy = SubFactory ( PolicyFactory ) <newline> certificate = SubFactory ( CertificateFactory ) <newline> source = SubFactory ( SourceFactory ) <newline> class Meta : <newline> <indent>  """ Factory ▁ Configuration. """  <newline> model = Endpoint <newline> <dedent> <dedent> class ApiKeyFactory ( BaseFactory ) : <newline> <indent>  """ Api ▁ Key ▁ Factory. """  <newline> name = Sequence ( lambda n : "api_key_{0}" . format ( n ) ) <newline> revoked = False <newline> ttl = - 1 <newline> issued_at = 1 <newline> class Meta : <newline> <indent>  """ Factory ▁ Configuration. """  <newline> model = ApiKey <newline> <dedent> @ post_generation <newline> def user ( self , create , extracted , ** kwargs ) : <newline> <indent> if not create : <newline> <indent> return <newline> <dedent> if extracted : <newline> <indent> self . userId = extracted . id <newline> <dedent> <dedent> <dedent> class PendingCertificateFactory ( BaseFactory ) : <newline> <indent>  """ PendingCertificate ▁ factory. """  <newline> name = Sequence ( lambda n : "pending_certificate{0}" . format ( n ) ) <newline> external_id = 12345 <newline> csr = CSR_STR <newline> chain = INTERMEDIATE_CERT_STR <newline> private_key = WILDCARD_CERT_KEY <newline> owner = "joe@example.com" <newline> status = FuzzyChoice ( [ "valid" , "revoked" , "unknown" ] ) <newline> deleted = False <newline> description = FuzzyText ( length = 128 ) <newline> date_created = FuzzyDate ( date ( 2016 , 1 , 1 ) , date ( 2020 , 1 , 1 ) ) <newline> number_attempts = 0 <newline> rename = False <newline> class Meta : <newline> <indent>  """ Factory ▁ Configuration. """  <newline> model = PendingCertificate <newline> <dedent> @ post_generation <newline> def user ( self , create , extracted , ** kwargs ) : <newline> <indent> if not create : <newline> <indent> return <newline> <dedent> if extracted : <newline> <indent> self . user_id = extracted . id <newline> <dedent> <dedent> @ post_generation <newline> def authority ( self , create , extracted , ** kwargs ) : <newline> <indent> if not create : <newline> <indent> return <newline> <dedent> if extracted : <newline> <indent> self . authority_id = extracted . id <newline> <dedent> <dedent> @ post_generation <newline> def notifications ( self , create , extracted , ** kwargs ) : <newline> <indent> if not create : <newline> <indent> return <newline> <dedent> if extracted : <newline> <indent> for notification in extracted : <newline> <indent> self . notifications . append ( notification ) <newline> <dedent> <dedent> <dedent> @ post_generation <newline> def destinations ( self , create , extracted , ** kwargs ) : <newline> <indent> if not create : <newline> <indent> return <newline> <dedent> if extracted : <newline> <indent> for destination in extracted : <newline> <indent> self . destintations . append ( destination ) <newline> <dedent> <dedent> <dedent> @ post_generation <newline> def replaces ( self , create , extracted , ** kwargs ) : <newline> <indent> if not create : <newline> <indent> return <newline> <dedent> if extracted : <newline> <indent> for replace in extracted : <newline> <indent> self . replaces . append ( replace ) <newline> <dedent> <dedent> <dedent> @ post_generation <newline> def sources ( self , create , extracted , ** kwargs ) : <newline> <indent> if not create : <newline> <indent> return <newline> <dedent> if extracted : <newline> <indent> for source in extracted : <newline> <indent> self . sources . append ( source ) <newline> <dedent> <dedent> <dedent> @ post_generation <newline> def domains ( self , create , extracted , ** kwargs ) : <newline> <indent> if not create : <newline> <indent> return <newline> <dedent> if extracted : <newline> <indent> for domain in extracted : <newline> <indent> self . domains . append ( domain ) <newline> <dedent> <dedent> <dedent> @ post_generation <newline> def roles ( self , create , extracted , ** kwargs ) : <newline> <indent> if not create : <newline> <indent> return <newline> <dedent> if extracted : <newline> <indent> for domain in extracted : <newline> <indent> self . roles . append ( domain ) <newline> <dedent> <dedent> <dedent> <dedent>
 # !/usr/bin/python <encdom> from __future__ import ( absolute_import , division , print_function ) <newline> __metaclass__ = type <newline> import json <newline> def main ( ) : <newline> <indent> print ( "junk_before_module_output" ) <newline> print ( json . dumps ( dict ( changed = False , source = 'user' ) ) ) <newline> print ( "junk_after_module_output" ) <newline> <dedent> if __name__ == '__main__' : <newline> <indent> main ( ) <newline> <dedent>