import unittest <newline> from datetime import ( date as original_date , datetime as original_datetime , time as original_time , ) <newline> from django . utils . datetime_safe import date , datetime , time <newline> class DatetimeTests ( unittest . TestCase ) : <newline> <indent> def setUp ( self ) : <newline> <indent> self . just_safe = ( 1900 , 1 , 1 ) <newline> self . just_unsafe = ( 1899 , 12 , 31 , 23 , 59 , 59 ) <newline> self . just_time = ( 11 , 30 , 59 ) <newline> self . really_old = ( 20 , 1 , 1 ) <newline> self . more_recent = ( 2006 , 1 , 1 ) <newline> <dedent> def test_compare_datetimes ( self ) : <newline> <indent> self . assertEqual ( original_datetime ( * self . more_recent ) , datetime ( * self . more_recent ) ) <newline> self . assertEqual ( original_datetime ( * self . really_old ) , datetime ( * self . really_old ) ) <newline> self . assertEqual ( original_date ( * self . more_recent ) , date ( * self . more_recent ) ) <newline> self . assertEqual ( original_date ( * self . really_old ) , date ( * self . really_old ) ) <newline> self . assertEqual ( original_date ( * self . just_safe ) . strftime ( '%Y-%m-%d' ) , date ( * self . just_safe ) . strftime ( '%Y-%m-%d' ) ) <newline> self . assertEqual ( original_datetime ( * self . just_safe ) . strftime ( '%Y-%m-%d' ) , datetime ( * self . just_safe ) . strftime ( '%Y-%m-%d' ) ) <newline> self . assertEqual ( original_time ( * self . just_time ) . strftime ( '%H:%M:%S' ) , time ( * self . just_time ) . strftime ( '%H:%M:%S' ) ) <newline> <dedent> def test_safe_strftime ( self ) : <newline> <indent> self . assertEqual ( date ( * self . just_unsafe [ : 3 ] ) . strftime ( '%Y-%m-%d ▁ (weekday ▁ %w)' ) , '1899-12-31 ▁ (weekday ▁ 0)' ) <newline> self . assertEqual ( date ( * self . just_safe ) . strftime ( '%Y-%m-%d ▁ (weekday ▁ %w)' ) , '1900-01-01 ▁ (weekday ▁ 1)' ) <newline> self . assertEqual ( datetime ( * self . just_unsafe ) . strftime ( '%Y-%m-%d ▁ %H:%M:%S ▁ (weekday ▁ %w)' ) , '1899-12-31 ▁ 23:59:59 ▁ (weekday ▁ 0)' ) <newline> self . assertEqual ( datetime ( * self . just_safe ) . strftime ( '%Y-%m-%d ▁ %H:%M:%S ▁ (weekday ▁ %w)' ) , '1900-01-01 ▁ 00:00:00 ▁ (weekday ▁ 1)' ) <newline> self . assertEqual ( time ( * self . just_time ) . strftime ( '%H:%M:%S ▁ AM' ) , '11:30:59 ▁ AM' ) <newline>  # ▁ %y ▁ will ▁ error ▁ before ▁ this ▁ date <encdom> self . assertEqual ( date ( * self . just_safe ) . strftime ( '%y' ) , '00' ) <newline> self . assertEqual ( datetime ( * self . just_safe ) . strftime ( '%y' ) , '00' ) <newline> self . assertEqual ( date ( 1850 , 8 , 2 ) . strftime ( "%Y/%m/%d ▁ was ▁ a ▁ %A" ) , '1850/08/02 ▁ was ▁ a ▁ Friday' ) <newline> <dedent> def test_zero_padding ( self ) : <newline> <indent>  """ <strnewline> ▁ Regression ▁ for ▁ # 12524 <strnewline> <strnewline> ▁ Check ▁ that ▁ pre-1000AD ▁ dates ▁ are ▁ padded ▁ with ▁ zeros ▁ if ▁ necessary <strnewline> ▁ """  <newline> self . assertEqual ( date ( 1 , 1 , 1 ) . strftime ( "%Y/%m/%d ▁ was ▁ a ▁ %A" ) , '0001/01/01 ▁ was ▁ a ▁ Monday' ) <newline> <dedent> <dedent>
 # # ▁ Very, ▁ very ▁ experimental. ▁ Do ▁ NOT ▁ USE. <encdom> import curses <newline> from . import fmForm <newline> from . wgwidget import NotEnoughSpaceForWidget <newline> from . import wgNMenuDisplay <newline> class FormMultiPage ( fmForm . FormBaseNew ) : <newline> <indent> page_info_pre_pages_display = '[ ▁ ' <newline> page_info_post_pages_display = ' ▁ ]' <newline> page_info_pages_name = 'Page' <newline> page_info_out_of = 'of' <newline> def __init__ ( self , display_pages = True , pages_label_color = 'NORMAL' , * args , ** keywords ) : <newline> <indent> self . display_pages = display_pages <newline> self . pages_label_color = pages_label_color <newline> super ( FormMultiPage , self ) . __init__ ( * args , ** keywords ) <newline> self . switch_page ( 0 ) <newline> <dedent> def draw_form ( self , * args , ** keywords ) : <newline> <indent> super ( FormMultiPage , self ) . draw_form ( * args , ** keywords ) <newline> self . display_page_number ( ) <newline> <dedent> def _resize ( self , * args ) : <newline> <indent> if not self . ALLOW_RESIZE : <newline> <indent> return False <newline> <dedent> if hasattr ( self , 'parentApp' ) : <newline> <indent> self . parentApp . resize ( ) <newline> <dedent> self . _create_screen ( ) <newline> self . resize ( ) <newline> for page in self . _pages__ : <newline> <indent> for w in page : <newline> <indent> w . _resize ( ) <newline> <dedent> <dedent> self . DISPLAY ( ) <newline> <dedent> def display_page_number ( self ) : <newline> <indent> if not self . display_pages : <newline> <indent> return False <newline> <dedent> if len ( self . _pages__ ) > 1 : <newline> <indent> display_text = "%s%s ▁ %s ▁ %s ▁ %s%s" % ( self . page_info_pre_pages_display , self . page_info_pages_name , self . _active_page + 1 , self . page_info_out_of , len ( self . _pages__ ) , self . page_info_post_pages_display , ) <newline>  # ▁ for ▁ python2 <encdom> if isinstance ( display_text , bytes ) : <newline> <indent> display_text = display_text . decode ( 'utf-8' , 'replace' ) <newline> <dedent> maxy , maxx = self . curses_pad . getmaxyx ( ) <newline> if ( maxx - 5 ) <= len ( display_text ) : <newline>  # ▁ then ▁ give ▁ up. <encdom> <indent> return False <newline> <dedent> self . add_line ( maxy - 1 , maxx - len ( display_text ) - 2 , display_text , self . make_attributes_list ( display_text , curses . A_NORMAL | self . theme_manager . findPair ( self , self . pages_label_color ) ) , maxx - len ( display_text ) - 2 , ) <newline> <dedent> <dedent> def add_widget_intelligent ( self , * args , ** keywords ) : <newline> <indent> try : <newline> <indent> return self . add_widget ( * args , ** keywords ) <newline> <dedent> except NotEnoughSpaceForWidget : <newline> <indent> self . add_page ( ) <newline> return self . add_widget ( * args , ** keywords ) <newline> <dedent> <dedent> def _clear_all_widgets ( self , ) : <newline> <indent> super ( FormMultiPage , self ) . _clear_all_widgets ( ) <newline> self . _pages__ = [ [ ] , ] <newline> self . _active_page = 0 <newline> self . switch_page ( self . _active_page , display = False ) <newline> <dedent> def switch_page ( self , page , display = True ) : <newline> <indent> self . _widgets__ = self . _pages__ [ page ] <newline> self . _active_page = page <newline> self . editw = 0 <newline> if display : <newline> <indent> self . display ( clear = True ) <newline> <dedent> <dedent> def add_page ( self ) : <newline> <indent> self . _pages__ . append ( [ ] ) <newline> page_number = len ( self . _pages__ ) - 1 <newline> self . nextrely = self . DEFAULT_NEXTRELY <newline> self . nextrelx = self . DEFAULT_X_OFFSET <newline> self . switch_page ( page_number , display = False ) <newline> return page_number <newline> <dedent> def find_next_editable ( self , * args ) : <newline> <indent> if not self . editw == len ( self . _widgets__ ) : <newline> <indent> value_changed = False <newline> if not self . cycle_widgets : <newline> <indent> r = list ( range ( self . editw + 1 , len ( self . _widgets__ ) ) ) <newline> <dedent> else : <newline> <indent> r = list ( range ( self . editw + 1 , len ( self . _widgets__ ) ) ) + list ( range ( 0 , self . editw ) ) <newline> <dedent> for n in r : <newline> <indent> if self . _widgets__ [ n ] . editable and not self . _widgets__ [ n ] . hidden : <newline> <indent> self . editw = n <newline> value_changed = True <newline> break <newline> <dedent> <dedent> if not value_changed : <newline> <indent> if self . _active_page < len ( self . _pages__ ) - 1 : <newline> <indent> self . switch_page ( self . _active_page + 1 ) <newline> <dedent> <dedent> <dedent> self . display ( ) <newline> <dedent> def find_previous_editable ( self , * args ) : <newline> <indent> if self . editw == 0 : <newline> <indent> if self . _active_page > 0 : <newline> <indent> self . switch_page ( self . _active_page - 1 ) <newline> <dedent> <dedent> if not self . editw == 0 : <newline>  # ▁ remember ▁ that ▁ xrange ▁ does ▁ not ▁ return ▁ the ▁'last' ▁ value, <encdom>  # ▁ so ▁ go ▁ to ▁ -1, ▁ not ▁ 0! ▁ (fence ▁ post ▁ error ▁ in ▁ reverse) <encdom> <indent> for n in range ( self . editw - 1 , - 1 , - 1 ) : <newline> <indent> if self . _widgets__ [ n ] . editable and not self . _widgets__ [ n ] . hidden : <newline> <indent> self . editw = n <newline> break <newline> <dedent> <dedent> <dedent> <dedent> <dedent> class FormMultiPageAction ( FormMultiPage ) : <newline> <indent> CANCEL_BUTTON_BR_OFFSET = ( 2 , 12 ) <newline> OK_BUTTON_TEXT = "OK" <newline> CANCEL_BUTTON_TEXT = "Cancel" <newline> def on_ok ( self ) : <newline> <indent> pass <newline> <dedent> def on_cancel ( self ) : <newline> <indent> pass <newline> <dedent> def pre_edit_loop ( self ) : <newline> <indent> self . _page_for_buttons = len ( self . _pages__ ) - 1 <newline> self . switch_page ( self . _page_for_buttons ) <newline>  # ▁ Add ▁ ok ▁ and ▁ cancel ▁ buttons. ▁ Will ▁ remove ▁ later <encdom> tmp_rely , tmp_relx = self . nextrely , self . nextrelx <newline> c_button_text = self . CANCEL_BUTTON_TEXT <newline> cmy , cmx = self . curses_pad . getmaxyx ( ) <newline> cmy -= self . __class__ . CANCEL_BUTTON_BR_OFFSET [ 0 ] <newline> cmx -= len ( c_button_text ) + self . __class__ . CANCEL_BUTTON_BR_OFFSET [ 1 ] <newline> self . c_button = self . add_widget ( self . __class__ . OKBUTTON_TYPE , name = c_button_text , rely = cmy , relx = cmx , use_max_space = True ) <newline> self . _c_button_postion = len ( self . _widgets__ ) - 1 <newline> self . c_button . update ( ) <newline> my , mx = self . curses_pad . getmaxyx ( ) <newline> ok_button_text = self . OK_BUTTON_TEXT <newline> my -= self . __class__ . OK_BUTTON_BR_OFFSET [ 0 ] <newline> mx -= len ( ok_button_text ) + self . __class__ . OK_BUTTON_BR_OFFSET [ 1 ] <newline> self . ok_button = self . add_widget ( self . __class__ . OKBUTTON_TYPE , name = ok_button_text , rely = my , relx = mx , use_max_space = True ) <newline> self . _ok_button_postion = len ( self . _widgets__ ) - 1 <newline>  # ▁ End ▁ add ▁ buttons <encdom> self . nextrely , self . nextrelx = tmp_rely , tmp_relx <newline> self . switch_page ( 0 ) <newline> <dedent> def _during_edit_loop ( self ) : <newline> <indent> if self . ok_button . value or self . c_button . value : <newline> <indent> self . editing = False <newline> <dedent> if self . ok_button . value : <newline> <indent> self . ok_button . value = False <newline> self . edit_return_value = self . on_ok ( ) <newline> <dedent> elif self . c_button . value : <newline> <indent> self . c_button . value = False <newline> self . edit_return_value = self . on_cancel ( ) <newline> <dedent> <dedent> def resize ( self ) : <newline> <indent> super ( FormMultiPageAction , self ) . resize ( ) <newline> self . move_ok_button ( ) <newline> <dedent> def move_ok_button ( self ) : <newline> <indent> if hasattr ( self , 'ok_button' ) : <newline> <indent> my , mx = self . curses_pad . getmaxyx ( ) <newline> my -= self . __class__ . OK_BUTTON_BR_OFFSET [ 0 ] <newline> mx -= len ( self . __class__ . OK_BUTTON_TEXT ) + self . __class__ . OK_BUTTON_BR_OFFSET [ 1 ] <newline> self . ok_button . relx = mx <newline> self . ok_button . rely = my <newline> <dedent> if hasattr ( self , 'c_button' ) : <newline> <indent> c_button_text = self . CANCEL_BUTTON_TEXT <newline> cmy , cmx = self . curses_pad . getmaxyx ( ) <newline> cmy -= self . __class__ . CANCEL_BUTTON_BR_OFFSET [ 0 ] <newline> cmx -= len ( c_button_text ) + self . __class__ . CANCEL_BUTTON_BR_OFFSET [ 1 ] <newline> self . c_button . rely = cmy <newline> self . c_button . relx = cmx <newline> <dedent> <dedent> def post_edit_loop ( self ) : <newline> <indent> self . switch_page ( self . _page_for_buttons ) <newline> self . ok_button . destroy ( ) <newline> self . c_button . destroy ( ) <newline> del self . _widgets__ [ self . _ok_button_postion ] <newline> del self . ok_button <newline> del self . _widgets__ [ self . _c_button_postion ] <newline> del self . c_button <newline>  # self.nextrely, ▁ self.nextrelx ▁ = ▁ tmp_rely, ▁ tmp_relx <encdom> self . display ( ) <newline> self . editing = False <newline> return self . edit_return_value <newline> <dedent> <dedent> class FormMultiPageWithMenus ( fmForm . FormBaseNew ) : <newline> <indent> def __init__ ( self , * args , ** keywords ) : <newline> <indent> super ( FormMultiPageWithMenus , self ) . __init__ ( * args , ** keywords ) <newline> self . initialize_menus ( ) <newline> <dedent> <dedent> class FormMultiPageActionWithMenus ( FormMultiPageAction , wgNMenuDisplay . HasMenus ) : <newline> <indent> def __init__ ( self , * args , ** keywords ) : <newline> <indent> super ( FormMultiPageActionWithMenus , self ) . __init__ ( * args , ** keywords ) <newline> self . initialize_menus ( ) <newline> <dedent> <dedent>
 ''' <strnewline> Created ▁ on ▁ Jun ▁ 14, ▁ 2011 <strnewline> <strnewline> @author: ▁ lebleu1 <strnewline> '''  <newline> import unittest <newline> from network . ipAddress import IpAddress <newline> class Test ( unittest . TestCase ) : <newline> <indent> def testPack ( self ) : <newline> <indent> address = IpAddress ( "192.168.1.12" ) <newline> self . assertEquals ( "\xC0\xA8\x01\x0C" , address . pack ( ) ) <newline> <dedent> <dedent>
 # ▁ Created ▁ for ▁ aenea ▁ using ▁ libraries ▁ from ▁ the ▁ Dictation ▁ Toolbox <encdom>  # ▁ https://github.com/dictation-toolbox/dragonfly-scripts <encdom>  # ▁ Commands ▁ for ▁ writing ▁ SQL ▁ queries <encdom>  # ▁ Author: ▁ Tony ▁ Grosinger <encdom>  # ▁ Licensed ▁ under ▁ LGPL <encdom> import aenea <newline> import aenea . configuration <newline> from aenea import Choice <newline> from aenea . lax import Text <newline> import dragonfly <newline> sql_map = { "update" : "UPDATE ▁ " , "select" : "SELECT ▁ " , "from" : "FROM ▁ " , "count" : "COUNT ▁ " , "values" : "VALUES ▁ " , "as" : "AS ▁ " , "when" : "WHEN ▁ " , "in" : "IN ▁ " , "into" : "INTO ▁ " , "and" : "AND ▁ " , "all" : "ALL ▁ " , "similar ▁ to" : "SIMILAR ▁ TO ▁ " , "like" : "LIKE ▁ " , "set" : "SET ▁ " , } <newline> sql_mapping = aenea . configuration . make_grammar_commands ( 'sql' , { '<sqlKeyword>' : Text ( "%(text)s" ) , } ) <newline> class SQL ( dragonfly . MappingRule ) : <newline> <indent> mapping = sql_mapping <newline> extras = [ Choice ( 'sqlKeyword' , sql_map , ) ] <newline> <dedent> def get_grammar ( context ) : <newline> <indent> sql_grammar = dragonfly . Grammar ( 'sql' , context = context ) <newline> sql_grammar . add_rule ( SQL ( ) ) <newline> return sql_grammar <newline> <dedent>
 """ engine.SCons.Platform.hpux <strnewline> <strnewline> Platform-specific ▁ initialization ▁ for ▁ HP-UX ▁ systems. <strnewline> <strnewline> There ▁ normally ▁ shouldn't ▁ be ▁ any ▁ need ▁ to ▁ import ▁ this ▁ module ▁ directly. ▁ It <strnewline> will ▁ usually ▁ be ▁ imported ▁ through ▁ the ▁ generic ▁ SCons.Platform.Platform() <strnewline> selection ▁ method. <strnewline> """  <newline>  # ▁ Copyright ▁ (c) ▁ 2001, ▁ 2002, ▁ 2003, ▁ 2004, ▁ 2005, ▁ 2006, ▁ 2007, ▁ 2008, ▁ 2009, ▁ 2010, ▁ 2011, ▁ 2012 ▁ The ▁ SCons ▁ Foundation <encdom>  # ▁ Permission ▁ is ▁ hereby ▁ granted, ▁ free ▁ of ▁ charge, ▁ to ▁ any ▁ person ▁ obtaining <encdom>  # ▁ a ▁ copy ▁ of ▁ this ▁ software ▁ and ▁ associated ▁ documentation ▁ files ▁ (the <encdom>  # ▁"Software"), ▁ to ▁ deal ▁ in ▁ the ▁ Software ▁ without ▁ restriction, ▁ including <encdom>  # ▁ without ▁ limitation ▁ the ▁ rights ▁ to ▁ use, ▁ copy, ▁ modify, ▁ merge, ▁ publish, <encdom>  # ▁ distribute, ▁ sublicense, ▁ and/or ▁ sell ▁ copies ▁ of ▁ the ▁ Software, ▁ and ▁ to <encdom>  # ▁ permit ▁ persons ▁ to ▁ whom ▁ the ▁ Software ▁ is ▁ furnished ▁ to ▁ do ▁ so, ▁ subject ▁ to <encdom>  # ▁ the ▁ following ▁ conditions: <encdom>  # ▁ The ▁ above ▁ copyright ▁ notice ▁ and ▁ this ▁ permission ▁ notice ▁ shall ▁ be ▁ included <encdom>  # ▁ in ▁ all ▁ copies ▁ or ▁ substantial ▁ portions ▁ of ▁ the ▁ Software. <encdom>  # ▁ THE ▁ SOFTWARE ▁ IS ▁ PROVIDED ▁"AS ▁ IS", ▁ WITHOUT ▁ WARRANTY ▁ OF ▁ ANY <encdom>  # ▁ KIND, ▁ EXPRESS ▁ OR ▁ IMPLIED, ▁ INCLUDING ▁ BUT ▁ NOT ▁ LIMITED ▁ TO ▁ THE <encdom>  # ▁ WARRANTIES ▁ OF ▁ MERCHANTABILITY, ▁ FITNESS ▁ FOR ▁ A ▁ PARTICULAR ▁ PURPOSE ▁ AND <encdom>  # ▁ NONINFRINGEMENT. ▁ IN ▁ NO ▁ EVENT ▁ SHALL ▁ THE ▁ AUTHORS ▁ OR ▁ COPYRIGHT ▁ HOLDERS ▁ BE <encdom>  # ▁ LIABLE ▁ FOR ▁ ANY ▁ CLAIM, ▁ DAMAGES ▁ OR ▁ OTHER ▁ LIABILITY, ▁ WHETHER ▁ IN ▁ AN ▁ ACTION <encdom>  # ▁ OF ▁ CONTRACT, ▁ TORT ▁ OR ▁ OTHERWISE, ▁ ARISING ▁ FROM, ▁ OUT ▁ OF ▁ OR ▁ IN ▁ CONNECTION <encdom>  # ▁ WITH ▁ THE ▁ SOFTWARE ▁ OR ▁ THE ▁ USE ▁ OR ▁ OTHER ▁ DEALINGS ▁ IN ▁ THE ▁ SOFTWARE. <encdom> __revision__ = "src/engine/SCons/Platform/hpux.py ▁ issue-2856:2676:d23b7a2f45e8 ▁ 2012/08/05 ▁ 15:38:28 ▁ garyo" <newline> import posix <newline> def generate ( env ) : <newline> <indent> posix . generate ( env ) <newline>  # Based ▁ on ▁ HP-UX11i: ▁ ARG_MAX=2048000 ▁ - ▁ 3000 ▁ for ▁ environment ▁ expansion <encdom> env [ 'MAXLINELENGTH' ] = 2045000 <newline>  # ▁ Local ▁ Variables: <encdom>  # ▁ tab-width:4 <encdom>  # ▁ indent-tabs-mode:nil <encdom>  # ▁ End: <encdom>  # ▁ vim: ▁ set ▁ expandtab ▁ tabstop=4 ▁ shiftwidth=4: <encdom> <dedent>
import json <newline> import os <newline> import os . path <newline> import re <newline> import sys <newline> from collections import defaultdict <newline> from distutils . command . build_scripts import build_scripts as BuildScripts <newline> from distutils . command . sdist import sdist as SDist <newline> try : <newline> <indent> from setuptools import setup , find_packages <newline> from setuptools . command . build_py import build_py as BuildPy <newline> from setuptools . command . install_lib import install_lib as InstallLib <newline> from setuptools . command . install_scripts import install_scripts as InstallScripts <newline> <dedent> except ImportError : <newline> <indent> print ( "Ansible ▁ now ▁ needs ▁ setuptools ▁ in ▁ order ▁ to ▁ build. ▁ Install ▁ it ▁ using" " ▁ your ▁ package ▁ manager ▁ (usually ▁ python-setuptools) ▁ or ▁ via ▁ pip ▁ (pip" " ▁ install ▁ setuptools)." ) <newline> sys . exit ( 1 ) <newline> <dedent> sys . path . insert ( 0 , os . path . abspath ( 'lib' ) ) <newline> from ansible . release import __version__ , __author__ <newline> SYMLINK_CACHE = 'SYMLINK_CACHE.json' <newline> def _find_symlinks ( topdir , extension = '' ) : <newline> <indent>  """ Find ▁ symlinks ▁ that ▁ should ▁ be ▁ maintained <strnewline> <strnewline> ▁ Maintained ▁ symlinks ▁ exist ▁ in ▁ the ▁ bin ▁ dir ▁ or ▁ are ▁ modules ▁ which ▁ have <strnewline> ▁ aliases. ▁ Our ▁ heuristic ▁ is ▁ that ▁ they ▁ are ▁ a ▁ link ▁ in ▁ a ▁ certain ▁ path ▁ which <strnewline> ▁ point ▁ to ▁ a ▁ file ▁ in ▁ the ▁ same ▁ directory. <strnewline> ▁ """  <newline> symlinks = defaultdict ( list ) <newline> for base_path , dirs , files in os . walk ( topdir ) : <newline> <indent> for filename in files : <newline> <indent> filepath = os . path . join ( base_path , filename ) <newline> if os . path . islink ( filepath ) and filename . endswith ( extension ) : <newline> <indent> target = os . readlink ( filepath ) <newline> if os . path . dirname ( target ) == '' : <newline> <indent> link = filepath [ len ( topdir ) : ] <newline> if link . startswith ( '/' ) : <newline> <indent> link = link [ 1 : ] <newline> <dedent> symlinks [ os . path . basename ( target ) ] . append ( link ) <newline> <dedent> <dedent> <dedent> <dedent> return symlinks <newline> <dedent> def _cache_symlinks ( symlink_data ) : <newline> <indent> with open ( SYMLINK_CACHE , 'w' ) as f : <newline> <indent> f . write ( json . dumps ( symlink_data ) ) <newline> <dedent> <dedent> def _maintain_symlinks ( symlink_type , base_path ) : <newline> <indent>  """ Switch ▁ a ▁ real ▁ file ▁ into ▁ a ▁ symlink """  <newline> try : <newline>  # ▁ Try ▁ the ▁ cache ▁ first ▁ because ▁ going ▁ from ▁ git ▁ checkout ▁ to ▁ sdist ▁ is ▁ the <encdom>  # ▁ only ▁ time ▁ we ▁ know ▁ that ▁ we're ▁ going ▁ to ▁ cache ▁ correctly <encdom> <indent> with open ( SYMLINK_CACHE , 'r' ) as f : <newline> <indent> symlink_data = json . loads ( f . read ( ) ) <newline> <dedent> <dedent> except ( IOError , OSError ) as e : <newline>  # ▁ IOError ▁ on ▁ py2, ▁ OSError ▁ on ▁ py3. ▁ Both ▁ have ▁ errno <encdom> <indent> if e . errno == 2 : <newline>  # ▁ SYMLINKS_CACHE ▁ doesn't ▁ exist. ▁ Fallback ▁ to ▁ trying ▁ to ▁ create ▁ the <encdom>  # ▁ cache ▁ now. ▁ Will ▁ work ▁ if ▁ we're ▁ running ▁ directly ▁ from ▁ a ▁ git <encdom>  # ▁ checkout ▁ or ▁ from ▁ an ▁ sdist ▁ created ▁ earlier. <encdom> <indent> symlink_data = { 'script' : _find_symlinks ( 'bin' ) , 'library' : _find_symlinks ( 'lib' , '.py' ) , } <newline>  # ▁ Sanity ▁ check ▁ that ▁ something ▁ we ▁ know ▁ should ▁ be ▁ a ▁ symlink ▁ was <encdom>  # ▁ found. ▁ We'll ▁ take ▁ that ▁ to ▁ mean ▁ that ▁ the ▁ current ▁ directory <encdom>  # ▁ structure ▁ properly ▁ reflects ▁ symlinks ▁ in ▁ the ▁ git ▁ repo <encdom> if 'ansible-playbook' in symlink_data [ 'script' ] [ 'ansible' ] : <newline> <indent> _cache_symlinks ( symlink_data ) <newline> <dedent> else : <newline> <indent> raise <newline> <dedent> <dedent> else : <newline> <indent> raise <newline> <dedent> <dedent> symlinks = symlink_data [ symlink_type ] <newline> for source in symlinks : <newline> <indent> for dest in symlinks [ source ] : <newline> <indent> dest_path = os . path . join ( base_path , dest ) <newline> if not os . path . islink ( dest_path ) : <newline> <indent> try : <newline> <indent> os . unlink ( dest_path ) <newline> <dedent> except OSError as e : <newline> <indent> if e . errno == 2 : <newline>  # ▁ File ▁ does ▁ not ▁ exist ▁ which ▁ is ▁ all ▁ we ▁ wanted <encdom> <indent> pass <newline> <dedent> <dedent> os . symlink ( source , dest_path ) <newline> <dedent> <dedent> <dedent> <dedent> class BuildPyCommand ( BuildPy ) : <newline> <indent> def run ( self ) : <newline> <indent> BuildPy . run ( self ) <newline> _maintain_symlinks ( 'library' , self . build_lib ) <newline> <dedent> <dedent> class BuildScriptsCommand ( BuildScripts ) : <newline> <indent> def run ( self ) : <newline> <indent> BuildScripts . run ( self ) <newline> _maintain_symlinks ( 'script' , self . build_dir ) <newline> <dedent> <dedent> class InstallLibCommand ( InstallLib ) : <newline> <indent> def run ( self ) : <newline> <indent> InstallLib . run ( self ) <newline> _maintain_symlinks ( 'library' , self . install_dir ) <newline> <dedent> <dedent> class InstallScriptsCommand ( InstallScripts ) : <newline> <indent> def run ( self ) : <newline> <indent> InstallScripts . run ( self ) <newline> _maintain_symlinks ( 'script' , self . install_dir ) <newline> <dedent> <dedent> class SDistCommand ( SDist ) : <newline> <indent> def run ( self ) : <newline>  # ▁ have ▁ to ▁ generate ▁ the ▁ cache ▁ of ▁ symlinks ▁ for ▁ release ▁ as ▁ sdist ▁ is ▁ the <encdom>  # ▁ only ▁ command ▁ that ▁ has ▁ access ▁ to ▁ symlinks ▁ from ▁ the ▁ git ▁ repo <encdom> <indent> symlinks = { 'script' : _find_symlinks ( 'bin' ) , 'library' : _find_symlinks ( 'lib' , '.py' ) , } <newline> _cache_symlinks ( symlinks ) <newline> SDist . run ( self ) <newline> <dedent> <dedent> with open ( 'requirements.txt' ) as requirements_file : <newline> <indent> install_requirements = requirements_file . read ( ) . splitlines ( ) <newline> if not install_requirements : <newline> <indent> print ( "Unable ▁ to ▁ read ▁ requirements ▁ from ▁ the ▁ requirements.txt ▁ file" "That ▁ indicates ▁ this ▁ copy ▁ of ▁ the ▁ source ▁ code ▁ is ▁ incomplete." ) <newline> sys . exit ( 2 ) <newline>  # ▁ pycrypto ▁ or ▁ cryptography. ▁ We ▁ choose ▁ a ▁ default ▁ but ▁ allow ▁ the ▁ user ▁ to <encdom>  # ▁ override ▁ it. ▁ This ▁ translates ▁ into ▁ pip ▁ install ▁ of ▁ the ▁ sdist ▁ deciding ▁ what <encdom>  # ▁ package ▁ to ▁ install ▁ and ▁ also ▁ the ▁ runtime ▁ dependencies ▁ that ▁ pkg_resources <encdom>  # ▁ knows ▁ about <encdom> <dedent> <dedent> crypto_backend = os . environ . get ( 'ANSIBLE_CRYPTO_BACKEND' , None ) <newline> if crypto_backend : <newline> <indent> if crypto_backend . strip ( ) == 'pycrypto' : <newline>  # ▁ Attempt ▁ to ▁ set ▁ version ▁ requirements <encdom> <indent> crypto_backend = 'pycrypto ▁ >= ▁ 2.6' <newline> <dedent> install_requirements = [ r for r in install_requirements if not ( r . lower ( ) . startswith ( 'pycrypto' ) or r . lower ( ) . startswith ( 'cryptography' ) ) ] <newline> install_requirements . append ( crypto_backend ) <newline>  # ▁ specify ▁ any ▁ extra ▁ requirements ▁ for ▁ installation <encdom> <dedent> extra_requirements = dict ( ) <newline> extra_requirements_dir = 'packaging/requirements' <newline> for extra_requirements_filename in os . listdir ( extra_requirements_dir ) : <newline> <indent> filename_match = re . search ( r'^requirements-(\w*).txt$' , extra_requirements_filename ) <newline> if filename_match : <newline> <indent> with open ( os . path . join ( extra_requirements_dir , extra_requirements_filename ) ) as extra_requirements_file : <newline> <indent> extra_requirements [ filename_match . group ( 1 ) ] = extra_requirements_file . read ( ) . splitlines ( ) <newline> <dedent> <dedent> <dedent> setup (  # ▁ Use ▁ the ▁ distutils ▁ SDist ▁ so ▁ that ▁ symlinks ▁ are ▁ not ▁ expanded <encdom>  # ▁ Use ▁ a ▁ custom ▁ Build ▁ for ▁ the ▁ same ▁ reason <encdom> cmdclass = { 'build_py' : BuildPyCommand , 'build_scripts' : BuildScriptsCommand , 'install_lib' : InstallLibCommand , 'install_scripts' : InstallScriptsCommand , 'sdist' : SDistCommand , } , name = 'ansible' , version = __version__ , description = 'Radically ▁ simple ▁ IT ▁ automation' , author = __author__ , author_email = 'info@ansible.com' , url = 'https://ansible.com/' , license = 'GPLv3+' ,  # ▁ Ansible ▁ will ▁ also ▁ make ▁ use ▁ of ▁ a ▁ system ▁ copy ▁ of ▁ python-six ▁ and <encdom>  # ▁ python-selectors2 ▁ if ▁ installed ▁ but ▁ use ▁ a ▁ Bundled ▁ copy ▁ if ▁ it's ▁ not. <encdom> install_requires = install_requirements , package_dir = { '' : 'lib' } , packages = find_packages ( 'lib' ) , package_data = { '' : [ 'module_utils/powershell/*.psm1' , 'module_utils/powershell/*/*.psm1' , 'modules/windows/*.ps1' , 'modules/windows/*/*.ps1' , 'galaxy/data/*/*.*' , 'galaxy/data/*/*/.*' , 'galaxy/data/*/*/*.*' , 'galaxy/data/*/tests/inventory' , 'config/base.yml' , ] , } , classifiers = [ 'Development ▁ Status ▁ :: ▁ 5 ▁ - ▁ Production/Stable' , 'Environment ▁ :: ▁ Console' , 'Intended ▁ Audience ▁ :: ▁ Developers' , 'Intended ▁ Audience ▁ :: ▁ Information ▁ Technology' , 'Intended ▁ Audience ▁ :: ▁ System ▁ Administrators' , 'License ▁ :: ▁ OSI ▁ Approved ▁ :: ▁ GNU ▁ General ▁ Public ▁ License ▁ v3 ▁ or ▁ later ▁ (GPLv3+)' , 'Natural ▁ Language ▁ :: ▁ English' , 'Operating ▁ System ▁ :: ▁ POSIX' , 'Programming ▁ Language ▁ :: ▁ Python ▁ :: ▁ 2.6' , 'Programming ▁ Language ▁ :: ▁ Python ▁ :: ▁ 2.7' , 'Topic ▁ :: ▁ System ▁ :: ▁ Installation/Setup' , 'Topic ▁ :: ▁ System ▁ :: ▁ Systems ▁ Administration' , 'Topic ▁ :: ▁ Utilities' , ] , scripts = [ 'bin/ansible' , 'bin/ansible-playbook' , 'bin/ansible-pull' , 'bin/ansible-doc' , 'bin/ansible-galaxy' , 'bin/ansible-console' , 'bin/ansible-connection' , 'bin/ansible-vault' , ] , data_files = [ ] , extras_require = extra_requirements ,  # ▁ Installing ▁ as ▁ zip ▁ files ▁ would ▁ break ▁ due ▁ to ▁ references ▁ to ▁ __file__ <encdom> zip_safe = False ) <newline>
import tornado . testing <newline> import tornado . web <newline> import tornado . escape <newline> from tornado . options import options <newline> from urls import url_patterns <newline> from urllib import parse <newline> class TestBase ( tornado . testing . AsyncHTTPTestCase ) : <newline> <indent> def setUp ( self ) : <newline> <indent> super ( TestBase , self ) . setUp ( ) <newline> <dedent> def get_app ( self ) : <newline> <indent> self . app = tornado . web . Application ( handlers = url_patterns , xsrf_cookies = False ) <newline> <dedent> def get_http_port ( self ) : <newline> <indent> return options . port <newline> <dedent> def user_login ( self ) : <newline> <indent> login_url = '/auth/login/' <newline> post_args = { 'email' : 'test@test.co.jp' , 'password' : 'test' } <newline> response = self . fetch ( login_url , method = 'POST' , body = parse . urlencode ( post_args ) , follow_redirects = False ) <newline> return response <newline> <dedent> def user_logout ( self ) : <newline> <indent> test_url = '/auth/logout/' <newline> response = self . fetch ( test_url , method = 'GET' , follow_redirects = False ) <newline> return response <newline> <dedent> <dedent>
 # ▁ Copyright ▁ 2013 ▁ OpenStack ▁ Foundation <encdom>  # ▁ All ▁ Rights ▁ Reserved. <encdom>  # ▁ Licensed ▁ under ▁ the ▁ Apache ▁ License, ▁ Version ▁ 2.0 ▁ (the ▁"License"); ▁ you ▁ may <encdom>  # ▁ not ▁ use ▁ this ▁ file ▁ except ▁ in ▁ compliance ▁ with ▁ the ▁ License. ▁ You ▁ may ▁ obtain <encdom>  # ▁ a ▁ copy ▁ of ▁ the ▁ License ▁ at <encdom>  # ▁ http://www.apache.org/licenses/LICENSE-2.0 <encdom>  # ▁ Unless ▁ required ▁ by ▁ applicable ▁ law ▁ or ▁ agreed ▁ to ▁ in ▁ writing, ▁ software <encdom>  # ▁ distributed ▁ under ▁ the ▁ License ▁ is ▁ distributed ▁ on ▁ an ▁"AS ▁ IS" ▁ BASIS, ▁ WITHOUT <encdom>  # ▁ WARRANTIES ▁ OR ▁ CONDITIONS ▁ OF ▁ ANY ▁ KIND, ▁ either ▁ express ▁ or ▁ implied. ▁ See ▁ the <encdom>  # ▁ License ▁ for ▁ the ▁ specific ▁ language ▁ governing ▁ permissions ▁ and ▁ limitations <encdom>  # ▁ under ▁ the ▁ License. <encdom> from mox3 import mox <newline> import six <newline> from nova import context <newline> from nova import test <newline> from nova . tests . unit . virt . xenapi import stubs <newline> from nova . virt . xenapi import driver as xenapi_conn <newline> from nova . virt . xenapi import fake <newline> from nova . virt . xenapi . image import bittorrent <newline> from nova . virt . xenapi import vm_utils <newline> class TestBittorrentStore ( stubs . XenAPITestBaseNoDB ) : <newline> <indent> def setUp ( self ) : <newline> <indent> super ( TestBittorrentStore , self ) . setUp ( ) <newline> self . store = bittorrent . BittorrentStore ( ) <newline> self . mox = mox . Mox ( ) <newline> self . flags ( torrent_base_url = 'http://foo' , connection_url = 'test_url' , connection_password = 'test_pass' , group = 'xenserver' ) <newline> self . context = context . RequestContext ( 'user' , 'project' , auth_token = 'foobar' ) <newline> fake . reset ( ) <newline> stubs . stubout_session ( self . stubs , fake . SessionBase ) <newline> driver = xenapi_conn . XenAPIDriver ( False ) <newline> self . session = driver . _session <newline> self . stubs . Set ( vm_utils , 'get_sr_path' , lambda * a , ** kw : '/fake/sr/path' ) <newline> <dedent> def test_download_image ( self ) : <newline> <indent> instance = { 'uuid' : '00000000-0000-0000-0000-000000007357' } <newline> params = { 'image_id' : 'fake_image_uuid' , 'sr_path' : '/fake/sr/path' , 'torrent_download_stall_cutoff' : 600 , 'torrent_listen_port_end' : 6891 , 'torrent_listen_port_start' : 6881 , 'torrent_max_last_accessed' : 86400 , 'torrent_max_seeder_processes_per_host' : 1 , 'torrent_seed_chance' : 1.0 , 'torrent_seed_duration' : 3600 , 'torrent_url' : 'http://foo/fake_image_uuid.torrent' , 'uuid_stack' : [ 'uuid1' ] } <newline> self . stubs . Set ( vm_utils , '_make_uuid_stack' , lambda * a , ** kw : [ 'uuid1' ] ) <newline> self . mox . StubOutWithMock ( self . session , 'call_plugin_serialized' ) <newline> self . session . call_plugin_serialized ( 'bittorrent' , 'download_vhd' , ** params ) <newline> self . mox . ReplayAll ( ) <newline> self . store . download_image ( self . context , self . session , instance , 'fake_image_uuid' ) <newline> self . mox . VerifyAll ( ) <newline> <dedent> def test_upload_image ( self ) : <newline> <indent> self . assertRaises ( NotImplementedError , self . store . upload_image , self . context , self . session , mox . IgnoreArg , 'fake_image_uuid' , [ 'fake_vdi_uuid' ] ) <newline> <dedent> <dedent> class LookupTorrentURLTestCase ( test . NoDBTestCase ) : <newline> <indent> def setUp ( self ) : <newline> <indent> super ( LookupTorrentURLTestCase , self ) . setUp ( ) <newline> self . store = bittorrent . BittorrentStore ( ) <newline> self . image_id = 'fakeimageid' <newline> <dedent> def test_default_fetch_url_no_base_url_set ( self ) : <newline> <indent> self . flags ( torrent_base_url = None , group = 'xenserver' ) <newline> exc = self . assertRaises ( RuntimeError , self . store . _lookup_torrent_url_fn ) <newline> self . assertEqual ( 'Cannot ▁ create ▁ default ▁ bittorrent ▁ URL ▁ without' ' ▁ xenserver.torrent_base_url ▁ configuration ▁ option' ' ▁ set.' , six . text_type ( exc ) ) <newline> <dedent> def test_default_fetch_url_base_url_is_set ( self ) : <newline> <indent> self . flags ( torrent_base_url = 'http://foo' , group = 'xenserver' ) <newline> lookup_fn = self . store . _lookup_torrent_url_fn ( ) <newline> self . assertEqual ( 'http://foo/fakeimageid.torrent' , lookup_fn ( self . image_id ) ) <newline> <dedent> def test_invalid_base_url_warning_logged ( self ) : <newline> <indent> self . flags ( torrent_base_url = 'www.foo.com' , group = 'xenserver' ) <newline>  # ▁ Make ▁ sure ▁ a ▁ warning ▁ is ▁ logged ▁ when ▁ an ▁ invalid ▁ base ▁ URL ▁ is ▁ set, <encdom>  # ▁ where ▁ invalid ▁ means ▁ it ▁ does ▁ not ▁ contain ▁ any ▁ slash ▁ characters <encdom> warnings = [ ] <newline> def fake_warn ( msg ) : <newline> <indent> warnings . append ( msg ) <newline> <dedent> self . stubs . Set ( bittorrent . LOG , 'warn' , fake_warn ) <newline> lookup_fn = self . store . _lookup_torrent_url_fn ( ) <newline> self . assertEqual ( 'fakeimageid.torrent' , lookup_fn ( self . image_id ) ) <newline> self . assertTrue ( any ( 'does ▁ not ▁ contain ▁ a ▁ slash ▁ character' in msg for msg in warnings ) , '_lookup_torrent_url_fn() ▁ did ▁ not ▁ log ▁ a ▁ warning ▁ ' 'message ▁ when ▁ the ▁ torrent_base_url ▁ did ▁ not ▁ contain ▁ a ▁ ' 'slash ▁ character.' ) <newline> <dedent> <dedent>
 # # # # # ▁ BEGIN ▁ LICENSE ▁ BLOCK ▁ # # # # # <encdom>  # ▁ The ▁ Original ▁ Code ▁ is ▁ mozilla.org ▁ code. <encdom>  # ▁ The ▁ Initial ▁ Developer ▁ of ▁ the ▁ Original ▁ Code ▁ is <encdom>  # ▁ Netscape ▁ Communications ▁ Corporation. <encdom>  # ▁ Portions ▁ created ▁ by ▁ the ▁ Initial ▁ Developer ▁ are ▁ Copyright ▁ (C) ▁ 1998 <encdom>  # ▁ the ▁ Initial ▁ Developer. ▁ All ▁ Rights ▁ Reserved. <encdom>  # ▁ Contributor(s): <encdom>  # ▁ Mark ▁ Pilgrim ▁ - ▁ port ▁ to ▁ Python <encdom>  # ▁ This ▁ library ▁ is ▁ free ▁ software; ▁ you ▁ can ▁ redistribute ▁ it ▁ and/or <encdom>  # ▁ modify ▁ it ▁ under ▁ the ▁ terms ▁ of ▁ the ▁ GNU ▁ Lesser ▁ General ▁ Public <encdom>  # ▁ License ▁ as ▁ published ▁ by ▁ the ▁ Free ▁ Software ▁ Foundation; ▁ either <encdom>  # ▁ version ▁ 2.1 ▁ of ▁ the ▁ License, ▁ or ▁ (at ▁ your ▁ option) ▁ any ▁ later ▁ version. <encdom>  # ▁ This ▁ library ▁ is ▁ distributed ▁ in ▁ the ▁ hope ▁ that ▁ it ▁ will ▁ be ▁ useful, <encdom>  # ▁ but ▁ WITHOUT ▁ ANY ▁ WARRANTY; ▁ without ▁ even ▁ the ▁ implied ▁ warranty ▁ of <encdom>  # ▁ MERCHANTABILITY ▁ or ▁ FITNESS ▁ FOR ▁ A ▁ PARTICULAR ▁ PURPOSE. ▁ See ▁ the ▁ GNU <encdom>  # ▁ Lesser ▁ General ▁ Public ▁ License ▁ for ▁ more ▁ details. <encdom>  # ▁ You ▁ should ▁ have ▁ received ▁ a ▁ copy ▁ of ▁ the ▁ GNU ▁ Lesser ▁ General ▁ Public <encdom>  # ▁ License ▁ along ▁ with ▁ this ▁ library; ▁ if ▁ not, ▁ write ▁ to ▁ the ▁ Free ▁ Software <encdom>  # ▁ Foundation, ▁ Inc., ▁ 51 ▁ Franklin ▁ St, ▁ Fifth ▁ Floor, ▁ Boston, ▁ MA <encdom>  # ▁ 02110-1301 ▁ USA <encdom>  # # # # # ▁ END ▁ LICENSE ▁ BLOCK ▁ # # # # # <encdom> from . mbcharsetprober import MultiByteCharSetProber <newline> from . codingstatemachine import CodingStateMachine <newline> from . chardistribution import GB2312DistributionAnalysis <newline> from . mbcssm import GB2312SMModel <newline> class GB2312Prober ( MultiByteCharSetProber ) : <newline> <indent> def __init__ ( self ) : <newline> <indent> MultiByteCharSetProber . __init__ ( self ) <newline> self . _mCodingSM = CodingStateMachine ( GB2312SMModel ) <newline> self . _mDistributionAnalyzer = GB2312DistributionAnalysis ( ) <newline> self . reset ( ) <newline> <dedent> def get_charset_name ( self ) : <newline> <indent> return "GB2312" <newline> <dedent> <dedent>