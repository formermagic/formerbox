"""
This type stub file was generated by pyright.
"""

import torch
import torch.nn.functional as F
from .utils import logging

logger = logging.get_logger(__name__)
def swish(x):
    ...

def gelu_new(x):
    """Implementation of the gelu activation function currently in Google Bert repo (identical to OpenAI GPT).
    Also see https://arxiv.org/abs/1606.08415
    """
    ...

if torch.__version__ < "1.4.0":
    gelu = _gelu_python
else:
    gelu = F.gelu
def gelu_fast(x):
    ...

def mish(x):
    ...

def linear_act(x):
    ...

ACT2FN = { "relu": F.relu,"swish": swish,"gelu": gelu,"tanh": torch.tanh,"gelu_new": gelu_new,"gelu_fast": gelu_fast,"mish": mish,"linear": linear_act,"sigmoid": torch.sigmoid }
def get_activation(activation_string):
    ...

