"""
This type stub file was generated by pyright.
"""

import torch
from typing import Dict, List, Optional
from torch.utils.data.dataset import Dataset
from ...tokenization_utils import PreTrainedTokenizer
from ...utils import logging

"""
This type stub file was generated by pyright.
"""
logger = logging.get_logger(__name__)
class TextDataset(Dataset):
    """
    This will be superseded by a framework-agnostic approach
    soon.
    """
    def __init__(self, tokenizer: PreTrainedTokenizer, file_path: str, block_size: int, overwrite_cache=..., cache_dir: Optional[str] = ...) -> None:
        ...
    
    def __len__(self):
        ...
    
    def __getitem__(self, i) -> torch.Tensor:
        ...
    


class LineByLineTextDataset(Dataset):
    """
    This will be superseded by a framework-agnostic approach
    soon.
    """
    def __init__(self, tokenizer: PreTrainedTokenizer, file_path: str, block_size: int) -> None:
        ...
    
    def __len__(self):
        ...
    
    def __getitem__(self, i) -> torch.Tensor:
        ...
    


class LineByLineWithSOPTextDataset(Dataset):
    """
    Dataset for sentence order prediction task, prepare sentence pairs for SOP task
    """
    def __init__(self, tokenizer: PreTrainedTokenizer, file_dir: str, block_size: int) -> None:
        ...
    
    def create_examples_from_document(self, document, block_size, tokenizer, short_seq_prob=...):
        """Creates examples for a single document."""
        ...
    
    def __len__(self):
        ...
    
    def __getitem__(self, i) -> Dict[str, torch.tensor]:
        ...
    


class TextDatasetForNextSentencePrediction(Dataset):
    """
    This will be superseded by a framework-agnostic approach
    soon.
    """
    def __init__(self, tokenizer: PreTrainedTokenizer, file_path: str, block_size: int, overwrite_cache=..., short_seq_probability=..., nsp_probability=...) -> None:
        ...
    
    def create_examples_from_document(self, document: List[List[int]], doc_index: int):
        """Creates examples for a single document."""
        ...
    
    def __len__(self):
        ...
    
    def __getitem__(self, i):
        ...
    


