"""
This type stub file was generated by pyright.
"""

from .tokenization_xlm import XLMTokenizer
from .utils import logging

logger = logging.get_logger(__name__)
VOCAB_FILES_NAMES = { "vocab_file": "vocab.json","merges_file": "merges.txt" }
PRETRAINED_VOCAB_FILES_MAP = { "vocab_file": { "allegro/herbert-base-cased": "https://cdn.huggingface.co/allegro/herbert-base-cased/vocab.json" },"merges_file": { "allegro/herbert-base-cased": "https://cdn.huggingface.co/allegro/herbert-base-cased/merges.txt" } }
PRETRAINED_POSITIONAL_EMBEDDINGS_SIZES = { "allegro/herbert-base-cased": 514 }
PRETRAINED_INIT_CONFIGURATION = {  }
class HerbertTokenizer(XLMTokenizer):
    """
    Construct a BPE tokenizer for HerBERT.

    Peculiarities:

    - uses BERT's pre-tokenizer: BaseTokenizer splits tokens on spaces, and also on punctuation.
      Each occurence of a punctuation character will be treated separately.

    - Such pretokenized input is BPE subtokenized

    This tokenizer inherits from :class:`~transformers.XLMTokenizer` which contains most of the methods. Users
    should refer to the superclass for more information regarding methods.
    """
    vocab_files_names = ...
    pretrained_vocab_files_map = ...
    pretrained_init_configuration = ...
    max_model_input_sizes = ...
    def __init__(self, **kwargs) -> None:
        ...
    


