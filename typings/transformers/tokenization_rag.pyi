"""
This type stub file was generated by pyright.
"""

from typing import List, Optional
from .file_utils import add_start_docstrings
from .tokenization_utils_base import BatchEncoding, PREPARE_SEQ2SEQ_BATCH_DOCSTRING
from .utils import logging

"""
This type stub file was generated by pyright.
"""
logger = logging.get_logger(__name__)
class RagTokenizer:
    def __init__(self, question_encoder, generator) -> None:
        ...
    
    def save_pretrained(self, save_directory):
        ...
    
    @classmethod
    def from_pretrained(cls, pretrained_model_name_or_path, **kwargs):
        ...
    
    def __call__(self, *args, **kwargs):
        ...
    
    def batch_decode(self, *args, **kwargs):
        ...
    
    @add_start_docstrings(PREPARE_SEQ2SEQ_BATCH_DOCSTRING)
    def prepare_seq2seq_batch(self, src_texts: List[str], tgt_texts: Optional[List[str]] = ..., max_length: Optional[int] = ..., max_target_length: Optional[int] = ..., padding: str = ..., return_tensors: str = ..., truncation=..., **kwargs) -> BatchEncoding:
        ...
    


